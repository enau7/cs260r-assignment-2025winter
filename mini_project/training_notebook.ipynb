{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f778b5a3593e43b7a182293b092f1b5a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2baad5feb680425bba7086366451eb85",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m  10%\u001b[0m \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99,980/1,000,000 \u001b[0m [ \u001b[33m0:03:30\u001b[0m < \u001b[36m0:36:06\u001b[0m , \u001b[31m416 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">  10%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">99,980/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:03:30</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:36:06</span> , <span style=\"color: #800000; text-decoration-color: #800000\">416 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "2baad5feb680425bba7086366451eb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEk847zUg9zC",
        "outputId": "7ddb2edc-666f-4aa1-b6e5-dfbf08f698b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/mini_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbRL7hByhEx-",
        "outputId": "ca28a94d-7eb1-4db1-a249-f7a2655841de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mini_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3[extra]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWy2DpcrMJal",
        "outputId": "97538927-fc29-4197-94d2-0cbf5f2aa5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable_baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable_baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable_baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable_baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable_baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable_baselines3[extra]) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/metadriverse/metadrive.git"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc2-5R5BMQ_9",
        "outputId": "3f71412d-3302-46dc-d295-7dc8795c7a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/metadriverse/metadrive.git\n",
            "  Cloning https://github.com/metadriverse/metadrive.git to /tmp/pip-req-build-bz5p0uw1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/metadriverse/metadrive.git /tmp/pip-req-build-bz5p0uw1\n",
            "  Resolved https://github.com/metadriverse/metadrive.git to commit a09bc963b067c9ce7e348586f43e7253cba55875\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (2.32.3)\n",
            "Requirement already satisfied: gymnasium>=0.28 in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (3.10.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (2.6.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (0.43.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (4.67.1)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (2.5)\n",
            "Requirement already satisfied: panda3d==1.10.14 in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (1.10.14)\n",
            "Requirement already satisfied: panda3d-gltf==0.13 in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (0.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (11.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (4.11.0.86)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (5.3.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (5.9.5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (2.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (3.17.0)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (2.18.0)\n",
            "Requirement already satisfied: mediapy in /usr/local/lib/python3.11/dist-packages (from metadrive-simulator==0.4.3) (1.2.2)\n",
            "Requirement already satisfied: panda3d-simplepbr>=0.6 in /usr/local/lib/python3.11/dist-packages (from panda3d-gltf==0.13->metadrive-simulator==0.4.3) (0.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (2.8.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from mediapy->metadrive-simulator==0.4.3) (7.34.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->metadrive-simulator==0.4.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->metadrive-simulator==0.4.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->metadrive-simulator==0.4.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->metadrive-simulator==0.4.3) (2025.1.31)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->metadrive-simulator==0.4.3) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->metadrive-simulator==0.4.3) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->mediapy->metadrive-simulator==0.4.3) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->mediapy->metadrive-simulator==0.4.3) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy->metadrive-simulator==0.4.3) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RL Environment"
      ],
      "metadata": {
        "id": "RydCRCp7Q7YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from metadrive.envs.safe_metadrive_env import SafeMetaDriveEnv\n",
        "\n",
        "DEFAULT_CONFIG = {\n",
        "    # The below are default configs copied from SafeMetaDriveEnv\n",
        "    # Environment difficulty\n",
        "    \"accident_prob\": 0.8,\n",
        "    \"traffic_density\": 0.05,\n",
        "    # Termination conditions\n",
        "    \"crash_vehicle_done\": False,\n",
        "    \"crash_object_done\": False,\n",
        "    # Reward\n",
        "    \"success_reward\": 10.0,\n",
        "    \"driving_reward\": 1.0,\n",
        "    \"speed_reward\": 0.1,\n",
        "    # Penalty will be negated and added to reward\n",
        "    \"out_of_road_penalty\": 5.0,\n",
        "    \"crash_vehicle_penalty\": 1.0,\n",
        "    \"crash_object_penalty\": 1.0,\n",
        "    # Cost will be return in info[\"cost\"] and you can do constrained optimization with it\n",
        "    \"crash_vehicle_cost\": 1.0,\n",
        "    \"crash_object_cost\": 1.0,\n",
        "    \"out_of_road_cost\": 1.0,\n",
        "}\n",
        "\n",
        "# Use deepcopy to avoid modifying the DEFAULT_CONFIG\n",
        "TRAINING_CONFIG = copy.deepcopy(DEFAULT_CONFIG)\n",
        "TRAINING_CONFIG.update(\n",
        "    {  # Environment setting\n",
        "        \"num_scenarios\": 50,  # There are totally 50 possible maps.\n",
        "        \"start_seed\": 100,  # We will use the map with seeds in [100, 150) as the default training environment.\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "def get_training_env(extra_config=None):\n",
        "    config = copy.deepcopy(TRAINING_CONFIG)\n",
        "    if extra_config:\n",
        "        config.update(extra_config)\n",
        "    return SafeMetaDriveEnv(config)\n",
        "\n",
        "\n",
        "VALIDATION_CONFIG = copy.deepcopy(DEFAULT_CONFIG)\n",
        "VALIDATION_CONFIG.update(\n",
        "    {  # Environment setting\n",
        "        \"num_scenarios\": 50,  # There are totally 50 possible maps.\n",
        "        \"start_seed\": 1000,  # We will use the map with seeds in [1000, 1050) as the default validation environment.\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "def get_validation_env(extra_config=None):\n",
        "    config = copy.deepcopy(VALIDATION_CONFIG)\n",
        "    if extra_config:\n",
        "        config.update(extra_config)\n",
        "    return SafeMetaDriveEnv(config)\n"
      ],
      "metadata": {
        "id": "fFBku609MWPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and utilities"
      ],
      "metadata": {
        "id": "uurzjp7fQ-2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import logging\n",
        "import os\n",
        "import uuid\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from metadrive.engine.logger import set_log_level\n",
        "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from stable_baselines3.ppo import PPO\n",
        "from stable_baselines3.ppo.policies import ActorCriticPolicy\n",
        "\n",
        "from stable_baselines3.td3 import TD3\n",
        "from stable_baselines3.td3.policies import TD3Policy\n",
        "\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Remove MetaDrive's logging information when episode ends.\n",
        "set_log_level(logging.ERROR)"
      ],
      "metadata": {
        "id": "gIfW6RQSMGmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_time_str():\n",
        "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "\n",
        "def remove_reset_seed_and_add_monitor(make_env, trial_dir):\n",
        "    \"\"\"\n",
        "    MetaDrive env's reset function takes a seed argument and use it to determine the map to load.\n",
        "    However, in stable-baselines3, it calls reset function with a seed argument serving as the random seed,\n",
        "    which is not what we want. We do a trick here to remap the random seed to map index.\n",
        "\n",
        "    Stable-baselines3 recommends using Monitor wrapper to log training data. We add a Monitor wrapper here.\n",
        "    \"\"\"\n",
        "    from gymnasium import Wrapper\n",
        "    from stable_baselines3.common.monitor import Monitor\n",
        "    class NewClass(Wrapper):\n",
        "        def reset(self, seed=None, **kwargs):\n",
        "            # PZH: We do a trick here to remap the seed to the map index. This can help randomize the maps.\n",
        "            if seed is not None:\n",
        "                new_seed = self.env.start_index + (seed % self.env.num_scenarios)\n",
        "            else:\n",
        "                new_seed = None\n",
        "            return self.env.reset(seed=new_seed, **kwargs)\n",
        "\n",
        "    def new_make_env():\n",
        "        env = make_env()\n",
        "        NewClass.__name__ = env.__class__.__name__ + \"WithoutResetSeed\"\n",
        "        wrapped_env = NewClass(env)\n",
        "        wrapped_env = Monitor(env=wrapped_env, filename=str(trial_dir))\n",
        "        return wrapped_env\n",
        "\n",
        "    return new_make_env\n",
        "\n",
        "\n",
        "class CustomizedEvalCallback(EvalCallback):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.evaluations_info_buffer = defaultdict(list)\n",
        "\n",
        "    def _log_success_callback(self, locals_, globals_):\n",
        "        info = locals_[\"info\"]\n",
        "\n",
        "        if locals_[\"done\"]:\n",
        "            maybe_is_success = info.get(\"is_success\")\n",
        "            if maybe_is_success is not None:\n",
        "                self._is_success_buffer.append(maybe_is_success)\n",
        "\n",
        "            maybe_is_success2 = info.get(\"arrive_dest\", None)\n",
        "            if maybe_is_success2 is not None:\n",
        "                self._is_success_buffer.append(maybe_is_success2)\n",
        "\n",
        "            assert (maybe_is_success is None) or (maybe_is_success2 is None), \"We cannot have two success flags!\"\n",
        "\n",
        "            for k in [\"route_completion\", \"total_cost\", \"arrive_dest\", \"max_step\", \"out_of_road\", \"crash\"]:\n",
        "                if k in info:\n",
        "                    self.evaluations_info_buffer[k].append(info[k])\n",
        "\n",
        "        if \"raw_action\" in info:\n",
        "            self.evaluations_info_buffer[\"raw_action\"].append(info[\"raw_action\"])\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        \"\"\"\n",
        "        PZH Note: Overall this function is copied from original EvalCallback._on_step.\n",
        "        We additionally record evaluations_info_buffer to the logger.\n",
        "        \"\"\"\n",
        "\n",
        "        from stable_baselines3.common.evaluation import evaluate_policy\n",
        "        from stable_baselines3.common.vec_env import sync_envs_normalization\n",
        "\n",
        "        continue_training = True\n",
        "\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Sync training and eval env if there is VecNormalize\n",
        "            if self.model.get_vec_normalize_env() is not None:\n",
        "                try:\n",
        "                    sync_envs_normalization(self.training_env, self.eval_env)\n",
        "                except AttributeError as e:\n",
        "                    raise AssertionError(\n",
        "                        \"Training and eval env are not wrapped the same way, \"\n",
        "                        \"see https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html#evalcallback \"\n",
        "                        \"and warning above.\"\n",
        "                    ) from e\n",
        "\n",
        "            # Reset success rate buffer\n",
        "            self._is_success_buffer = []\n",
        "\n",
        "            episode_rewards, episode_lengths = evaluate_policy(\n",
        "                self.model,\n",
        "                self.eval_env,\n",
        "                n_eval_episodes=self.n_eval_episodes,\n",
        "                render=self.render,\n",
        "                deterministic=self.deterministic,\n",
        "                return_episode_rewards=True,\n",
        "                warn=self.warn,\n",
        "                callback=self._log_success_callback,\n",
        "            )\n",
        "\n",
        "            if self.log_path is not None:\n",
        "                assert isinstance(episode_rewards, list)\n",
        "                assert isinstance(episode_lengths, list)\n",
        "                self.evaluations_timesteps.append(self.num_timesteps)\n",
        "                self.evaluations_results.append(episode_rewards)\n",
        "                self.evaluations_length.append(episode_lengths)\n",
        "\n",
        "                kwargs = {}\n",
        "                # Save success log if present\n",
        "                if len(self._is_success_buffer) > 0:\n",
        "                    self.evaluations_successes.append(self._is_success_buffer)\n",
        "                    kwargs = dict(successes=self.evaluations_successes)\n",
        "\n",
        "                # PZH: Save evaluations_info_buffer to the log file\n",
        "                for k, v in self.evaluations_info_buffer.items():\n",
        "                    kwargs[k] = v\n",
        "\n",
        "                np.savez(\n",
        "                    self.log_path,\n",
        "                    timesteps=self.evaluations_timesteps,\n",
        "                    results=self.evaluations_results,\n",
        "                    ep_lengths=self.evaluations_length,\n",
        "                    **kwargs,  # type: ignore[arg-type]\n",
        "                )\n",
        "\n",
        "            mean_reward, std_reward = np.mean(episode_rewards), np.std(episode_rewards)\n",
        "            mean_ep_length, std_ep_length = np.mean(episode_lengths), np.std(episode_lengths)\n",
        "            self.last_mean_reward = float(mean_reward)\n",
        "\n",
        "            if self.verbose >= 1:\n",
        "                print(\n",
        "                    f\"Eval num_timesteps={self.num_timesteps}, \" f\"episode_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "                print(f\"Episode length: {mean_ep_length:.2f} +/- {std_ep_length:.2f}\")\n",
        "            # Add to current Logger\n",
        "            self.logger.record(\"eval/mean_reward\", float(mean_reward))\n",
        "            self.logger.record(\"eval/mean_ep_length\", mean_ep_length)\n",
        "\n",
        "            # PZH: Add this metric.\n",
        "            self.logger.record(\"eval/num_episodes\", len(episode_rewards))\n",
        "\n",
        "            if len(self._is_success_buffer) > 0:\n",
        "                success_rate = np.mean(self._is_success_buffer)\n",
        "                if self.verbose >= 1:\n",
        "                    print(f\"Success rate: {100 * success_rate:.2f}%\")\n",
        "                self.logger.record(\"eval/success_rate\", success_rate)\n",
        "\n",
        "            # PZH: We record evaluations_info_buffer to the logger\n",
        "            for k, v in self.evaluations_info_buffer.items():\n",
        "                self.logger.record(\"eval/{}\".format(k), np.mean(np.asarray(v)))\n",
        "\n",
        "            # Dump log so the evaluation results are printed with the correct timestep\n",
        "            self.logger.record(\"time/total_timesteps\", self.num_timesteps, exclude=\"tensorboard\")\n",
        "            self.logger.dump(self.num_timesteps)\n",
        "\n",
        "            if mean_reward > self.best_mean_reward:\n",
        "                if self.verbose >= 1:\n",
        "                    print(\"New best mean reward!\")\n",
        "                if self.best_model_save_path is not None:\n",
        "                    self.model.save(os.path.join(self.best_model_save_path, \"best_model\"))\n",
        "                self.best_mean_reward = float(mean_reward)\n",
        "                # Trigger callback on new best model, if needed\n",
        "                if self.callback_on_new_best is not None:\n",
        "                    continue_training = self.callback_on_new_best.on_step()\n",
        "\n",
        "            # Trigger callback after every evaluation, if needed\n",
        "            if self.callback is not None:\n",
        "                continue_training = continue_training and self._on_event()\n",
        "\n",
        "        return continue_training\n"
      ],
      "metadata": {
        "id": "g5dhUBr7MHFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup PPO trainer\n"
      ],
      "metadata": {
        "id": "YeOXgzj7RDTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===== Set up some arguments =====\n",
        "exp_name = \"ppo_metadrive\"\n",
        "use_wandb = True\n",
        "\n",
        "experiment_batch_name = \"{}\".format(exp_name)\n",
        "trial_name = \"{}_{}_{}\".format(experiment_batch_name, get_time_str(), uuid.uuid4().hex[:8])\n",
        "experiment_dir = Path(\"runs\") / experiment_batch_name\n",
        "trial_dir = experiment_dir / trial_name\n",
        "os.makedirs(experiment_dir, exist_ok=True)\n",
        "os.makedirs(trial_dir, exist_ok=True)\n",
        "print(f\"We start logging training data into {trial_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4I25BRYMltK",
        "outputId": "2bc95044-3a02-4ebc-c096-f395468de6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We start logging training data into runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Setup environment =====\n",
        "num_train_envs = 10\n",
        "num_eval_envs = 5\n",
        "train_env = make_vec_env(remove_reset_seed_and_add_monitor(get_training_env, trial_dir), n_envs=num_train_envs,\n",
        "                            vec_env_cls=SubprocVecEnv)\n",
        "eval_env = make_vec_env(remove_reset_seed_and_add_monitor(get_validation_env, trial_dir), n_envs=num_eval_envs,\n",
        "                        vec_env_cls=SubprocVecEnv)"
      ],
      "metadata": {
        "id": "Yle5pkCvOQAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Setup evaluation, checkpointing, and wandb =====\n",
        "save_freq = 10_000  # Number of steps per model checkpoint\n",
        "eval_freq = 10_000  # Number of steps per evaluation\n",
        "\n",
        "wandb_save_freq = 10_000  # Number of steps per evaluation\n",
        "\n",
        "num_eval_episodes = 5\n",
        "\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    name_prefix=\"rl_model\",\n",
        "    verbose=2,\n",
        "    save_freq=save_freq,\n",
        "    save_path=str(trial_dir / \"models\")\n",
        ")\n",
        "eval_callback = CustomizedEvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=str(trial_dir / \"eval\"),\n",
        "    log_path=str(trial_dir / \"eval\"),\n",
        "    eval_freq=max(eval_freq // num_train_envs, 1),\n",
        "    n_eval_episodes=num_eval_episodes,\n",
        ")\n",
        "callbacks = [checkpoint_callback, eval_callback]\n",
        "if use_wandb:\n",
        "    wandb.init(\n",
        "        project=\"cs260r\",\n",
        "        id=trial_name,\n",
        "        name=experiment_batch_name,\n",
        "        sync_tensorboard=True,\n",
        "        dir=str(trial_dir),\n",
        "    )\n",
        "    callbacks.append(WandbCallback(model_save_path=str(trial_dir / \"wandb_models\"), model_save_freq=wandb_save_freq))\n",
        "callbacks = CallbackList(callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "IP_wvQMBMzoR",
        "outputId": "be907254-74fc-483c-f1c4-4cba051355c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcoltonrowe\u001b[0m (\u001b[33mcoltonrowe-ucla\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/wandb/run-20250317_002006-ppo_metadrive_2025-03-17_00-19-44_726dad05</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/coltonrowe-ucla/cs260r/runs/ppo_metadrive_2025-03-17_00-19-44_726dad05' target=\"_blank\">ppo_metadrive</a></strong> to <a href='https://wandb.ai/coltonrowe-ucla/cs260r' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/coltonrowe-ucla/cs260r' target=\"_blank\">https://wandb.ai/coltonrowe-ucla/cs260r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/coltonrowe-ucla/cs260r/runs/ppo_metadrive_2025-03-17_00-19-44_726dad05' target=\"_blank\">https://wandb.ai/coltonrowe-ucla/cs260r/runs/ppo_metadrive_2025-03-17_00-19-44_726dad05</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===== Setup the training algorithm =====\n",
        "# model = TD3(\n",
        "#     env=train_env,\n",
        "#     policy=TD3Policy,\n",
        "#     learning_rate=5e-5,\n",
        "#     buffer_size=1_000_000,\n",
        "#     learning_starts=100,\n",
        "#     batch_size=256,\n",
        "#     tau=0.005,\n",
        "#     gamma = 0.99,\n",
        "#     train_freq=1,\n",
        "#     gradient_steps=1,\n",
        "#     action_noise=None,\n",
        "#     replay_buffer_class=None,\n",
        "#     replay_buffer_kwargs=None,\n",
        "#     optimize_memory_usage=False,\n",
        "#     policy_delay=2,\n",
        "#     target_policy_noise=0.2,\n",
        "#     target_noise_clip=0.5,\n",
        "#     stats_window_size=100,\n",
        "#     tensorboard_log=None,\n",
        "#     policy_kwargs=None,\n",
        "#     verbose=2,\n",
        "#     seed=None,\n",
        "#     device='auto',\n",
        "#     _init_setup_model=True\n",
        "#     )\n",
        "model = PPO(\n",
        "    env=train_env,\n",
        "    policy=ActorCriticPolicy,\n",
        "    n_steps=500,  # n_steps * n_envs = total_batch_size\n",
        "    n_epochs=20,\n",
        "    learning_rate=5e-5,\n",
        "    batch_size=256,\n",
        "    clip_range=0.1,\n",
        "    vf_coef=0.5,\n",
        "    ent_coef=0.0,\n",
        "    max_grad_norm=10.0,\n",
        "    tensorboard_log=str(trial_dir),\n",
        "    verbose=2,\n",
        "    device=\"auto\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7umQKXAMuJf",
        "outputId": "ff850c72-31d4-4748-913a-bb190c4ebfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5000`, after every 19 untruncated mini-batches, there will be a truncated mini-batch of size 136\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=500 and n_envs=10)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = None\n",
        "if ckpt:\n",
        "    ckpt = Path(ckpt)\n",
        "    print(f\"Loading checkpoint from {ckpt}!\")\n",
        "    from stable_baselines3.common.save_util import load_from_zip_file\n",
        "    data, params, pytorch_variables = load_from_zip_file(ckpt, device=model.device, print_system_info=False)\n",
        "    model.set_parameters(params, exact_match=True, device=model.device)\n"
      ],
      "metadata": {
        "id": "YfnwlEiTNKeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Launch training =====\n",
        "total_timesteps = 1_000_000  # 1M steps\n",
        "model.learn(\n",
        "    total_timesteps=total_timesteps,\n",
        "    callback=callbacks,\n",
        "    reset_num_timesteps=True,\n",
        "    tb_log_name=experiment_batch_name,\n",
        "    log_interval=1,\n",
        "    progress_bar=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f778b5a3593e43b7a182293b092f1b5a",
            "2baad5feb680425bba7086366451eb85"
          ]
        },
        "id": "W1baXGNANOQ-",
        "outputId": "3d5d46ec-68bc-4e00-ee3b-753d548160f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/ppo_metadrive_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f778b5a3593e43b7a182293b092f1b5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget_output.py:111: DeprecationWarning: \n",
              "Kernel._parent_header is deprecated in ipykernel 6. Use .get_parent()\n",
              "  if ip and hasattr(ip, 'kernel') and hasattr(ip.kernel, '_parent_header'):\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget_output.py:111: DeprecationWarning: \n",
              "Kernel._parent_header is deprecated in ipykernel 6. Use .get_parent()\n",
              "  if ip and hasattr(ip, 'kernel') and hasattr(ip.kernel, '_parent_header'):\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 369      |\n",
            "|    ep_rew_mean     | -0.553   |\n",
            "| time/              |          |\n",
            "|    fps             | 838      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 5000     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=10000, episode_reward=41.65 +/- 24.79\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=10000, episode_reward=41.65 +/- 24.79\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 192.20 +/- 54.81\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 192.20 +/- 54.81\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    arrive_dest          | 0           |\n",
            "|    crash                | 0           |\n",
            "|    max_step             | 0           |\n",
            "|    mean_ep_length       | 192         |\n",
            "|    mean_reward          | 41.6        |\n",
            "|    num_episodes         | 5           |\n",
            "|    out_of_road          | 1           |\n",
            "|    raw_action           | 0.03362635  |\n",
            "|    route_completion     | 0.127       |\n",
            "|    success_rate         | 0           |\n",
            "|    total_cost           | 1           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002651404 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | -0.00145    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.0101      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00517    |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 0.0947      |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 369      |\n",
            "|    ep_rew_mean     | -0.553   |\n",
            "| time/              |          |\n",
            "|    fps             | 639      |\n",
            "|    iterations      | 2        |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 369          |\n",
            "|    ep_rew_mean          | -0.553       |\n",
            "| time/                   |              |\n",
            "|    fps                  | 675          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 15000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042068968 |\n",
            "|    clip_fraction        | 0.249        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.0403       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | -0.014       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 0.0173       |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=20000, episode_reward=42.37 +/- 33.83\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=20000, episode_reward=42.37 +/- 33.83\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 106.00 +/- 40.88\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 106.00 +/- 40.88\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    arrive_dest          | 0           |\n",
            "|    crash                | 0           |\n",
            "|    max_step             | 0           |\n",
            "|    mean_ep_length       | 106         |\n",
            "|    mean_reward          | 42.4        |\n",
            "|    num_episodes         | 5           |\n",
            "|    out_of_road          | 1           |\n",
            "|    raw_action           | 0.06419066  |\n",
            "|    route_completion     | 0.123       |\n",
            "|    success_rate         | 0           |\n",
            "|    total_cost           | 1           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003851429 |\n",
            "|    clip_fraction        | 0.269       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.81       |\n",
            "|    explained_variance   | 0.0683      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.0104      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    std                  | 0.985       |\n",
            "|    value_loss           | 0.0317      |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.2e+03  |\n",
            "|    ep_rew_mean     | 12.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 632      |\n",
            "|    iterations      | 4        |\n",
            "|    time_elapsed    | 31       |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.32e+03     |\n",
            "|    ep_rew_mean          | 16.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 655          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 25000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031472477 |\n",
            "|    clip_fraction        | 0.184        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.0133       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.114        |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00464     |\n",
            "|    std                  | 0.976        |\n",
            "|    value_loss           | 0.192        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=30000, episode_reward=17.89 +/- 7.99\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=30000, episode_reward=17.89 +/- 7.99\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 60.60 +/- 12.21\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 60.60 +/- 12.21\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    arrive_dest          | 0           |\n",
            "|    crash                | 0           |\n",
            "|    max_step             | 0           |\n",
            "|    mean_ep_length       | 60.6        |\n",
            "|    mean_reward          | 17.9        |\n",
            "|    num_episodes         | 5           |\n",
            "|    out_of_road          | 1           |\n",
            "|    raw_action           | 0.08423468  |\n",
            "|    route_completion     | 0.114       |\n",
            "|    success_rate         | 0           |\n",
            "|    total_cost           | 1           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003858048 |\n",
            "|    clip_fraction        | 0.258       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.78       |\n",
            "|    explained_variance   | 0.000143    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.0418      |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0105     |\n",
            "|    std                  | 0.969       |\n",
            "|    value_loss           | 0.0996      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.6e+03  |\n",
            "|    ep_rew_mean     | 24.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 633      |\n",
            "|    iterations      | 6        |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.27e+03     |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 623          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 35000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025094175 |\n",
            "|    clip_fraction        | 0.148        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.00181      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.484        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00411     |\n",
            "|    std                  | 0.966        |\n",
            "|    value_loss           | 0.428        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=40000, episode_reward=28.41 +/- 18.51\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=40000, episode_reward=28.41 +/- 18.51\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 62.20 +/- 18.24\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 62.20 +/- 18.24\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0            |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 62.2         |\n",
            "|    mean_reward          | 28.4         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.11059802   |\n",
            "|    route_completion     | 0.116        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 1            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 40000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025350326 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.76        |\n",
            "|    explained_variance   | 0.0359       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.345        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00455     |\n",
            "|    std                  | 0.957        |\n",
            "|    value_loss           | 0.614        |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 20.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 585      |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 68       |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 927          |\n",
            "|    ep_rew_mean          | 18.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 579          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 77           |\n",
            "|    total_timesteps      | 45000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017534383 |\n",
            "|    clip_fraction        | 0.0792       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.74        |\n",
            "|    explained_variance   | 0.0616       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.556        |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    std                  | 0.951        |\n",
            "|    value_loss           | 0.917        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=50000, episode_reward=97.82 +/- 30.56\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=50000, episode_reward=97.82 +/- 30.56\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 142.20 +/- 60.56\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 142.20 +/- 60.56\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0            |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 142          |\n",
            "|    mean_reward          | 97.8         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.16267653   |\n",
            "|    route_completion     | 0.175        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 4.8          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 50000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016656378 |\n",
            "|    clip_fraction        | 0.0638       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.73        |\n",
            "|    explained_variance   | 0.0904       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.596        |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    std                  | 0.945        |\n",
            "|    value_loss           | 0.931        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 850      |\n",
            "|    ep_rew_mean     | 17.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 554      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 50000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 752          |\n",
            "|    ep_rew_mean          | 17.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 544          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 101          |\n",
            "|    total_timesteps      | 55000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023093007 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.72        |\n",
            "|    explained_variance   | 0.0762       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.114        |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00461     |\n",
            "|    std                  | 0.94         |\n",
            "|    value_loss           | 0.731        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=60000, episode_reward=43.45 +/- 16.70\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=60000, episode_reward=43.45 +/- 16.70\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 67.00 +/- 15.84\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 67.00 +/- 15.84\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.0333       |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 67           |\n",
            "|    mean_reward          | 43.5         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.18630944   |\n",
            "|    route_completion     | 0.17         |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 4.17         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 60000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012999474 |\n",
            "|    clip_fraction        | 0.0513       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.71        |\n",
            "|    explained_variance   | -0.00672     |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.89         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00134     |\n",
            "|    std                  | 0.942        |\n",
            "|    value_loss           | 1.53         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 718      |\n",
            "|    ep_rew_mean     | 18.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 533      |\n",
            "|    iterations      | 12       |\n",
            "|    time_elapsed    | 112      |\n",
            "|    total_timesteps | 60000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 639          |\n",
            "|    ep_rew_mean          | 17.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 528          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 122          |\n",
            "|    total_timesteps      | 65000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027186412 |\n",
            "|    clip_fraction        | 0.125        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.71        |\n",
            "|    explained_variance   | 0.0321       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    std                  | 0.938        |\n",
            "|    value_loss           | 1.04         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=70000, episode_reward=37.90 +/- 16.65\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=70000, episode_reward=37.90 +/- 16.65\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 60.60 +/- 16.66\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 60.60 +/- 16.66\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.0286       |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 60.6         |\n",
            "|    mean_reward          | 37.9         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.20788956   |\n",
            "|    route_completion     | 0.165        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 3.71         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 70000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016013015 |\n",
            "|    clip_fraction        | 0.0599       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.7         |\n",
            "|    explained_variance   | -0.0303      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.967        |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00175     |\n",
            "|    std                  | 0.934        |\n",
            "|    value_loss           | 2.24         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 440      |\n",
            "|    ep_rew_mean     | 16.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 513      |\n",
            "|    iterations      | 14       |\n",
            "|    time_elapsed    | 136      |\n",
            "|    total_timesteps | 70000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 333          |\n",
            "|    ep_rew_mean          | 15.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 511          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 75000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011732291 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.7         |\n",
            "|    explained_variance   | 0.0367       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.03         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.000709    |\n",
            "|    std                  | 0.93         |\n",
            "|    value_loss           | 2.24         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=80000, episode_reward=26.24 +/- 7.64\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=26.24 +/- 7.64\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 48.80 +/- 7.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 48.80 +/- 7.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.05         |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 48.8         |\n",
            "|    mean_reward          | 26.2         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.2233046    |\n",
            "|    route_completion     | 0.157        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 3.38         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 80000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014195004 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.68        |\n",
            "|    explained_variance   | 0.0509       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 2.26         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    std                  | 0.924        |\n",
            "|    value_loss           | 5.77         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 329      |\n",
            "|    ep_rew_mean     | 16.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 508      |\n",
            "|    iterations      | 16       |\n",
            "|    time_elapsed    | 157      |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 287          |\n",
            "|    ep_rew_mean          | 17           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 506          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 167          |\n",
            "|    total_timesteps      | 85000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021086442 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.67        |\n",
            "|    explained_variance   | 0.0805       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.753        |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.0038      |\n",
            "|    std                  | 0.917        |\n",
            "|    value_loss           | 1.92         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=90000, episode_reward=111.49 +/- 49.46\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=90000, episode_reward=111.49 +/- 49.46\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 94.80 +/- 25.74\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 94.80 +/- 25.74\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.0889       |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 94.8         |\n",
            "|    mean_reward          | 111          |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.25366578   |\n",
            "|    route_completion     | 0.177        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 3.18         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 90000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015916002 |\n",
            "|    clip_fraction        | 0.0762       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.66        |\n",
            "|    explained_variance   | 0.0685       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 2.11         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00256     |\n",
            "|    std                  | 0.914        |\n",
            "|    value_loss           | 4.08         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 241      |\n",
            "|    ep_rew_mean     | 16.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 492      |\n",
            "|    iterations      | 18       |\n",
            "|    time_elapsed    | 182      |\n",
            "|    total_timesteps | 90000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 17.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 488          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 194          |\n",
            "|    total_timesteps      | 95000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016711758 |\n",
            "|    clip_fraction        | 0.0434       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.65        |\n",
            "|    explained_variance   | 0.0496       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 3.16         |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00231     |\n",
            "|    std                  | 0.907        |\n",
            "|    value_loss           | 4.41         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving model checkpoint to \n",
              "runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/models/rl_model_100000_steps.zip\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saving model checkpoint to \n",
              "runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/models/rl_model_100000_steps.zip\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=100000, episode_reward=81.51 +/- 31.01\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=100000, episode_reward=81.51 +/- 31.01\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 81.40 +/- 20.36\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 81.40 +/- 20.36\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.1          |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 81.4         |\n",
            "|    mean_reward          | 81.5         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.27489084   |\n",
            "|    route_completion     | 0.183        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 3.16         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 100000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010825213 |\n",
            "|    clip_fraction        | 0.0324       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.63        |\n",
            "|    explained_variance   | -0.0155      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 2.15         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    std                  | 0.901        |\n",
            "|    value_loss           | 4.78         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 95] Operation not supported: '/content/drive/MyDrive/mini_project/runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/wandb_models/model.zip' -> 'runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/wandb/run-20250317_002006-ppo_metadrive_2025-03-17_00-19-44_726dad05/files/model.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9074ed7aaab2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ===== Launch training =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1_000_000\u001b[0m  \u001b[0;31m# 1M steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.learn(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Give access to local variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Return False (stop training) if at least one callback returns False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Return False (stop training) if at least one callback returns False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/integration/sb3/sb3.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_calls\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/integration/sb3/sb3.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving model checkpoint to {self.path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_finished\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 default_message = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_attaching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, glob_str, base_path, policy)\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mresolved_base_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         return self._save(\n\u001b[0m\u001b[1;32m   1976\u001b[0m             \u001b[0mresolved_glob_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m             \u001b[0mresolved_base_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, glob_path, base_path, policy)\u001b[0m\n\u001b[1;32m   2032\u001b[0m             \u001b[0mtarget_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m             \u001b[0mtarget_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;31m# Inform users that new files aren't detected automatically.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36msymlink_to\u001b[0;34m(self, target, target_is_directory)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"symlink\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"os.symlink() not available on this system\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_is_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhardlink_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: '/content/drive/MyDrive/mini_project/runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/wandb_models/model.zip' -> 'runs/ppo_metadrive/ppo_metadrive_2025-03-17_00-19-44_726dad05/wandb/run-20250317_002006-ppo_metadrive_2025-03-17_00-19-44_726dad05/files/model.zip'"
          ]
        }
      ]
    }
  ]
}