Using cpu device
c:\Users\Colton\anaconda3\envs\cs260r\Lib\site-packages\stable_baselines3\ppo\ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5000`, after every 19 untruncated mini-batches, there will be a truncated mini-batch of size 136
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=500 and n_envs=10)
  warnings.warn(
Logging to runs\ppo_metadrive\ppo_metadrive_2025-03-16_17-43-31_a51009e7\ppo_metadrive_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 92       |
|    ep_rew_mean     | -2.64    |
| time/              |          |
|    fps             | 1439     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 5000     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 206          |
|    mean_reward          | 47.9         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.033996757  |
|    route_completion     | 0.17         |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0026634517 |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0353      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00569      |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00759     |
|    std                  | 1            |
|    value_loss           | 0.0603       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | -1.29    |
| time/              |          |
|    fps             | 932      |
|    iterations      | 2        |
|    time_elapsed    | 10       |
|    total_timesteps | 10000    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 984         |
|    ep_rew_mean          | 8.19        |
| time/                   |             |
|    fps                  | 982         |
|    iterations           | 3           |
|    time_elapsed         | 15          |
|    total_timesteps      | 15000       |
| train/                  |             |
|    approx_kl            | 0.003381066 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.0133      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0173      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00965    |
|    std                  | 0.994       |
|    value_loss           | 0.0699      |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 34.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.058816493  |
|    route_completion     | 0.158        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0021977765 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.82        |
|    explained_variance   | -0.0191      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0236       |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00328     |
|    std                  | 0.99         |
|    value_loss           | 0.22         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 9.32     |
| time/              |          |
|    fps             | 901      |
|    iterations      | 4        |
|    time_elapsed    | 22       |
|    total_timesteps | 20000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.59e+03     |
|    ep_rew_mean          | 18.3         |
| time/                   |              |
|    fps                  | 922          |
|    iterations           | 5            |
|    time_elapsed         | 27           |
|    total_timesteps      | 25000        |
| train/                  |              |
|    approx_kl            | 0.0041936925 |
|    clip_fraction        | 0.262        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.81        |
|    explained_variance   | -0.0169      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0227       |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0108      |
|    std                  | 0.985        |
|    value_loss           | 0.0892       |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 71.4         |
|    mean_reward          | 25.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.081829436  |
|    route_completion     | 0.134        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0023435077 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.0371       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.129        |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00432     |
|    std                  | 0.981        |
|    value_loss           | 0.321        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.55e+03 |
|    ep_rew_mean     | 20.2     |
| time/              |          |
|    fps             | 889      |
|    iterations      | 6        |
|    time_elapsed    | 33       |
|    total_timesteps | 30000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.22e+03     |
|    ep_rew_mean          | 19           |
| time/                   |              |
|    fps                  | 878          |
|    iterations           | 7            |
|    time_elapsed         | 39           |
|    total_timesteps      | 35000        |
| train/                  |              |
|    approx_kl            | 0.0033879578 |
|    clip_fraction        | 0.173        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0319       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.209        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00593     |
|    std                  | 0.972        |
|    value_loss           | 0.253        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.05         |
|    max_step             | 0            |
|    mean_ep_length       | 132          |
|    mean_reward          | 86.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.12483836   |
|    route_completion     | 0.174        |
|    success_rate         | 0            |
|    total_cost           | 3.1          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0020069717 |
|    clip_fraction        | 0.0723       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.0279       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.31         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00201     |
|    std                  | 0.968        |
|    value_loss           | 0.731        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 19.8     |
| time/              |          |
|    fps             | 818      |
|    iterations      | 8        |
|    time_elapsed    | 48       |
|    total_timesteps | 40000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 977          |
|    ep_rew_mean          | 18.5         |
| time/                   |              |
|    fps                  | 805          |
|    iterations           | 9            |
|    time_elapsed         | 55           |
|    total_timesteps      | 45000        |
| train/                  |              |
|    approx_kl            | 0.0030468146 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.76        |
|    explained_variance   | -0.0223      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.349        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00526     |
|    std                  | 0.959        |
|    value_loss           | 0.551        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.04         |
|    max_step             | 0            |
|    mean_ep_length       | 74.4         |
|    mean_reward          | 48           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.14997362   |
|    route_completion     | 0.166        |
|    success_rate         | 0            |
|    total_cost           | 2.68         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0020844506 |
|    clip_fraction        | 0.0957       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.023        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.549        |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00259     |
|    std                  | 0.955        |
|    value_loss           | 0.985        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 18.3     |
| time/              |          |
|    fps             | 781      |
|    iterations      | 10       |
|    time_elapsed    | 64       |
|    total_timesteps | 50000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 811          |
|    ep_rew_mean          | 17.8         |
| time/                   |              |
|    fps                  | 787          |
|    iterations           | 11           |
|    time_elapsed         | 69           |
|    total_timesteps      | 55000        |
| train/                  |              |
|    approx_kl            | 0.0018461039 |
|    clip_fraction        | 0.078        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.582        |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.951        |
|    value_loss           | 1.11         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 74.6         |
|    mean_reward          | 58.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1761587    |
|    route_completion     | 0.172        |
|    success_rate         | 0            |
|    total_cost           | 2.5          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0021749625 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.00674      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.3          |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00379     |
|    std                  | 0.943        |
|    value_loss           | 0.756        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 754      |
|    ep_rew_mean     | 18.7     |
| time/              |          |
|    fps             | 771      |
|    iterations      | 12       |
|    time_elapsed    | 77       |
|    total_timesteps | 60000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 697          |
|    ep_rew_mean          | 19           |
| time/                   |              |
|    fps                  | 764          |
|    iterations           | 13           |
|    time_elapsed         | 84           |
|    total_timesteps      | 65000        |
| train/                  |              |
|    approx_kl            | 0.0020491523 |
|    clip_fraction        | 0.0946       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.029        |
|    learning_rate        | 5e-05        |
|    loss                 | 1.26         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00312     |
|    std                  | 0.934        |
|    value_loss           | 1.38         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.114        |
|    max_step             | 0            |
|    mean_ep_length       | 65           |
|    mean_reward          | 50.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.19784625   |
|    route_completion     | 0.17         |
|    success_rate         | 0            |
|    total_cost           | 2.29         |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0022834758 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.0183       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.846        |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00322     |
|    std                  | 0.934        |
|    value_loss           | 1.58         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 603      |
|    ep_rew_mean     | 18.7     |
| time/              |          |
|    fps             | 736      |
|    iterations      | 14       |
|    time_elapsed    | 94       |
|    total_timesteps | 70000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 422          |
|    ep_rew_mean          | 18.8         |
| time/                   |              |
|    fps                  | 721          |
|    iterations           | 15           |
|    time_elapsed         | 103          |
|    total_timesteps      | 75000        |
| train/                  |              |
|    approx_kl            | 0.0022469738 |
|    clip_fraction        | 0.0969       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.0315       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.4          |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00271     |
|    std                  | 0.929        |
|    value_loss           | 2.28         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.15         |
|    max_step             | 0            |
|    mean_ep_length       | 46           |
|    mean_reward          | 24.4         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.21283023   |
|    route_completion     | 0.162        |
|    success_rate         | 0            |
|    total_cost           | 2.12         |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0013771876 |
|    clip_fraction        | 0.0725       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.68        |
|    explained_variance   | 0.00227      |
|    learning_rate        | 5e-05        |
|    loss                 | 1.52         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.924        |
|    value_loss           | 2.75         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 17.4     |
| time/              |          |
|    fps             | 703      |
|    iterations      | 16       |
|    time_elapsed    | 113      |
|    total_timesteps | 80000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 241          |
|    ep_rew_mean          | 15.1         |
| time/                   |              |
|    fps                  | 685          |
|    iterations           | 17           |
|    time_elapsed         | 123          |
|    total_timesteps      | 85000        |
| train/                  |              |
|    approx_kl            | 0.0019166674 |
|    clip_fraction        | 0.0616       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.049        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.1          |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.918        |
|    value_loss           | 3.74         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.156        |
|    max_step             | 0            |
|    mean_ep_length       | 33.8         |
|    mean_reward          | 11.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.22374982   |
|    route_completion     | 0.15         |
|    success_rate         | 0            |
|    total_cost           | 2            |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0017809641 |
|    clip_fraction        | 0.0667       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.66        |
|    explained_variance   | -0.00222     |
|    learning_rate        | 5e-05        |
|    loss                 | 2.52         |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00226     |
|    std                  | 0.913        |
|    value_loss           | 4.63         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 14.9     |
| time/              |          |
|    fps             | 664      |
|    iterations      | 18       |
|    time_elapsed    | 135      |
|    total_timesteps | 90000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 192          |
|    ep_rew_mean          | 15.6         |
| time/                   |              |
|    fps                  | 663          |
|    iterations           | 19           |
|    time_elapsed         | 143          |
|    total_timesteps      | 95000        |
| train/                  |              |
|    approx_kl            | 0.0009955105 |
|    clip_fraction        | 0.0699       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.058        |
|    learning_rate        | 5e-05        |
|    loss                 | 3.16         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00267     |
|    std                  | 0.906        |
|    value_loss           | 4.62         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.18         |
|    max_step             | 0            |
|    mean_ep_length       | 58.4         |
|    mean_reward          | 45.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.2416878    |
|    route_completion     | 0.154        |
|    success_rate         | 0            |
|    total_cost           | 1.9          |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0015193938 |
|    clip_fraction        | 0.056        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.0766       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.37         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00237     |
|    std                  | 0.901        |
|    value_loss           | 4.62         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 17.5     |
| time/              |          |
|    fps             | 656      |
|    iterations      | 20       |
|    time_elapsed    | 152      |
|    total_timesteps | 100000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 202          |
|    ep_rew_mean          | 21           |
| time/                   |              |
|    fps                  | 657          |
|    iterations           | 21           |
|    time_elapsed         | 159          |
|    total_timesteps      | 105000       |
| train/                  |              |
|    approx_kl            | 0.0020019454 |
|    clip_fraction        | 0.0747       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.13         |
|    learning_rate        | 5e-05        |
|    loss                 | 1.82         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00289     |
|    std                  | 0.898        |
|    value_loss           | 4.67         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.164        |
|    max_step             | 0            |
|    mean_ep_length       | 59.8         |
|    mean_reward          | 47.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.25702918   |
|    route_completion     | 0.153        |
|    success_rate         | 0            |
|    total_cost           | 1.82         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0012741673 |
|    clip_fraction        | 0.0459       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.0368       |
|    learning_rate        | 5e-05        |
|    loss                 | 4            |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00308     |
|    std                  | 0.892        |
|    value_loss           | 4.76         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 22.3     |
| time/              |          |
|    fps             | 657      |
|    iterations      | 22       |
|    time_elapsed    | 167      |
|    total_timesteps | 110000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 220         |
|    ep_rew_mean          | 25.7        |
| time/                   |             |
|    fps                  | 658         |
|    iterations           | 23          |
|    time_elapsed         | 174         |
|    total_timesteps      | 115000      |
| train/                  |             |
|    approx_kl            | 0.002073293 |
|    clip_fraction        | 0.0593      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.6        |
|    explained_variance   | 0.115       |
|    learning_rate        | 5e-05       |
|    loss                 | 3.14        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00274    |
|    std                  | 0.889       |
|    value_loss           | 7.31        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.183        |
|    max_step             | 0            |
|    mean_ep_length       | 101          |
|    mean_reward          | 95.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.2792714    |
|    route_completion     | 0.17         |
|    success_rate         | 0            |
|    total_cost           | 2.4          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0015684167 |
|    clip_fraction        | 0.065        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.304        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.71         |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00306     |
|    std                  | 0.885        |
|    value_loss           | 6.15         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 25.8     |
| time/              |          |
|    fps             | 651      |
|    iterations      | 24       |
|    time_elapsed    | 184      |
|    total_timesteps | 120000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 215          |
|    ep_rew_mean          | 29.9         |
| time/                   |              |
|    fps                  | 644          |
|    iterations           | 25           |
|    time_elapsed         | 193          |
|    total_timesteps      | 125000       |
| train/                  |              |
|    approx_kl            | 0.0017037019 |
|    clip_fraction        | 0.085        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.194        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.97         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00412     |
|    std                  | 0.879        |
|    value_loss           | 6.03         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.185        |
|    max_step             | 0            |
|    mean_ep_length       | 95           |
|    mean_reward          | 96.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.29696774   |
|    route_completion     | 0.179        |
|    success_rate         | 0            |
|    total_cost           | 2.55         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0016538494 |
|    clip_fraction        | 0.0464       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.0143       |
|    learning_rate        | 5e-05        |
|    loss                 | 5.23         |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.0029      |
|    std                  | 0.874        |
|    value_loss           | 10.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 33.8     |
| time/              |          |
|    fps             | 646      |
|    iterations      | 26       |
|    time_elapsed    | 201      |
|    total_timesteps | 130000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 229          |
|    ep_rew_mean          | 38.2         |
| time/                   |              |
|    fps                  | 649          |
|    iterations           | 27           |
|    time_elapsed         | 207          |
|    total_timesteps      | 135000       |
| train/                  |              |
|    approx_kl            | 0.0016003707 |
|    clip_fraction        | 0.0497       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.0778       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.14         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00218     |
|    std                  | 0.866        |
|    value_loss           | 8.98         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0143       |
|    crash                | 0.186        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 104          |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.32120183   |
|    route_completion     | 0.203        |
|    success_rate         | 0.2          |
|    total_cost           | 4.66         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0015746423 |
|    clip_fraction        | 0.0775       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.172        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.99         |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00361     |
|    std                  | 0.86         |
|    value_loss           | 8.83         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 243      |
|    ep_rew_mean     | 44.7     |
| time/              |          |
|    fps             | 643      |
|    iterations      | 28       |
|    time_elapsed    | 217      |
|    total_timesteps | 140000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 262          |
|    ep_rew_mean          | 51.1         |
| time/                   |              |
|    fps                  | 648          |
|    iterations           | 29           |
|    time_elapsed         | 223          |
|    total_timesteps      | 145000       |
| train/                  |              |
|    approx_kl            | 0.0012389034 |
|    clip_fraction        | 0.0565       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.363        |
|    learning_rate        | 5e-05        |
|    loss                 | 3.11         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00288     |
|    std                  | 0.858        |
|    value_loss           | 10.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0133       |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 118          |
|    num_episodes         | 5            |
|    out_of_road          | 0.987        |
|    raw_action           | 0.33585605   |
|    route_completion     | 0.216        |
|    success_rate         | 0            |
|    total_cost           | 4.77         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0013855045 |
|    clip_fraction        | 0.0767       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.211        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.8          |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.003       |
|    std                  | 0.854        |
|    value_loss           | 11.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 280      |
|    ep_rew_mean     | 58.6     |
| time/              |          |
|    fps             | 649      |
|    iterations      | 30       |
|    time_elapsed    | 230      |
|    total_timesteps | 150000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 309         |
|    ep_rew_mean          | 67.7        |
| time/                   |             |
|    fps                  | 655         |
|    iterations           | 31          |
|    time_elapsed         | 236         |
|    total_timesteps      | 155000      |
| train/                  |             |
|    approx_kl            | 0.002576915 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.51       |
|    explained_variance   | 0.203       |
|    learning_rate        | 5e-05       |
|    loss                 | 5.56        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00373    |
|    std                  | 0.848       |
|    value_loss           | 9.67        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0125       |
|    crash                | 0.225        |
|    max_step             | 0            |
|    mean_ep_length       | 74.6         |
|    mean_reward          | 65.6         |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.3450317    |
|    route_completion     | 0.219        |
|    success_rate         | 0            |
|    total_cost           | 4.65         |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0019665752 |
|    clip_fraction        | 0.0845       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.522        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.33         |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.00403     |
|    std                  | 0.844        |
|    value_loss           | 11.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 320      |
|    ep_rew_mean     | 73.3     |
| time/              |          |
|    fps             | 654      |
|    iterations      | 32       |
|    time_elapsed    | 244      |
|    total_timesteps | 160000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 340          |
|    ep_rew_mean          | 82           |
| time/                   |              |
|    fps                  | 662          |
|    iterations           | 33           |
|    time_elapsed         | 249          |
|    total_timesteps      | 165000       |
| train/                  |              |
|    approx_kl            | 0.0010822697 |
|    clip_fraction        | 0.0452       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.331        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.37         |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00364     |
|    std                  | 0.838        |
|    value_loss           | 16.7         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0118      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 132         |
|    mean_reward          | 141         |
|    num_episodes         | 5           |
|    out_of_road          | 0.988       |
|    raw_action           | 0.35849148  |
|    route_completion     | 0.233       |
|    success_rate         | 0           |
|    total_cost           | 5.02        |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.001842917 |
|    clip_fraction        | 0.0652      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.48       |
|    explained_variance   | 0.803       |
|    learning_rate        | 5e-05       |
|    loss                 | 4.09        |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00333    |
|    std                  | 0.833       |
|    value_loss           | 12.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 367      |
|    ep_rew_mean     | 95       |
| time/              |          |
|    fps             | 659      |
|    iterations      | 34       |
|    time_elapsed    | 257      |
|    total_timesteps | 170000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 97.3         |
| time/                   |              |
|    fps                  | 663          |
|    iterations           | 35           |
|    time_elapsed         | 263          |
|    total_timesteps      | 175000       |
| train/                  |              |
|    approx_kl            | 0.0011107788 |
|    clip_fraction        | 0.0614       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.454        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.98         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00266     |
|    std                  | 0.829        |
|    value_loss           | 24.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0111       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 110          |
|    num_episodes         | 5            |
|    out_of_road          | 0.989        |
|    raw_action           | 0.366094     |
|    route_completion     | 0.243        |
|    success_rate         | 0            |
|    total_cost           | 5.24         |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0015239009 |
|    clip_fraction        | 0.0892       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.324        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.01         |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00198     |
|    std                  | 0.823        |
|    value_loss           | 16.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 664      |
|    iterations      | 36       |
|    time_elapsed    | 270      |
|    total_timesteps | 180000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 669         |
|    iterations           | 37          |
|    time_elapsed         | 276         |
|    total_timesteps      | 185000      |
| train/                  |             |
|    approx_kl            | 0.001591762 |
|    clip_fraction        | 0.0849      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.431       |
|    learning_rate        | 5e-05       |
|    loss                 | 9.46        |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.818       |
|    value_loss           | 14.8        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0105       |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 118          |
|    mean_reward          | 149          |
|    num_episodes         | 5            |
|    out_of_road          | 0.989        |
|    raw_action           | 0.37313223   |
|    route_completion     | 0.251        |
|    success_rate         | 0            |
|    total_cost           | 5.08         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0012522198 |
|    clip_fraction        | 0.0837       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.447        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.37         |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.815        |
|    value_loss           | 20           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 123      |
| time/              |          |
|    fps             | 667      |
|    iterations      | 38       |
|    time_elapsed    | 284      |
|    total_timesteps | 190000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 405         |
|    ep_rew_mean          | 133         |
| time/                   |             |
|    fps                  | 671         |
|    iterations           | 39          |
|    time_elapsed         | 290         |
|    total_timesteps      | 195000      |
| train/                  |             |
|    approx_kl            | 0.001366463 |
|    clip_fraction        | 0.0725      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.419       |
|    learning_rate        | 5e-05       |
|    loss                 | 9.7         |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00268    |
|    std                  | 0.811       |
|    value_loss           | 20.3        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.01         |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 123          |
|    mean_reward          | 152          |
|    num_episodes         | 5            |
|    out_of_road          | 0.99         |
|    raw_action           | 0.38044482   |
|    route_completion     | 0.263        |
|    success_rate         | 0            |
|    total_cost           | 5.14         |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0015084939 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.178        |
|    learning_rate        | 5e-05        |
|    loss                 | 10.7         |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00149     |
|    std                  | 0.804        |
|    value_loss           | 20           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 140      |
| time/              |          |
|    fps             | 672      |
|    iterations      | 40       |
|    time_elapsed    | 297      |
|    total_timesteps | 200000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 420          |
|    ep_rew_mean          | 149          |
| time/                   |              |
|    fps                  | 674          |
|    iterations           | 41           |
|    time_elapsed         | 304          |
|    total_timesteps      | 205000       |
| train/                  |              |
|    approx_kl            | 0.0017640574 |
|    clip_fraction        | 0.0866       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.218        |
|    learning_rate        | 5e-05        |
|    loss                 | 10.3         |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.0018      |
|    std                  | 0.798        |
|    value_loss           | 16.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00952      |
|    crash                | 0.229        |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 119          |
|    num_episodes         | 5            |
|    out_of_road          | 0.99         |
|    raw_action           | 0.38426098   |
|    route_completion     | 0.267        |
|    success_rate         | 0            |
|    total_cost           | 5.24         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0018637588 |
|    clip_fraction        | 0.0645       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.119        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.27         |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00315     |
|    std                  | 0.794        |
|    value_loss           | 26.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 154      |
| time/              |          |
|    fps             | 673      |
|    iterations      | 42       |
|    time_elapsed    | 311      |
|    total_timesteps | 210000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 439          |
|    ep_rew_mean          | 168          |
| time/                   |              |
|    fps                  | 675          |
|    iterations           | 43           |
|    time_elapsed         | 318          |
|    total_timesteps      | 215000       |
| train/                  |              |
|    approx_kl            | 0.0014547457 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.257        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.18         |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00154     |
|    std                  | 0.79         |
|    value_loss           | 19.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00909      |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 130          |
|    num_episodes         | 5            |
|    out_of_road          | 0.991        |
|    raw_action           | 0.38908494   |
|    route_completion     | 0.271        |
|    success_rate         | 0            |
|    total_cost           | 5.11         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0016062362 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.209        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.2         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00225     |
|    std                  | 0.786        |
|    value_loss           | 30.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 174      |
| time/              |          |
|    fps             | 674      |
|    iterations      | 44       |
|    time_elapsed    | 326      |
|    total_timesteps | 220000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 431          |
|    ep_rew_mean          | 174          |
| time/                   |              |
|    fps                  | 678          |
|    iterations           | 45           |
|    time_elapsed         | 331          |
|    total_timesteps      | 225000       |
| train/                  |              |
|    approx_kl            | 0.0013871351 |
|    clip_fraction        | 0.073        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.342        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.1         |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.783        |
|    value_loss           | 28.3         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0087      |
|    crash                | 0.217       |
|    max_step             | 0           |
|    mean_ep_length       | 89          |
|    mean_reward          | 97          |
|    num_episodes         | 5           |
|    out_of_road          | 0.991       |
|    raw_action           | 0.392813    |
|    route_completion     | 0.273       |
|    success_rate         | 0           |
|    total_cost           | 4.97        |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.001475627 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.0944      |
|    learning_rate        | 5e-05       |
|    loss                 | 8.41        |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00269    |
|    std                  | 0.777       |
|    value_loss           | 21.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 183      |
| time/              |          |
|    fps             | 679      |
|    iterations      | 46       |
|    time_elapsed    | 338      |
|    total_timesteps | 230000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 408          |
|    ep_rew_mean          | 186          |
| time/                   |              |
|    fps                  | 683          |
|    iterations           | 47           |
|    time_elapsed         | 343          |
|    total_timesteps      | 235000       |
| train/                  |              |
|    approx_kl            | 0.0012663906 |
|    clip_fraction        | 0.0733       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.0866       |
|    learning_rate        | 5e-05        |
|    loss                 | 22.3         |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.775        |
|    value_loss           | 37.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00833      |
|    crash                | 0.208        |
|    max_step             | 0            |
|    mean_ep_length       | 125          |
|    mean_reward          | 146          |
|    num_episodes         | 5            |
|    out_of_road          | 0.992        |
|    raw_action           | 0.3944366    |
|    route_completion     | 0.277        |
|    success_rate         | 0            |
|    total_cost           | 4.96         |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0015160354 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.0755       |
|    learning_rate        | 5e-05        |
|    loss                 | 18           |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.000818    |
|    std                  | 0.771        |
|    value_loss           | 40.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 394      |
|    ep_rew_mean     | 185      |
| time/              |          |
|    fps             | 681      |
|    iterations      | 48       |
|    time_elapsed    | 352      |
|    total_timesteps | 240000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 396          |
|    ep_rew_mean          | 190          |
| time/                   |              |
|    fps                  | 685          |
|    iterations           | 49           |
|    time_elapsed         | 357          |
|    total_timesteps      | 245000       |
| train/                  |              |
|    approx_kl            | 0.0009360819 |
|    clip_fraction        | 0.0862       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.257        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.6         |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00323     |
|    std                  | 0.768        |
|    value_loss           | 28.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.016        |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 202          |
|    num_episodes         | 5            |
|    out_of_road          | 0.984        |
|    raw_action           | 0.39979178   |
|    route_completion     | 0.288        |
|    success_rate         | 0.2          |
|    total_cost           | 4.91         |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0007106776 |
|    clip_fraction        | 0.0986       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.215        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.5         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00143     |
|    std                  | 0.766        |
|    value_loss           | 32.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 178      |
| time/              |          |
|    fps             | 683      |
|    iterations      | 50       |
|    time_elapsed    | 365      |
|    total_timesteps | 250000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 361          |
|    ep_rew_mean          | 184          |
| time/                   |              |
|    fps                  | 685          |
|    iterations           | 51           |
|    time_elapsed         | 371          |
|    total_timesteps      | 255000       |
| train/                  |              |
|    approx_kl            | 0.0019312318 |
|    clip_fraction        | 0.0743       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.274        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.7         |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.00284     |
|    std                  | 0.763        |
|    value_loss           | 37.3         |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.0154        |
|    crash                | 0.223         |
|    max_step             | 0             |
|    mean_ep_length       | 154           |
|    mean_reward          | 113           |
|    num_episodes         | 5             |
|    out_of_road          | 0.985         |
|    raw_action           | 0.40444338    |
|    route_completion     | 0.294         |
|    success_rate         | 0             |
|    total_cost           | 5.78          |
| time/                   |               |
|    total_timesteps      | 260000        |
| train/                  |               |
|    approx_kl            | 0.00085497985 |
|    clip_fraction        | 0.0698        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.29         |
|    explained_variance   | 0.276         |
|    learning_rate        | 5e-05         |
|    loss                 | 16.2          |
|    n_updates            | 1020          |
|    policy_gradient_loss | -0.000944     |
|    std                  | 0.761         |
|    value_loss           | 41.2          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 367      |
|    ep_rew_mean     | 191      |
| time/              |          |
|    fps             | 680      |
|    iterations      | 52       |
|    time_elapsed    | 381      |
|    total_timesteps | 260000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 365          |
|    ep_rew_mean          | 191          |
| time/                   |              |
|    fps                  | 683          |
|    iterations           | 53           |
|    time_elapsed         | 387          |
|    total_timesteps      | 265000       |
| train/                  |              |
|    approx_kl            | 0.0039465716 |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.0584       |
|    learning_rate        | 5e-05        |
|    loss                 | 5.72         |
|    n_updates            | 1040         |
|    policy_gradient_loss | 0.00034      |
|    std                  | 0.76         |
|    value_loss           | 19           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0148       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 103          |
|    mean_reward          | 127          |
|    num_episodes         | 5            |
|    out_of_road          | 0.985        |
|    raw_action           | 0.4103741    |
|    route_completion     | 0.297        |
|    success_rate         | 0            |
|    total_cost           | 5.61         |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0015905257 |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.125        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.7         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00259     |
|    std                  | 0.757        |
|    value_loss           | 43.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 189      |
| time/              |          |
|    fps             | 681      |
|    iterations      | 54       |
|    time_elapsed    | 395      |
|    total_timesteps | 270000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 204         |
| time/                   |             |
|    fps                  | 684         |
|    iterations           | 55          |
|    time_elapsed         | 401         |
|    total_timesteps      | 275000      |
| train/                  |             |
|    approx_kl            | 0.001527702 |
|    clip_fraction        | 0.0703      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.331       |
|    learning_rate        | 5e-05       |
|    loss                 | 8.64        |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00153    |
|    std                  | 0.754       |
|    value_loss           | 35.2        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0143       |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 77.2         |
|    mean_reward          | 75.2         |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.41255745   |
|    route_completion     | 0.295        |
|    success_rate         | 0            |
|    total_cost           | 5.44         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0044126883 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.112        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.9         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00049     |
|    std                  | 0.752        |
|    value_loss           | 31.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 683      |
|    iterations      | 56       |
|    time_elapsed    | 409      |
|    total_timesteps | 280000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 399          |
|    ep_rew_mean          | 218          |
| time/                   |              |
|    fps                  | 685          |
|    iterations           | 57           |
|    time_elapsed         | 416          |
|    total_timesteps      | 285000       |
| train/                  |              |
|    approx_kl            | 0.0016944504 |
|    clip_fraction        | 0.0796       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.355        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.8         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00234     |
|    std                  | 0.75         |
|    value_loss           | 29.5         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0138     |
|    crash                | 0.214      |
|    max_step             | 0          |
|    mean_ep_length       | 98.4       |
|    mean_reward          | 90.7       |
|    num_episodes         | 5          |
|    out_of_road          | 0.986      |
|    raw_action           | 0.41385093 |
|    route_completion     | 0.296      |
|    success_rate         | 0          |
|    total_cost           | 5.5        |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.00292307 |
|    clip_fraction        | 0.109      |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.26      |
|    explained_variance   | 0.149      |
|    learning_rate        | 5e-05      |
|    loss                 | 20.3       |
|    n_updates            | 1140       |
|    policy_gradient_loss | 0.00052    |
|    std                  | 0.746      |
|    value_loss           | 31.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 422      |
|    ep_rew_mean     | 233      |
| time/              |          |
|    fps             | 686      |
|    iterations      | 58       |
|    time_elapsed    | 422      |
|    total_timesteps | 290000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 426          |
|    ep_rew_mean          | 235          |
| time/                   |              |
|    fps                  | 688          |
|    iterations           | 59           |
|    time_elapsed         | 428          |
|    total_timesteps      | 295000       |
| train/                  |              |
|    approx_kl            | 0.0015471267 |
|    clip_fraction        | 0.0912       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.6          |
|    learning_rate        | 5e-05        |
|    loss                 | 15.2         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00118     |
|    std                  | 0.745        |
|    value_loss           | 39.4         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.02        |
|    crash                | 0.207       |
|    max_step             | 0           |
|    mean_ep_length       | 162         |
|    mean_reward          | 162         |
|    num_episodes         | 5           |
|    out_of_road          | 0.98        |
|    raw_action           | 0.41905218  |
|    route_completion     | 0.307       |
|    success_rate         | 0.2         |
|    total_cost           | 5.89        |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.003908264 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.25       |
|    explained_variance   | 0.592       |
|    learning_rate        | 5e-05       |
|    loss                 | 12.5        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00217    |
|    std                  | 0.744       |
|    value_loss           | 37.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 440      |
|    ep_rew_mean     | 245      |
| time/              |          |
|    fps             | 687      |
|    iterations      | 60       |
|    time_elapsed    | 436      |
|    total_timesteps | 300000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 449          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 690          |
|    iterations           | 61           |
|    time_elapsed         | 441          |
|    total_timesteps      | 305000       |
| train/                  |              |
|    approx_kl            | 0.0013183707 |
|    clip_fraction        | 0.176        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.119        |
|    learning_rate        | 5e-05        |
|    loss                 | 10           |
|    n_updates            | 1200         |
|    policy_gradient_loss | 0.000258     |
|    std                  | 0.745        |
|    value_loss           | 27.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0258       |
|    crash                | 0.206        |
|    max_step             | 0            |
|    mean_ep_length       | 120          |
|    mean_reward          | 141          |
|    num_episodes         | 5            |
|    out_of_road          | 0.974        |
|    raw_action           | 0.42381582   |
|    route_completion     | 0.312        |
|    success_rate         | 0.2          |
|    total_cost           | 5.88         |
| time/                   |              |
|    total_timesteps      | 310000       |
| train/                  |              |
|    approx_kl            | 0.0011302407 |
|    clip_fraction        | 0.0531       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.315        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.5         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00163     |
|    std                  | 0.742        |
|    value_loss           | 36           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 691      |
|    iterations      | 62       |
|    time_elapsed    | 448      |
|    total_timesteps | 310000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 449          |
|    ep_rew_mean          | 260          |
| time/                   |              |
|    fps                  | 693          |
|    iterations           | 63           |
|    time_elapsed         | 454          |
|    total_timesteps      | 315000       |
| train/                  |              |
|    approx_kl            | 0.0011160129 |
|    clip_fraction        | 0.0699       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.281        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.8         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.741        |
|    value_loss           | 44.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.025        |
|    crash                | 0.206        |
|    max_step             | 0            |
|    mean_ep_length       | 167          |
|    mean_reward          | 128          |
|    num_episodes         | 5            |
|    out_of_road          | 0.975        |
|    raw_action           | 0.4296858    |
|    route_completion     | 0.317        |
|    success_rate         | 0            |
|    total_cost           | 6.39         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0027951784 |
|    clip_fraction        | 0.0915       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.203        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.7         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.0018      |
|    std                  | 0.74         |
|    value_loss           | 53           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    fps             | 689      |
|    iterations      | 64       |
|    time_elapsed    | 463      |
|    total_timesteps | 320000   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 437           |
|    ep_rew_mean          | 253           |
| time/                   |               |
|    fps                  | 691           |
|    iterations           | 65            |
|    time_elapsed         | 469           |
|    total_timesteps      | 325000        |
| train/                  |               |
|    approx_kl            | 0.00040479112 |
|    clip_fraction        | 0.119         |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.23         |
|    explained_variance   | 0.179         |
|    learning_rate        | 5e-05         |
|    loss                 | 18.5          |
|    n_updates            | 1280          |
|    policy_gradient_loss | 0.000243      |
|    std                  | 0.737         |
|    value_loss           | 47            |
-------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0303      |
|    crash                | 0.212       |
|    max_step             | 0           |
|    mean_ep_length       | 163         |
|    mean_reward          | 194         |
|    num_episodes         | 5           |
|    out_of_road          | 0.97        |
|    raw_action           | 0.43397808  |
|    route_completion     | 0.327       |
|    success_rate         | 0.2         |
|    total_cost           | 6.67        |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.016417982 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.359       |
|    learning_rate        | 5e-05       |
|    loss                 | 18.5        |
|    n_updates            | 1300        |
|    policy_gradient_loss | 4.54e-05    |
|    std                  | 0.733       |
|    value_loss           | 41.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 691      |
|    iterations      | 66       |
|    time_elapsed    | 476      |
|    total_timesteps | 330000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 434          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 694          |
|    iterations           | 67           |
|    time_elapsed         | 482          |
|    total_timesteps      | 335000       |
| train/                  |              |
|    approx_kl            | 0.0023691352 |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.198        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.3         |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.00101     |
|    std                  | 0.729        |
|    value_loss           | 46.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0353       |
|    crash                | 0.212        |
|    max_step             | 0            |
|    mean_ep_length       | 148          |
|    mean_reward          | 95.2         |
|    num_episodes         | 5            |
|    out_of_road          | 0.965        |
|    raw_action           | 0.4357877    |
|    route_completion     | 0.332        |
|    success_rate         | 0.2          |
|    total_cost           | 7.39         |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0034473422 |
|    clip_fraction        | 0.0822       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.279        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.6         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00152     |
|    std                  | 0.724        |
|    value_loss           | 41.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 266      |
| time/              |          |
|    fps             | 693      |
|    iterations      | 68       |
|    time_elapsed    | 490      |
|    total_timesteps | 340000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 411          |
|    ep_rew_mean          | 257          |
| time/                   |              |
|    fps                  | 696          |
|    iterations           | 69           |
|    time_elapsed         | 495          |
|    total_timesteps      | 345000       |
| train/                  |              |
|    approx_kl            | 0.0020817178 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.141        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.2         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.000436    |
|    std                  | 0.722        |
|    value_loss           | 56.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.04         |
|    crash                | 0.223        |
|    max_step             | 0            |
|    mean_ep_length       | 161          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.96         |
|    raw_action           | 0.4385816    |
|    route_completion     | 0.337        |
|    success_rate         | 0.2          |
|    total_cost           | 8.01         |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0012599599 |
|    clip_fraction        | 0.0985       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.312        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.4         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.000284    |
|    std                  | 0.72         |
|    value_loss           | 57.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 399      |
|    ep_rew_mean     | 251      |
| time/              |          |
|    fps             | 693      |
|    iterations      | 70       |
|    time_elapsed    | 504      |
|    total_timesteps | 350000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 407          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 695          |
|    iterations           | 71           |
|    time_elapsed         | 510          |
|    total_timesteps      | 355000       |
| train/                  |              |
|    approx_kl            | 0.0013140849 |
|    clip_fraction        | 0.0806       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.268        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.2         |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00139     |
|    std                  | 0.718        |
|    value_loss           | 58.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0389       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 102          |
|    num_episodes         | 5            |
|    out_of_road          | 0.961        |
|    raw_action           | 0.43845674   |
|    route_completion     | 0.336        |
|    success_rate         | 0            |
|    total_cost           | 7.84         |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0028784208 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.25         |
|    learning_rate        | 5e-05        |
|    loss                 | 20.8         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000517    |
|    std                  | 0.715        |
|    value_loss           | 53.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 399      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 696      |
|    iterations      | 72       |
|    time_elapsed    | 516      |
|    total_timesteps | 360000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 396         |
|    ep_rew_mean          | 259         |
| time/                   |             |
|    fps                  | 699         |
|    iterations           | 73          |
|    time_elapsed         | 522         |
|    total_timesteps      | 365000      |
| train/                  |             |
|    approx_kl            | 0.006504187 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.236       |
|    learning_rate        | 5e-05       |
|    loss                 | 11.8        |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.713       |
|    value_loss           | 58.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0378       |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.962        |
|    raw_action           | 0.43909484   |
|    route_completion     | 0.338        |
|    success_rate         | 0            |
|    total_cost           | 7.71         |
| time/                   |              |
|    total_timesteps      | 370000       |
| train/                  |              |
|    approx_kl            | 0.0047182753 |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.308        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.9         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00154     |
|    std                  | 0.71         |
|    value_loss           | 50.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 700      |
|    iterations      | 74       |
|    time_elapsed    | 528      |
|    total_timesteps | 370000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 256         |
| time/                   |             |
|    fps                  | 703         |
|    iterations           | 75          |
|    time_elapsed         | 533         |
|    total_timesteps      | 375000      |
| train/                  |             |
|    approx_kl            | 0.006172828 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.315       |
|    learning_rate        | 5e-05       |
|    loss                 | 8.76        |
|    n_updates            | 1480        |
|    policy_gradient_loss | 0.00105     |
|    std                  | 0.707       |
|    value_loss           | 60.1        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0368      |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 114         |
|    mean_reward          | 109         |
|    num_episodes         | 5           |
|    out_of_road          | 0.963       |
|    raw_action           | 0.44021443  |
|    route_completion     | 0.339       |
|    success_rate         | 0           |
|    total_cost           | 7.74        |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.002455233 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.33        |
|    learning_rate        | 5e-05       |
|    loss                 | 16.7        |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.000802    |
|    std                  | 0.704       |
|    value_loss           | 57.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 702      |
|    iterations      | 76       |
|    time_elapsed    | 540      |
|    total_timesteps | 380000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 370          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 705          |
|    iterations           | 77           |
|    time_elapsed         | 546          |
|    total_timesteps      | 385000       |
| train/                  |              |
|    approx_kl            | 0.0011319022 |
|    clip_fraction        | 0.0922       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.214        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.5         |
|    n_updates            | 1520         |
|    policy_gradient_loss | -0.00247     |
|    std                  | 0.701        |
|    value_loss           | 78.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0359      |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 168         |
|    mean_reward          | 230         |
|    num_episodes         | 5           |
|    out_of_road          | 0.964       |
|    raw_action           | 0.4423072   |
|    route_completion     | 0.346       |
|    success_rate         | 0           |
|    total_cost           | 7.59        |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.003034351 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.309       |
|    learning_rate        | 5e-05       |
|    loss                 | 17.2        |
|    n_updates            | 1540        |
|    policy_gradient_loss | 0.000962    |
|    std                  | 0.702       |
|    value_loss           | 60.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 247      |
| time/              |          |
|    fps             | 704      |
|    iterations      | 78       |
|    time_elapsed    | 553      |
|    total_timesteps | 390000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 254          |
| time/                   |              |
|    fps                  | 707          |
|    iterations           | 79           |
|    time_elapsed         | 558          |
|    total_timesteps      | 395000       |
| train/                  |              |
|    approx_kl            | 0.0011041415 |
|    clip_fraction        | 0.0959       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.405        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.6         |
|    n_updates            | 1560         |
|    policy_gradient_loss | -0.00171     |
|    std                  | 0.698        |
|    value_loss           | 62.1         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.045       |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 186         |
|    mean_reward          | 211         |
|    num_episodes         | 5           |
|    out_of_road          | 0.955       |
|    raw_action           | 0.44515857  |
|    route_completion     | 0.353       |
|    success_rate         | 0.4         |
|    total_cost           | 7.72        |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.002093027 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.326       |
|    learning_rate        | 5e-05       |
|    loss                 | 33.5        |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.696       |
|    value_loss           | 55.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 706      |
|    iterations      | 80       |
|    time_elapsed    | 566      |
|    total_timesteps | 400000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 257          |
| time/                   |              |
|    fps                  | 708          |
|    iterations           | 81           |
|    time_elapsed         | 571          |
|    total_timesteps      | 405000       |
| train/                  |              |
|    approx_kl            | 0.0057929913 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.391        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.4         |
|    n_updates            | 1600         |
|    policy_gradient_loss | -0.000394    |
|    std                  | 0.694        |
|    value_loss           | 63.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0488       |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 155          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.951        |
|    raw_action           | 0.4456217    |
|    route_completion     | 0.356        |
|    success_rate         | 0.2          |
|    total_cost           | 8.12         |
| time/                   |              |
|    total_timesteps      | 410000       |
| train/                  |              |
|    approx_kl            | 0.0026373935 |
|    clip_fraction        | 0.172        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.393        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.7         |
|    n_updates            | 1620         |
|    policy_gradient_loss | 0.00316      |
|    std                  | 0.69         |
|    value_loss           | 63.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 262      |
| time/              |          |
|    fps             | 707      |
|    iterations      | 82       |
|    time_elapsed    | 579      |
|    total_timesteps | 410000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 378          |
|    ep_rew_mean          | 261          |
| time/                   |              |
|    fps                  | 710          |
|    iterations           | 83           |
|    time_elapsed         | 584          |
|    total_timesteps      | 415000       |
| train/                  |              |
|    approx_kl            | 0.0046448363 |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.481        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.9         |
|    n_updates            | 1640         |
|    policy_gradient_loss | -0.00105     |
|    std                  | 0.688        |
|    value_loss           | 50.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0476       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 143          |
|    num_episodes         | 5            |
|    out_of_road          | 0.952        |
|    raw_action           | 0.4469892    |
|    route_completion     | 0.356        |
|    success_rate         | 0            |
|    total_cost           | 7.95         |
| time/                   |              |
|    total_timesteps      | 420000       |
| train/                  |              |
|    approx_kl            | 0.0014550366 |
|    clip_fraction        | 0.0789       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.631        |
|    learning_rate        | 5e-05        |
|    loss                 | 23           |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.00208     |
|    std                  | 0.687        |
|    value_loss           | 67.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    fps             | 709      |
|    iterations      | 84       |
|    time_elapsed    | 591      |
|    total_timesteps | 420000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 380         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 712         |
|    iterations           | 85          |
|    time_elapsed         | 596         |
|    total_timesteps      | 425000      |
| train/                  |             |
|    approx_kl            | 0.001329047 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.364       |
|    learning_rate        | 5e-05       |
|    loss                 | 24.6        |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.00112    |
|    std                  | 0.688       |
|    value_loss           | 80.9        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0465      |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 119         |
|    mean_reward          | 144         |
|    num_episodes         | 5           |
|    out_of_road          | 0.953       |
|    raw_action           | 0.44605944  |
|    route_completion     | 0.357       |
|    success_rate         | 0           |
|    total_cost           | 7.8         |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.016840424 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.401       |
|    learning_rate        | 5e-05       |
|    loss                 | 20.8        |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.000692    |
|    std                  | 0.688       |
|    value_loss           | 51.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 712      |
|    iterations      | 86       |
|    time_elapsed    | 603      |
|    total_timesteps | 430000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 380          |
|    ep_rew_mean          | 268          |
| time/                   |              |
|    fps                  | 714          |
|    iterations           | 87           |
|    time_elapsed         | 608          |
|    total_timesteps      | 435000       |
| train/                  |              |
|    approx_kl            | 0.0055317776 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.475        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.9         |
|    n_updates            | 1720         |
|    policy_gradient_loss | -5.29e-05    |
|    std                  | 0.686        |
|    value_loss           | 53.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0455       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 127          |
|    mean_reward          | 138          |
|    num_episodes         | 5            |
|    out_of_road          | 0.955        |
|    raw_action           | 0.4476871    |
|    route_completion     | 0.36         |
|    success_rate         | 0            |
|    total_cost           | 7.82         |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0012328071 |
|    clip_fraction        | 0.0863       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.614        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.1         |
|    n_updates            | 1740         |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.685        |
|    value_loss           | 71.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 266      |
| time/              |          |
|    fps             | 715      |
|    iterations      | 88       |
|    time_elapsed    | 615      |
|    total_timesteps | 440000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 374          |
|    ep_rew_mean          | 262          |
| time/                   |              |
|    fps                  | 717          |
|    iterations           | 89           |
|    time_elapsed         | 620          |
|    total_timesteps      | 445000       |
| train/                  |              |
|    approx_kl            | 0.0017520677 |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.58         |
|    learning_rate        | 5e-05        |
|    loss                 | 35.5         |
|    n_updates            | 1760         |
|    policy_gradient_loss | 0.00222      |
|    std                  | 0.684        |
|    value_loss           | 78.7         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0444      |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 77          |
|    mean_reward          | 75.5        |
|    num_episodes         | 5           |
|    out_of_road          | 0.956       |
|    raw_action           | 0.44824728  |
|    route_completion     | 0.357       |
|    success_rate         | 0           |
|    total_cost           | 7.67        |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.014898786 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.515       |
|    learning_rate        | 5e-05       |
|    loss                 | 25          |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.00114    |
|    std                  | 0.683       |
|    value_loss           | 66.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 717      |
|    iterations      | 90       |
|    time_elapsed    | 626      |
|    total_timesteps | 450000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 371         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 719         |
|    iterations           | 91          |
|    time_elapsed         | 632         |
|    total_timesteps      | 455000      |
| train/                  |             |
|    approx_kl            | 0.003736989 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.506       |
|    learning_rate        | 5e-05       |
|    loss                 | 38.7        |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.000525    |
|    std                  | 0.679       |
|    value_loss           | 49.5        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0435       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 150          |
|    num_episodes         | 5            |
|    out_of_road          | 0.957        |
|    raw_action           | 0.44893825   |
|    route_completion     | 0.36         |
|    success_rate         | 0            |
|    total_cost           | 7.7          |
| time/                   |              |
|    total_timesteps      | 460000       |
| train/                  |              |
|    approx_kl            | 0.0027336474 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.38         |
|    learning_rate        | 5e-05        |
|    loss                 | 50.6         |
|    n_updates            | 1820         |
|    policy_gradient_loss | -0.000817    |
|    std                  | 0.676        |
|    value_loss           | 89.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 719      |
|    iterations      | 92       |
|    time_elapsed    | 639      |
|    total_timesteps | 460000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 368          |
|    ep_rew_mean          | 261          |
| time/                   |              |
|    fps                  | 721          |
|    iterations           | 93           |
|    time_elapsed         | 644          |
|    total_timesteps      | 465000       |
| train/                  |              |
|    approx_kl            | 0.0021405178 |
|    clip_fraction        | 0.082        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.683        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.2         |
|    n_updates            | 1840         |
|    policy_gradient_loss | -0.00184     |
|    std                  | 0.676        |
|    value_loss           | 58.2         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0426      |
|    crash                | 0.23        |
|    max_step             | 0           |
|    mean_ep_length       | 92.8        |
|    mean_reward          | 99.7        |
|    num_episodes         | 5           |
|    out_of_road          | 0.957       |
|    raw_action           | 0.45052528  |
|    route_completion     | 0.36        |
|    success_rate         | 0           |
|    total_cost           | 7.58        |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.003292445 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.747       |
|    learning_rate        | 5e-05       |
|    loss                 | 21.1        |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.00129     |
|    std                  | 0.676       |
|    value_loss           | 68.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 721      |
|    iterations      | 94       |
|    time_elapsed    | 651      |
|    total_timesteps | 470000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 347          |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 723          |
|    iterations           | 95           |
|    time_elapsed         | 656          |
|    total_timesteps      | 475000       |
| train/                  |              |
|    approx_kl            | 0.0016652724 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.519        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.5         |
|    n_updates            | 1880         |
|    policy_gradient_loss | 0.0006       |
|    std                  | 0.674        |
|    value_loss           | 89.7         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.05       |
|    crash                | 0.229      |
|    max_step             | 0          |
|    mean_ep_length       | 144        |
|    mean_reward          | 149        |
|    num_episodes         | 5          |
|    out_of_road          | 0.95       |
|    raw_action           | 0.45271283 |
|    route_completion     | 0.364      |
|    success_rate         | 0.4        |
|    total_cost           | 7.6        |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.01507427 |
|    clip_fraction        | 0.13       |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.04      |
|    explained_variance   | 0.537      |
|    learning_rate        | 5e-05      |
|    loss                 | 27.5       |
|    n_updates            | 1900       |
|    policy_gradient_loss | 1.22e-05   |
|    std                  | 0.672      |
|    value_loss           | 78.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 248      |
| time/              |          |
|    fps             | 724      |
|    iterations      | 96       |
|    time_elapsed    | 662      |
|    total_timesteps | 480000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 334          |
|    ep_rew_mean          | 249          |
| time/                   |              |
|    fps                  | 726          |
|    iterations           | 97           |
|    time_elapsed         | 667          |
|    total_timesteps      | 485000       |
| train/                  |              |
|    approx_kl            | 0.0064509185 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.524        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.4         |
|    n_updates            | 1920         |
|    policy_gradient_loss | 0.000317     |
|    std                  | 0.671        |
|    value_loss           | 70.6         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0531     |
|    crash                | 0.229      |
|    max_step             | 0          |
|    mean_ep_length       | 171        |
|    mean_reward          | 128        |
|    num_episodes         | 5          |
|    out_of_road          | 0.947      |
|    raw_action           | 0.45416123 |
|    route_completion     | 0.366      |
|    success_rate         | 0.2        |
|    total_cost           | 7.98       |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.00463545 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.03      |
|    explained_variance   | 0.523      |
|    learning_rate        | 5e-05      |
|    loss                 | 28.2       |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.000478  |
|    std                  | 0.669      |
|    value_loss           | 63.1       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 725      |
|    iterations      | 98       |
|    time_elapsed    | 675      |
|    total_timesteps | 490000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 335         |
|    ep_rew_mean          | 253         |
| time/                   |             |
|    fps                  | 727         |
|    iterations           | 99          |
|    time_elapsed         | 680         |
|    total_timesteps      | 495000      |
| train/                  |             |
|    approx_kl            | 0.002396465 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.448       |
|    learning_rate        | 5e-05       |
|    loss                 | 21.9        |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00138     |
|    std                  | 0.669       |
|    value_loss           | 80.3        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.056        |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 162          |
|    mean_reward          | 191          |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.45573094   |
|    route_completion     | 0.372        |
|    success_rate         | 0.2          |
|    total_cost           | 8.09         |
| time/                   |              |
|    total_timesteps      | 500000       |
| train/                  |              |
|    approx_kl            | 0.0019258012 |
|    clip_fraction        | 0.0865       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.531        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.8         |
|    n_updates            | 1980         |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.668        |
|    value_loss           | 79           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 726      |
|    iterations      | 100      |
|    time_elapsed    | 688      |
|    total_timesteps | 500000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 334          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 727          |
|    iterations           | 101          |
|    time_elapsed         | 694          |
|    total_timesteps      | 505000       |
| train/                  |              |
|    approx_kl            | 0.0010545428 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.608        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.6         |
|    n_updates            | 2000         |
|    policy_gradient_loss | 0.0003       |
|    std                  | 0.667        |
|    value_loss           | 72.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0588       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 147          |
|    mean_reward          | 202          |
|    num_episodes         | 5            |
|    out_of_road          | 0.941        |
|    raw_action           | 0.4566249    |
|    route_completion     | 0.376        |
|    success_rate         | 0.2          |
|    total_cost           | 8.01         |
| time/                   |              |
|    total_timesteps      | 510000       |
| train/                  |              |
|    approx_kl            | 0.0022608102 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.497        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.6         |
|    n_updates            | 2020         |
|    policy_gradient_loss | -0.000604    |
|    std                  | 0.665        |
|    value_loss           | 90.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 726      |
|    iterations      | 102      |
|    time_elapsed    | 701      |
|    total_timesteps | 510000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 339          |
|    ep_rew_mean          | 264          |
| time/                   |              |
|    fps                  | 728          |
|    iterations           | 103          |
|    time_elapsed         | 706          |
|    total_timesteps      | 515000       |
| train/                  |              |
|    approx_kl            | 0.0019228349 |
|    clip_fraction        | 0.186        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.509        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.4         |
|    n_updates            | 2040         |
|    policy_gradient_loss | 0.00231      |
|    std                  | 0.663        |
|    value_loss           | 81           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0615       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 153          |
|    num_episodes         | 5            |
|    out_of_road          | 0.938        |
|    raw_action           | 0.45856723   |
|    route_completion     | 0.38         |
|    success_rate         | 0.2          |
|    total_cost           | 8.28         |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0014395001 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.634        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.6         |
|    n_updates            | 2060         |
|    policy_gradient_loss | 0.000488     |
|    std                  | 0.663        |
|    value_loss           | 65.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 728      |
|    iterations      | 104      |
|    time_elapsed    | 714      |
|    total_timesteps | 520000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 340         |
|    ep_rew_mean          | 265         |
| time/                   |             |
|    fps                  | 729         |
|    iterations           | 105         |
|    time_elapsed         | 719         |
|    total_timesteps      | 525000      |
| train/                  |             |
|    approx_kl            | 0.002646322 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.701       |
|    learning_rate        | 5e-05       |
|    loss                 | 15.4        |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.000815    |
|    std                  | 0.663       |
|    value_loss           | 44.1        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0604       |
|    crash                | 0.245        |
|    max_step             | 0            |
|    mean_ep_length       | 163          |
|    mean_reward          | 186          |
|    num_episodes         | 5            |
|    out_of_road          | 0.94         |
|    raw_action           | 0.4593429    |
|    route_completion     | 0.384        |
|    success_rate         | 0            |
|    total_cost           | 8.35         |
| time/                   |              |
|    total_timesteps      | 530000       |
| train/                  |              |
|    approx_kl            | 0.0019632378 |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.507        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.2         |
|    n_updates            | 2100         |
|    policy_gradient_loss | -0.000691    |
|    std                  | 0.661        |
|    value_loss           | 92           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 729      |
|    iterations      | 106      |
|    time_elapsed    | 726      |
|    total_timesteps | 530000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 266          |
| time/                   |              |
|    fps                  | 731          |
|    iterations           | 107          |
|    time_elapsed         | 731          |
|    total_timesteps      | 535000       |
| train/                  |              |
|    approx_kl            | 0.0021460168 |
|    clip_fraction        | 0.0816       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.551        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.4         |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.66         |
|    value_loss           | 71.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0593       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 111          |
|    mean_reward          | 121          |
|    num_episodes         | 5            |
|    out_of_road          | 0.941        |
|    raw_action           | 0.4588907    |
|    route_completion     | 0.384        |
|    success_rate         | 0            |
|    total_cost           | 8.32         |
| time/                   |              |
|    total_timesteps      | 540000       |
| train/                  |              |
|    approx_kl            | 0.0011301633 |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.576        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.3         |
|    n_updates            | 2140         |
|    policy_gradient_loss | -0.000133    |
|    std                  | 0.66         |
|    value_loss           | 70.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 732      |
|    iterations      | 108      |
|    time_elapsed    | 737      |
|    total_timesteps | 540000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 327          |
|    ep_rew_mean          | 263          |
| time/                   |              |
|    fps                  | 734          |
|    iterations           | 109          |
|    time_elapsed         | 742          |
|    total_timesteps      | 545000       |
| train/                  |              |
|    approx_kl            | 0.0038788735 |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.634        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.8         |
|    n_updates            | 2160         |
|    policy_gradient_loss | 0.00073      |
|    std                  | 0.659        |
|    value_loss           | 84.3         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0582      |
|    crash                | 0.244       |
|    max_step             | 0           |
|    mean_ep_length       | 104         |
|    mean_reward          | 103         |
|    num_episodes         | 5           |
|    out_of_road          | 0.942       |
|    raw_action           | 0.45899388  |
|    route_completion     | 0.383       |
|    success_rate         | 0           |
|    total_cost           | 8.25        |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.002420627 |
|    clip_fraction        | 0.0904      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.517       |
|    learning_rate        | 5e-05       |
|    loss                 | 28.1        |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0022     |
|    std                  | 0.657       |
|    value_loss           | 83.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    fps             | 734      |
|    iterations      | 110      |
|    time_elapsed    | 748      |
|    total_timesteps | 550000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 330          |
|    ep_rew_mean          | 262          |
| time/                   |              |
|    fps                  | 736          |
|    iterations           | 111          |
|    time_elapsed         | 753          |
|    total_timesteps      | 555000       |
| train/                  |              |
|    approx_kl            | 0.0014092253 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.696        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.5         |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.000318    |
|    std                  | 0.657        |
|    value_loss           | 53.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0571       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 125          |
|    num_episodes         | 5            |
|    out_of_road          | 0.943        |
|    raw_action           | 0.45923236   |
|    route_completion     | 0.383        |
|    success_rate         | 0            |
|    total_cost           | 8.27         |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0015172607 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.1         |
|    n_updates            | 2220         |
|    policy_gradient_loss | 6.43e-05     |
|    std                  | 0.656        |
|    value_loss           | 67.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    fps             | 736      |
|    iterations      | 112      |
|    time_elapsed    | 760      |
|    total_timesteps | 560000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 328         |
|    ep_rew_mean          | 264         |
| time/                   |             |
|    fps                  | 738         |
|    iterations           | 113         |
|    time_elapsed         | 765         |
|    total_timesteps      | 565000      |
| train/                  |             |
|    approx_kl            | 0.005824237 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.669       |
|    learning_rate        | 5e-05       |
|    loss                 | 33.7        |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.00259     |
|    std                  | 0.655       |
|    value_loss           | 63.8        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0561       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 84.8         |
|    mean_reward          | 82.6         |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.45869      |
|    route_completion     | 0.382        |
|    success_rate         | 0            |
|    total_cost           | 8.17         |
| time/                   |              |
|    total_timesteps      | 570000       |
| train/                  |              |
|    approx_kl            | 0.0043407744 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.708        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.2         |
|    n_updates            | 2260         |
|    policy_gradient_loss | 0.001        |
|    std                  | 0.656        |
|    value_loss           | 74.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 738      |
|    iterations      | 114      |
|    time_elapsed    | 771      |
|    total_timesteps | 570000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 334          |
|    ep_rew_mean          | 263          |
| time/                   |              |
|    fps                  | 739          |
|    iterations           | 115          |
|    time_elapsed         | 777          |
|    total_timesteps      | 575000       |
| train/                  |              |
|    approx_kl            | 0.0021793551 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.729        |
|    learning_rate        | 5e-05        |
|    loss                 | 43           |
|    n_updates            | 2280         |
|    policy_gradient_loss | 0.000338     |
|    std                  | 0.656        |
|    value_loss           | 84.8         |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.0552        |
|    crash                | 0.234         |
|    max_step             | 0             |
|    mean_ep_length       | 109           |
|    mean_reward          | 130           |
|    num_episodes         | 5             |
|    out_of_road          | 0.945         |
|    raw_action           | 0.4584982     |
|    route_completion     | 0.382         |
|    success_rate         | 0             |
|    total_cost           | 8.07          |
| time/                   |               |
|    total_timesteps      | 580000        |
| train/                  |               |
|    approx_kl            | 0.00094536936 |
|    clip_fraction        | 0.0687        |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.98         |
|    explained_variance   | 0.697         |
|    learning_rate        | 5e-05         |
|    loss                 | 61.5          |
|    n_updates            | 2300          |
|    policy_gradient_loss | -0.00156      |
|    std                  | 0.654         |
|    value_loss           | 114           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 739      |
|    iterations      | 116      |
|    time_elapsed    | 783      |
|    total_timesteps | 580000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 329          |
|    ep_rew_mean          | 256          |
| time/                   |              |
|    fps                  | 741          |
|    iterations           | 117          |
|    time_elapsed         | 789          |
|    total_timesteps      | 585000       |
| train/                  |              |
|    approx_kl            | 0.0012205914 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.848        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.4         |
|    n_updates            | 2320         |
|    policy_gradient_loss | 0.00254      |
|    std                  | 0.651        |
|    value_loss           | 75.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0542       |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 194          |
|    mean_reward          | 173          |
|    num_episodes         | 5            |
|    out_of_road          | 0.946        |
|    raw_action           | 0.4591161    |
|    route_completion     | 0.385        |
|    success_rate         | 0            |
|    total_cost           | 8.38         |
| time/                   |              |
|    total_timesteps      | 590000       |
| train/                  |              |
|    approx_kl            | 0.0026405773 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.859        |
|    learning_rate        | 5e-05        |
|    loss                 | 28           |
|    n_updates            | 2340         |
|    policy_gradient_loss | 0.000213     |
|    std                  | 0.647        |
|    value_loss           | 52           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 249      |
| time/              |          |
|    fps             | 740      |
|    iterations      | 118      |
|    time_elapsed    | 797      |
|    total_timesteps | 590000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 318         |
|    ep_rew_mean          | 248         |
| time/                   |             |
|    fps                  | 741         |
|    iterations           | 119         |
|    time_elapsed         | 802         |
|    total_timesteps      | 595000      |
| train/                  |             |
|    approx_kl            | 0.002587267 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.607       |
|    learning_rate        | 5e-05       |
|    loss                 | 60.8        |
|    n_updates            | 2360        |
|    policy_gradient_loss | 0.000815    |
|    std                  | 0.645       |
|    value_loss           | 75.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0533       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 135          |
|    mean_reward          | 175          |
|    num_episodes         | 5            |
|    out_of_road          | 0.947        |
|    raw_action           | 0.45938647   |
|    route_completion     | 0.388        |
|    success_rate         | 0            |
|    total_cost           | 8.3          |
| time/                   |              |
|    total_timesteps      | 600000       |
| train/                  |              |
|    approx_kl            | 0.0026783838 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.681        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.9         |
|    n_updates            | 2380         |
|    policy_gradient_loss | -0.000781    |
|    std                  | 0.642        |
|    value_loss           | 81.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 742      |
|    iterations      | 120      |
|    time_elapsed    | 808      |
|    total_timesteps | 600000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 334          |
|    ep_rew_mean          | 255          |
| time/                   |              |
|    fps                  | 743          |
|    iterations           | 121          |
|    time_elapsed         | 813          |
|    total_timesteps      | 605000       |
| train/                  |              |
|    approx_kl            | 0.0046191285 |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.81         |
|    learning_rate        | 5e-05        |
|    loss                 | 22.9         |
|    n_updates            | 2400         |
|    policy_gradient_loss | 0.00163      |
|    std                  | 0.641        |
|    value_loss           | 73.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0525       |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 149          |
|    mean_reward          | 204          |
|    num_episodes         | 5            |
|    out_of_road          | 0.948        |
|    raw_action           | 0.4600119    |
|    route_completion     | 0.391        |
|    success_rate         | 0            |
|    total_cost           | 8.25         |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0018975653 |
|    clip_fraction        | 0.0852       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.823        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.4         |
|    n_updates            | 2420         |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.642        |
|    value_loss           | 69.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 743      |
|    iterations      | 122      |
|    time_elapsed    | 820      |
|    total_timesteps | 610000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 341         |
|    ep_rew_mean          | 262         |
| time/                   |             |
|    fps                  | 744         |
|    iterations           | 123         |
|    time_elapsed         | 826         |
|    total_timesteps      | 615000      |
| train/                  |             |
|    approx_kl            | 0.001076109 |
|    clip_fraction        | 0.081       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.674       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.9        |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.00119    |
|    std                  | 0.641       |
|    value_loss           | 102         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0548       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 132          |
|    mean_reward          | 123          |
|    num_episodes         | 5            |
|    out_of_road          | 0.945        |
|    raw_action           | 0.461105     |
|    route_completion     | 0.39         |
|    success_rate         | 0.2          |
|    total_cost           | 8.39         |
| time/                   |              |
|    total_timesteps      | 620000       |
| train/                  |              |
|    approx_kl            | 0.0015291976 |
|    clip_fraction        | 0.208        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.721        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.5         |
|    n_updates            | 2460         |
|    policy_gradient_loss | 0.00182      |
|    std                  | 0.643        |
|    value_loss           | 55.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 743      |
|    iterations      | 124      |
|    time_elapsed    | 833      |
|    total_timesteps | 620000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 345         |
|    ep_rew_mean          | 268         |
| time/                   |             |
|    fps                  | 744         |
|    iterations           | 125         |
|    time_elapsed         | 839         |
|    total_timesteps      | 625000      |
| train/                  |             |
|    approx_kl            | 0.002411202 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.661       |
|    learning_rate        | 5e-05       |
|    loss                 | 31          |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.00145    |
|    std                  | 0.644       |
|    value_loss           | 75.1        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0571      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 176         |
|    mean_reward          | 181         |
|    num_episodes         | 5           |
|    out_of_road          | 0.943       |
|    raw_action           | 0.46072963  |
|    route_completion     | 0.393       |
|    success_rate         | 0.2         |
|    total_cost           | 8.65        |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.008572719 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.661       |
|    learning_rate        | 5e-05       |
|    loss                 | 47.5        |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.00211     |
|    std                  | 0.642       |
|    value_loss           | 80.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 743      |
|    iterations      | 126      |
|    time_elapsed    | 846      |
|    total_timesteps | 630000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 745          |
|    iterations           | 127          |
|    time_elapsed         | 852          |
|    total_timesteps      | 635000       |
| train/                  |              |
|    approx_kl            | 0.0035771667 |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.694        |
|    learning_rate        | 5e-05        |
|    loss                 | 21.5         |
|    n_updates            | 2520         |
|    policy_gradient_loss | -0.0011      |
|    std                  | 0.642        |
|    value_loss           | 71.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0563       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 95.4         |
|    mean_reward          | 90.3         |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.46111807   |
|    route_completion     | 0.393        |
|    success_rate         | 0            |
|    total_cost           | 8.58         |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0023555637 |
|    clip_fraction        | 0.199        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.754        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.5         |
|    n_updates            | 2540         |
|    policy_gradient_loss | 0.00104      |
|    std                  | 0.642        |
|    value_loss           | 49.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 745      |
|    iterations      | 128      |
|    time_elapsed    | 858      |
|    total_timesteps | 640000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 299          |
| time/                   |              |
|    fps                  | 747          |
|    iterations           | 129          |
|    time_elapsed         | 863          |
|    total_timesteps      | 645000       |
| train/                  |              |
|    approx_kl            | 0.0043029143 |
|    clip_fraction        | 0.161        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.742        |
|    learning_rate        | 5e-05        |
|    loss                 | 45           |
|    n_updates            | 2560         |
|    policy_gradient_loss | -0.000293    |
|    std                  | 0.64         |
|    value_loss           | 55.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0554       |
|    crash                | 0.24         |
|    max_step             | 0            |
|    mean_ep_length       | 126          |
|    mean_reward          | 162          |
|    num_episodes         | 5            |
|    out_of_road          | 0.945        |
|    raw_action           | 0.46184558   |
|    route_completion     | 0.393        |
|    success_rate         | 0            |
|    total_cost           | 8.49         |
| time/                   |              |
|    total_timesteps      | 650000       |
| train/                  |              |
|    approx_kl            | 0.0015351316 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.2         |
|    n_updates            | 2580         |
|    policy_gradient_loss | -0.00103     |
|    std                  | 0.64         |
|    value_loss           | 67.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 294      |
| time/              |          |
|    fps             | 747      |
|    iterations      | 130      |
|    time_elapsed    | 869      |
|    total_timesteps | 650000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 361          |
|    ep_rew_mean          | 294          |
| time/                   |              |
|    fps                  | 748          |
|    iterations           | 131          |
|    time_elapsed         | 874          |
|    total_timesteps      | 655000       |
| train/                  |              |
|    approx_kl            | 0.0029040452 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.707        |
|    learning_rate        | 5e-05        |
|    loss                 | 21.1         |
|    n_updates            | 2600         |
|    policy_gradient_loss | -0.000101    |
|    std                  | 0.638        |
|    value_loss           | 76.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0545      |
|    crash                | 0.242       |
|    max_step             | 0           |
|    mean_ep_length       | 129         |
|    mean_reward          | 153         |
|    num_episodes         | 5           |
|    out_of_road          | 0.945       |
|    raw_action           | 0.4617454   |
|    route_completion     | 0.395       |
|    success_rate         | 0           |
|    total_cost           | 8.43        |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.001116737 |
|    clip_fraction        | 0.0804      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.707       |
|    learning_rate        | 5e-05       |
|    loss                 | 50.2        |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.001      |
|    std                  | 0.638       |
|    value_loss           | 66.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 297      |
| time/              |          |
|    fps             | 748      |
|    iterations      | 132      |
|    time_elapsed    | 881      |
|    total_timesteps | 660000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 299          |
| time/                   |              |
|    fps                  | 749          |
|    iterations           | 133          |
|    time_elapsed         | 886          |
|    total_timesteps      | 665000       |
| train/                  |              |
|    approx_kl            | 0.0035500962 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.696        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.3         |
|    n_updates            | 2640         |
|    policy_gradient_loss | 0.000506     |
|    std                  | 0.638        |
|    value_loss           | 59.2         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0537      |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 88.8        |
|    mean_reward          | 97.3        |
|    num_episodes         | 5           |
|    out_of_road          | 0.946       |
|    raw_action           | 0.46184334  |
|    route_completion     | 0.393       |
|    success_rate         | 0           |
|    total_cost           | 8.32        |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.004387529 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.714       |
|    learning_rate        | 5e-05       |
|    loss                 | 27.4        |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.00167    |
|    std                  | 0.637       |
|    value_loss           | 74.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 750      |
|    iterations      | 134      |
|    time_elapsed    | 892      |
|    total_timesteps | 670000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 343         |
|    ep_rew_mean          | 292         |
| time/                   |             |
|    fps                  | 752         |
|    iterations           | 135         |
|    time_elapsed         | 897         |
|    total_timesteps      | 675000      |
| train/                  |             |
|    approx_kl            | 0.001129987 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.671       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.2        |
|    n_updates            | 2680        |
|    policy_gradient_loss | 0.000844    |
|    std                  | 0.635       |
|    value_loss           | 78.6        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0529       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 111          |
|    mean_reward          | 97.7         |
|    num_episodes         | 5            |
|    out_of_road          | 0.947        |
|    raw_action           | 0.46195564   |
|    route_completion     | 0.393        |
|    success_rate         | 0            |
|    total_cost           | 8.35         |
| time/                   |              |
|    total_timesteps      | 680000       |
| train/                  |              |
|    approx_kl            | 0.0012545893 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.651        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.5         |
|    n_updates            | 2700         |
|    policy_gradient_loss | -0.000677    |
|    std                  | 0.636        |
|    value_loss           | 88           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 752      |
|    iterations      | 136      |
|    time_elapsed    | 904      |
|    total_timesteps | 680000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 325          |
|    ep_rew_mean          | 279          |
| time/                   |              |
|    fps                  | 753          |
|    iterations           | 137          |
|    time_elapsed         | 909          |
|    total_timesteps      | 685000       |
| train/                  |              |
|    approx_kl            | 0.0044864817 |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.619        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.9         |
|    n_updates            | 2720         |
|    policy_gradient_loss | 0.000117     |
|    std                  | 0.636        |
|    value_loss           | 85.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0522       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 195          |
|    num_episodes         | 5            |
|    out_of_road          | 0.948        |
|    raw_action           | 0.46223566   |
|    route_completion     | 0.395        |
|    success_rate         | 0            |
|    total_cost           | 8.3          |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0011712838 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.644        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.3         |
|    n_updates            | 2740         |
|    policy_gradient_loss | -0.00132     |
|    std                  | 0.636        |
|    value_loss           | 96.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 753      |
|    iterations      | 138      |
|    time_elapsed    | 915      |
|    total_timesteps | 690000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 323         |
|    ep_rew_mean          | 274         |
| time/                   |             |
|    fps                  | 754         |
|    iterations           | 139         |
|    time_elapsed         | 921         |
|    total_timesteps      | 695000      |
| train/                  |             |
|    approx_kl            | 0.001963633 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.752       |
|    learning_rate        | 5e-05       |
|    loss                 | 26          |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.00197     |
|    std                  | 0.635       |
|    value_loss           | 53.4        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0514      |
|    crash                | 0.231       |
|    max_step             | 0           |
|    mean_ep_length       | 150         |
|    mean_reward          | 195         |
|    num_episodes         | 5           |
|    out_of_road          | 0.949       |
|    raw_action           | 0.46190226  |
|    route_completion     | 0.397       |
|    success_rate         | 0           |
|    total_cost           | 8.26        |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.009255468 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.741       |
|    learning_rate        | 5e-05       |
|    loss                 | 34.3        |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.00272     |
|    std                  | 0.633       |
|    value_loss           | 72.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    fps             | 753      |
|    iterations      | 140      |
|    time_elapsed    | 928      |
|    total_timesteps | 700000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 327          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 755          |
|    iterations           | 141          |
|    time_elapsed         | 933          |
|    total_timesteps      | 705000       |
| train/                  |              |
|    approx_kl            | 0.0009903199 |
|    clip_fraction        | 0.205        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.7          |
|    learning_rate        | 5e-05        |
|    loss                 | 48.2         |
|    n_updates            | 2800         |
|    policy_gradient_loss | 0.00342      |
|    std                  | 0.632        |
|    value_loss           | 73.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0535       |
|    crash                | 0.228        |
|    max_step             | 0            |
|    mean_ep_length       | 140          |
|    mean_reward          | 179          |
|    num_episodes         | 5            |
|    out_of_road          | 0.946        |
|    raw_action           | 0.46233445   |
|    route_completion     | 0.398        |
|    success_rate         | 0.2          |
|    total_cost           | 8.19         |
| time/                   |              |
|    total_timesteps      | 710000       |
| train/                  |              |
|    approx_kl            | 0.0028044293 |
|    clip_fraction        | 0.0817       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.9         |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.00256     |
|    std                  | 0.631        |
|    value_loss           | 66.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 754      |
|    iterations      | 142      |
|    time_elapsed    | 941      |
|    total_timesteps | 710000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 335        |
|    ep_rew_mean          | 283        |
| time/                   |            |
|    fps                  | 755        |
|    iterations           | 143        |
|    time_elapsed         | 946        |
|    total_timesteps      | 715000     |
| train/                  |            |
|    approx_kl            | 0.01084832 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.89      |
|    explained_variance   | 0.688      |
|    learning_rate        | 5e-05      |
|    loss                 | 45.3       |
|    n_updates            | 2840       |
|    policy_gradient_loss | 0.00428    |
|    std                  | 0.632      |
|    value_loss           | 80.6       |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0556       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 181          |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.46296272   |
|    route_completion     | 0.4          |
|    success_rate         | 0.2          |
|    total_cost           | 8.17         |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0017288171 |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.646        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.5         |
|    n_updates            | 2860         |
|    policy_gradient_loss | -0.00111     |
|    std                  | 0.632        |
|    value_loss           | 99           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 755      |
|    iterations      | 144      |
|    time_elapsed    | 953      |
|    total_timesteps | 720000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 329         |
|    ep_rew_mean          | 280         |
| time/                   |             |
|    fps                  | 756         |
|    iterations           | 145         |
|    time_elapsed         | 958         |
|    total_timesteps      | 725000      |
| train/                  |             |
|    approx_kl            | 0.001068841 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.73        |
|    learning_rate        | 5e-05       |
|    loss                 | 32.1        |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.00139    |
|    std                  | 0.631       |
|    value_loss           | 60.9        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0548       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 170          |
|    num_episodes         | 5            |
|    out_of_road          | 0.945        |
|    raw_action           | 0.46337488   |
|    route_completion     | 0.401        |
|    success_rate         | 0            |
|    total_cost           | 8.16         |
| time/                   |              |
|    total_timesteps      | 730000       |
| train/                  |              |
|    approx_kl            | 0.0019644871 |
|    clip_fraction        | 0.0874       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.77         |
|    learning_rate        | 5e-05        |
|    loss                 | 30.1         |
|    n_updates            | 2900         |
|    policy_gradient_loss | -0.00115     |
|    std                  | 0.629        |
|    value_loss           | 86.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 756      |
|    iterations      | 146      |
|    time_elapsed    | 965      |
|    total_timesteps | 730000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 327          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 757          |
|    iterations           | 147          |
|    time_elapsed         | 970          |
|    total_timesteps      | 735000       |
| train/                  |              |
|    approx_kl            | 0.0012916148 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.861        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.9         |
|    n_updates            | 2920         |
|    policy_gradient_loss | 0.00137      |
|    std                  | 0.626        |
|    value_loss           | 78.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0541       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 120          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.946        |
|    raw_action           | 0.4638999    |
|    route_completion     | 0.402        |
|    success_rate         | 0            |
|    total_cost           | 8.09         |
| time/                   |              |
|    total_timesteps      | 740000       |
| train/                  |              |
|    approx_kl            | 0.0012717682 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.915        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.4         |
|    n_updates            | 2940         |
|    policy_gradient_loss | -0.00101     |
|    std                  | 0.624        |
|    value_loss           | 66.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 757      |
|    iterations      | 148      |
|    time_elapsed    | 977      |
|    total_timesteps | 740000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 315         |
|    ep_rew_mean          | 271         |
| time/                   |             |
|    fps                  | 758         |
|    iterations           | 149         |
|    time_elapsed         | 982         |
|    total_timesteps      | 745000      |
| train/                  |             |
|    approx_kl            | 0.002792193 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.922       |
|    learning_rate        | 5e-05       |
|    loss                 | 25          |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.00153    |
|    std                  | 0.624       |
|    value_loss           | 69.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.056        |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 165          |
|    mean_reward          | 136          |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.4650784    |
|    route_completion     | 0.404        |
|    success_rate         | 0.2          |
|    total_cost           | 8.34         |
| time/                   |              |
|    total_timesteps      | 750000       |
| train/                  |              |
|    approx_kl            | 0.0069511333 |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.894        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.3         |
|    n_updates            | 2980         |
|    policy_gradient_loss | -0.000471    |
|    std                  | 0.625        |
|    value_loss           | 95.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 757      |
|    iterations      | 150      |
|    time_elapsed    | 989      |
|    total_timesteps | 750000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 309          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 759          |
|    iterations           | 151          |
|    time_elapsed         | 994          |
|    total_timesteps      | 755000       |
| train/                  |              |
|    approx_kl            | 0.0023901141 |
|    clip_fraction        | 0.181        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.902        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.6         |
|    n_updates            | 3000         |
|    policy_gradient_loss | 0.00303      |
|    std                  | 0.625        |
|    value_loss           | 74           |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0553      |
|    crash                | 0.229       |
|    max_step             | 0           |
|    mean_ep_length       | 195         |
|    mean_reward          | 255         |
|    num_episodes         | 5           |
|    out_of_road          | 0.945       |
|    raw_action           | 0.46490926  |
|    route_completion     | 0.408       |
|    success_rate         | 0           |
|    total_cost           | 8.42        |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.002554124 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.864       |
|    learning_rate        | 5e-05       |
|    loss                 | 34.9        |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.000319   |
|    std                  | 0.628       |
|    value_loss           | 90.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 758      |
|    iterations      | 152      |
|    time_elapsed    | 1001     |
|    total_timesteps | 760000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 315          |
|    ep_rew_mean          | 275          |
| time/                   |              |
|    fps                  | 760          |
|    iterations           | 153          |
|    time_elapsed         | 1006         |
|    total_timesteps      | 765000       |
| train/                  |              |
|    approx_kl            | 0.0046933247 |
|    clip_fraction        | 0.0856       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.866        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.6         |
|    n_updates            | 3040         |
|    policy_gradient_loss | -0.000873    |
|    std                  | 0.627        |
|    value_loss           | 75.8         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0545     |
|    crash                | 0.226      |
|    max_step             | 0          |
|    mean_ep_length       | 104        |
|    mean_reward          | 124        |
|    num_episodes         | 5          |
|    out_of_road          | 0.945      |
|    raw_action           | 0.46475112 |
|    route_completion     | 0.408      |
|    success_rate         | 0          |
|    total_cost           | 8.34       |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.01288798 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.87      |
|    explained_variance   | 0.826      |
|    learning_rate        | 5e-05      |
|    loss                 | 29.1       |
|    n_updates            | 3060       |
|    policy_gradient_loss | -0.000274  |
|    std                  | 0.629      |
|    value_loss           | 84         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 760      |
|    iterations      | 154      |
|    time_elapsed    | 1012     |
|    total_timesteps | 770000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 311          |
|    ep_rew_mean          | 271          |
| time/                   |              |
|    fps                  | 761          |
|    iterations           | 155          |
|    time_elapsed         | 1018         |
|    total_timesteps      | 775000       |
| train/                  |              |
|    approx_kl            | 0.0034588687 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.861        |
|    learning_rate        | 5e-05        |
|    loss                 | 44.4         |
|    n_updates            | 3080         |
|    policy_gradient_loss | -0.00142     |
|    std                  | 0.628        |
|    value_loss           | 75.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0564      |
|    crash                | 0.226       |
|    max_step             | 0           |
|    mean_ep_length       | 129         |
|    mean_reward          | 124         |
|    num_episodes         | 5           |
|    out_of_road          | 0.944       |
|    raw_action           | 0.46576092  |
|    route_completion     | 0.408       |
|    success_rate         | 0.2         |
|    total_cost           | 8.36        |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.002290646 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.872       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.9        |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.626       |
|    value_loss           | 72.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 760      |
|    iterations      | 156      |
|    time_elapsed    | 1025     |
|    total_timesteps | 780000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 306          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 761          |
|    iterations           | 157          |
|    time_elapsed         | 1030         |
|    total_timesteps      | 785000       |
| train/                  |              |
|    approx_kl            | 0.0020651715 |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.826        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.1         |
|    n_updates            | 3120         |
|    policy_gradient_loss | 0.00147      |
|    std                  | 0.626        |
|    value_loss           | 78.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0557       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.4662986    |
|    route_completion     | 0.409        |
|    success_rate         | 0            |
|    total_cost           | 8.27         |
| time/                   |              |
|    total_timesteps      | 790000       |
| train/                  |              |
|    approx_kl            | 0.0025845172 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.887        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.9         |
|    n_updates            | 3140         |
|    policy_gradient_loss | -0.00133     |
|    std                  | 0.627        |
|    value_loss           | 88.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 762      |
|    iterations      | 158      |
|    time_elapsed    | 1036     |
|    total_timesteps | 790000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 309         |
|    ep_rew_mean          | 273         |
| time/                   |             |
|    fps                  | 763         |
|    iterations           | 159         |
|    time_elapsed         | 1041        |
|    total_timesteps      | 795000      |
| train/                  |             |
|    approx_kl            | 0.003159965 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.901       |
|    learning_rate        | 5e-05       |
|    loss                 | 50          |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.000283   |
|    std                  | 0.625       |
|    value_loss           | 95.8        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.055        |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 116          |
|    mean_reward          | 103          |
|    num_episodes         | 5            |
|    out_of_road          | 0.945        |
|    raw_action           | 0.46597445   |
|    route_completion     | 0.408        |
|    success_rate         | 0            |
|    total_cost           | 8.36         |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0017692477 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.928        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.1         |
|    n_updates            | 3180         |
|    policy_gradient_loss | 0.000603     |
|    std                  | 0.625        |
|    value_loss           | 80           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 762      |
|    iterations      | 160      |
|    time_elapsed    | 1048     |
|    total_timesteps | 800000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 308          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 764          |
|    iterations           | 161          |
|    time_elapsed         | 1053         |
|    total_timesteps      | 805000       |
| train/                  |              |
|    approx_kl            | 0.0031045994 |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.942        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.3         |
|    n_updates            | 3200         |
|    policy_gradient_loss | -0.0014      |
|    std                  | 0.624        |
|    value_loss           | 65           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0568       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.943        |
|    raw_action           | 0.46650156   |
|    route_completion     | 0.41         |
|    success_rate         | 0.2          |
|    total_cost           | 8.57         |
| time/                   |              |
|    total_timesteps      | 810000       |
| train/                  |              |
|    approx_kl            | 0.0031125757 |
|    clip_fraction        | 0.207        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.84        |
|    explained_variance   | 0.931        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.7         |
|    n_updates            | 3220         |
|    policy_gradient_loss | 0.00531      |
|    std                  | 0.622        |
|    value_loss           | 79.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 763      |
|    iterations      | 162      |
|    time_elapsed    | 1060     |
|    total_timesteps | 810000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 394          |
|    ep_rew_mean          | 222          |
| time/                   |              |
|    fps                  | 764          |
|    iterations           | 163          |
|    time_elapsed         | 1066         |
|    total_timesteps      | 815000       |
| train/                  |              |
|    approx_kl            | 0.0014031057 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.84        |
|    explained_variance   | 0.919        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.3         |
|    n_updates            | 3240         |
|    policy_gradient_loss | 0.000698     |
|    std                  | 0.619        |
|    value_loss           | 94.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0634      |
|    crash                | 0.234       |
|    max_step             | 0           |
|    mean_ep_length       | 189         |
|    mean_reward          | 216         |
|    num_episodes         | 5           |
|    out_of_road          | 0.937       |
|    raw_action           | 0.4678248   |
|    route_completion     | 0.414       |
|    success_rate         | 0.6         |
|    total_cost           | 8.66        |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.003750932 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.865       |
|    learning_rate        | 5e-05       |
|    loss                 | 27.3        |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.000511   |
|    std                  | 0.617       |
|    value_loss           | 74.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 764      |
|    iterations      | 164      |
|    time_elapsed    | 1072     |
|    total_timesteps | 820000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 393          |
|    ep_rew_mean          | 224          |
| time/                   |              |
|    fps                  | 765          |
|    iterations           | 165          |
|    time_elapsed         | 1078         |
|    total_timesteps      | 825000       |
| train/                  |              |
|    approx_kl            | 0.0018388778 |
|    clip_fraction        | 0.0795       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.5         |
|    n_updates            | 3280         |
|    policy_gradient_loss | -0.00201     |
|    std                  | 0.615        |
|    value_loss           | 92.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0627      |
|    crash                | 0.231       |
|    max_step             | 0           |
|    mean_ep_length       | 138         |
|    mean_reward          | 173         |
|    num_episodes         | 5           |
|    out_of_road          | 0.937       |
|    raw_action           | 0.4680888   |
|    route_completion     | 0.414       |
|    success_rate         | 0           |
|    total_cost           | 8.6         |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.002583946 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.698       |
|    learning_rate        | 5e-05       |
|    loss                 | 37.6        |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.0003      |
|    std                  | 0.612       |
|    value_loss           | 91.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 387      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 765      |
|    iterations      | 166      |
|    time_elapsed    | 1084     |
|    total_timesteps | 830000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 379          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 766          |
|    iterations           | 167          |
|    time_elapsed         | 1089         |
|    total_timesteps      | 835000       |
| train/                  |              |
|    approx_kl            | 0.0065606497 |
|    clip_fraction        | 0.194        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.678        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.9         |
|    n_updates            | 3320         |
|    policy_gradient_loss | 0.00278      |
|    std                  | 0.612        |
|    value_loss           | 102          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0619       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 101          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 0.938        |
|    raw_action           | 0.46831536   |
|    route_completion     | 0.413        |
|    success_rate         | 0            |
|    total_cost           | 8.52         |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0025514937 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.595        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.3         |
|    n_updates            | 3340         |
|    policy_gradient_loss | 0.000308     |
|    std                  | 0.611        |
|    value_loss           | 121          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 766      |
|    iterations      | 168      |
|    time_elapsed    | 1095     |
|    total_timesteps | 840000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 276          |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 767          |
|    iterations           | 169          |
|    time_elapsed         | 1100         |
|    total_timesteps      | 845000       |
| train/                  |              |
|    approx_kl            | 0.0026552654 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.68         |
|    learning_rate        | 5e-05        |
|    loss                 | 48.5         |
|    n_updates            | 3360         |
|    policy_gradient_loss | -0.000456    |
|    std                  | 0.613        |
|    value_loss           | 105          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0612      |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 118         |
|    mean_reward          | 151         |
|    num_episodes         | 5           |
|    out_of_road          | 0.939       |
|    raw_action           | 0.46816647  |
|    route_completion     | 0.414       |
|    success_rate         | 0           |
|    total_cost           | 8.45        |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.002586177 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.701       |
|    learning_rate        | 5e-05       |
|    loss                 | 53.5        |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.000281   |
|    std                  | 0.612       |
|    value_loss           | 101         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 268      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 767      |
|    iterations      | 170      |
|    time_elapsed    | 1107     |
|    total_timesteps | 850000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 273          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 768          |
|    iterations           | 171          |
|    time_elapsed         | 1112         |
|    total_timesteps      | 855000       |
| train/                  |              |
|    approx_kl            | 0.0015282301 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.64         |
|    learning_rate        | 5e-05        |
|    loss                 | 68.8         |
|    n_updates            | 3400         |
|    policy_gradient_loss | -0.00116     |
|    std                  | 0.611        |
|    value_loss           | 117          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0628       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 156          |
|    mean_reward          | 207          |
|    num_episodes         | 5            |
|    out_of_road          | 0.937        |
|    raw_action           | 0.46835357   |
|    route_completion     | 0.416        |
|    success_rate         | 0.2          |
|    total_cost           | 8.45         |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0032259382 |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.732        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.2         |
|    n_updates            | 3420         |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.61         |
|    value_loss           | 84.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 274      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 768      |
|    iterations      | 172      |
|    time_elapsed    | 1119     |
|    total_timesteps | 860000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 288        |
|    ep_rew_mean          | 258        |
| time/                   |            |
|    fps                  | 769        |
|    iterations           | 173        |
|    time_elapsed         | 1124       |
|    total_timesteps      | 865000     |
| train/                  |            |
|    approx_kl            | 0.13223135 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.79      |
|    explained_variance   | 0.699      |
|    learning_rate        | 5e-05      |
|    loss                 | 114        |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.00556    |
|    std                  | 0.608      |
|    value_loss           | 122        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0621       |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 97.6         |
|    mean_reward          | 98.8         |
|    num_episodes         | 5            |
|    out_of_road          | 0.938        |
|    raw_action           | 0.46900705   |
|    route_completion     | 0.415        |
|    success_rate         | 0            |
|    total_cost           | 8.38         |
| time/                   |              |
|    total_timesteps      | 870000       |
| train/                  |              |
|    approx_kl            | 0.0048948023 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.656        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.2         |
|    n_updates            | 3460         |
|    policy_gradient_loss | 0.000365     |
|    std                  | 0.609        |
|    value_loss           | 86.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 769      |
|    iterations      | 174      |
|    time_elapsed    | 1130     |
|    total_timesteps | 870000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 287          |
|    ep_rew_mean          | 260          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 175          |
|    time_elapsed         | 1136         |
|    total_timesteps      | 875000       |
| train/                  |              |
|    approx_kl            | 0.0026456022 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.593        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.7         |
|    n_updates            | 3480         |
|    policy_gradient_loss | 0.000773     |
|    std                  | 0.607        |
|    value_loss           | 116          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0614      |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 116         |
|    mean_reward          | 152         |
|    num_episodes         | 5           |
|    out_of_road          | 0.939       |
|    raw_action           | 0.46882692  |
|    route_completion     | 0.416       |
|    success_rate         | 0           |
|    total_cost           | 8.31        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.004197233 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.719       |
|    learning_rate        | 5e-05       |
|    loss                 | 37.7        |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.0003     |
|    std                  | 0.607       |
|    value_loss           | 90          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 294      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 769      |
|    iterations      | 176      |
|    time_elapsed    | 1143     |
|    total_timesteps | 880000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 297          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 177          |
|    time_elapsed         | 1150         |
|    total_timesteps      | 885000       |
| train/                  |              |
|    approx_kl            | 0.0018140789 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.75         |
|    learning_rate        | 5e-05        |
|    loss                 | 42.1         |
|    n_updates            | 3520         |
|    policy_gradient_loss | -0.00156     |
|    std                  | 0.606        |
|    value_loss           | 93.7         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0607      |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 94.6        |
|    mean_reward          | 110         |
|    num_episodes         | 5           |
|    out_of_road          | 0.939       |
|    raw_action           | 0.46960637  |
|    route_completion     | 0.416       |
|    success_rate         | 0           |
|    total_cost           | 8.23        |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.008883422 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.765       |
|    learning_rate        | 5e-05       |
|    loss                 | 53.2        |
|    n_updates            | 3540        |
|    policy_gradient_loss | 0.00148     |
|    std                  | 0.606       |
|    value_loss           | 81.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 768      |
|    iterations      | 178      |
|    time_elapsed    | 1157     |
|    total_timesteps | 890000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 288          |
|    ep_rew_mean          | 268          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 179          |
|    time_elapsed         | 1163         |
|    total_timesteps      | 895000       |
| train/                  |              |
|    approx_kl            | 0.0028437874 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 31           |
|    n_updates            | 3560         |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.604        |
|    value_loss           | 104          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0622      |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 136         |
|    mean_reward          | 146         |
|    num_episodes         | 5           |
|    out_of_road          | 0.938       |
|    raw_action           | 0.470301    |
|    route_completion     | 0.416       |
|    success_rate         | 0.2         |
|    total_cost           | 8.19        |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.007962584 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.673       |
|    learning_rate        | 5e-05       |
|    loss                 | 44          |
|    n_updates            | 3580        |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.604       |
|    value_loss           | 102         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 768      |
|    iterations      | 180      |
|    time_elapsed    | 1171     |
|    total_timesteps | 900000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 291         |
|    ep_rew_mean          | 261         |
| time/                   |             |
|    fps                  | 768         |
|    iterations           | 181         |
|    time_elapsed         | 1176        |
|    total_timesteps      | 905000      |
| train/                  |             |
|    approx_kl            | 0.015549461 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.689       |
|    learning_rate        | 5e-05       |
|    loss                 | 59.3        |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00318     |
|    std                  | 0.603       |
|    value_loss           | 110         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0615       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 128          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 0.938        |
|    raw_action           | 0.47109938   |
|    route_completion     | 0.417        |
|    success_rate         | 0            |
|    total_cost           | 8.29         |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0077061467 |
|    clip_fraction        | 0.234        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.596        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.6         |
|    n_updates            | 3620         |
|    policy_gradient_loss | 0.00214      |
|    std                  | 0.602        |
|    value_loss           | 108          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 768      |
|    iterations      | 182      |
|    time_elapsed    | 1184     |
|    total_timesteps | 910000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 288          |
|    ep_rew_mean          | 264          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 183          |
|    time_elapsed         | 1189         |
|    total_timesteps      | 915000       |
| train/                  |              |
|    approx_kl            | 0.0018294345 |
|    clip_fraction        | 0.172        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.4         |
|    n_updates            | 3640         |
|    policy_gradient_loss | 0.0012       |
|    std                  | 0.6          |
|    value_loss           | 69.2         |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.0609        |
|    crash                | 0.235         |
|    max_step             | 0             |
|    mean_ep_length       | 113           |
|    mean_reward          | 143           |
|    num_episodes         | 5             |
|    out_of_road          | 0.939         |
|    raw_action           | 0.47127813    |
|    route_completion     | 0.417         |
|    success_rate         | 0             |
|    total_cost           | 8.22          |
| time/                   |               |
|    total_timesteps      | 920000        |
| train/                  |               |
|    approx_kl            | 0.00092391326 |
|    clip_fraction        | 0.0949        |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.76         |
|    explained_variance   | 0.665         |
|    learning_rate        | 5e-05         |
|    loss                 | 57            |
|    n_updates            | 3660          |
|    policy_gradient_loss | -0.00176      |
|    std                  | 0.601         |
|    value_loss           | 121           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 769      |
|    iterations      | 184      |
|    time_elapsed    | 1196     |
|    total_timesteps | 920000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 281          |
|    ep_rew_mean          | 259          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 185          |
|    time_elapsed         | 1201         |
|    total_timesteps      | 925000       |
| train/                  |              |
|    approx_kl            | 0.0031316008 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.685        |
|    learning_rate        | 5e-05        |
|    loss                 | 61           |
|    n_updates            | 3680         |
|    policy_gradient_loss | -0.00122     |
|    std                  | 0.6          |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0624       |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 185          |
|    mean_reward          | 220          |
|    num_episodes         | 5            |
|    out_of_road          | 0.938        |
|    raw_action           | 0.4730851    |
|    route_completion     | 0.421        |
|    success_rate         | 0.2          |
|    total_cost           | 8.24         |
| time/                   |              |
|    total_timesteps      | 930000       |
| train/                  |              |
|    approx_kl            | 0.0017661791 |
|    clip_fraction        | 0.16         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.698        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.5         |
|    n_updates            | 3700         |
|    policy_gradient_loss | -0.000223    |
|    std                  | 0.599        |
|    value_loss           | 90.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 276      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 769      |
|    iterations      | 186      |
|    time_elapsed    | 1208     |
|    total_timesteps | 930000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 270          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 187          |
|    time_elapsed         | 1214         |
|    total_timesteps      | 935000       |
| train/                  |              |
|    approx_kl            | 0.0014734366 |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 41           |
|    n_updates            | 3720         |
|    policy_gradient_loss | 0.00338      |
|    std                  | 0.598        |
|    value_loss           | 111          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0617      |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 138         |
|    mean_reward          | 197         |
|    num_episodes         | 5           |
|    out_of_road          | 0.938       |
|    raw_action           | 0.47342178  |
|    route_completion     | 0.422       |
|    success_rate         | 0           |
|    total_cost           | 8.17        |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.001781694 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.65        |
|    learning_rate        | 5e-05       |
|    loss                 | 44.4        |
|    n_updates            | 3740        |
|    policy_gradient_loss | 0.000504    |
|    std                  | 0.597       |
|    value_loss           | 105         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 270      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 769      |
|    iterations      | 188      |
|    time_elapsed    | 1222     |
|    total_timesteps | 940000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 270          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 189          |
|    time_elapsed         | 1227         |
|    total_timesteps      | 945000       |
| train/                  |              |
|    approx_kl            | 0.0035762251 |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.736        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.5         |
|    n_updates            | 3760         |
|    policy_gradient_loss | -0.00141     |
|    std                  | 0.597        |
|    value_loss           | 118          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0611       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 99.8         |
|    mean_reward          | 121          |
|    num_episodes         | 5            |
|    out_of_road          | 0.939        |
|    raw_action           | 0.4740604    |
|    route_completion     | 0.422        |
|    success_rate         | 0            |
|    total_cost           | 8.09         |
| time/                   |              |
|    total_timesteps      | 950000       |
| train/                  |              |
|    approx_kl            | 0.0010033199 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.846        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.6         |
|    n_updates            | 3780         |
|    policy_gradient_loss | -0.00135     |
|    std                  | 0.594        |
|    value_loss           | 98.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 265      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 770      |
|    iterations      | 190      |
|    time_elapsed    | 1233     |
|    total_timesteps | 950000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 267          |
|    ep_rew_mean          | 246          |
| time/                   |              |
|    fps                  | 770          |
|    iterations           | 191          |
|    time_elapsed         | 1239         |
|    total_timesteps      | 955000       |
| train/                  |              |
|    approx_kl            | 0.0036452091 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.906        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.1         |
|    n_updates            | 3800         |
|    policy_gradient_loss | -0.000526    |
|    std                  | 0.594        |
|    value_loss           | 88           |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0604      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 126         |
|    mean_reward          | 162         |
|    num_episodes         | 5           |
|    out_of_road          | 0.94        |
|    raw_action           | 0.47390705  |
|    route_completion     | 0.422       |
|    success_rate         | 0           |
|    total_cost           | 8.05        |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.001614628 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.909       |
|    learning_rate        | 5e-05       |
|    loss                 | 48.7        |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.000309   |
|    std                  | 0.595       |
|    value_loss           | 97.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 270      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 770      |
|    iterations      | 192      |
|    time_elapsed    | 1245     |
|    total_timesteps | 960000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 261          |
|    ep_rew_mean          | 238          |
| time/                   |              |
|    fps                  | 770          |
|    iterations           | 193          |
|    time_elapsed         | 1251         |
|    total_timesteps      | 965000       |
| train/                  |              |
|    approx_kl            | 0.0075705377 |
|    clip_fraction        | 0.176        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.927        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.7         |
|    n_updates            | 3840         |
|    policy_gradient_loss | -0.000802    |
|    std                  | 0.594        |
|    value_loss           | 85.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0598       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.94         |
|    raw_action           | 0.47443315   |
|    route_completion     | 0.422        |
|    success_rate         | 0            |
|    total_cost           | 7.99         |
| time/                   |              |
|    total_timesteps      | 970000       |
| train/                  |              |
|    approx_kl            | 0.0013747392 |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.891        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.4         |
|    n_updates            | 3860         |
|    policy_gradient_loss | -0.00016     |
|    std                  | 0.594        |
|    value_loss           | 134          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 235      |
| time/              |          |
|    fps             | 770      |
|    iterations      | 194      |
|    time_elapsed    | 1258     |
|    total_timesteps | 970000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 260          |
|    ep_rew_mean          | 239          |
| time/                   |              |
|    fps                  | 771          |
|    iterations           | 195          |
|    time_elapsed         | 1264         |
|    total_timesteps      | 975000       |
| train/                  |              |
|    approx_kl            | 0.0033246193 |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.912        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.7         |
|    n_updates            | 3880         |
|    policy_gradient_loss | -0.0019      |
|    std                  | 0.593        |
|    value_loss           | 109          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0592      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 138         |
|    mean_reward          | 174         |
|    num_episodes         | 5           |
|    out_of_road          | 0.941       |
|    raw_action           | 0.4745727   |
|    route_completion     | 0.423       |
|    success_rate         | 0           |
|    total_cost           | 7.97        |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.002338577 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.925       |
|    learning_rate        | 5e-05       |
|    loss                 | 64.4        |
|    n_updates            | 3900        |
|    policy_gradient_loss | -7.82e-05   |
|    std                  | 0.595       |
|    value_loss           | 88.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | 237      |
| time/              |          |
|    fps             | 770      |
|    iterations      | 196      |
|    time_elapsed    | 1272     |
|    total_timesteps | 980000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 244          |
|    ep_rew_mean          | 222          |
| time/                   |              |
|    fps                  | 771          |
|    iterations           | 197          |
|    time_elapsed         | 1277         |
|    total_timesteps      | 985000       |
| train/                  |              |
|    approx_kl            | 0.0031890802 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.93         |
|    learning_rate        | 5e-05        |
|    loss                 | 37.4         |
|    n_updates            | 3920         |
|    policy_gradient_loss | -0.000225    |
|    std                  | 0.594        |
|    value_loss           | 97.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0586       |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 127          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.941        |
|    raw_action           | 0.47443172   |
|    route_completion     | 0.423        |
|    success_rate         | 0            |
|    total_cost           | 7.92         |
| time/                   |              |
|    total_timesteps      | 990000       |
| train/                  |              |
|    approx_kl            | 0.0015454286 |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.915        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.6         |
|    n_updates            | 3940         |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.594        |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    fps             | 770      |
|    iterations      | 198      |
|    time_elapsed    | 1284     |
|    total_timesteps | 990000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 306         |
|    ep_rew_mean          | 202         |
| time/                   |             |
|    fps                  | 771         |
|    iterations           | 199         |
|    time_elapsed         | 1289        |
|    total_timesteps      | 995000      |
| train/                  |             |
|    approx_kl            | 0.011416991 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.922       |
|    learning_rate        | 5e-05       |
|    loss                 | 36.5        |
|    n_updates            | 3960        |
|    policy_gradient_loss | 0.00226     |
|    std                  | 0.592       |
|    value_loss           | 99.8        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.058        |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 119          |
|    num_episodes         | 5            |
|    out_of_road          | 0.942        |
|    raw_action           | 0.4746339    |
|    route_completion     | 0.422        |
|    success_rate         | 0            |
|    total_cost           | 7.89         |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0031997715 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.875        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.3         |
|    n_updates            | 3980         |
|    policy_gradient_loss | -0.000471    |
|    std                  | 0.593        |
|    value_loss           | 85.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 771      |
|    iterations      | 200      |
|    time_elapsed    | 1296     |
|    total_timesteps | 1000000  |
---------------------------------
