Using cpu device
c:\Users\Colton\anaconda3\envs\cs260r\Lib\site-packages\stable_baselines3\ppo\ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5000`, after every 19 untruncated mini-batches, there will be a truncated mini-batch of size 136
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=500 and n_envs=10)
  warnings.warn(
Logging to runs\ppo_metadrive\ppo_metadrive_2025-03-16_17-29-24_4f9e3eb3\ppo_metadrive_1
-----------------------------
| time/              |      |
|    fps             | 1794 |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 5000 |
-----------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 181          |
|    mean_reward          | 33.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.041834407  |
|    route_completion     | 0.12         |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0033830528 |
|    clip_fraction        | 0.214        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.83        |
|    explained_variance   | -0.0726      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.00731     |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.012       |
|    std                  | 0.996        |
|    value_loss           | 0.0128       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 569      |
|    ep_rew_mean     | 1.39     |
| time/              |          |
|    fps             | 1079     |
|    iterations      | 2        |
|    time_elapsed    | 9        |
|    total_timesteps | 10000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 815          |
|    ep_rew_mean          | 4.56         |
| time/                   |              |
|    fps                  | 1121         |
|    iterations           | 3            |
|    time_elapsed         | 13           |
|    total_timesteps      | 15000        |
| train/                  |              |
|    approx_kl            | 0.0022342398 |
|    clip_fraction        | 0.0933       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.00753      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.143        |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00263     |
|    std                  | 0.99         |
|    value_loss           | 0.179        |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0           |
|    max_step             | 0           |
|    mean_ep_length       | 106         |
|    mean_reward          | 31.5        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.06284152  |
|    route_completion     | 0.117       |
|    success_rate         | 0           |
|    total_cost           | 1           |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.003504892 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0.00328     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0414      |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00769    |
|    std                  | 0.989       |
|    value_loss           | 0.119       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 10       |
| time/              |          |
|    fps             | 1046     |
|    iterations      | 4        |
|    time_elapsed    | 19       |
|    total_timesteps | 20000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.26e+03     |
|    ep_rew_mean          | 12.9         |
| time/                   |              |
|    fps                  | 1067         |
|    iterations           | 5            |
|    time_elapsed         | 23           |
|    total_timesteps      | 25000        |
| train/                  |              |
|    approx_kl            | 0.0028919943 |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.82        |
|    explained_variance   | -0.00414     |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0286       |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00576     |
|    std                  | 0.989        |
|    value_loss           | 0.177        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 55.2         |
|    mean_reward          | 12           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.0788421    |
|    route_completion     | 0.0985       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0029714052 |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.034        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0486       |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00618     |
|    std                  | 0.987        |
|    value_loss           | 0.201        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 15.3     |
| time/              |          |
|    fps             | 994      |
|    iterations      | 6        |
|    time_elapsed    | 30       |
|    total_timesteps | 30000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.27e+03     |
|    ep_rew_mean          | 17.7         |
| time/                   |              |
|    fps                  | 1001         |
|    iterations           | 7            |
|    time_elapsed         | 34           |
|    total_timesteps      | 35000        |
| train/                  |              |
|    approx_kl            | 0.0033026126 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.00711      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.165        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00499     |
|    std                  | 0.981        |
|    value_loss           | 0.342        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.05         |
|    max_step             | 0            |
|    mean_ep_length       | 61.6         |
|    mean_reward          | 24.9         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.104180194  |
|    route_completion     | 0.0987       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0026328643 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0482       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.133        |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00378     |
|    std                  | 0.972        |
|    value_loss           | 0.356        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 17.8     |
| time/              |          |
|    fps             | 948      |
|    iterations      | 8        |
|    time_elapsed    | 42       |
|    total_timesteps | 40000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.13e+03     |
|    ep_rew_mean          | 19.9         |
| time/                   |              |
|    fps                  | 944          |
|    iterations           | 9            |
|    time_elapsed         | 47           |
|    total_timesteps      | 45000        |
| train/                  |              |
|    approx_kl            | 0.0023351084 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.0165       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0922       |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00423     |
|    std                  | 0.97         |
|    value_loss           | 0.412        |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.04        |
|    max_step             | 0           |
|    mean_ep_length       | 59.4        |
|    mean_reward          | 31.2        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.13094038  |
|    route_completion     | 0.101       |
|    success_rate         | 0           |
|    total_cost           | 1           |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.001725862 |
|    clip_fraction        | 0.0842      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.77       |
|    explained_variance   | -0.000459   |
|    learning_rate        | 5e-05       |
|    loss                 | 1.72        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00227    |
|    std                  | 0.968       |
|    value_loss           | 2.94        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 17       |
| time/              |          |
|    fps             | 880      |
|    iterations      | 10       |
|    time_elapsed    | 56       |
|    total_timesteps | 50000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 942          |
|    ep_rew_mean          | 15.5         |
| time/                   |              |
|    fps                  | 876          |
|    iterations           | 11           |
|    time_elapsed         | 62           |
|    total_timesteps      | 55000        |
| train/                  |              |
|    approx_kl            | 0.0024923035 |
|    clip_fraction        | 0.0603       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.00946      |
|    learning_rate        | 5e-05        |
|    loss                 | 1.04         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00188     |
|    std                  | 0.967        |
|    value_loss           | 1.76         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0333       |
|    max_step             | 0            |
|    mean_ep_length       | 35.2         |
|    mean_reward          | 8.34         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1474918    |
|    route_completion     | 0.0929       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0009244747 |
|    clip_fraction        | 0.0373       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.245        |
|    learning_rate        | 5e-05        |
|    loss                 | 1.27         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00135     |
|    std                  | 0.968        |
|    value_loss           | 3.36         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 15.5     |
| time/              |          |
|    fps             | 836      |
|    iterations      | 12       |
|    time_elapsed    | 71       |
|    total_timesteps | 60000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 785          |
|    ep_rew_mean          | 16.5         |
| time/                   |              |
|    fps                  | 831          |
|    iterations           | 13           |
|    time_elapsed         | 78           |
|    total_timesteps      | 65000        |
| train/                  |              |
|    approx_kl            | 0.0017058563 |
|    clip_fraction        | 0.0781       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.76        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.733        |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00262     |
|    std                  | 0.962        |
|    value_loss           | 1.61         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0571       |
|    max_step             | 0            |
|    mean_ep_length       | 54           |
|    mean_reward          | 29.9         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.17341857   |
|    route_completion     | 0.0948       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0022183964 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.75        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.514        |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.0034      |
|    std                  | 0.955        |
|    value_loss           | 1.12         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 684      |
|    ep_rew_mean     | 16       |
| time/              |          |
|    fps             | 797      |
|    iterations      | 14       |
|    time_elapsed    | 87       |
|    total_timesteps | 70000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 484          |
|    ep_rew_mean          | 15.7         |
| time/                   |              |
|    fps                  | 785          |
|    iterations           | 15           |
|    time_elapsed         | 95           |
|    total_timesteps      | 75000        |
| train/                  |              |
|    approx_kl            | 0.0016244196 |
|    clip_fraction        | 0.0659       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.74        |
|    explained_variance   | -0.00053     |
|    learning_rate        | 5e-05        |
|    loss                 | 0.989        |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00187     |
|    std                  | 0.951        |
|    value_loss           | 2.22         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.075        |
|    max_step             | 0            |
|    mean_ep_length       | 60           |
|    mean_reward          | 43.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.19929133   |
|    route_completion     | 0.108        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0012836055 |
|    clip_fraction        | 0.0473       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.0308       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.73         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0015      |
|    std                  | 0.951        |
|    value_loss           | 2.58         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 14.2     |
| time/              |          |
|    fps             | 760      |
|    iterations      | 16       |
|    time_elapsed    | 105      |
|    total_timesteps | 80000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 297          |
|    ep_rew_mean          | 16           |
| time/                   |              |
|    fps                  | 750          |
|    iterations           | 17           |
|    time_elapsed         | 113          |
|    total_timesteps      | 85000        |
| train/                  |              |
|    approx_kl            | 0.0017421963 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.73        |
|    explained_variance   | -0.0031      |
|    learning_rate        | 5e-05        |
|    loss                 | 1.11         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00147     |
|    std                  | 0.947        |
|    value_loss           | 2.6          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 52.2         |
|    mean_reward          | 35.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.22289234   |
|    route_completion     | 0.108        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0011705082 |
|    clip_fraction        | 0.0653       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.72        |
|    explained_variance   | -0.00965     |
|    learning_rate        | 5e-05        |
|    loss                 | 0.973        |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00228     |
|    std                  | 0.94         |
|    value_loss           | 2.85         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 266      |
|    ep_rew_mean     | 15.9     |
| time/              |          |
|    fps             | 736      |
|    iterations      | 18       |
|    time_elapsed    | 122      |
|    total_timesteps | 90000    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 246          |
|    ep_rew_mean          | 16.2         |
| time/                   |              |
|    fps                  | 728          |
|    iterations           | 19           |
|    time_elapsed         | 130          |
|    total_timesteps      | 95000        |
| train/                  |              |
|    approx_kl            | 0.0012886429 |
|    clip_fraction        | 0.0491       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.0354       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.55         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00156     |
|    std                  | 0.934        |
|    value_loss           | 3.03         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.08         |
|    max_step             | 0            |
|    mean_ep_length       | 42.4         |
|    mean_reward          | 22.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.23900251   |
|    route_completion     | 0.106        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0015480656 |
|    clip_fraction        | 0.0509       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.0169       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.54         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.928        |
|    value_loss           | 4            |
------------------------------------------
