Using cpu device
Logging to runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_09-12-37_679e3d6f\ppo_metadrive_new_reward_5000_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 1.82     |
| time/              |          |
|    fps             | 1634     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 303          |
|    mean_reward          | 88.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.03679105   |
|    route_completion     | 0.252        |
|    success_rate         | 0            |
|    total_cost           | 2.4          |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0034204822 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.21         |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0186       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0121       |
|    max_step             | 0            |
|    n_updates            | 20           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0103      |
|    route_completion     | 0.194        |
|    std                  | 1            |
|    total_cost           | 1            |
|    value_loss           | 0.022        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 25.5     |
| time/              |          |
|    fps             | 712      |
|    iterations      | 2        |
|    time_elapsed    | 14       |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 412          |
|    ep_rew_mean          | 20.7         |
| time/                   |              |
|    fps                  | 850          |
|    iterations           | 3            |
|    time_elapsed         | 18           |
|    total_timesteps      | 15360        |
| train/                  |              |
|    approx_kl            | 0.0035049357 |
|    clip_fraction        | 0.219        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.0794       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00894      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00939     |
|    std                  | 0.997        |
|    value_loss           | 0.0397       |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0          |
|    crash                | 0.1        |
|    max_step             | 0          |
|    mean_ep_length       | 232        |
|    mean_reward          | 183        |
|    num_episodes         | 5          |
|    out_of_road          | 1          |
|    raw_action           | 0.07592809 |
|    route_completion     | 0.396      |
|    success_rate         | 0.2        |
|    total_cost           | 5.9        |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.00380272 |
|    arrive_dest          | 0.2        |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.1        |
|    crash                | 0.3        |
|    entropy_loss         | -2.82      |
|    explained_variance   | 0.149      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.000138  |
|    max_step             | 0          |
|    n_updates            | 60         |
|    out_of_road          | 0.8        |
|    policy_gradient_loss | -0.0116    |
|    route_completion     | 0.42       |
|    std                  | 0.99       |
|    total_cost           | 10.1       |
|    value_loss           | 0.0348     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 36.2     |
| time/              |          |
|    fps             | 625      |
|    iterations      | 4        |
|    time_elapsed    | 32       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 347         |
|    ep_rew_mean          | 32          |
| time/                   |             |
|    fps                  | 689         |
|    iterations           | 5           |
|    time_elapsed         | 37          |
|    total_timesteps      | 25600       |
| train/                  |             |
|    approx_kl            | 0.002014771 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0.0054      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.336       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00301    |
|    std                  | 0.986       |
|    value_loss           | 0.652       |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 75.2         |
|    mean_reward          | 30           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.08856686   |
|    route_completion     | 0.297        |
|    success_rate         | 0            |
|    total_cost           | 4.27         |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0037477624 |
|    arrive_dest          | 0.133        |
|    clip_fraction        | 0.238        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.0579       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00691      |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 0.867        |
|    policy_gradient_loss | -0.0102      |
|    route_completion     | 0.314        |
|    std                  | 0.979        |
|    total_cost           | 7.07         |
|    value_loss           | 0.0765       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 29.6     |
| time/              |          |
|    fps             | 665      |
|    iterations      | 6        |
|    time_elapsed    | 46       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 371          |
|    ep_rew_mean          | 24           |
| time/                   |              |
|    fps                  | 702          |
|    iterations           | 7            |
|    time_elapsed         | 51           |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 0.0026027386 |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.00462      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0891       |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00475     |
|    std                  | 0.971        |
|    value_loss           | 0.305        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.05         |
|    max_step             | 0            |
|    mean_ep_length       | 77.8         |
|    mean_reward          | 47.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.10838185   |
|    route_completion     | 0.261        |
|    success_rate         | 0            |
|    total_cost           | 3.45         |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0029276921 |
|    arrive_dest          | 0.1          |
|    clip_fraction        | 0.19         |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.0775       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0669       |
|    max_step             | 0            |
|    n_updates            | 140          |
|    out_of_road          | 0.9          |
|    policy_gradient_loss | -0.00687     |
|    route_completion     | 0.284        |
|    std                  | 0.965        |
|    total_cost           | 5.55         |
|    value_loss           | 0.225        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 367      |
|    ep_rew_mean     | 22.5     |
| time/              |          |
|    fps             | 672      |
|    iterations      | 8        |
|    time_elapsed    | 60       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 353          |
|    ep_rew_mean          | 21.5         |
| time/                   |              |
|    fps                  | 686          |
|    iterations           | 9            |
|    time_elapsed         | 67           |
|    total_timesteps      | 46080        |
| train/                  |              |
|    approx_kl            | 0.0018041872 |
|    clip_fraction        | 0.0988       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.0033       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.487        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00292     |
|    std                  | 0.964        |
|    value_loss           | 0.854        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.04         |
|    max_step             | 0            |
|    mean_ep_length       | 59           |
|    mean_reward          | 32.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.12055241   |
|    route_completion     | 0.229        |
|    success_rate         | 0            |
|    total_cost           | 2.96         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0027413624 |
|    arrive_dest          | 0.08         |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    crash                | 0.16         |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.0286       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.168        |
|    max_step             | 0            |
|    n_updates            | 180          |
|    out_of_road          | 0.92         |
|    policy_gradient_loss | -0.00555     |
|    route_completion     | 0.239        |
|    std                  | 0.96         |
|    total_cost           | 4.64         |
|    value_loss           | 0.484        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 21.3     |
| time/              |          |
|    fps             | 681      |
|    iterations      | 10       |
|    time_elapsed    | 75       |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 334         |
|    ep_rew_mean          | 20.8        |
| time/                   |             |
|    fps                  | 684         |
|    iterations           | 11          |
|    time_elapsed         | 82          |
|    total_timesteps      | 56320       |
| train/                  |             |
|    approx_kl            | 0.001481158 |
|    clip_fraction        | 0.0889      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.75       |
|    explained_variance   | 0.0209      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.563       |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0023     |
|    std                  | 0.957       |
|    value_loss           | 1.19        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 116          |
|    mean_reward          | 86.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1589229    |
|    route_completion     | 0.242        |
|    success_rate         | 0            |
|    total_cost           | 4.23         |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0026144653 |
|    arrive_dest          | 0.0667       |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.013        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.51         |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 0.933        |
|    policy_gradient_loss | -0.00412     |
|    route_completion     | 0.255        |
|    std                  | 0.948        |
|    total_cost           | 7.9          |
|    value_loss           | 1.27         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 301      |
|    ep_rew_mean     | 22.1     |
| time/              |          |
|    fps             | 620      |
|    iterations      | 12       |
|    time_elapsed    | 98       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 283          |
|    ep_rew_mean          | 21.8         |
| time/                   |              |
|    fps                  | 627          |
|    iterations           | 13           |
|    time_elapsed         | 106          |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0007346341 |
|    clip_fraction        | 0.00683      |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.99         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.000416    |
|    std                  | 0.945        |
|    value_loss           | 4.41         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.114       |
|    max_step             | 0           |
|    mean_ep_length       | 107         |
|    mean_reward          | 119         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.18641457  |
|    route_completion     | 0.249       |
|    success_rate         | 0.1         |
|    total_cost           | 4.06        |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.001686365 |
|    arrive_dest          | 0.0857      |
|    clip_fraction        | 0.0781      |
|    clip_range           | 0.1         |
|    crash                | 0.114       |
|    entropy_loss         | -2.72       |
|    explained_variance   | 0.00899     |
|    learning_rate        | 5e-05       |
|    loss                 | 1.23        |
|    max_step             | 0           |
|    n_updates            | 260         |
|    out_of_road          | 0.914       |
|    policy_gradient_loss | -0.00267    |
|    route_completion     | 0.288       |
|    std                  | 0.938       |
|    total_cost           | 7           |
|    value_loss           | 1.76        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | 23.7     |
| time/              |          |
|    fps             | 597      |
|    iterations      | 14       |
|    time_elapsed    | 120      |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 255          |
|    ep_rew_mean          | 24.4         |
| time/                   |              |
|    fps                  | 600          |
|    iterations           | 15           |
|    time_elapsed         | 127          |
|    total_timesteps      | 76800        |
| train/                  |              |
|    approx_kl            | 0.0010721256 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.024        |
|    learning_rate        | 5e-05        |
|    loss                 | 1.65         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.001       |
|    std                  | 0.936        |
|    value_loss           | 4.42         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 38.4         |
|    mean_reward          | 17.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.19824845   |
|    route_completion     | 0.226        |
|    success_rate         | 0            |
|    total_cost           | 3.67         |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0013049188 |
|    arrive_dest          | 0.075        |
|    clip_fraction        | 0.0511       |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.0251       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.97         |
|    max_step             | 0            |
|    n_updates            | 300          |
|    out_of_road          | 0.925        |
|    policy_gradient_loss | -0.00174     |
|    route_completion     | 0.262        |
|    std                  | 0.931        |
|    total_cost           | 6.25         |
|    value_loss           | 2.61         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | 22.8     |
| time/              |          |
|    fps             | 589      |
|    iterations      | 16       |
|    time_elapsed    | 138      |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 204          |
|    ep_rew_mean          | 19.9         |
| time/                   |              |
|    fps                  | 587          |
|    iterations           | 17           |
|    time_elapsed         | 148          |
|    total_timesteps      | 87040        |
| train/                  |              |
|    approx_kl            | 0.0017191904 |
|    clip_fraction        | 0.0641       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.014        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.48         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00182     |
|    std                  | 0.928        |
|    value_loss           | 3.66         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.111        |
|    max_step             | 0            |
|    mean_ep_length       | 51.4         |
|    mean_reward          | 36           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.21115042   |
|    route_completion     | 0.215        |
|    success_rate         | 0            |
|    total_cost           | 3.47         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0015167866 |
|    arrive_dest          | 0.0667       |
|    clip_fraction        | 0.0597       |
|    clip_range           | 0.1          |
|    crash                | 0.111        |
|    entropy_loss         | -2.68        |
|    explained_variance   | 0.0165       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.45         |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 0.933        |
|    policy_gradient_loss | -0.00191     |
|    route_completion     | 0.247        |
|    std                  | 0.923        |
|    total_cost           | 5.67         |
|    value_loss           | 4.06         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 17.9     |
| time/              |          |
|    fps             | 569      |
|    iterations      | 18       |
|    time_elapsed    | 161      |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 172          |
|    ep_rew_mean          | 17.4         |
| time/                   |              |
|    fps                  | 572          |
|    iterations           | 19           |
|    time_elapsed         | 169          |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0019858193 |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.00762      |
|    learning_rate        | 5e-05        |
|    loss                 | 3.96         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00319     |
|    std                  | 0.921        |
|    value_loss           | 7.91         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 45.8         |
|    mean_reward          | 30           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.22396083   |
|    route_completion     | 0.203        |
|    success_rate         | 0            |
|    total_cost           | 3.22         |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0014105997 |
|    arrive_dest          | 0.06         |
|    clip_fraction        | 0.0466       |
|    clip_range           | 0.1          |
|    crash                | 0.12         |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.0302       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.24         |
|    max_step             | 0            |
|    n_updates            | 380          |
|    out_of_road          | 0.94         |
|    policy_gradient_loss | -0.00147     |
|    route_completion     | 0.235        |
|    std                  | 0.92         |
|    total_cost           | 5.2          |
|    value_loss           | 4.65         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 19       |
| time/              |          |
|    fps             | 557      |
|    iterations      | 20       |
|    time_elapsed    | 183      |
|    total_timesteps | 102400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 149          |
|    ep_rew_mean          | 19           |
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 21           |
|    time_elapsed         | 195          |
|    total_timesteps      | 107520       |
| train/                  |              |
|    approx_kl            | 0.0015122488 |
|    clip_fraction        | 0.0552       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.0357       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.84         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00185     |
|    std                  | 0.915        |
|    value_loss           | 6.46         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.127        |
|    max_step             | 0            |
|    mean_ep_length       | 59.6         |
|    mean_reward          | 49           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.23651935   |
|    route_completion     | 0.2          |
|    success_rate         | 0            |
|    total_cost           | 3.02         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0012174186 |
|    arrive_dest          | 0.0545       |
|    clip_fraction        | 0.0531       |
|    clip_range           | 0.1          |
|    crash                | 0.127        |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0281       |
|    learning_rate        | 5e-05        |
|    loss                 | 4.18         |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 0.945        |
|    policy_gradient_loss | -0.00177     |
|    route_completion     | 0.225        |
|    std                  | 0.911        |
|    total_cost           | 4.82         |
|    value_loss           | 8.64         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 123      |
|    ep_rew_mean     | 17.9     |
| time/              |          |
|    fps             | 527      |
|    iterations      | 22       |
|    time_elapsed    | 213      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 114          |
|    ep_rew_mean          | 15.9         |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 23           |
|    time_elapsed         | 227          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0012519419 |
|    clip_fraction        | 0.0327       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.104        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.81         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00127     |
|    std                  | 0.907        |
|    value_loss           | 10.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0167       |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 169          |
|    mean_reward          | 87.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.983        |
|    raw_action           | 0.25343904   |
|    route_completion     | 0.216        |
|    success_rate         | 0.1          |
|    total_cost           | 7.05         |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0014420247 |
|    arrive_dest          | 0.05         |
|    clip_fraction        | 0.0593       |
|    clip_range           | 0.1          |
|    crash                | 0.117        |
|    entropy_loss         | -2.64        |
|    explained_variance   | 0.0789       |
|    learning_rate        | 5e-05        |
|    loss                 | 4.84         |
|    max_step             | 0            |
|    n_updates            | 460          |
|    out_of_road          | 0.95         |
|    policy_gradient_loss | -0.00247     |
|    route_completion     | 0.227        |
|    std                  | 0.906        |
|    total_cost           | 4.55         |
|    value_loss           | 10.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.3     |
|    ep_rew_mean     | 19.4     |
| time/              |          |
|    fps             | 490      |
|    iterations      | 24       |
|    time_elapsed    | 250      |
|    total_timesteps | 122880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 109          |
|    ep_rew_mean          | 21.5         |
| time/                   |              |
|    fps                  | 487          |
|    iterations           | 25           |
|    time_elapsed         | 262          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0009237338 |
|    clip_fraction        | 0.022        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.124        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.7         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00115     |
|    std                  | 0.902        |
|    value_loss           | 21.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0308       |
|    crash                | 0.123        |
|    max_step             | 0            |
|    mean_ep_length       | 160          |
|    mean_reward          | 118          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.26826814   |
|    route_completion     | 0.236        |
|    success_rate         | 0.1          |
|    total_cost           | 9.43         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0015951975 |
|    arrive_dest          | 0.0462       |
|    clip_fraction        | 0.0303       |
|    clip_range           | 0.1          |
|    crash                | 0.169        |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.293        |
|    learning_rate        | 5e-05        |
|    loss                 | 3.86         |
|    max_step             | 0            |
|    n_updates            | 500          |
|    out_of_road          | 0.954        |
|    policy_gradient_loss | -0.0015      |
|    route_completion     | 0.231        |
|    std                  | 0.898        |
|    total_cost           | 4.57         |
|    value_loss           | 8.93         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | 20.4     |
| time/              |          |
|    fps             | 468      |
|    iterations      | 26       |
|    time_elapsed    | 283      |
|    total_timesteps | 133120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 102          |
|    ep_rew_mean          | 18.5         |
| time/                   |              |
|    fps                  | 463          |
|    iterations           | 27           |
|    time_elapsed         | 298          |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0012823656 |
|    clip_fraction        | 0.042        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.304        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.9          |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00178     |
|    std                  | 0.897        |
|    value_loss           | 12.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0429       |
|    crash                | 0.129        |
|    max_step             | 0            |
|    mean_ep_length       | 146          |
|    mean_reward          | 138          |
|    num_episodes         | 5            |
|    out_of_road          | 0.957        |
|    raw_action           | 0.28194562   |
|    route_completion     | 0.25         |
|    success_rate         | 0.1          |
|    total_cost           | 10.5         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0011657848 |
|    arrive_dest          | 0.0429       |
|    clip_fraction        | 0.0532       |
|    clip_range           | 0.1          |
|    crash                | 0.171        |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.31         |
|    learning_rate        | 5e-05        |
|    loss                 | 5.34         |
|    max_step             | 0            |
|    n_updates            | 540          |
|    out_of_road          | 0.957        |
|    policy_gradient_loss | -0.00324     |
|    route_completion     | 0.232        |
|    std                  | 0.898        |
|    total_cost           | 4.7          |
|    value_loss           | 11.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.3     |
|    ep_rew_mean     | 19.5     |
| time/              |          |
|    fps             | 447      |
|    iterations      | 28       |
|    time_elapsed    | 320      |
|    total_timesteps | 143360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 107          |
|    ep_rew_mean          | 22.1         |
| time/                   |              |
|    fps                  | 445          |
|    iterations           | 29           |
|    time_elapsed         | 333          |
|    total_timesteps      | 148480       |
| train/                  |              |
|    approx_kl            | 0.0012054301 |
|    clip_fraction        | 0.0495       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.348        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.39         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00184     |
|    std                  | 0.897        |
|    value_loss           | 16.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.04         |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 73.8         |
|    mean_reward          | 87.2         |
|    num_episodes         | 5            |
|    out_of_road          | 0.96         |
|    raw_action           | 0.2938059    |
|    route_completion     | 0.251        |
|    success_rate         | 0            |
|    total_cost           | 9.85         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0008663001 |
|    arrive_dest          | 0.04         |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.1          |
|    crash                | 0.187        |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.476        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.82         |
|    max_step             | 0            |
|    n_updates            | 580          |
|    out_of_road          | 0.96         |
|    policy_gradient_loss | -0.00237     |
|    route_completion     | 0.234        |
|    std                  | 0.898        |
|    total_cost           | 4.47         |
|    value_loss           | 11.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | 21.5     |
| time/              |          |
|    fps             | 442      |
|    iterations      | 30       |
|    time_elapsed    | 347      |
|    total_timesteps | 153600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 118          |
|    ep_rew_mean          | 24           |
| time/                   |              |
|    fps                  | 442          |
|    iterations           | 31           |
|    time_elapsed         | 359          |
|    total_timesteps      | 158720       |
| train/                  |              |
|    approx_kl            | 0.0013250705 |
|    clip_fraction        | 0.043        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.436        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.24         |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00417     |
|    std                  | 0.893        |
|    value_loss           | 12.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.05         |
|    crash                | 0.125        |
|    max_step             | 0            |
|    mean_ep_length       | 135          |
|    mean_reward          | 165          |
|    num_episodes         | 5            |
|    out_of_road          | 0.95         |
|    raw_action           | 0.30541518   |
|    route_completion     | 0.266        |
|    success_rate         | 0.1          |
|    total_cost           | 9.95         |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0010352959 |
|    arrive_dest          | 0.0375       |
|    clip_fraction        | 0.0554       |
|    clip_range           | 0.1          |
|    crash                | 0.175        |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.431        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.34         |
|    max_step             | 0            |
|    n_updates            | 620          |
|    out_of_road          | 0.963        |
|    policy_gradient_loss | -0.00411     |
|    route_completion     | 0.235        |
|    std                  | 0.889        |
|    total_cost           | 4.49         |
|    value_loss           | 14.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 123      |
|    ep_rew_mean     | 29.5     |
| time/              |          |
|    fps             | 436      |
|    iterations      | 32       |
|    time_elapsed    | 375      |
|    total_timesteps | 163840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 138          |
|    ep_rew_mean          | 33.2         |
| time/                   |              |
|    fps                  | 440          |
|    iterations           | 33           |
|    time_elapsed         | 383          |
|    total_timesteps      | 168960       |
| train/                  |              |
|    approx_kl            | 0.0016589459 |
|    clip_fraction        | 0.0634       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.389        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.11         |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00311     |
|    std                  | 0.885        |
|    value_loss           | 22.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0588       |
|    crash                | 0.141        |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 132          |
|    num_episodes         | 5            |
|    out_of_road          | 0.941        |
|    raw_action           | 0.31577626   |
|    route_completion     | 0.274        |
|    success_rate         | 0.1          |
|    total_cost           | 9.49         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0013156913 |
|    arrive_dest          | 0.0353       |
|    clip_fraction        | 0.0643       |
|    clip_range           | 0.1          |
|    crash                | 0.212        |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.505        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.81         |
|    max_step             | 0            |
|    n_updates            | 660          |
|    out_of_road          | 0.965        |
|    policy_gradient_loss | -0.00425     |
|    route_completion     | 0.238        |
|    std                  | 0.881        |
|    total_cost           | 4.47         |
|    value_loss           | 12.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 158      |
|    ep_rew_mean     | 43.5     |
| time/              |          |
|    fps             | 438      |
|    iterations      | 34       |
|    time_elapsed    | 396      |
|    total_timesteps | 174080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 49.5         |
| time/                   |              |
|    fps                  | 442          |
|    iterations           | 35           |
|    time_elapsed         | 404          |
|    total_timesteps      | 179200       |
| train/                  |              |
|    approx_kl            | 0.0023345205 |
|    clip_fraction        | 0.0527       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.409        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.9          |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00303     |
|    std                  | 0.875        |
|    value_loss           | 19.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0556       |
|    crash                | 0.144        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 123          |
|    num_episodes         | 5            |
|    out_of_road          | 0.944        |
|    raw_action           | 0.33315405   |
|    route_completion     | 0.278        |
|    success_rate         | 0            |
|    total_cost           | 9.98         |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0016371931 |
|    arrive_dest          | 0.0333       |
|    clip_fraction        | 0.0653       |
|    clip_range           | 0.1          |
|    crash                | 0.233        |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.442        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.58         |
|    max_step             | 0            |
|    n_updates            | 700          |
|    out_of_road          | 0.967        |
|    policy_gradient_loss | -0.00356     |
|    route_completion     | 0.252        |
|    std                  | 0.873        |
|    total_cost           | 6.53         |
|    value_loss           | 15.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 57.3     |
| time/              |          |
|    fps             | 434      |
|    iterations      | 36       |
|    time_elapsed    | 424      |
|    total_timesteps | 184320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 239          |
|    ep_rew_mean          | 66.8         |
| time/                   |              |
|    fps                  | 439          |
|    iterations           | 37           |
|    time_elapsed         | 430          |
|    total_timesteps      | 189440       |
| train/                  |              |
|    approx_kl            | 0.0012860114 |
|    clip_fraction        | 0.053        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.42         |
|    learning_rate        | 5e-05        |
|    loss                 | 11.2         |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00291     |
|    std                  | 0.867        |
|    value_loss           | 19.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0632       |
|    crash                | 0.179        |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 130          |
|    num_episodes         | 5            |
|    out_of_road          | 0.937        |
|    raw_action           | 0.34857494   |
|    route_completion     | 0.291        |
|    success_rate         | 0.2          |
|    total_cost           | 11.4         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0012760191 |
|    arrive_dest          | 0.0421       |
|    clip_fraction        | 0.0755       |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.441        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.65         |
|    max_step             | 0            |
|    n_updates            | 740          |
|    out_of_road          | 0.958        |
|    policy_gradient_loss | -0.00309     |
|    route_completion     | 0.261        |
|    std                  | 0.861        |
|    total_cost           | 8.85         |
|    value_loss           | 16.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 73.5     |
| time/              |          |
|    fps             | 435      |
|    iterations      | 38       |
|    time_elapsed    | 446      |
|    total_timesteps | 194560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 281          |
|    ep_rew_mean          | 82.9         |
| time/                   |              |
|    fps                  | 441          |
|    iterations           | 39           |
|    time_elapsed         | 452          |
|    total_timesteps      | 199680       |
| train/                  |              |
|    approx_kl            | 0.0021606025 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.314        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.57         |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00398     |
|    std                  | 0.856        |
|    value_loss           | 18.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.07        |
|    crash                | 0.18        |
|    max_step             | 0           |
|    mean_ep_length       | 186         |
|    mean_reward          | 137         |
|    num_episodes         | 5           |
|    out_of_road          | 0.93        |
|    raw_action           | 0.3600318   |
|    route_completion     | 0.299       |
|    success_rate         | 0.2         |
|    total_cost           | 13.2        |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.001728324 |
|    arrive_dest          | 0.05        |
|    clip_fraction        | 0.0544      |
|    clip_range           | 0.1         |
|    crash                | 0.25        |
|    entropy_loss         | -2.52       |
|    explained_variance   | 0.416       |
|    learning_rate        | 5e-05       |
|    loss                 | 6.86        |
|    max_step             | 0           |
|    n_updates            | 780         |
|    out_of_road          | 0.95        |
|    policy_gradient_loss | -0.00311    |
|    route_completion     | 0.273       |
|    std                  | 0.849       |
|    total_cost           | 8.89        |
|    value_loss           | 15.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 279      |
|    ep_rew_mean     | 94.6     |
| time/              |          |
|    fps             | 435      |
|    iterations      | 40       |
|    time_elapsed    | 469      |
|    total_timesteps | 204800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 302          |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 441          |
|    iterations           | 41           |
|    time_elapsed         | 475          |
|    total_timesteps      | 209920       |
| train/                  |              |
|    approx_kl            | 0.0033315402 |
|    clip_fraction        | 0.0464       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.352        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.7         |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00252     |
|    std                  | 0.845        |
|    value_loss           | 33.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0762       |
|    crash                | 0.171        |
|    max_step             | 0            |
|    mean_ep_length       | 148          |
|    mean_reward          | 174          |
|    num_episodes         | 5            |
|    out_of_road          | 0.924        |
|    raw_action           | 0.36623666   |
|    route_completion     | 0.314        |
|    success_rate         | 0.2          |
|    total_cost           | 13.4         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0021552534 |
|    arrive_dest          | 0.0571       |
|    clip_fraction        | 0.0712       |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.287        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.5         |
|    max_step             | 0            |
|    n_updates            | 820          |
|    out_of_road          | 0.943        |
|    policy_gradient_loss | -0.00258     |
|    route_completion     | 0.278        |
|    std                  | 0.84         |
|    total_cost           | 8.76         |
|    value_loss           | 23.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 438      |
|    iterations      | 42       |
|    time_elapsed    | 490      |
|    total_timesteps | 215040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0727       |
|    crash                | 0.182        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 86.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.927        |
|    raw_action           | 0.3708955    |
|    route_completion     | 0.316        |
|    success_rate         | 0            |
|    total_cost           | 13.7         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0023572743 |
|    arrive_dest          | 0.0545       |
|    clip_fraction        | 0.0829       |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.311        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.9         |
|    max_step             | 0            |
|    n_updates            | 840          |
|    out_of_road          | 0.945        |
|    policy_gradient_loss | -0.00264     |
|    route_completion     | 0.282        |
|    std                  | 0.839        |
|    total_cost           | 8.94         |
|    value_loss           | 32.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 331      |
|    ep_rew_mean     | 123      |
| time/              |          |
|    fps             | 439      |
|    iterations      | 43       |
|    time_elapsed    | 501      |
|    total_timesteps | 220160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 320          |
|    ep_rew_mean          | 131          |
| time/                   |              |
|    fps                  | 443          |
|    iterations           | 44           |
|    time_elapsed         | 508          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0013570723 |
|    clip_fraction        | 0.0814       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.279        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.5         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00309     |
|    std                  | 0.835        |
|    value_loss           | 31.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0696       |
|    crash                | 0.174        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.93         |
|    raw_action           | 0.3783716    |
|    route_completion     | 0.321        |
|    success_rate         | 0.1          |
|    total_cost           | 13.8         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0016889509 |
|    arrive_dest          | 0.0609       |
|    clip_fraction        | 0.0924       |
|    clip_range           | 0.1          |
|    crash                | 0.278        |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.123        |
|    learning_rate        | 5e-05        |
|    loss                 | 13.9         |
|    max_step             | 0            |
|    n_updates            | 880          |
|    out_of_road          | 0.939        |
|    policy_gradient_loss | -0.00327     |
|    route_completion     | 0.29         |
|    std                  | 0.832        |
|    total_cost           | 9.44         |
|    value_loss           | 35.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 142      |
| time/              |          |
|    fps             | 440      |
|    iterations      | 45       |
|    time_elapsed    | 523      |
|    total_timesteps | 230400   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 334           |
|    ep_rew_mean          | 149           |
| time/                   |               |
|    fps                  | 444           |
|    iterations           | 46            |
|    time_elapsed         | 529           |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 0.00065586163 |
|    clip_fraction        | 0.0433        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.46         |
|    explained_variance   | 0.0802        |
|    learning_rate        | 5e-05         |
|    loss                 | 27            |
|    n_updates            | 900           |
|    policy_gradient_loss | -0.00107      |
|    std                  | 0.826         |
|    value_loss           | 50.2          |
-------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.075       |
|    crash                | 0.175       |
|    max_step             | 0           |
|    mean_ep_length       | 164         |
|    mean_reward          | 180         |
|    num_episodes         | 5           |
|    out_of_road          | 0.925       |
|    raw_action           | 0.38237053  |
|    route_completion     | 0.337       |
|    success_rate         | 0.1         |
|    total_cost           | 14.2        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.001849616 |
|    arrive_dest          | 0.0583      |
|    clip_fraction        | 0.0733      |
|    clip_range           | 0.1         |
|    crash                | 0.283       |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.164       |
|    learning_rate        | 5e-05       |
|    loss                 | 7.91        |
|    max_step             | 0           |
|    n_updates            | 920         |
|    out_of_road          | 0.942       |
|    policy_gradient_loss | -0.00322    |
|    route_completion     | 0.301       |
|    std                  | 0.822       |
|    total_cost           | 9.12        |
|    value_loss           | 21.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 159      |
| time/              |          |
|    fps             | 442      |
|    iterations      | 47       |
|    time_elapsed    | 543      |
|    total_timesteps | 240640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 158          |
| time/                   |              |
|    fps                  | 447          |
|    iterations           | 48           |
|    time_elapsed         | 549          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0018005583 |
|    clip_fraction        | 0.0677       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.114        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.1         |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.00183     |
|    std                  | 0.82         |
|    value_loss           | 49.1         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.072       |
|    crash                | 0.176       |
|    max_step             | 0           |
|    mean_ep_length       | 161         |
|    mean_reward          | 167         |
|    num_episodes         | 5           |
|    out_of_road          | 0.928       |
|    raw_action           | 0.3873998   |
|    route_completion     | 0.349       |
|    success_rate         | 0           |
|    total_cost           | 14.8        |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.001135616 |
|    arrive_dest          | 0.056       |
|    clip_fraction        | 0.0844      |
|    clip_range           | 0.1         |
|    crash                | 0.28        |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.0865      |
|    learning_rate        | 5e-05       |
|    loss                 | 17.6        |
|    max_step             | 0           |
|    n_updates            | 960         |
|    out_of_road          | 0.944       |
|    policy_gradient_loss | -0.00261    |
|    route_completion     | 0.309       |
|    std                  | 0.816       |
|    total_cost           | 9.27        |
|    value_loss           | 33          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 163      |
| time/              |          |
|    fps             | 443      |
|    iterations      | 49       |
|    time_elapsed    | 565      |
|    total_timesteps | 250880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 340          |
|    ep_rew_mean          | 166          |
| time/                   |              |
|    fps                  | 447          |
|    iterations           | 50           |
|    time_elapsed         | 572          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0010449914 |
|    clip_fraction        | 0.0564       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.104        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.3         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00138     |
|    std                  | 0.81         |
|    value_loss           | 57           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0923       |
|    crash                | 0.177        |
|    max_step             | 0            |
|    mean_ep_length       | 370          |
|    mean_reward          | 201          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.39453453   |
|    route_completion     | 0.367        |
|    success_rate         | 0.4          |
|    total_cost           | 19.6         |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0020438493 |
|    arrive_dest          | 0.0615       |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    crash                | 0.277        |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.0795       |
|    learning_rate        | 5e-05        |
|    loss                 | 23           |
|    max_step             | 0            |
|    n_updates            | 1000         |
|    out_of_road          | 0.938        |
|    policy_gradient_loss | -0.0024      |
|    route_completion     | 0.317        |
|    std                  | 0.808        |
|    total_cost           | 11.3         |
|    value_loss           | 45.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 329      |
|    ep_rew_mean     | 164      |
| time/              |          |
|    fps             | 442      |
|    iterations      | 51       |
|    time_elapsed    | 589      |
|    total_timesteps | 261120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 171          |
| time/                   |              |
|    fps                  | 446          |
|    iterations           | 52           |
|    time_elapsed         | 596          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0023143517 |
|    clip_fraction        | 0.0937       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.127        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.9         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.000834    |
|    std                  | 0.803        |
|    value_loss           | 53.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0963       |
|    crash                | 0.185        |
|    max_step             | 0            |
|    mean_ep_length       | 150          |
|    mean_reward          | 189          |
|    num_episodes         | 5            |
|    out_of_road          | 0.904        |
|    raw_action           | 0.40189648   |
|    route_completion     | 0.374        |
|    success_rate         | 0.2          |
|    total_cost           | 19           |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0013530828 |
|    arrive_dest          | 0.0667       |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    crash                | 0.289        |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.07         |
|    learning_rate        | 5e-05        |
|    loss                 | 20.9         |
|    max_step             | 0            |
|    n_updates            | 1040         |
|    out_of_road          | 0.933        |
|    policy_gradient_loss | -0.00118     |
|    route_completion     | 0.327        |
|    std                  | 0.8          |
|    total_cost           | 12.5         |
|    value_loss           | 51.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 176      |
| time/              |          |
|    fps             | 442      |
|    iterations      | 53       |
|    time_elapsed    | 612      |
|    total_timesteps | 271360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 176          |
| time/                   |              |
|    fps                  | 446          |
|    iterations           | 54           |
|    time_elapsed         | 619          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0016055219 |
|    clip_fraction        | 0.0682       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.195        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.7         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00209     |
|    std                  | 0.797        |
|    value_loss           | 53.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.1          |
|    crash                | 0.193        |
|    max_step             | 0            |
|    mean_ep_length       | 216          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.9          |
|    raw_action           | 0.4055483    |
|    route_completion     | 0.384        |
|    success_rate         | 0.2          |
|    total_cost           | 20.5         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0018339427 |
|    arrive_dest          | 0.0714       |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    crash                | 0.286        |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.041        |
|    learning_rate        | 5e-05        |
|    loss                 | 13.5         |
|    max_step             | 0            |
|    n_updates            | 1080         |
|    out_of_road          | 0.929        |
|    policy_gradient_loss | -0.00341     |
|    route_completion     | 0.331        |
|    std                  | 0.793        |
|    total_cost           | 13.5         |
|    value_loss           | 59.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 173      |
| time/              |          |
|    fps             | 441      |
|    iterations      | 55       |
|    time_elapsed    | 638      |
|    total_timesteps | 281600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 185          |
| time/                   |              |
|    fps                  | 444          |
|    iterations           | 56           |
|    time_elapsed         | 645          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0047855037 |
|    clip_fraction        | 0.0887       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.103        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.2         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00134     |
|    std                  | 0.791        |
|    value_loss           | 73.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.103        |
|    crash                | 0.193        |
|    max_step             | 0            |
|    mean_ep_length       | 129          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.897        |
|    raw_action           | 0.40947393   |
|    route_completion     | 0.384        |
|    success_rate         | 0.1          |
|    total_cost           | 20           |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0034457434 |
|    arrive_dest          | 0.069        |
|    clip_fraction        | 0.1          |
|    clip_range           | 0.1          |
|    crash                | 0.29         |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.101        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.5         |
|    max_step             | 0            |
|    n_updates            | 1120         |
|    out_of_road          | 0.931        |
|    policy_gradient_loss | -0.000918    |
|    route_completion     | 0.333        |
|    std                  | 0.789        |
|    total_cost           | 13.3         |
|    value_loss           | 52.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 193      |
| time/              |          |
|    fps             | 442      |
|    iterations      | 57       |
|    time_elapsed    | 659      |
|    total_timesteps | 291840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 376          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 446          |
|    iterations           | 58           |
|    time_elapsed         | 665          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0015486318 |
|    clip_fraction        | 0.0683       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.111        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.1         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.000456    |
|    std                  | 0.787        |
|    value_loss           | 58.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.113        |
|    crash                | 0.193        |
|    max_step             | 0            |
|    mean_ep_length       | 254          |
|    mean_reward          | 152          |
|    num_episodes         | 5            |
|    out_of_road          | 0.887        |
|    raw_action           | 0.41303018   |
|    route_completion     | 0.393        |
|    success_rate         | 0.2          |
|    total_cost           | 22           |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0016169358 |
|    arrive_dest          | 0.0667       |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    crash                | 0.28         |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.00815      |
|    learning_rate        | 5e-05        |
|    loss                 | 25.7         |
|    max_step             | 0            |
|    n_updates            | 1160         |
|    out_of_road          | 0.933        |
|    policy_gradient_loss | -0.00148     |
|    route_completion     | 0.341        |
|    std                  | 0.788        |
|    total_cost           | 13           |
|    value_loss           | 46.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 206      |
| time/              |          |
|    fps             | 444      |
|    iterations      | 59       |
|    time_elapsed    | 679      |
|    total_timesteps | 302080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 377          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 448          |
|    iterations           | 60           |
|    time_elapsed         | 685          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0015855649 |
|    clip_fraction        | 0.0594       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.0462       |
|    learning_rate        | 5e-05        |
|    loss                 | 36.7         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.00153     |
|    std                  | 0.787        |
|    value_loss           | 71.3         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.116       |
|    crash                | 0.187       |
|    max_step             | 0           |
|    mean_ep_length       | 139         |
|    mean_reward          | 185         |
|    num_episodes         | 5           |
|    out_of_road          | 0.884       |
|    raw_action           | 0.41425943  |
|    route_completion     | 0.399       |
|    success_rate         | 0.2         |
|    total_cost           | 21.5        |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.001437688 |
|    arrive_dest          | 0.071       |
|    clip_fraction        | 0.0576      |
|    clip_range           | 0.1         |
|    crash                | 0.29        |
|    entropy_loss         | -2.35       |
|    explained_variance   | 0.122       |
|    learning_rate        | 5e-05       |
|    loss                 | 31          |
|    max_step             | 0           |
|    n_updates            | 1200        |
|    out_of_road          | 0.929       |
|    policy_gradient_loss | -0.00117    |
|    route_completion     | 0.35        |
|    std                  | 0.783       |
|    total_cost           | 12.6        |
|    value_loss           | 57.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 447      |
|    iterations      | 61       |
|    time_elapsed    | 697      |
|    total_timesteps | 312320   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 378           |
|    ep_rew_mean          | 219           |
| time/                   |               |
|    fps                  | 450           |
|    iterations           | 62            |
|    time_elapsed         | 704           |
|    total_timesteps      | 317440        |
| train/                  |               |
|    approx_kl            | 0.00077923766 |
|    clip_fraction        | 0.091         |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.34         |
|    explained_variance   | 0.16          |
|    learning_rate        | 5e-05         |
|    loss                 | 32.2          |
|    n_updates            | 1220          |
|    policy_gradient_loss | -0.00151      |
|    std                  | 0.78          |
|    value_loss           | 76.2          |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.125        |
|    crash                | 0.188        |
|    max_step             | 0            |
|    mean_ep_length       | 237          |
|    mean_reward          | 225          |
|    num_episodes         | 5            |
|    out_of_road          | 0.875        |
|    raw_action           | 0.41730875   |
|    route_completion     | 0.406        |
|    success_rate         | 0.3          |
|    total_cost           | 22.2         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0022177915 |
|    arrive_dest          | 0.075        |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    crash                | 0.287        |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.091        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.2         |
|    max_step             | 0            |
|    n_updates            | 1240         |
|    out_of_road          | 0.925        |
|    policy_gradient_loss | -0.00108     |
|    route_completion     | 0.354        |
|    std                  | 0.776        |
|    total_cost           | 12.9         |
|    value_loss           | 62.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 220      |
| time/              |          |
|    fps             | 446      |
|    iterations      | 63       |
|    time_elapsed    | 722      |
|    total_timesteps | 322560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 221          |
| time/                   |              |
|    fps                  | 449          |
|    iterations           | 64           |
|    time_elapsed         | 729          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0011960922 |
|    clip_fraction        | 0.0701       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.188        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.5         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00175     |
|    std                  | 0.775        |
|    value_loss           | 104          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.127        |
|    crash                | 0.182        |
|    max_step             | 0            |
|    mean_ep_length       | 218          |
|    mean_reward          | 215          |
|    num_episodes         | 5            |
|    out_of_road          | 0.873        |
|    raw_action           | 0.4199972    |
|    route_completion     | 0.414        |
|    success_rate         | 0.1          |
|    total_cost           | 22.8         |
| time/                   |              |
|    total_timesteps      | 330000       |
| train/                  |              |
|    approx_kl            | 0.0016243194 |
|    arrive_dest          | 0.0727       |
|    clip_fraction        | 0.0666       |
|    clip_range           | 0.1          |
|    crash                | 0.279        |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.542        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.8         |
|    max_step             | 0            |
|    n_updates            | 1280         |
|    out_of_road          | 0.927        |
|    policy_gradient_loss | -0.00334     |
|    route_completion     | 0.357        |
|    std                  | 0.772        |
|    total_cost           | 12.6         |
|    value_loss           | 71.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 448      |
|    iterations      | 65       |
|    time_elapsed    | 742      |
|    total_timesteps | 332800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 371          |
|    ep_rew_mean          | 231          |
| time/                   |              |
|    fps                  | 451          |
|    iterations           | 66           |
|    time_elapsed         | 748          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0051277904 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.513        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.4         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -9.35e-05    |
|    std                  | 0.77         |
|    value_loss           | 95.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.129        |
|    crash                | 0.188        |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 200          |
|    num_episodes         | 5            |
|    out_of_road          | 0.871        |
|    raw_action           | 0.4242354    |
|    route_completion     | 0.417        |
|    success_rate         | 0.3          |
|    total_cost           | 22.5         |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0025705833 |
|    arrive_dest          | 0.0824       |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.276        |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.124        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.1         |
|    max_step             | 0            |
|    n_updates            | 1320         |
|    out_of_road          | 0.918        |
|    policy_gradient_loss | -0.000384    |
|    route_completion     | 0.365        |
|    std                  | 0.768        |
|    total_cost           | 13.5         |
|    value_loss           | 71.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 448      |
|    iterations      | 67       |
|    time_elapsed    | 764      |
|    total_timesteps | 343040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 383          |
|    ep_rew_mean          | 239          |
| time/                   |              |
|    fps                  | 451          |
|    iterations           | 68           |
|    time_elapsed         | 770          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0014269699 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.321        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.9         |
|    n_updates            | 1340         |
|    policy_gradient_loss | 0.000295     |
|    std                  | 0.767        |
|    value_loss           | 64.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.126        |
|    crash                | 0.189        |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 182          |
|    num_episodes         | 5            |
|    out_of_road          | 0.874        |
|    raw_action           | 0.42603484   |
|    route_completion     | 0.42         |
|    success_rate         | 0.1          |
|    total_cost           | 22           |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0021853875 |
|    arrive_dest          | 0.0857       |
|    clip_fraction        | 0.1          |
|    clip_range           | 0.1          |
|    crash                | 0.28         |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.0957       |
|    learning_rate        | 5e-05        |
|    loss                 | 34           |
|    max_step             | 0            |
|    n_updates            | 1360         |
|    out_of_road          | 0.914        |
|    policy_gradient_loss | 0.000473     |
|    route_completion     | 0.369        |
|    std                  | 0.763        |
|    total_cost           | 14.5         |
|    value_loss           | 67.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    fps             | 449      |
|    iterations      | 69       |
|    time_elapsed    | 786      |
|    total_timesteps | 353280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 378          |
|    ep_rew_mean          | 238          |
| time/                   |              |
|    fps                  | 452          |
|    iterations           | 70           |
|    time_elapsed         | 792          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0017696407 |
|    clip_fraction        | 0.0735       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.0894       |
|    learning_rate        | 5e-05        |
|    loss                 | 41.5         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.0029      |
|    std                  | 0.761        |
|    value_loss           | 99.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.122        |
|    crash                | 0.183        |
|    max_step             | 0            |
|    mean_ep_length       | 96.6         |
|    mean_reward          | 108          |
|    num_episodes         | 5            |
|    out_of_road          | 0.878        |
|    raw_action           | 0.42915475   |
|    route_completion     | 0.417        |
|    success_rate         | 0.2          |
|    total_cost           | 21.5         |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0073634824 |
|    arrive_dest          | 0.0944       |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.278        |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.0588       |
|    learning_rate        | 5e-05        |
|    loss                 | 33.7         |
|    max_step             | 0            |
|    n_updates            | 1400         |
|    out_of_road          | 0.906        |
|    policy_gradient_loss | 3.93e-05     |
|    route_completion     | 0.373        |
|    std                  | 0.761        |
|    total_cost           | 16.1         |
|    value_loss           | 80.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 370      |
|    ep_rew_mean     | 240      |
| time/              |          |
|    fps             | 450      |
|    iterations      | 71       |
|    time_elapsed    | 807      |
|    total_timesteps | 363520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 396          |
|    ep_rew_mean          | 255          |
| time/                   |              |
|    fps                  | 453          |
|    iterations           | 72           |
|    time_elapsed         | 813          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0037613488 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.0904       |
|    learning_rate        | 5e-05        |
|    loss                 | 38.7         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00133     |
|    std                  | 0.757        |
|    value_loss           | 92.3         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.119       |
|    crash                | 0.195       |
|    max_step             | 0           |
|    mean_ep_length       | 159         |
|    mean_reward          | 172         |
|    num_episodes         | 5           |
|    out_of_road          | 0.881       |
|    raw_action           | 0.4299367   |
|    route_completion     | 0.42        |
|    success_rate         | 0           |
|    total_cost           | 21.3        |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.002311178 |
|    arrive_dest          | 0.0919      |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.1         |
|    crash                | 0.276       |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.0281      |
|    learning_rate        | 5e-05       |
|    loss                 | 25.5        |
|    max_step             | 0           |
|    n_updates            | 1440        |
|    out_of_road          | 0.908       |
|    policy_gradient_loss | -0.000761   |
|    route_completion     | 0.369       |
|    std                  | 0.753       |
|    total_cost           | 15.7        |
|    value_loss           | 77.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 262      |
| time/              |          |
|    fps             | 453      |
|    iterations      | 73       |
|    time_elapsed    | 824      |
|    total_timesteps | 373760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 409          |
|    ep_rew_mean          | 270          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 74           |
|    time_elapsed         | 831          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0041992217 |
|    clip_fraction        | 0.089        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.0414       |
|    learning_rate        | 5e-05        |
|    loss                 | 66.4         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00116     |
|    std                  | 0.752        |
|    value_loss           | 90.2         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.126       |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 204         |
|    mean_reward          | 182         |
|    num_episodes         | 5           |
|    out_of_road          | 0.874       |
|    raw_action           | 0.43449378  |
|    route_completion     | 0.428       |
|    success_rate         | 0.3         |
|    total_cost           | 22.1        |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.009438385 |
|    arrive_dest          | 0.0947      |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.1         |
|    crash                | 0.274       |
|    entropy_loss         | -2.26       |
|    explained_variance   | 0.022       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.5        |
|    max_step             | 0           |
|    n_updates            | 1480        |
|    out_of_road          | 0.905       |
|    policy_gradient_loss | 0.00151     |
|    route_completion     | 0.372       |
|    std                  | 0.747       |
|    total_cost           | 15.7        |
|    value_loss           | 94.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 410      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 453      |
|    iterations      | 75       |
|    time_elapsed    | 847      |
|    total_timesteps | 384000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 410          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 76           |
|    time_elapsed         | 854          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0018212369 |
|    clip_fraction        | 0.0869       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.136        |
|    learning_rate        | 5e-05        |
|    loss                 | 36           |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00366     |
|    std                  | 0.747        |
|    value_loss           | 82.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.123        |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 134          |
|    mean_reward          | 194          |
|    num_episodes         | 5            |
|    out_of_road          | 0.877        |
|    raw_action           | 0.4347731    |
|    route_completion     | 0.43         |
|    success_rate         | 0            |
|    total_cost           | 21.6         |
| time/                   |              |
|    total_timesteps      | 390000       |
| train/                  |              |
|    approx_kl            | 0.0054249307 |
|    arrive_dest          | 0.0923       |
|    clip_fraction        | 0.197        |
|    clip_range           | 0.1          |
|    crash                | 0.272        |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.00599      |
|    learning_rate        | 5e-05        |
|    loss                 | 62           |
|    max_step             | 0            |
|    n_updates            | 1520         |
|    out_of_road          | 0.908        |
|    policy_gradient_loss | 0.000735     |
|    route_completion     | 0.369        |
|    std                  | 0.744        |
|    total_cost           | 15.4         |
|    value_loss           | 92.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 77       |
|    time_elapsed    | 865      |
|    total_timesteps | 394240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 396          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 78           |
|    time_elapsed         | 872          |
|    total_timesteps      | 399360       |
| train/                  |              |
|    approx_kl            | 0.0011467158 |
|    clip_fraction        | 0.0953       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.204        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.4         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.000979    |
|    std                  | 0.744        |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.12         |
|    crash                | 0.205        |
|    max_step             | 0            |
|    mean_ep_length       | 113          |
|    mean_reward          | 155          |
|    num_episodes         | 5            |
|    out_of_road          | 0.88         |
|    raw_action           | 0.4376253    |
|    route_completion     | 0.432        |
|    success_rate         | 0.1          |
|    total_cost           | 21.1         |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0017621396 |
|    arrive_dest          | 0.095        |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.228        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.8         |
|    max_step             | 0            |
|    n_updates            | 1560         |
|    out_of_road          | 0.905        |
|    policy_gradient_loss | 0.000747     |
|    route_completion     | 0.374        |
|    std                  | 0.743        |
|    total_cost           | 15.8         |
|    value_loss           | 94.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 395      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 79       |
|    time_elapsed    | 884      |
|    total_timesteps | 404480   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 264         |
| time/                   |             |
|    fps                  | 458         |
|    iterations           | 80          |
|    time_elapsed         | 892         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.001211035 |
|    clip_fraction        | 0.0773      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.142       |
|    learning_rate        | 5e-05       |
|    loss                 | 37.9        |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00144    |
|    std                  | 0.744       |
|    value_loss           | 110         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.127        |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 263          |
|    mean_reward          | 254          |
|    num_episodes         | 5            |
|    out_of_road          | 0.873        |
|    raw_action           | 0.43962613   |
|    route_completion     | 0.438        |
|    success_rate         | 0.4          |
|    total_cost           | 21.6         |
| time/                   |              |
|    total_timesteps      | 410000       |
| train/                  |              |
|    approx_kl            | 0.0025600153 |
|    arrive_dest          | 0.102        |
|    clip_fraction        | 0.0677       |
|    clip_range           | 0.1          |
|    crash                | 0.268        |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.269        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.9         |
|    max_step             | 0            |
|    n_updates            | 1600         |
|    out_of_road          | 0.898        |
|    policy_gradient_loss | -0.000807    |
|    route_completion     | 0.379        |
|    std                  | 0.742        |
|    total_cost           | 16.8         |
|    value_loss           | 125          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 81       |
|    time_elapsed    | 911      |
|    total_timesteps | 414720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 390          |
|    ep_rew_mean          | 268          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 82           |
|    time_elapsed         | 918          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0042986227 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.0243       |
|    learning_rate        | 5e-05        |
|    loss                 | 29.5         |
|    n_updates            | 1620         |
|    policy_gradient_loss | 0.00113      |
|    std                  | 0.739        |
|    value_loss           | 81.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.124        |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 175          |
|    num_episodes         | 5            |
|    out_of_road          | 0.876        |
|    raw_action           | 0.44140276   |
|    route_completion     | 0.44         |
|    success_rate         | 0.2          |
|    total_cost           | 21.4         |
| time/                   |              |
|    total_timesteps      | 420000       |
| train/                  |              |
|    approx_kl            | 0.0021433197 |
|    arrive_dest          | 0.11         |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.0868       |
|    learning_rate        | 5e-05        |
|    loss                 | 52.3         |
|    max_step             | 0            |
|    n_updates            | 1640         |
|    out_of_road          | 0.89         |
|    policy_gradient_loss | 0.00125      |
|    route_completion     | 0.384        |
|    std                  | 0.738        |
|    total_cost           | 17.6         |
|    value_loss           | 113          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 83       |
|    time_elapsed    | 934      |
|    total_timesteps | 424960   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.13         |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 216          |
|    num_episodes         | 5            |
|    out_of_road          | 0.87         |
|    raw_action           | 0.4415045    |
|    route_completion     | 0.445        |
|    success_rate         | 0.3          |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 430000       |
| train/                  |              |
|    approx_kl            | 0.0014812516 |
|    arrive_dest          | 0.112        |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.169        |
|    learning_rate        | 5e-05        |
|    loss                 | 37.4         |
|    max_step             | 0            |
|    n_updates            | 1660         |
|    out_of_road          | 0.888        |
|    policy_gradient_loss | -0.000344    |
|    route_completion     | 0.388        |
|    std                  | 0.738        |
|    total_cost           | 17.3         |
|    value_loss           | 106          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 242      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 84       |
|    time_elapsed    | 947      |
|    total_timesteps | 430080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 359          |
|    ep_rew_mean          | 245          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 85           |
|    time_elapsed         | 954          |
|    total_timesteps      | 435200       |
| train/                  |              |
|    approx_kl            | 0.0025722198 |
|    clip_fraction        | 0.0912       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.266        |
|    learning_rate        | 5e-05        |
|    loss                 | 89.7         |
|    n_updates            | 1680         |
|    policy_gradient_loss | -9.5e-05     |
|    std                  | 0.736        |
|    value_loss           | 153          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.136        |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 195          |
|    mean_reward          | 257          |
|    num_episodes         | 5            |
|    out_of_road          | 0.864        |
|    raw_action           | 0.4432403    |
|    route_completion     | 0.453        |
|    success_rate         | 0.4          |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0017106449 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    crash                | 0.268        |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.464        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.7         |
|    max_step             | 0            |
|    n_updates            | 1700         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | -0.00156     |
|    route_completion     | 0.394        |
|    std                  | 0.737        |
|    total_cost           | 17.7         |
|    value_loss           | 85.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    fps             | 453      |
|    iterations      | 86       |
|    time_elapsed    | 971      |
|    total_timesteps | 440320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 367          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 87           |
|    time_elapsed         | 978          |
|    total_timesteps      | 445440       |
| train/                  |              |
|    approx_kl            | 0.0017634224 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.544        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.2         |
|    n_updates            | 1720         |
|    policy_gradient_loss | -0.000573    |
|    std                  | 0.738        |
|    value_loss           | 117          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.138        |
|    crash                | 0.209        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 160          |
|    num_episodes         | 5            |
|    out_of_road          | 0.862        |
|    raw_action           | 0.444194     |
|    route_completion     | 0.456        |
|    success_rate         | 0.2          |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 450000       |
| train/                  |              |
|    approx_kl            | 0.0012062311 |
|    arrive_dest          | 0.12         |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.225        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.7         |
|    max_step             | 0            |
|    n_updates            | 1740         |
|    out_of_road          | 0.88         |
|    policy_gradient_loss | 0.00189      |
|    route_completion     | 0.397        |
|    std                  | 0.737        |
|    total_cost           | 17.5         |
|    value_loss           | 91.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 453      |
|    iterations      | 88       |
|    time_elapsed    | 992      |
|    total_timesteps | 450560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 387          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 89           |
|    time_elapsed         | 999          |
|    total_timesteps      | 455680       |
| train/                  |              |
|    approx_kl            | 0.0024608644 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.15         |
|    learning_rate        | 5e-05        |
|    loss                 | 52.7         |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00135     |
|    std                  | 0.735        |
|    value_loss           | 142          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.139        |
|    crash                | 0.209        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.861        |
|    raw_action           | 0.4437326    |
|    route_completion     | 0.459        |
|    success_rate         | 0.1          |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 460000       |
| train/                  |              |
|    approx_kl            | 0.0031940974 |
|    arrive_dest          | 0.117        |
|    clip_fraction        | 0.19         |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.234        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.8         |
|    max_step             | 0            |
|    n_updates            | 1780         |
|    out_of_road          | 0.883        |
|    policy_gradient_loss | 0.00273      |
|    route_completion     | 0.396        |
|    std                  | 0.733        |
|    total_cost           | 17.1         |
|    value_loss           | 124          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 90       |
|    time_elapsed    | 1009     |
|    total_timesteps | 460800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 380          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 91           |
|    time_elapsed         | 1016         |
|    total_timesteps      | 465920       |
| train/                  |              |
|    approx_kl            | 0.0072842278 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.146        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.2         |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.000739    |
|    std                  | 0.733        |
|    value_loss           | 119          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.145       |
|    crash                | 0.204       |
|    max_step             | 0           |
|    mean_ep_length       | 207         |
|    mean_reward          | 234         |
|    num_episodes         | 5           |
|    out_of_road          | 0.855       |
|    raw_action           | 0.4438623   |
|    route_completion     | 0.464       |
|    success_rate         | 0.4         |
|    total_cost           | 21.3        |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.003113464 |
|    arrive_dest          | 0.123       |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    crash                | 0.264       |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.0904      |
|    learning_rate        | 5e-05       |
|    loss                 | 69.5        |
|    max_step             | 0           |
|    n_updates            | 1820        |
|    out_of_road          | 0.877       |
|    policy_gradient_loss | 0.00194     |
|    route_completion     | 0.401       |
|    std                  | 0.729       |
|    total_cost           | 17.7        |
|    value_loss           | 148         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 92       |
|    time_elapsed    | 1036     |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 374         |
|    ep_rew_mean          | 285         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 93          |
|    time_elapsed         | 1042        |
|    total_timesteps      | 476160      |
| train/                  |             |
|    approx_kl            | 0.004750776 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.285       |
|    learning_rate        | 5e-05       |
|    loss                 | 52          |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.000867   |
|    std                  | 0.728       |
|    value_loss           | 151         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.146       |
|    crash                | 0.208       |
|    max_step             | 0           |
|    mean_ep_length       | 178         |
|    mean_reward          | 207         |
|    num_episodes         | 5           |
|    out_of_road          | 0.854       |
|    raw_action           | 0.4441976   |
|    route_completion     | 0.468       |
|    success_rate         | 0.1         |
|    total_cost           | 21.4        |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.017733878 |
|    arrive_dest          | 0.121       |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.1         |
|    crash                | 0.271       |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.0942      |
|    learning_rate        | 5e-05       |
|    loss                 | 42.5        |
|    max_step             | 0           |
|    n_updates            | 1860        |
|    out_of_road          | 0.879       |
|    policy_gradient_loss | 0.00742     |
|    route_completion     | 0.4         |
|    std                  | 0.726       |
|    total_cost           | 17.4        |
|    value_loss           | 124         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 94       |
|    time_elapsed    | 1055     |
|    total_timesteps | 481280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 95           |
|    time_elapsed         | 1062         |
|    total_timesteps      | 486400       |
| train/                  |              |
|    approx_kl            | 0.0069484646 |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.202        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.3         |
|    n_updates            | 1880         |
|    policy_gradient_loss | 0.00102      |
|    std                  | 0.723        |
|    value_loss           | 148          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.151        |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 197          |
|    mean_reward          | 204          |
|    num_episodes         | 5            |
|    out_of_road          | 0.849        |
|    raw_action           | 0.4456963    |
|    route_completion     | 0.473        |
|    success_rate         | 0.3          |
|    total_cost           | 21.6         |
| time/                   |              |
|    total_timesteps      | 490000       |
| train/                  |              |
|    approx_kl            | 0.0010957026 |
|    arrive_dest          | 0.122        |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    crash                | 0.273        |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.224        |
|    learning_rate        | 5e-05        |
|    loss                 | 95.6         |
|    max_step             | 0            |
|    n_updates            | 1900         |
|    out_of_road          | 0.878        |
|    policy_gradient_loss | 0.000806     |
|    route_completion     | 0.402        |
|    std                  | 0.722        |
|    total_cost           | 17.3         |
|    value_loss           | 171          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 96       |
|    time_elapsed    | 1078     |
|    total_timesteps | 491520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 97           |
|    time_elapsed         | 1084         |
|    total_timesteps      | 496640       |
| train/                  |              |
|    approx_kl            | 0.0056546945 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.262        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.7         |
|    n_updates            | 1920         |
|    policy_gradient_loss | -0.00028     |
|    std                  | 0.724        |
|    value_loss           | 151          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.148       |
|    crash                | 0.212       |
|    max_step             | 0           |
|    mean_ep_length       | 117         |
|    mean_reward          | 137         |
|    num_episodes         | 5           |
|    out_of_road          | 0.852       |
|    raw_action           | 0.4461406   |
|    route_completion     | 0.472       |
|    success_rate         | 0           |
|    total_cost           | 21.2        |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.009626768 |
|    arrive_dest          | 0.12        |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.1         |
|    crash                | 0.272       |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.238       |
|    learning_rate        | 5e-05       |
|    loss                 | 49.4        |
|    max_step             | 0           |
|    n_updates            | 1940        |
|    out_of_road          | 0.88        |
|    policy_gradient_loss | 0.000141    |
|    route_completion     | 0.401       |
|    std                  | 0.721       |
|    total_cost           | 17          |
|    value_loss           | 116         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 98       |
|    time_elapsed    | 1097     |
|    total_timesteps | 501760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 265          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 99           |
|    time_elapsed         | 1104         |
|    total_timesteps      | 506880       |
| train/                  |              |
|    approx_kl            | 0.0015153175 |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.233        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.9         |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.723        |
|    value_loss           | 144          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.145        |
|    crash                | 0.208        |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 184          |
|    num_episodes         | 5            |
|    out_of_road          | 0.855        |
|    raw_action           | 0.44910058   |
|    route_completion     | 0.473        |
|    success_rate         | 0.3          |
|    total_cost           | 20.9         |
| time/                   |              |
|    total_timesteps      | 510000       |
| train/                  |              |
|    approx_kl            | 0.0019109469 |
|    arrive_dest          | 0.129        |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.31         |
|    learning_rate        | 5e-05        |
|    loss                 | 56.4         |
|    max_step             | 0            |
|    n_updates            | 1980         |
|    out_of_road          | 0.871        |
|    policy_gradient_loss | -0.000738    |
|    route_completion     | 0.406        |
|    std                  | 0.722        |
|    total_cost           | 16.8         |
|    value_loss           | 142          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 100      |
|    time_elapsed    | 1118     |
|    total_timesteps | 512000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 259          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 101          |
|    time_elapsed         | 1125         |
|    total_timesteps      | 517120       |
| train/                  |              |
|    approx_kl            | 0.0013451342 |
|    clip_fraction        | 0.09         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.431        |
|    learning_rate        | 5e-05        |
|    loss                 | 84.6         |
|    n_updates            | 2000         |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.721        |
|    value_loss           | 166          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.15        |
|    crash                | 0.212       |
|    max_step             | 0           |
|    mean_ep_length       | 190         |
|    mean_reward          | 257         |
|    num_episodes         | 5           |
|    out_of_road          | 0.85        |
|    raw_action           | 0.4508732   |
|    route_completion     | 0.481       |
|    success_rate         | 0.2         |
|    total_cost           | 20.9        |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.002070525 |
|    arrive_dest          | 0.127       |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.1         |
|    crash                | 0.273       |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.404       |
|    learning_rate        | 5e-05       |
|    loss                 | 97.9        |
|    max_step             | 0           |
|    n_updates            | 2020        |
|    out_of_road          | 0.873       |
|    policy_gradient_loss | 0.000349    |
|    route_completion     | 0.404       |
|    std                  | 0.722       |
|    total_cost           | 16.6        |
|    value_loss           | 152         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 102      |
|    time_elapsed    | 1139     |
|    total_timesteps | 522240   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 348         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 459         |
|    iterations           | 103         |
|    time_elapsed         | 1146        |
|    total_timesteps      | 527360      |
| train/                  |             |
|    approx_kl            | 0.002570543 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.452       |
|    learning_rate        | 5e-05       |
|    loss                 | 52.6        |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00129    |
|    std                  | 0.722       |
|    value_loss           | 136         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.147       |
|    crash                | 0.219       |
|    max_step             | 0           |
|    mean_ep_length       | 116         |
|    mean_reward          | 150         |
|    num_episodes         | 5           |
|    out_of_road          | 0.853       |
|    raw_action           | 0.4522324   |
|    route_completion     | 0.479       |
|    success_rate         | 0.1         |
|    total_cost           | 20.6        |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.002249084 |
|    arrive_dest          | 0.128       |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.1         |
|    crash                | 0.272       |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.263       |
|    learning_rate        | 5e-05       |
|    loss                 | 43.5        |
|    max_step             | 0           |
|    n_updates            | 2060        |
|    out_of_road          | 0.872       |
|    policy_gradient_loss | 0.0018      |
|    route_completion     | 0.406       |
|    std                  | 0.72        |
|    total_cost           | 16.7        |
|    value_loss           | 139         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 104      |
|    time_elapsed    | 1163     |
|    total_timesteps | 532480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 342          |
|    ep_rew_mean          | 257          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 105          |
|    time_elapsed         | 1170         |
|    total_timesteps      | 537600       |
| train/                  |              |
|    approx_kl            | 0.0020178559 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.468        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.2         |
|    n_updates            | 2080         |
|    policy_gradient_loss | -0.00213     |
|    std                  | 0.719        |
|    value_loss           | 156          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.152        |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 233          |
|    mean_reward          | 213          |
|    num_episodes         | 5            |
|    out_of_road          | 0.848        |
|    raw_action           | 0.45311064   |
|    route_completion     | 0.482        |
|    success_rate         | 0.2          |
|    total_cost           | 21.1         |
| time/                   |              |
|    total_timesteps      | 540000       |
| train/                  |              |
|    approx_kl            | 0.0018593787 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.0835       |
|    clip_range           | 0.1          |
|    crash                | 0.274        |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.308        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.4         |
|    max_step             | 0            |
|    n_updates            | 2100         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | -0.00144     |
|    route_completion     | 0.402        |
|    std                  | 0.718        |
|    total_cost           | 16.5         |
|    value_loss           | 169          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 106      |
|    time_elapsed    | 1183     |
|    total_timesteps | 542720   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 340         |
|    ep_rew_mean          | 260         |
| time/                   |             |
|    fps                  | 459         |
|    iterations           | 107         |
|    time_elapsed         | 1191        |
|    total_timesteps      | 547840      |
| train/                  |             |
|    approx_kl            | 0.005908712 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.417       |
|    learning_rate        | 5e-05       |
|    loss                 | 71.1        |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.00135     |
|    std                  | 0.717       |
|    value_loss           | 134         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.16        |
|    crash                | 0.225       |
|    max_step             | 0           |
|    mean_ep_length       | 200         |
|    mean_reward          | 179         |
|    num_episodes         | 5           |
|    out_of_road          | 0.84        |
|    raw_action           | 0.45369804  |
|    route_completion     | 0.487       |
|    success_rate         | 0.4         |
|    total_cost           | 21.5        |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.002844392 |
|    arrive_dest          | 0.127       |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.1         |
|    crash                | 0.273       |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.415       |
|    learning_rate        | 5e-05       |
|    loss                 | 66.3        |
|    max_step             | 0           |
|    n_updates            | 2140        |
|    out_of_road          | 0.873       |
|    policy_gradient_loss | -0.000541   |
|    route_completion     | 0.405       |
|    std                  | 0.718       |
|    total_cost           | 16.3        |
|    value_loss           | 134         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 108      |
|    time_elapsed    | 1205     |
|    total_timesteps | 552960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 266          |
| time/                   |              |
|    fps                  | 460          |
|    iterations           | 109          |
|    time_elapsed         | 1212         |
|    total_timesteps      | 558080       |
| train/                  |              |
|    approx_kl            | 0.0016021726 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.466        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.7         |
|    n_updates            | 2160         |
|    policy_gradient_loss | -0.000548    |
|    std                  | 0.717        |
|    value_loss           | 166          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.161        |
|    crash                | 0.225        |
|    max_step             | 0            |
|    mean_ep_length       | 149          |
|    mean_reward          | 169          |
|    num_episodes         | 5            |
|    out_of_road          | 0.839        |
|    raw_action           | 0.45536917   |
|    route_completion     | 0.486        |
|    success_rate         | 0.3          |
|    total_cost           | 21.3         |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0019779443 |
|    arrive_dest          | 0.132        |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.275        |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.538        |
|    learning_rate        | 5e-05        |
|    loss                 | 84.1         |
|    max_step             | 0            |
|    n_updates            | 2180         |
|    out_of_road          | 0.868        |
|    policy_gradient_loss | 0.0014       |
|    route_completion     | 0.411        |
|    std                  | 0.714        |
|    total_cost           | 16.8         |
|    value_loss           | 138          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 110      |
|    time_elapsed    | 1230     |
|    total_timesteps | 563200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 111          |
|    time_elapsed         | 1237         |
|    total_timesteps      | 568320       |
| train/                  |              |
|    approx_kl            | 0.0024589084 |
|    clip_fraction        | 0.0794       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.538        |
|    learning_rate        | 5e-05        |
|    loss                 | 94.5         |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.000737    |
|    std                  | 0.712        |
|    value_loss           | 164          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.161        |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 192          |
|    mean_reward          | 288          |
|    num_episodes         | 5            |
|    out_of_road          | 0.839        |
|    raw_action           | 0.4557611    |
|    route_completion     | 0.491        |
|    success_rate         | 0.1          |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 570000       |
| train/                  |              |
|    approx_kl            | 0.0038027938 |
|    arrive_dest          | 0.13         |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    crash                | 0.277        |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.7          |
|    learning_rate        | 5e-05        |
|    loss                 | 37.7         |
|    max_step             | 0            |
|    n_updates            | 2220         |
|    out_of_road          | 0.87         |
|    policy_gradient_loss | -0.00158     |
|    route_completion     | 0.411        |
|    std                  | 0.711        |
|    total_cost           | 16.6         |
|    value_loss           | 125          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 459      |
|    iterations      | 112      |
|    time_elapsed    | 1249     |
|    total_timesteps | 573440   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 344         |
|    ep_rew_mean          | 272         |
| time/                   |             |
|    fps                  | 460         |
|    iterations           | 113         |
|    time_elapsed         | 1257        |
|    total_timesteps      | 578560      |
| train/                  |             |
|    approx_kl            | 0.004059597 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.484       |
|    learning_rate        | 5e-05       |
|    loss                 | 87.6        |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.00126     |
|    std                  | 0.709       |
|    value_loss           | 176         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.162        |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 218          |
|    mean_reward          | 176          |
|    num_episodes         | 5            |
|    out_of_road          | 0.838        |
|    raw_action           | 0.455471     |
|    route_completion     | 0.495        |
|    success_rate         | 0.1          |
|    total_cost           | 21.6         |
| time/                   |              |
|    total_timesteps      | 580000       |
| train/                  |              |
|    approx_kl            | 0.0013717853 |
|    arrive_dest          | 0.128        |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    crash                | 0.279        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.483        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.5         |
|    max_step             | 0            |
|    n_updates            | 2260         |
|    out_of_road          | 0.872        |
|    policy_gradient_loss | -0.000348    |
|    route_completion     | 0.411        |
|    std                  | 0.709        |
|    total_cost           | 16.6         |
|    value_loss           | 150          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 114      |
|    time_elapsed    | 1272     |
|    total_timesteps | 583680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 283          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 115          |
|    time_elapsed         | 1280         |
|    total_timesteps      | 588800       |
| train/                  |              |
|    approx_kl            | 0.0023437026 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.598        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.8         |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.000265    |
|    std                  | 0.707        |
|    value_loss           | 127          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.169        |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 201          |
|    mean_reward          | 147          |
|    num_episodes         | 5            |
|    out_of_road          | 0.831        |
|    raw_action           | 0.45663306   |
|    route_completion     | 0.498        |
|    success_rate         | 0.4          |
|    total_cost           | 22.1         |
| time/                   |              |
|    total_timesteps      | 590000       |
| train/                  |              |
|    approx_kl            | 0.0016981873 |
|    arrive_dest          | 0.129        |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    crash                | 0.278        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.559        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.8         |
|    max_step             | 0            |
|    n_updates            | 2300         |
|    out_of_road          | 0.871        |
|    policy_gradient_loss | -0.001       |
|    route_completion     | 0.414        |
|    std                  | 0.709        |
|    total_cost           | 16.7         |
|    value_loss           | 145          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 116      |
|    time_elapsed    | 1295     |
|    total_timesteps | 593920   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 355         |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 460         |
|    iterations           | 117         |
|    time_elapsed         | 1302        |
|    total_timesteps      | 599040      |
| train/                  |             |
|    approx_kl            | 0.006453281 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.535       |
|    learning_rate        | 5e-05       |
|    loss                 | 47.7        |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.000372   |
|    std                  | 0.707       |
|    value_loss           | 135         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.17        |
|    crash                | 0.243       |
|    max_step             | 0           |
|    mean_ep_length       | 209         |
|    mean_reward          | 151         |
|    num_episodes         | 5           |
|    out_of_road          | 0.83        |
|    raw_action           | 0.4581149   |
|    route_completion     | 0.498       |
|    success_rate         | 0.4         |
|    total_cost           | 22.6        |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.008124844 |
|    arrive_dest          | 0.137       |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.1         |
|    crash                | 0.277       |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.655       |
|    learning_rate        | 5e-05       |
|    loss                 | 59.4        |
|    max_step             | 0           |
|    n_updates            | 2340        |
|    out_of_road          | 0.863       |
|    policy_gradient_loss | -0.00101    |
|    route_completion     | 0.418       |
|    std                  | 0.707       |
|    total_cost           | 16.8        |
|    value_loss           | 146         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 118      |
|    time_elapsed    | 1318     |
|    total_timesteps | 604160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 298          |
| time/                   |              |
|    fps                  | 460          |
|    iterations           | 119          |
|    time_elapsed         | 1324         |
|    total_timesteps      | 609280       |
| train/                  |              |
|    approx_kl            | 0.0016093074 |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.649        |
|    learning_rate        | 5e-05        |
|    loss                 | 88.2         |
|    n_updates            | 2360         |
|    policy_gradient_loss | -6.72e-05    |
|    std                  | 0.705        |
|    value_loss           | 150          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.17         |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 125          |
|    mean_reward          | 151          |
|    num_episodes         | 5            |
|    out_of_road          | 0.83         |
|    raw_action           | 0.45906723   |
|    route_completion     | 0.498        |
|    success_rate         | 0.2          |
|    total_cost           | 22.3         |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0016238298 |
|    arrive_dest          | 0.138        |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    crash                | 0.282        |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.536        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.5         |
|    max_step             | 0            |
|    n_updates            | 2380         |
|    out_of_road          | 0.862        |
|    policy_gradient_loss | 0.00217      |
|    route_completion     | 0.421        |
|    std                  | 0.704        |
|    total_cost           | 16.6         |
|    value_loss           | 124          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 459      |
|    iterations      | 120      |
|    time_elapsed    | 1338     |
|    total_timesteps | 614400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 365          |
|    ep_rew_mean          | 308          |
| time/                   |              |
|    fps                  | 460          |
|    iterations           | 121          |
|    time_elapsed         | 1345         |
|    total_timesteps      | 619520       |
| train/                  |              |
|    approx_kl            | 0.0026750392 |
|    clip_fraction        | 0.0929       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.606        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.1         |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.000591    |
|    std                  | 0.703        |
|    value_loss           | 154          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.174       |
|    crash                | 0.252       |
|    max_step             | 0           |
|    mean_ep_length       | 229         |
|    mean_reward          | 161         |
|    num_episodes         | 5           |
|    out_of_road          | 0.826       |
|    raw_action           | 0.45988643  |
|    route_completion     | 0.5         |
|    success_rate         | 0.5         |
|    total_cost           | 23.1        |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.002158278 |
|    arrive_dest          | 0.145       |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.1         |
|    crash                | 0.284       |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.626       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.7        |
|    max_step             | 0           |
|    n_updates            | 2420        |
|    out_of_road          | 0.855       |
|    policy_gradient_loss | -0.000312   |
|    route_completion     | 0.426       |
|    std                  | 0.702       |
|    total_cost           | 17.5        |
|    value_loss           | 116         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 122      |
|    time_elapsed    | 1363     |
|    total_timesteps | 624640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 359          |
|    ep_rew_mean          | 304          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 123          |
|    time_elapsed         | 1370         |
|    total_timesteps      | 629760       |
| train/                  |              |
|    approx_kl            | 0.0017322947 |
|    clip_fraction        | 0.1          |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.481        |
|    learning_rate        | 5e-05        |
|    loss                 | 91           |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.00134     |
|    std                  | 0.699        |
|    value_loss           | 165          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.175        |
|    crash                | 0.251        |
|    max_step             | 0            |
|    mean_ep_length       | 150          |
|    mean_reward          | 222          |
|    num_episodes         | 5            |
|    out_of_road          | 0.825        |
|    raw_action           | 0.46034062   |
|    route_completion     | 0.504        |
|    success_rate         | 0.1          |
|    total_cost           | 22.7         |
| time/                   |              |
|    total_timesteps      | 630000       |
| train/                  |              |
|    approx_kl            | 0.0048511247 |
|    arrive_dest          | 0.143        |
|    clip_fraction        | 0.263        |
|    clip_range           | 0.1          |
|    crash                | 0.286        |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.608        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.2         |
|    max_step             | 0            |
|    n_updates            | 2460         |
|    out_of_road          | 0.857        |
|    policy_gradient_loss | 0.00818      |
|    route_completion     | 0.426        |
|    std                  | 0.697        |
|    total_cost           | 17.3         |
|    value_loss           | 119          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 124      |
|    time_elapsed    | 1384     |
|    total_timesteps | 634880   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.172        |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.828        |
|    raw_action           | 0.46143207   |
|    route_completion     | 0.501        |
|    success_rate         | 0            |
|    total_cost           | 22.4         |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0016041247 |
|    arrive_dest          | 0.141        |
|    clip_fraction        | 0.138        |
|    clip_range           | 0.1          |
|    crash                | 0.287        |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.476        |
|    learning_rate        | 5e-05        |
|    loss                 | 98.4         |
|    max_step             | 0            |
|    n_updates            | 2480         |
|    out_of_road          | 0.859        |
|    policy_gradient_loss | -0.000346    |
|    route_completion     | 0.426        |
|    std                  | 0.698        |
|    total_cost           | 17           |
|    value_loss           | 194          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 125      |
|    time_elapsed    | 1397     |
|    total_timesteps | 640000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 355         |
|    ep_rew_mean          | 307         |
| time/                   |             |
|    fps                  | 459         |
|    iterations           | 126         |
|    time_elapsed         | 1405        |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.003629354 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.542       |
|    learning_rate        | 5e-05       |
|    loss                 | 146         |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.000401    |
|    std                  | 0.697       |
|    value_loss           | 192         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.169        |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 136          |
|    mean_reward          | 144          |
|    num_episodes         | 5            |
|    out_of_road          | 0.831        |
|    raw_action           | 0.46311465   |
|    route_completion     | 0.5          |
|    success_rate         | 0            |
|    total_cost           | 22.1         |
| time/                   |              |
|    total_timesteps      | 650000       |
| train/                  |              |
|    approx_kl            | 0.0017485833 |
|    arrive_dest          | 0.138        |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    crash                | 0.289        |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.768        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.4         |
|    max_step             | 0            |
|    n_updates            | 2520         |
|    out_of_road          | 0.862        |
|    policy_gradient_loss | -0.00242     |
|    route_completion     | 0.426        |
|    std                  | 0.695        |
|    total_cost           | 16.8         |
|    value_loss           | 128          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 127      |
|    time_elapsed    | 1416     |
|    total_timesteps | 650240   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 367         |
|    ep_rew_mean          | 308         |
| time/                   |             |
|    fps                  | 460         |
|    iterations           | 128         |
|    time_elapsed         | 1423        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.001040256 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.862       |
|    learning_rate        | 5e-05       |
|    loss                 | 102         |
|    n_updates            | 2540        |
|    policy_gradient_loss | 0.00295     |
|    std                  | 0.694       |
|    value_loss           | 132         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.173       |
|    crash                | 0.255       |
|    max_step             | 0           |
|    mean_ep_length       | 203         |
|    mean_reward          | 224         |
|    num_episodes         | 5           |
|    out_of_road          | 0.827       |
|    raw_action           | 0.4642881   |
|    route_completion     | 0.503       |
|    success_rate         | 0.4         |
|    total_cost           | 22.3        |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.002334475 |
|    arrive_dest          | 0.142       |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.1         |
|    crash                | 0.294       |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.516       |
|    learning_rate        | 5e-05       |
|    loss                 | 80.8        |
|    max_step             | 0           |
|    n_updates            | 2560        |
|    out_of_road          | 0.858       |
|    policy_gradient_loss | 0.00366     |
|    route_completion     | 0.43        |
|    std                  | 0.692       |
|    total_cost           | 17.2        |
|    value_loss           | 139         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 129      |
|    time_elapsed    | 1441     |
|    total_timesteps | 660480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 377          |
|    ep_rew_mean          | 300          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 130          |
|    time_elapsed         | 1449         |
|    total_timesteps      | 665600       |
| train/                  |              |
|    approx_kl            | 0.0010605466 |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.574        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.3         |
|    n_updates            | 2580         |
|    policy_gradient_loss | 0.00104      |
|    std                  | 0.693        |
|    value_loss           | 185          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.176        |
|    crash                | 0.254        |
|    max_step             | 0            |
|    mean_ep_length       | 185          |
|    mean_reward          | 161          |
|    num_episodes         | 5            |
|    out_of_road          | 0.824        |
|    raw_action           | 0.46441114   |
|    route_completion     | 0.504        |
|    success_rate         | 0.3          |
|    total_cost           | 22.5         |
| time/                   |              |
|    total_timesteps      | 670000       |
| train/                  |              |
|    approx_kl            | 0.0050257156 |
|    arrive_dest          | 0.143        |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    crash                | 0.293        |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.504        |
|    learning_rate        | 5e-05        |
|    loss                 | 95.1         |
|    max_step             | 0            |
|    n_updates            | 2600         |
|    out_of_road          | 0.857        |
|    policy_gradient_loss | -0.000664    |
|    route_completion     | 0.43         |
|    std                  | 0.694        |
|    total_cost           | 17.1         |
|    value_loss           | 191          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 365      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 131      |
|    time_elapsed    | 1465     |
|    total_timesteps | 670720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 372          |
|    ep_rew_mean          | 291          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 132          |
|    time_elapsed         | 1472         |
|    total_timesteps      | 675840       |
| train/                  |              |
|    approx_kl            | 0.0044195205 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.568        |
|    learning_rate        | 5e-05        |
|    loss                 | 104          |
|    n_updates            | 2620         |
|    policy_gradient_loss | -0.000502    |
|    std                  | 0.693        |
|    value_loss           | 181          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.176        |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 154          |
|    mean_reward          | 210          |
|    num_episodes         | 5            |
|    out_of_road          | 0.824        |
|    raw_action           | 0.4647563    |
|    route_completion     | 0.505        |
|    success_rate         | 0.3          |
|    total_cost           | 22.3         |
| time/                   |              |
|    total_timesteps      | 680000       |
| train/                  |              |
|    approx_kl            | 0.0010056583 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.0844       |
|    clip_range           | 0.1          |
|    crash                | 0.297        |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.8         |
|    max_step             | 0            |
|    n_updates            | 2640         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | -0.000887    |
|    route_completion     | 0.433        |
|    std                  | 0.691        |
|    total_cost           | 17.2         |
|    value_loss           | 126          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 133      |
|    time_elapsed    | 1488     |
|    total_timesteps | 680960   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 371         |
|    ep_rew_mean          | 287         |
| time/                   |             |
|    fps                  | 458         |
|    iterations           | 134         |
|    time_elapsed         | 1495        |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.012583686 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.689       |
|    learning_rate        | 5e-05       |
|    loss                 | 84.1        |
|    n_updates            | 2660        |
|    policy_gradient_loss | 0.00664     |
|    std                  | 0.69        |
|    value_loss           | 155         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.177        |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 169          |
|    mean_reward          | 205          |
|    num_episodes         | 5            |
|    out_of_road          | 0.823        |
|    raw_action           | 0.46519452   |
|    route_completion     | 0.505        |
|    success_rate         | 0.2          |
|    total_cost           | 22.1         |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0016206022 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    crash                | 0.299        |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.9         |
|    max_step             | 0            |
|    n_updates            | 2680         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | -0.000207    |
|    route_completion     | 0.434        |
|    std                  | 0.69         |
|    total_cost           | 17.2         |
|    value_loss           | 96           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 135      |
|    time_elapsed    | 1514     |
|    total_timesteps | 691200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 339          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 136          |
|    time_elapsed         | 1521         |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 0.0023035235 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.755        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.9         |
|    n_updates            | 2700         |
|    policy_gradient_loss | 8.36e-05     |
|    std                  | 0.69         |
|    value_loss           | 178          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.174       |
|    crash                | 0.249       |
|    max_step             | 0           |
|    mean_ep_length       | 111         |
|    mean_reward          | 141         |
|    num_episodes         | 5           |
|    out_of_road          | 0.826       |
|    raw_action           | 0.46518973  |
|    route_completion     | 0.503       |
|    success_rate         | 0.1         |
|    total_cost           | 21.9        |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.004617436 |
|    arrive_dest          | 0.149       |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.1         |
|    crash                | 0.294       |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.631       |
|    learning_rate        | 5e-05       |
|    loss                 | 90.5        |
|    max_step             | 0           |
|    n_updates            | 2720        |
|    out_of_road          | 0.851       |
|    policy_gradient_loss | 0.000694    |
|    route_completion     | 0.436       |
|    std                  | 0.688       |
|    total_cost           | 17          |
|    value_loss           | 176         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 137      |
|    time_elapsed    | 1536     |
|    total_timesteps | 701440   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 138          |
|    time_elapsed         | 1545         |
|    total_timesteps      | 706560       |
| train/                  |              |
|    approx_kl            | 0.0037396662 |
|    clip_fraction        | 0.0972       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.713        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.7         |
|    n_updates            | 2740         |
|    policy_gradient_loss | -0.000586    |
|    std                  | 0.687        |
|    value_loss           | 112          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.172        |
|    crash                | 0.251        |
|    max_step             | 0            |
|    mean_ep_length       | 154          |
|    mean_reward          | 189          |
|    num_episodes         | 5            |
|    out_of_road          | 0.828        |
|    raw_action           | 0.4651985    |
|    route_completion     | 0.504        |
|    success_rate         | 0            |
|    total_cost           | 21.6         |
| time/                   |              |
|    total_timesteps      | 710000       |
| train/                  |              |
|    approx_kl            | 0.0056709973 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.183        |
|    clip_range           | 0.1          |
|    crash                | 0.29         |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.852        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.7         |
|    max_step             | 0            |
|    n_updates            | 2760         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | 0.00204      |
|    route_completion     | 0.434        |
|    std                  | 0.686        |
|    total_cost           | 16.8         |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 285      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 139      |
|    time_elapsed    | 1556     |
|    total_timesteps | 711680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 338          |
|    ep_rew_mean          | 278          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 140          |
|    time_elapsed         | 1564         |
|    total_timesteps      | 716800       |
| train/                  |              |
|    approx_kl            | 0.0013733602 |
|    clip_fraction        | 0.0966       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5e-05        |
|    loss                 | 135          |
|    n_updates            | 2780         |
|    policy_gradient_loss | -0.000253    |
|    std                  | 0.688        |
|    value_loss           | 197          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.172        |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 173          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.828        |
|    raw_action           | 0.46597448   |
|    route_completion     | 0.505        |
|    success_rate         | 0.1          |
|    total_cost           | 21.8         |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0019943707 |
|    arrive_dest          | 0.144        |
|    clip_fraction        | 0.097        |
|    clip_range           | 0.1          |
|    crash                | 0.297        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.476        |
|    learning_rate        | 5e-05        |
|    loss                 | 104          |
|    max_step             | 0            |
|    n_updates            | 2800         |
|    out_of_road          | 0.856        |
|    policy_gradient_loss | -0.000357    |
|    route_completion     | 0.434        |
|    std                  | 0.688        |
|    total_cost           | 16.6         |
|    value_loss           | 197          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 141      |
|    time_elapsed    | 1575     |
|    total_timesteps | 721920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 328          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 142          |
|    time_elapsed         | 1584         |
|    total_timesteps      | 727040       |
| train/                  |              |
|    approx_kl            | 0.0015719632 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.9         |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.687        |
|    value_loss           | 135          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.175        |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 265          |
|    num_episodes         | 5            |
|    out_of_road          | 0.825        |
|    raw_action           | 0.46665823   |
|    route_completion     | 0.509        |
|    success_rate         | 0.4          |
|    total_cost           | 21.6         |
| time/                   |              |
|    total_timesteps      | 730000       |
| train/                  |              |
|    approx_kl            | 0.0009127643 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    crash                | 0.299        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.699        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.2         |
|    max_step             | 0            |
|    n_updates            | 2840         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | 0.00115      |
|    route_completion     | 0.439        |
|    std                  | 0.689        |
|    total_cost           | 16.7         |
|    value_loss           | 156          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 143      |
|    time_elapsed    | 1600     |
|    total_timesteps | 732160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 320        |
|    ep_rew_mean          | 264        |
| time/                   |            |
|    fps                  | 457        |
|    iterations           | 144        |
|    time_elapsed         | 1610       |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.02471565 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.07      |
|    explained_variance   | 0.654      |
|    learning_rate        | 5e-05      |
|    loss                 | 83.6       |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.00251    |
|    std                  | 0.689      |
|    value_loss           | 166        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.178        |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 181          |
|    mean_reward          | 238          |
|    num_episodes         | 5            |
|    out_of_road          | 0.822        |
|    raw_action           | 0.46690252   |
|    route_completion     | 0.512        |
|    success_rate         | 0.2          |
|    total_cost           | 21.5         |
| time/                   |              |
|    total_timesteps      | 740000       |
| train/                  |              |
|    approx_kl            | 0.0013050894 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    crash                | 0.3          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.433        |
|    learning_rate        | 5e-05        |
|    loss                 | 147          |
|    max_step             | 0            |
|    n_updates            | 2880         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.000405    |
|    route_completion     | 0.44         |
|    std                  | 0.689        |
|    total_cost           | 16.6         |
|    value_loss           | 292          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 145      |
|    time_elapsed    | 1624     |
|    total_timesteps | 742400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 314          |
|    ep_rew_mean          | 257          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 146          |
|    time_elapsed         | 1632         |
|    total_timesteps      | 747520       |
| train/                  |              |
|    approx_kl            | 0.0018327382 |
|    clip_fraction        | 0.17         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.47         |
|    learning_rate        | 5e-05        |
|    loss                 | 69           |
|    n_updates            | 2900         |
|    policy_gradient_loss | 0.000656     |
|    std                  | 0.689        |
|    value_loss           | 202          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 213          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.46733508   |
|    route_completion     | 0.511        |
|    success_rate         | 0.2          |
|    total_cost           | 21.3         |
| time/                   |              |
|    total_timesteps      | 750000       |
| train/                  |              |
|    approx_kl            | 0.0073687667 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    crash                | 0.301        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.648        |
|    learning_rate        | 5e-05        |
|    loss                 | 101          |
|    max_step             | 0            |
|    n_updates            | 2920         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.000437     |
|    route_completion     | 0.442        |
|    std                  | 0.688        |
|    total_cost           | 16.8         |
|    value_loss           | 172          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 147      |
|    time_elapsed    | 1650     |
|    total_timesteps | 752640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 312          |
|    ep_rew_mean          | 254          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 148          |
|    time_elapsed         | 1657         |
|    total_timesteps      | 757760       |
| train/                  |              |
|    approx_kl            | 0.0024023976 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.646        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.4         |
|    n_updates            | 2940         |
|    policy_gradient_loss | 0.000612     |
|    std                  | 0.689        |
|    value_loss           | 201          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.176      |
|    crash                | 0.25       |
|    max_step             | 0          |
|    mean_ep_length       | 154        |
|    mean_reward          | 125        |
|    num_episodes         | 5          |
|    out_of_road          | 0.824      |
|    raw_action           | 0.4674044  |
|    route_completion     | 0.511      |
|    success_rate         | 0.1        |
|    total_cost           | 21.3       |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.00824101 |
|    arrive_dest          | 0.147      |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.1        |
|    crash                | 0.3        |
|    entropy_loss         | -2.07      |
|    explained_variance   | 0.556      |
|    learning_rate        | 5e-05      |
|    loss                 | 114        |
|    max_step             | 0          |
|    n_updates            | 2960       |
|    out_of_road          | 0.853      |
|    policy_gradient_loss | 0.00219    |
|    route_completion     | 0.443      |
|    std                  | 0.688      |
|    total_cost           | 16.6       |
|    value_loss           | 181        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 305      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 149      |
|    time_elapsed    | 1669     |
|    total_timesteps | 762880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 303          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 150          |
|    time_elapsed         | 1676         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 0.0026873054 |
|    clip_fraction        | 0.0904       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.63         |
|    learning_rate        | 5e-05        |
|    loss                 | 73.6         |
|    n_updates            | 2980         |
|    policy_gradient_loss | -0.00148     |
|    std                  | 0.688        |
|    value_loss           | 172          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 156          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.46795738   |
|    route_completion     | 0.512        |
|    success_rate         | 0.3          |
|    total_cost           | 21.1         |
| time/                   |              |
|    total_timesteps      | 770000       |
| train/                  |              |
|    approx_kl            | 0.0036858213 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    crash                | 0.299        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.709        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.4         |
|    max_step             | 0            |
|    n_updates            | 3000         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | 0.000608     |
|    route_completion     | 0.446        |
|    std                  | 0.687        |
|    total_cost           | 16.8         |
|    value_loss           | 173          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | 245      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 151      |
|    time_elapsed    | 1693     |
|    total_timesteps | 773120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 294          |
|    ep_rew_mean          | 243          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 152          |
|    time_elapsed         | 1702         |
|    total_timesteps      | 778240       |
| train/                  |              |
|    approx_kl            | 0.0018951062 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.462        |
|    learning_rate        | 5e-05        |
|    loss                 | 97.9         |
|    n_updates            | 3020         |
|    policy_gradient_loss | -0.000342    |
|    std                  | 0.686        |
|    value_loss           | 266          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 136          |
|    mean_reward          | 136          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.4687502    |
|    route_completion     | 0.512        |
|    success_rate         | 0.2          |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 780000       |
| train/                  |              |
|    approx_kl            | 0.0027752765 |
|    arrive_dest          | 0.149        |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.295        |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 86           |
|    max_step             | 0            |
|    n_updates            | 3040         |
|    out_of_road          | 0.851        |
|    policy_gradient_loss | 0.00117      |
|    route_completion     | 0.447        |
|    std                  | 0.685        |
|    total_cost           | 16.6         |
|    value_loss           | 196          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 153      |
|    time_elapsed    | 1714     |
|    total_timesteps | 783360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 298          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 154          |
|    time_elapsed         | 1722         |
|    total_timesteps      | 788480       |
| train/                  |              |
|    approx_kl            | 0.0016336844 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.666        |
|    learning_rate        | 5e-05        |
|    loss                 | 86.4         |
|    n_updates            | 3060         |
|    policy_gradient_loss | -0.00197     |
|    std                  | 0.683        |
|    value_loss           | 185          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.18         |
|    crash                | 0.251        |
|    max_step             | 0            |
|    mean_ep_length       | 154          |
|    mean_reward          | 208          |
|    num_episodes         | 5            |
|    out_of_road          | 0.82         |
|    raw_action           | 0.46851358   |
|    route_completion     | 0.513        |
|    success_rate         | 0.1          |
|    total_cost           | 20.8         |
| time/                   |              |
|    total_timesteps      | 790000       |
| train/                  |              |
|    approx_kl            | 0.0080017345 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.172        |
|    clip_range           | 0.1          |
|    crash                | 0.294        |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.586        |
|    learning_rate        | 5e-05        |
|    loss                 | 157          |
|    max_step             | 0            |
|    n_updates            | 3080         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.000229     |
|    route_completion     | 0.446        |
|    std                  | 0.681        |
|    total_cost           | 16.5         |
|    value_loss           | 191          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 276      |
|    ep_rew_mean     | 230      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 155      |
|    time_elapsed    | 1736     |
|    total_timesteps | 793600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 288          |
|    ep_rew_mean          | 237          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 156          |
|    time_elapsed         | 1744         |
|    total_timesteps      | 798720       |
| train/                  |              |
|    approx_kl            | 0.0027842429 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.349        |
|    learning_rate        | 5e-05        |
|    loss                 | 150          |
|    n_updates            | 3100         |
|    policy_gradient_loss | 0.00078      |
|    std                  | 0.68         |
|    value_loss           | 289          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.182       |
|    crash                | 0.25        |
|    max_step             | 0           |
|    mean_ep_length       | 199         |
|    mean_reward          | 276         |
|    num_episodes         | 5           |
|    out_of_road          | 0.818       |
|    raw_action           | 0.4683912   |
|    route_completion     | 0.517       |
|    success_rate         | 0.2         |
|    total_cost           | 20.6        |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.004876813 |
|    arrive_dest          | 0.145       |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.1         |
|    crash                | 0.292       |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.579       |
|    learning_rate        | 5e-05       |
|    loss                 | 69.2        |
|    max_step             | 0           |
|    n_updates            | 3120        |
|    out_of_road          | 0.855       |
|    policy_gradient_loss | 0.00178     |
|    route_completion     | 0.445       |
|    std                  | 0.681       |
|    total_cost           | 16.3        |
|    value_loss           | 135         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 233      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 157      |
|    time_elapsed    | 1756     |
|    total_timesteps | 803840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 306          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 158          |
|    time_elapsed         | 1763         |
|    total_timesteps      | 808960       |
| train/                  |              |
|    approx_kl            | 0.0031243023 |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.534        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.2         |
|    n_updates            | 3140         |
|    policy_gradient_loss | 0.00106      |
|    std                  | 0.682        |
|    value_loss           | 217          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.18         |
|    crash                | 0.254        |
|    max_step             | 0            |
|    mean_ep_length       | 115          |
|    mean_reward          | 139          |
|    num_episodes         | 5            |
|    out_of_road          | 0.82         |
|    raw_action           | 0.4684196    |
|    route_completion     | 0.516        |
|    success_rate         | 0.1          |
|    total_cost           | 20.3         |
| time/                   |              |
|    total_timesteps      | 810000       |
| train/                  |              |
|    approx_kl            | 0.0033145144 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.0928       |
|    clip_range           | 0.1          |
|    crash                | 0.294        |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.3         |
|    max_step             | 0            |
|    n_updates            | 3160         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.00101     |
|    route_completion     | 0.446        |
|    std                  | 0.684        |
|    total_cost           | 16.1         |
|    value_loss           | 133          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 159      |
|    time_elapsed    | 1777     |
|    total_timesteps | 814080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 320         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 458         |
|    iterations           | 160         |
|    time_elapsed         | 1784        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.005243348 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.619       |
|    learning_rate        | 5e-05       |
|    loss                 | 97.1        |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.00345     |
|    std                  | 0.684       |
|    value_loss           | 181         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.178       |
|    crash                | 0.251       |
|    max_step             | 0           |
|    mean_ep_length       | 118         |
|    mean_reward          | 157         |
|    num_episodes         | 5           |
|    out_of_road          | 0.822       |
|    raw_action           | 0.46928802  |
|    route_completion     | 0.515       |
|    success_rate         | 0.1         |
|    total_cost           | 20.1        |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.037283927 |
|    arrive_dest          | 0.146       |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.1         |
|    crash                | 0.3         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.655       |
|    learning_rate        | 5e-05       |
|    loss                 | 77.4        |
|    max_step             | 0           |
|    n_updates            | 3200        |
|    out_of_road          | 0.854       |
|    policy_gradient_loss | 0.00306     |
|    route_completion     | 0.446       |
|    std                  | 0.682       |
|    total_cost           | 16.2        |
|    value_loss           | 156         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 161      |
|    time_elapsed    | 1800     |
|    total_timesteps | 824320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 288          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 162          |
|    time_elapsed         | 1808         |
|    total_timesteps      | 829440       |
| train/                  |              |
|    approx_kl            | 0.0011291868 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.511        |
|    learning_rate        | 5e-05        |
|    loss                 | 96.3         |
|    n_updates            | 3220         |
|    policy_gradient_loss | -0.000687    |
|    std                  | 0.682        |
|    value_loss           | 196          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.178        |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 138          |
|    mean_reward          | 184          |
|    num_episodes         | 5            |
|    out_of_road          | 0.822        |
|    raw_action           | 0.46926254   |
|    route_completion     | 0.516        |
|    success_rate         | 0.1          |
|    total_cost           | 19.9         |
| time/                   |              |
|    total_timesteps      | 830000       |
| train/                  |              |
|    approx_kl            | 0.0014114755 |
|    arrive_dest          | 0.145        |
|    clip_fraction        | 0.185        |
|    clip_range           | 0.1          |
|    crash                | 0.299        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.68         |
|    learning_rate        | 5e-05        |
|    loss                 | 38.1         |
|    max_step             | 0            |
|    n_updates            | 3240         |
|    out_of_road          | 0.855        |
|    policy_gradient_loss | 0.0017       |
|    route_completion     | 0.447        |
|    std                  | 0.68         |
|    total_cost           | 16.1         |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 163      |
|    time_elapsed    | 1820     |
|    total_timesteps | 834560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 333          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 164          |
|    time_elapsed         | 1827         |
|    total_timesteps      | 839680       |
| train/                  |              |
|    approx_kl            | 0.0021914218 |
|    clip_fraction        | 0.0584       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.585        |
|    learning_rate        | 5e-05        |
|    loss                 | 89.9         |
|    n_updates            | 3260         |
|    policy_gradient_loss | -0.000714    |
|    std                  | 0.679        |
|    value_loss           | 200          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.176        |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 151          |
|    mean_reward          | 216          |
|    num_episodes         | 5            |
|    out_of_road          | 0.824        |
|    raw_action           | 0.4701205    |
|    route_completion     | 0.517        |
|    success_rate         | 0.2          |
|    total_cost           | 19.7         |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0011876288 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.0893       |
|    clip_range           | 0.1          |
|    crash                | 0.302        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.652        |
|    learning_rate        | 5e-05        |
|    loss                 | 76           |
|    max_step             | 0            |
|    n_updates            | 3280         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | -0.00123     |
|    route_completion     | 0.449        |
|    std                  | 0.679        |
|    total_cost           | 16           |
|    value_loss           | 157          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 165      |
|    time_elapsed    | 1842     |
|    total_timesteps | 844800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 338         |
|    ep_rew_mean          | 283         |
| time/                   |             |
|    fps                  | 459         |
|    iterations           | 166         |
|    time_elapsed         | 1849        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.021880077 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.77        |
|    learning_rate        | 5e-05       |
|    loss                 | 61.4        |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.681       |
|    value_loss           | 150         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 223          |
|    mean_reward          | 198          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.47069612   |
|    route_completion     | 0.519        |
|    success_rate         | 0.2          |
|    total_cost           | 20           |
| time/                   |              |
|    total_timesteps      | 850000       |
| train/                  |              |
|    approx_kl            | 0.0013650657 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    crash                | 0.301        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.4         |
|    max_step             | 0            |
|    n_updates            | 3320         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.000632    |
|    route_completion     | 0.449        |
|    std                  | 0.682        |
|    total_cost           | 15.8         |
|    value_loss           | 159          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 167      |
|    time_elapsed    | 1864     |
|    total_timesteps | 855040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 220          |
|    mean_reward          | 258          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.47040778   |
|    route_completion     | 0.522        |
|    success_rate         | 0.1          |
|    total_cost           | 20.1         |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0026512141 |
|    arrive_dest          | 0.144        |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    crash                | 0.302        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.696        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.8         |
|    max_step             | 0            |
|    n_updates            | 3340         |
|    out_of_road          | 0.856        |
|    policy_gradient_loss | -3.94e-05    |
|    route_completion     | 0.448        |
|    std                  | 0.679        |
|    total_cost           | 15.7         |
|    value_loss           | 169          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 168      |
|    time_elapsed    | 1876     |
|    total_timesteps | 860160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 339          |
|    ep_rew_mean          | 284          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 169          |
|    time_elapsed         | 1883         |
|    total_timesteps      | 865280       |
| train/                  |              |
|    approx_kl            | 0.0020590667 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.7         |
|    n_updates            | 3360         |
|    policy_gradient_loss | 0.000666     |
|    std                  | 0.679        |
|    value_loss           | 124          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 190          |
|    mean_reward          | 246          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.47100276   |
|    route_completion     | 0.523        |
|    success_rate         | 0.3          |
|    total_cost           | 20.1         |
| time/                   |              |
|    total_timesteps      | 870000       |
| train/                  |              |
|    approx_kl            | 0.0114980275 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.232        |
|    clip_range           | 0.1          |
|    crash                | 0.303        |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.747        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.4         |
|    max_step             | 0            |
|    n_updates            | 3380         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.00558      |
|    route_completion     | 0.451        |
|    std                  | 0.678        |
|    total_cost           | 15.8         |
|    value_loss           | 160          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 170      |
|    time_elapsed    | 1900     |
|    total_timesteps | 870400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 332          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 171          |
|    time_elapsed         | 1909         |
|    total_timesteps      | 875520       |
| train/                  |              |
|    approx_kl            | 0.0039577987 |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.604        |
|    learning_rate        | 5e-05        |
|    loss                 | 88.9         |
|    n_updates            | 3400         |
|    policy_gradient_loss | -9.44e-05    |
|    std                  | 0.678        |
|    value_loss           | 235          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.18       |
|    crash                | 0.255      |
|    max_step             | 0          |
|    mean_ep_length       | 142        |
|    mean_reward          | 202        |
|    num_episodes         | 5          |
|    out_of_road          | 0.82       |
|    raw_action           | 0.47136608 |
|    route_completion     | 0.524      |
|    success_rate         | 0.1        |
|    total_cost           | 19.9       |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.00224811 |
|    arrive_dest          | 0.145      |
|    clip_fraction        | 0.099      |
|    clip_range           | 0.1        |
|    crash                | 0.3        |
|    entropy_loss         | -2.03      |
|    explained_variance   | 0.583      |
|    learning_rate        | 5e-05      |
|    loss                 | 92.9       |
|    max_step             | 0          |
|    n_updates            | 3420       |
|    out_of_road          | 0.855      |
|    policy_gradient_loss | -0.000658  |
|    route_completion     | 0.451      |
|    std                  | 0.677      |
|    total_cost           | 15.7       |
|    value_loss           | 207        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 172      |
|    time_elapsed    | 1921     |
|    total_timesteps | 880640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 328          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 173          |
|    time_elapsed         | 1929         |
|    total_timesteps      | 885760       |
| train/                  |              |
|    approx_kl            | 0.0011626714 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.565        |
|    learning_rate        | 5e-05        |
|    loss                 | 148          |
|    n_updates            | 3440         |
|    policy_gradient_loss | 0.00169      |
|    std                  | 0.676        |
|    value_loss           | 183          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 201          |
|    mean_reward          | 256          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.47184873   |
|    route_completion     | 0.526        |
|    success_rate         | 0.2          |
|    total_cost           | 19.9         |
| time/                   |              |
|    total_timesteps      | 890000       |
| train/                  |              |
|    approx_kl            | 0.0076099923 |
|    arrive_dest          | 0.144        |
|    clip_fraction        | 0.0997       |
|    clip_range           | 0.1          |
|    crash                | 0.301        |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.506        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.8         |
|    max_step             | 0            |
|    n_updates            | 3460         |
|    out_of_road          | 0.856        |
|    policy_gradient_loss | -0.00131     |
|    route_completion     | 0.451        |
|    std                  | 0.677        |
|    total_cost           | 15.6         |
|    value_loss           | 188          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    fps             | 458      |
|    iterations      | 174      |
|    time_elapsed    | 1944     |
|    total_timesteps | 890880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 287          |
| time/                   |              |
|    fps                  | 459          |
|    iterations           | 175          |
|    time_elapsed         | 1951         |
|    total_timesteps      | 896000       |
| train/                  |              |
|    approx_kl            | 0.0023107682 |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.631        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.2         |
|    n_updates            | 3480         |
|    policy_gradient_loss | 0.000325     |
|    std                  | 0.675        |
|    value_loss           | 199          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.251        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.47173035   |
|    route_completion     | 0.526        |
|    success_rate         | 0.3          |
|    total_cost           | 20           |
| time/                   |              |
|    total_timesteps      | 900000       |
| train/                  |              |
|    approx_kl            | 0.0016014127 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    crash                | 0.298        |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.657        |
|    learning_rate        | 5e-05        |
|    loss                 | 88.2         |
|    max_step             | 0            |
|    n_updates            | 3500         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.00154      |
|    route_completion     | 0.453        |
|    std                  | 0.676        |
|    total_cost           | 15.6         |
|    value_loss           | 163          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 457      |
|    iterations      | 176      |
|    time_elapsed    | 1970     |
|    total_timesteps | 901120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 324          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 458          |
|    iterations           | 177          |
|    time_elapsed         | 1977         |
|    total_timesteps      | 906240       |
| train/                  |              |
|    approx_kl            | 0.0016449041 |
|    clip_fraction        | 0.0885       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.692        |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    n_updates            | 3520         |
|    policy_gradient_loss | -0.00123     |
|    std                  | 0.675        |
|    value_loss           | 190          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.18         |
|    crash                | 0.251        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 142          |
|    num_episodes         | 5            |
|    out_of_road          | 0.82         |
|    raw_action           | 0.47153848   |
|    route_completion     | 0.524        |
|    success_rate         | 0.2          |
|    total_cost           | 19.8         |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0015607916 |
|    arrive_dest          | 0.149        |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.1          |
|    crash                | 0.295        |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.673        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.2         |
|    max_step             | 0            |
|    n_updates            | 3540         |
|    out_of_road          | 0.851        |
|    policy_gradient_loss | 0.00333      |
|    route_completion     | 0.454        |
|    std                  | 0.676        |
|    total_cost           | 15.7         |
|    value_loss           | 197          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 178      |
|    time_elapsed    | 1997     |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 337         |
|    ep_rew_mean          | 289         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 179         |
|    time_elapsed         | 2005        |
|    total_timesteps      | 916480      |
| train/                  |             |
|    approx_kl            | 0.017203204 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.703       |
|    learning_rate        | 5e-05       |
|    loss                 | 103         |
|    n_updates            | 3560        |
|    policy_gradient_loss | 0.00326     |
|    std                  | 0.676       |
|    value_loss           | 183         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.178      |
|    crash                | 0.248      |
|    max_step             | 0          |
|    mean_ep_length       | 138        |
|    mean_reward          | 180        |
|    num_episodes         | 5          |
|    out_of_road          | 0.822      |
|    raw_action           | 0.47116402 |
|    route_completion     | 0.524      |
|    success_rate         | 0          |
|    total_cost           | 19.6       |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.00982638 |
|    arrive_dest          | 0.148      |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.1        |
|    crash                | 0.291      |
|    entropy_loss         | -2.02      |
|    explained_variance   | 0.713      |
|    learning_rate        | 5e-05      |
|    loss                 | 93.2       |
|    max_step             | 0          |
|    n_updates            | 3580       |
|    out_of_road          | 0.852      |
|    policy_gradient_loss | -0.000696  |
|    route_completion     | 0.452      |
|    std                  | 0.675      |
|    total_cost           | 15.6       |
|    value_loss           | 177        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 180      |
|    time_elapsed    | 2016     |
|    total_timesteps | 921600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 340          |
|    ep_rew_mean          | 293          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 181          |
|    time_elapsed         | 2024         |
|    total_timesteps      | 926720       |
| train/                  |              |
|    approx_kl            | 0.0017125746 |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.655        |
|    learning_rate        | 5e-05        |
|    loss                 | 70.3         |
|    n_updates            | 3600         |
|    policy_gradient_loss | -0.00097     |
|    std                  | 0.673        |
|    value_loss           | 177          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.178        |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 161          |
|    mean_reward          | 187          |
|    num_episodes         | 5            |
|    out_of_road          | 0.822        |
|    raw_action           | 0.47156733   |
|    route_completion     | 0.524        |
|    success_rate         | 0.1          |
|    total_cost           | 19.6         |
| time/                   |              |
|    total_timesteps      | 930000       |
| train/                  |              |
|    approx_kl            | 0.0033885967 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.29         |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.3         |
|    max_step             | 0            |
|    n_updates            | 3620         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.00198     |
|    route_completion     | 0.454        |
|    std                  | 0.671        |
|    total_cost           | 15.4         |
|    value_loss           | 130          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 182      |
|    time_elapsed    | 2041     |
|    total_timesteps | 931840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 333          |
|    ep_rew_mean          | 288          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 183          |
|    time_elapsed         | 2048         |
|    total_timesteps      | 936960       |
| train/                  |              |
|    approx_kl            | 0.0031098998 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 101          |
|    n_updates            | 3640         |
|    policy_gradient_loss | 0.00222      |
|    std                  | 0.671        |
|    value_loss           | 199          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.177       |
|    crash                | 0.251       |
|    max_step             | 0           |
|    mean_ep_length       | 125         |
|    mean_reward          | 128         |
|    num_episodes         | 5           |
|    out_of_road          | 0.823       |
|    raw_action           | 0.47133833  |
|    route_completion     | 0.524       |
|    success_rate         | 0           |
|    total_cost           | 19.5        |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.038462467 |
|    arrive_dest          | 0.145       |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.1         |
|    crash                | 0.287       |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.71        |
|    learning_rate        | 5e-05       |
|    loss                 | 93.1        |
|    max_step             | 0           |
|    n_updates            | 3660        |
|    out_of_road          | 0.855       |
|    policy_gradient_loss | 0.00206     |
|    route_completion     | 0.454       |
|    std                  | 0.672       |
|    total_cost           | 15.4        |
|    value_loss           | 166         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 184      |
|    time_elapsed    | 2061     |
|    total_timesteps | 942080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 298          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 185          |
|    time_elapsed         | 2069         |
|    total_timesteps      | 947200       |
| train/                  |              |
|    approx_kl            | 0.0035469676 |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.731        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.2         |
|    n_updates            | 3680         |
|    policy_gradient_loss | 0.00188      |
|    std                  | 0.672        |
|    value_loss           | 147          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.177       |
|    crash                | 0.253       |
|    max_step             | 0           |
|    mean_ep_length       | 198         |
|    mean_reward          | 190         |
|    num_episodes         | 5           |
|    out_of_road          | 0.823       |
|    raw_action           | 0.4712109   |
|    route_completion     | 0.526       |
|    success_rate         | 0.2         |
|    total_cost           | 19.7        |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.008334636 |
|    arrive_dest          | 0.145       |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.1         |
|    crash                | 0.286       |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.837       |
|    learning_rate        | 5e-05       |
|    loss                 | 48.2        |
|    max_step             | 0           |
|    n_updates            | 3700        |
|    out_of_road          | 0.855       |
|    policy_gradient_loss | 0.00335     |
|    route_completion     | 0.454       |
|    std                  | 0.672       |
|    total_cost           | 15.4        |
|    value_loss           | 99          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 297      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 186      |
|    time_elapsed    | 2090     |
|    total_timesteps | 952320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 353          |
|    ep_rew_mean          | 304          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 187          |
|    time_elapsed         | 2097         |
|    total_timesteps      | 957440       |
| train/                  |              |
|    approx_kl            | 0.0062008062 |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.4         |
|    n_updates            | 3720         |
|    policy_gradient_loss | 0.000347     |
|    std                  | 0.672        |
|    value_loss           | 153          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.256        |
|    max_step             | 0            |
|    mean_ep_length       | 196          |
|    mean_reward          | 238          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.4716122    |
|    route_completion     | 0.527        |
|    success_rate         | 0.3          |
|    total_cost           | 19.7         |
| time/                   |              |
|    total_timesteps      | 960000       |
| train/                  |              |
|    approx_kl            | 0.0010381506 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    crash                | 0.29         |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.775        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.8         |
|    max_step             | 0            |
|    n_updates            | 3740         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.000287    |
|    route_completion     | 0.455        |
|    std                  | 0.673        |
|    total_cost           | 15.3         |
|    value_loss           | 180          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 188      |
|    time_elapsed    | 2113     |
|    total_timesteps | 962560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 355         |
|    ep_rew_mean          | 309         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 189         |
|    time_elapsed         | 2121        |
|    total_timesteps      | 967680      |
| train/                  |             |
|    approx_kl            | 0.015339914 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.627       |
|    learning_rate        | 5e-05       |
|    loss                 | 72.3        |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.000938    |
|    std                  | 0.675       |
|    value_loss           | 170         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.177        |
|    crash                | 0.258        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 0.823        |
|    raw_action           | 0.47155496   |
|    route_completion     | 0.525        |
|    success_rate         | 0            |
|    total_cost           | 19.6         |
| time/                   |              |
|    total_timesteps      | 970000       |
| train/                  |              |
|    approx_kl            | 0.0025604344 |
|    arrive_dest          | 0.144        |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    crash                | 0.295        |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.738        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.7         |
|    max_step             | 0            |
|    n_updates            | 3780         |
|    out_of_road          | 0.856        |
|    policy_gradient_loss | 0.000701     |
|    route_completion     | 0.455        |
|    std                  | 0.674        |
|    total_cost           | 15.2         |
|    value_loss           | 162          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 312      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 190      |
|    time_elapsed    | 2134     |
|    total_timesteps | 972800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 363          |
|    ep_rew_mean          | 316          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 191          |
|    time_elapsed         | 2142         |
|    total_timesteps      | 977920       |
| train/                  |              |
|    approx_kl            | 0.0015705635 |
|    clip_fraction        | 0.169        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.634        |
|    learning_rate        | 5e-05        |
|    loss                 | 99.9         |
|    n_updates            | 3800         |
|    policy_gradient_loss | 0.00212      |
|    std                  | 0.675        |
|    value_loss           | 189          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.178       |
|    crash                | 0.255       |
|    max_step             | 0           |
|    mean_ep_length       | 163         |
|    mean_reward          | 180         |
|    num_episodes         | 5           |
|    out_of_road          | 0.822       |
|    raw_action           | 0.47138053  |
|    route_completion     | 0.526       |
|    success_rate         | 0.2         |
|    total_cost           | 19.5        |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.005851528 |
|    arrive_dest          | 0.145       |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.1         |
|    crash                | 0.294       |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.816       |
|    learning_rate        | 5e-05       |
|    loss                 | 46.9        |
|    max_step             | 0           |
|    n_updates            | 3820        |
|    out_of_road          | 0.855       |
|    policy_gradient_loss | 0.00146     |
|    route_completion     | 0.457       |
|    std                  | 0.677       |
|    total_cost           | 15.5        |
|    value_loss           | 112         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 192      |
|    time_elapsed    | 2158     |
|    total_timesteps | 983040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 354         |
|    ep_rew_mean          | 305         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 193         |
|    time_elapsed         | 2165        |
|    total_timesteps      | 988160      |
| train/                  |             |
|    approx_kl            | 0.005508217 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.706       |
|    learning_rate        | 5e-05       |
|    loss                 | 58.4        |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.000324   |
|    std                  | 0.676       |
|    value_loss           | 193         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.255        |
|    max_step             | 0            |
|    mean_ep_length       | 219          |
|    mean_reward          | 227          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.47128528   |
|    route_completion     | 0.527        |
|    success_rate         | 0.4          |
|    total_cost           | 19.7         |
| time/                   |              |
|    total_timesteps      | 990000       |
| train/                  |              |
|    approx_kl            | 0.0018011106 |
|    arrive_dest          | 0.145        |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    crash                | 0.291        |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.799        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.2         |
|    max_step             | 0            |
|    n_updates            | 3860         |
|    out_of_road          | 0.855        |
|    policy_gradient_loss | 0.00146      |
|    route_completion     | 0.457        |
|    std                  | 0.675        |
|    total_cost           | 15.5         |
|    value_loss           | 147          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 310      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 194      |
|    time_elapsed    | 2179     |
|    total_timesteps | 993280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 352         |
|    ep_rew_mean          | 305         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 195         |
|    time_elapsed         | 2186        |
|    total_timesteps      | 998400      |
| train/                  |             |
|    approx_kl            | 0.015514533 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.736       |
|    learning_rate        | 5e-05       |
|    loss                 | 57.2        |
|    n_updates            | 3880        |
|    policy_gradient_loss | 0.00139     |
|    std                  | 0.674       |
|    value_loss           | 142         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.184        |
|    crash                | 0.258        |
|    max_step             | 0            |
|    mean_ep_length       | 250          |
|    mean_reward          | 212          |
|    num_episodes         | 5            |
|    out_of_road          | 0.816        |
|    raw_action           | 0.47160304   |
|    route_completion     | 0.53         |
|    success_rate         | 0.3          |
|    total_cost           | 20.2         |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0025743216 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.292        |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.793        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.1         |
|    max_step             | 0            |
|    n_updates            | 3900         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.00102     |
|    route_completion     | 0.457        |
|    std                  | 0.673        |
|    total_cost           | 15.4         |
|    value_loss           | 129          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 196      |
|    time_elapsed    | 2201     |
|    total_timesteps | 1003520  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 353         |
|    ep_rew_mean          | 302         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 197         |
|    time_elapsed         | 2209        |
|    total_timesteps      | 1008640     |
| train/                  |             |
|    approx_kl            | 0.001271379 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.74        |
|    learning_rate        | 5e-05       |
|    loss                 | 103         |
|    n_updates            | 3920        |
|    policy_gradient_loss | 0.00423     |
|    std                  | 0.672       |
|    value_loss           | 181         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.259        |
|    max_step             | 0            |
|    mean_ep_length       | 99           |
|    mean_reward          | 119          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.4716301    |
|    route_completion     | 0.528        |
|    success_rate         | 0.1          |
|    total_cost           | 20           |
| time/                   |              |
|    total_timesteps      | 1010000      |
| train/                  |              |
|    approx_kl            | 0.0029192695 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    crash                | 0.291        |
|    entropy_loss         | -2           |
|    explained_variance   | 0.76         |
|    learning_rate        | 5e-05        |
|    loss                 | 52.7         |
|    max_step             | 0            |
|    n_updates            | 3940         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.000301     |
|    route_completion     | 0.457        |
|    std                  | 0.67         |
|    total_cost           | 15.3         |
|    value_loss           | 163          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 198      |
|    time_elapsed    | 2221     |
|    total_timesteps | 1013760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 305          |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 199          |
|    time_elapsed         | 2227         |
|    total_timesteps      | 1018880      |
| train/                  |              |
|    approx_kl            | 0.0027374574 |
|    clip_fraction        | 0.161        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.633        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.7         |
|    n_updates            | 3960         |
|    policy_gradient_loss | 0.00141      |
|    std                  | 0.672        |
|    value_loss           | 130          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.186        |
|    crash                | 0.259        |
|    max_step             | 0            |
|    mean_ep_length       | 273          |
|    mean_reward          | 251          |
|    num_episodes         | 5            |
|    out_of_road          | 0.814        |
|    raw_action           | 0.4712553    |
|    route_completion     | 0.53         |
|    success_rate         | 0.4          |
|    total_cost           | 20.4         |
| time/                   |              |
|    total_timesteps      | 1020000      |
| train/                  |              |
|    approx_kl            | 0.0073038107 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.199        |
|    clip_range           | 0.1          |
|    crash                | 0.29         |
|    entropy_loss         | -2           |
|    explained_variance   | 0.819        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.4         |
|    max_step             | 0            |
|    n_updates            | 3980         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.00345      |
|    route_completion     | 0.457        |
|    std                  | 0.673        |
|    total_cost           | 15.3         |
|    value_loss           | 87.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 200      |
|    time_elapsed    | 2244     |
|    total_timesteps | 1024000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 378          |
|    ep_rew_mean          | 314          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 201          |
|    time_elapsed         | 2252         |
|    total_timesteps      | 1029120      |
| train/                  |              |
|    approx_kl            | 0.0033600617 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.735        |
|    learning_rate        | 5e-05        |
|    loss                 | 70.5         |
|    n_updates            | 4000         |
|    policy_gradient_loss | -0.000491    |
|    std                  | 0.671        |
|    value_loss           | 139          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.188        |
|    crash                | 0.258        |
|    max_step             | 0            |
|    mean_ep_length       | 173          |
|    mean_reward          | 231          |
|    num_episodes         | 5            |
|    out_of_road          | 0.812        |
|    raw_action           | 0.4708957    |
|    route_completion     | 0.532        |
|    success_rate         | 0.4          |
|    total_cost           | 20.3         |
| time/                   |              |
|    total_timesteps      | 1030000      |
| train/                  |              |
|    approx_kl            | 0.0043158852 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    crash                | 0.291        |
|    entropy_loss         | -2           |
|    explained_variance   | 0.77         |
|    learning_rate        | 5e-05        |
|    loss                 | 70.5         |
|    max_step             | 0            |
|    n_updates            | 4020         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | 0.00103      |
|    route_completion     | 0.458        |
|    std                  | 0.67         |
|    total_cost           | 15.5         |
|    value_loss           | 120          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 202      |
|    time_elapsed    | 2269     |
|    total_timesteps | 1034240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 363          |
|    ep_rew_mean          | 306          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 203          |
|    time_elapsed         | 2277         |
|    total_timesteps      | 1039360      |
| train/                  |              |
|    approx_kl            | 0.0015095967 |
|    clip_fraction        | 0.371        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.672        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.6         |
|    n_updates            | 4040         |
|    policy_gradient_loss | 0.0201       |
|    std                  | 0.671        |
|    value_loss           | 142          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.192        |
|    crash                | 0.262        |
|    max_step             | 0            |
|    mean_ep_length       | 238          |
|    mean_reward          | 198          |
|    num_episodes         | 5            |
|    out_of_road          | 0.808        |
|    raw_action           | 0.47106484   |
|    route_completion     | 0.533        |
|    success_rate         | 0.4          |
|    total_cost           | 20.8         |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0031614196 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    crash                | 0.29         |
|    entropy_loss         | -2           |
|    explained_variance   | 0.783        |
|    learning_rate        | 5e-05        |
|    loss                 | 86           |
|    max_step             | 0            |
|    n_updates            | 4060         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | -0.000461    |
|    route_completion     | 0.46         |
|    std                  | 0.671        |
|    total_cost           | 15.6         |
|    value_loss           | 136          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 204      |
|    time_elapsed    | 2297     |
|    total_timesteps | 1044480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 363          |
|    ep_rew_mean          | 305          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 205          |
|    time_elapsed         | 2305         |
|    total_timesteps      | 1049600      |
| train/                  |              |
|    approx_kl            | 0.0038548962 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.644        |
|    learning_rate        | 5e-05        |
|    loss                 | 130          |
|    n_updates            | 4080         |
|    policy_gradient_loss | 0.000719     |
|    std                  | 0.671        |
|    value_loss           | 220          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.192       |
|    crash                | 0.261       |
|    max_step             | 0           |
|    mean_ep_length       | 214         |
|    mean_reward          | 270         |
|    num_episodes         | 5           |
|    out_of_road          | 0.808       |
|    raw_action           | 0.47115126  |
|    route_completion     | 0.535       |
|    success_rate         | 0.4         |
|    total_cost           | 20.8        |
| time/                   |             |
|    total_timesteps      | 1050000     |
| train/                  |             |
|    approx_kl            | 0.001753514 |
|    arrive_dest          | 0.154       |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.1         |
|    crash                | 0.291       |
|    entropy_loss         | -2          |
|    explained_variance   | 0.768       |
|    learning_rate        | 5e-05       |
|    loss                 | 70.1        |
|    max_step             | 0           |
|    n_updates            | 4100        |
|    out_of_road          | 0.846       |
|    policy_gradient_loss | 0.000819    |
|    route_completion     | 0.463       |
|    std                  | 0.672       |
|    total_cost           | 15.8        |
|    value_loss           | 130         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 206      |
|    time_elapsed    | 2321     |
|    total_timesteps | 1054720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 302          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 207          |
|    time_elapsed         | 2328         |
|    total_timesteps      | 1059840      |
| train/                  |              |
|    approx_kl            | 0.0028621443 |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.603        |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    n_updates            | 4120         |
|    policy_gradient_loss | 0.000287     |
|    std                  | 0.673        |
|    value_loss           | 189          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.191      |
|    crash                | 0.262      |
|    max_step             | 0          |
|    mean_ep_length       | 140        |
|    mean_reward          | 160        |
|    num_episodes         | 5          |
|    out_of_road          | 0.809      |
|    raw_action           | 0.47179908 |
|    route_completion     | 0.534      |
|    success_rate         | 0          |
|    total_cost           | 20.7       |
| time/                   |            |
|    total_timesteps      | 1060000    |
| train/                  |            |
|    approx_kl            | 0.01695894 |
|    arrive_dest          | 0.153      |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.1        |
|    crash                | 0.294      |
|    entropy_loss         | -2         |
|    explained_variance   | 0.749      |
|    learning_rate        | 5e-05      |
|    loss                 | 51.2       |
|    max_step             | 0          |
|    n_updates            | 4140       |
|    out_of_road          | 0.847      |
|    policy_gradient_loss | 0.000629   |
|    route_completion     | 0.462      |
|    std                  | 0.669      |
|    total_cost           | 15.6       |
|    value_loss           | 168        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 208      |
|    time_elapsed    | 2339     |
|    total_timesteps | 1064960  |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.193        |
|    crash                | 0.262        |
|    max_step             | 0            |
|    mean_ep_length       | 183          |
|    mean_reward          | 218          |
|    num_episodes         | 5            |
|    out_of_road          | 0.807        |
|    raw_action           | 0.47207206   |
|    route_completion     | 0.535        |
|    success_rate         | 0.3          |
|    total_cost           | 20.6         |
| time/                   |              |
|    total_timesteps      | 1070000      |
| train/                  |              |
|    approx_kl            | 0.0015127746 |
|    arrive_dest          | 0.153        |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    crash                | 0.293        |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.6         |
|    max_step             | 0            |
|    n_updates            | 4160         |
|    out_of_road          | 0.847        |
|    policy_gradient_loss | 0.00125      |
|    route_completion     | 0.464        |
|    std                  | 0.667        |
|    total_cost           | 15.7         |
|    value_loss           | 195          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 209      |
|    time_elapsed    | 2352     |
|    total_timesteps | 1070080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 295          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 210          |
|    time_elapsed         | 2361         |
|    total_timesteps      | 1075200      |
| train/                  |              |
|    approx_kl            | 0.0030978306 |
|    clip_fraction        | 0.0996       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.796        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.7         |
|    n_updates            | 4180         |
|    policy_gradient_loss | -0.000316    |
|    std                  | 0.667        |
|    value_loss           | 172          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.194       |
|    crash                | 0.263       |
|    max_step             | 0           |
|    mean_ep_length       | 185         |
|    mean_reward          | 213         |
|    num_episodes         | 5           |
|    out_of_road          | 0.806       |
|    raw_action           | 0.47240093  |
|    route_completion     | 0.536       |
|    success_rate         | 0.2         |
|    total_cost           | 20.6        |
| time/                   |             |
|    total_timesteps      | 1080000     |
| train/                  |             |
|    approx_kl            | 0.011576104 |
|    arrive_dest          | 0.152       |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.1         |
|    crash                | 0.293       |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.773       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.1        |
|    max_step             | 0           |
|    n_updates            | 4200        |
|    out_of_road          | 0.848       |
|    policy_gradient_loss | 0.00209     |
|    route_completion     | 0.464       |
|    std                  | 0.669       |
|    total_cost           | 15.6        |
|    value_loss           | 161         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 211      |
|    time_elapsed    | 2376     |
|    total_timesteps | 1080320  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 308          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 212          |
|    time_elapsed         | 2383         |
|    total_timesteps      | 1085440      |
| train/                  |              |
|    approx_kl            | 0.0025069064 |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.681        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.9         |
|    n_updates            | 4220         |
|    policy_gradient_loss | 0.000224     |
|    std                  | 0.67         |
|    value_loss           | 161          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.194        |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 219          |
|    num_episodes         | 5            |
|    out_of_road          | 0.806        |
|    raw_action           | 0.47333843   |
|    route_completion     | 0.537        |
|    success_rate         | 0.3          |
|    total_cost           | 20.4         |
| time/                   |              |
|    total_timesteps      | 1090000      |
| train/                  |              |
|    approx_kl            | 0.0022879217 |
|    arrive_dest          | 0.154        |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    crash                | 0.294        |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 96.4         |
|    max_step             | 0            |
|    n_updates            | 4240         |
|    out_of_road          | 0.846        |
|    policy_gradient_loss | 0.00092      |
|    route_completion     | 0.465        |
|    std                  | 0.67         |
|    total_cost           | 15.5         |
|    value_loss           | 193          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 213      |
|    time_elapsed    | 2396     |
|    total_timesteps | 1090560  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 361         |
|    ep_rew_mean          | 312         |
| time/                   |             |
|    fps                  | 455         |
|    iterations           | 214         |
|    time_elapsed         | 2403        |
|    total_timesteps      | 1095680     |
| train/                  |             |
|    approx_kl            | 0.025639182 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.827       |
|    learning_rate        | 5e-05       |
|    loss                 | 33.4        |
|    n_updates            | 4260        |
|    policy_gradient_loss | 0.00444     |
|    std                  | 0.67        |
|    value_loss           | 107         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.196        |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 224          |
|    mean_reward          | 165          |
|    num_episodes         | 5            |
|    out_of_road          | 0.804        |
|    raw_action           | 0.4730232    |
|    route_completion     | 0.538        |
|    success_rate         | 0.3          |
|    total_cost           | 20.9         |
| time/                   |              |
|    total_timesteps      | 1100000      |
| train/                  |              |
|    approx_kl            | 0.0025773444 |
|    arrive_dest          | 0.155        |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    crash                | 0.291        |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.727        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.9         |
|    max_step             | 0            |
|    n_updates            | 4280         |
|    out_of_road          | 0.845        |
|    policy_gradient_loss | -4.17e-05    |
|    route_completion     | 0.465        |
|    std                  | 0.667        |
|    total_cost           | 15.4         |
|    value_loss           | 190          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 316      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 215      |
|    time_elapsed    | 2420     |
|    total_timesteps | 1100800  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 376          |
|    ep_rew_mean          | 327          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 216          |
|    time_elapsed         | 2427         |
|    total_timesteps      | 1105920      |
| train/                  |              |
|    approx_kl            | 0.0009276376 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.754        |
|    learning_rate        | 5e-05        |
|    loss                 | 84           |
|    n_updates            | 4300         |
|    policy_gradient_loss | 0.000298     |
|    std                  | 0.668        |
|    value_loss           | 141          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.196       |
|    crash                | 0.267       |
|    max_step             | 0           |
|    mean_ep_length       | 146         |
|    mean_reward          | 157         |
|    num_episodes         | 5           |
|    out_of_road          | 0.804       |
|    raw_action           | 0.47341314  |
|    route_completion     | 0.537       |
|    success_rate         | 0.1         |
|    total_cost           | 20.8        |
| time/                   |             |
|    total_timesteps      | 1110000     |
| train/                  |             |
|    approx_kl            | 0.034430154 |
|    arrive_dest          | 0.153       |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.1         |
|    crash                | 0.288       |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.779       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.7        |
|    max_step             | 0           |
|    n_updates            | 4320        |
|    out_of_road          | 0.847       |
|    policy_gradient_loss | 0.00624     |
|    route_completion     | 0.466       |
|    std                  | 0.667       |
|    total_cost           | 15.3        |
|    value_loss           | 131         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 321      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 217      |
|    time_elapsed    | 2440     |
|    total_timesteps | 1111040  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 316          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 218          |
|    time_elapsed         | 2447         |
|    total_timesteps      | 1116160      |
| train/                  |              |
|    approx_kl            | 0.0022711768 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.63         |
|    learning_rate        | 5e-05        |
|    loss                 | 115          |
|    n_updates            | 4340         |
|    policy_gradient_loss | 0.00183      |
|    std                  | 0.667        |
|    value_loss           | 247          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.195       |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 115         |
|    mean_reward          | 147         |
|    num_episodes         | 5           |
|    out_of_road          | 0.805       |
|    raw_action           | 0.4738678   |
|    route_completion     | 0.536       |
|    success_rate         | 0.1         |
|    total_cost           | 20.7        |
| time/                   |             |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.004576552 |
|    arrive_dest          | 0.154       |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.1         |
|    crash                | 0.289       |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.684       |
|    learning_rate        | 5e-05       |
|    loss                 | 107         |
|    max_step             | 0           |
|    n_updates            | 4360        |
|    out_of_road          | 0.846       |
|    policy_gradient_loss | -0.000606   |
|    route_completion     | 0.468       |
|    std                  | 0.667       |
|    total_cost           | 15.3        |
|    value_loss           | 187         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 219      |
|    time_elapsed    | 2460     |
|    total_timesteps | 1121280  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 341          |
|    ep_rew_mean          | 291          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 220          |
|    time_elapsed         | 2467         |
|    total_timesteps      | 1126400      |
| train/                  |              |
|    approx_kl            | 0.0020910115 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.56         |
|    learning_rate        | 5e-05        |
|    loss                 | 52.1         |
|    n_updates            | 4380         |
|    policy_gradient_loss | -0.00116     |
|    std                  | 0.667        |
|    value_loss           | 190          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.193        |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 226          |
|    num_episodes         | 5            |
|    out_of_road          | 0.807        |
|    raw_action           | 0.47358656   |
|    route_completion     | 0.536        |
|    success_rate         | 0.1          |
|    total_cost           | 20.5         |
| time/                   |              |
|    total_timesteps      | 1130000      |
| train/                  |              |
|    approx_kl            | 0.0014829079 |
|    arrive_dest          | 0.154        |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.287        |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.738        |
|    learning_rate        | 5e-05        |
|    loss                 | 44.1         |
|    max_step             | 0            |
|    n_updates            | 4400         |
|    out_of_road          | 0.846        |
|    policy_gradient_loss | 0.000937     |
|    route_completion     | 0.468        |
|    std                  | 0.666        |
|    total_cost           | 15.1         |
|    value_loss           | 140          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 221      |
|    time_elapsed    | 2479     |
|    total_timesteps | 1131520  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 325        |
|    ep_rew_mean          | 282        |
| time/                   |            |
|    fps                  | 457        |
|    iterations           | 222        |
|    time_elapsed         | 2486       |
|    total_timesteps      | 1136640    |
| train/                  |            |
|    approx_kl            | 0.00285636 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.98      |
|    explained_variance   | 0.643      |
|    learning_rate        | 5e-05      |
|    loss                 | 120        |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.000312  |
|    std                  | 0.665      |
|    value_loss           | 194        |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.191       |
|    crash                | 0.265       |
|    max_step             | 0           |
|    mean_ep_length       | 146         |
|    mean_reward          | 214         |
|    num_episodes         | 5           |
|    out_of_road          | 0.809       |
|    raw_action           | 0.4740148   |
|    route_completion     | 0.536       |
|    success_rate         | 0.1         |
|    total_cost           | 20.4        |
| time/                   |             |
|    total_timesteps      | 1140000     |
| train/                  |             |
|    approx_kl            | 0.005909669 |
|    arrive_dest          | 0.154       |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.286       |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5e-05       |
|    loss                 | 92.8        |
|    max_step             | 0           |
|    n_updates            | 4440        |
|    out_of_road          | 0.846       |
|    policy_gradient_loss | 0.000473    |
|    route_completion     | 0.468       |
|    std                  | 0.664       |
|    total_cost           | 15.1        |
|    value_loss           | 170         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 320      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 456      |
|    iterations      | 223      |
|    time_elapsed    | 2503     |
|    total_timesteps | 1141760  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 315         |
|    ep_rew_mean          | 271         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 224         |
|    time_elapsed         | 2510        |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.003969756 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.675       |
|    learning_rate        | 5e-05       |
|    loss                 | 80.6        |
|    n_updates            | 4460        |
|    policy_gradient_loss | 0.000123    |
|    std                  | 0.662       |
|    value_loss           | 194         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.193        |
|    crash                | 0.264        |
|    max_step             | 0            |
|    mean_ep_length       | 238          |
|    mean_reward          | 256          |
|    num_episodes         | 5            |
|    out_of_road          | 0.807        |
|    raw_action           | 0.4738874    |
|    route_completion     | 0.538        |
|    success_rate         | 0.3          |
|    total_cost           | 20.5         |
| time/                   |              |
|    total_timesteps      | 1150000      |
| train/                  |              |
|    approx_kl            | 0.0022447153 |
|    arrive_dest          | 0.155        |
|    clip_fraction        | 0.219        |
|    clip_range           | 0.1          |
|    crash                | 0.285        |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.771        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.9         |
|    max_step             | 0            |
|    n_updates            | 4480         |
|    out_of_road          | 0.845        |
|    policy_gradient_loss | 0.00306      |
|    route_completion     | 0.47         |
|    std                  | 0.665        |
|    total_cost           | 15.1         |
|    value_loss           | 138          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 225      |
|    time_elapsed    | 2530     |
|    total_timesteps | 1152000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 330          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 456          |
|    iterations           | 226          |
|    time_elapsed         | 2537         |
|    total_timesteps      | 1157120      |
| train/                  |              |
|    approx_kl            | 0.0026868829 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.68         |
|    learning_rate        | 5e-05        |
|    loss                 | 133          |
|    n_updates            | 4500         |
|    policy_gradient_loss | -0.00121     |
|    std                  | 0.664        |
|    value_loss           | 213          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.191       |
|    crash                | 0.262       |
|    max_step             | 0           |
|    mean_ep_length       | 116         |
|    mean_reward          | 125         |
|    num_episodes         | 5           |
|    out_of_road          | 0.809       |
|    raw_action           | 0.4739426   |
|    route_completion     | 0.536       |
|    success_rate         | 0.2         |
|    total_cost           | 20.4        |
| time/                   |             |
|    total_timesteps      | 1160000     |
| train/                  |             |
|    approx_kl            | 0.004390237 |
|    arrive_dest          | 0.157       |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.1         |
|    crash                | 0.284       |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5e-05       |
|    loss                 | 94.8        |
|    max_step             | 0           |
|    n_updates            | 4520        |
|    out_of_road          | 0.843       |
|    policy_gradient_loss | 0.00987     |
|    route_completion     | 0.472       |
|    std                  | 0.662       |
|    total_cost           | 15          |
|    value_loss           | 164         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 331      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 455      |
|    iterations      | 227      |
|    time_elapsed    | 2550     |
|    total_timesteps | 1162240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 333         |
|    ep_rew_mean          | 286         |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 228         |
|    time_elapsed         | 2557        |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.008170153 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.765       |
|    learning_rate        | 5e-05       |
|    loss                 | 54.4        |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.0017     |
|    std                  | 0.662       |
|    value_loss           | 137         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.19         |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.81         |
|    raw_action           | 0.47406292   |
|    route_completion     | 0.536        |
|    success_rate         | 0.2          |
|    total_cost           | 20.3         |
| time/                   |              |
|    total_timesteps      | 1170000      |
| train/                  |              |
|    approx_kl            | 0.0044050748 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    crash                | 0.285        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.736        |
|    learning_rate        | 5e-05        |
|    loss                 | 119          |
|    max_step             | 0            |
|    n_updates            | 4560         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | -0.000625    |
|    route_completion     | 0.473        |
|    std                  | 0.66         |
|    total_cost           | 15.2         |
|    value_loss           | 172          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 229      |
|    time_elapsed    | 2578     |
|    total_timesteps | 1172480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 338          |
|    ep_rew_mean          | 294          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 230          |
|    time_elapsed         | 2585         |
|    total_timesteps      | 1177600      |
| train/                  |              |
|    approx_kl            | 0.0017079569 |
|    clip_fraction        | 0.0981       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.619        |
|    learning_rate        | 5e-05        |
|    loss                 | 108          |
|    n_updates            | 4580         |
|    policy_gradient_loss | -0.000401    |
|    std                  | 0.658        |
|    value_loss           | 217          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.192        |
|    crash                | 0.263        |
|    max_step             | 0            |
|    mean_ep_length       | 282          |
|    mean_reward          | 210          |
|    num_episodes         | 5            |
|    out_of_road          | 0.808        |
|    raw_action           | 0.4743832    |
|    route_completion     | 0.537        |
|    success_rate         | 0.3          |
|    total_cost           | 20.7         |
| time/                   |              |
|    total_timesteps      | 1180000      |
| train/                  |              |
|    approx_kl            | 0.0012953505 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.285        |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.788        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.4         |
|    max_step             | 0            |
|    n_updates            | 4600         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | 0.00062      |
|    route_completion     | 0.473        |
|    std                  | 0.659        |
|    total_cost           | 15.1         |
|    value_loss           | 114          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 294      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 231      |
|    time_elapsed    | 2600     |
|    total_timesteps | 1182720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 344          |
|    ep_rew_mean          | 295          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 232          |
|    time_elapsed         | 2608         |
|    total_timesteps      | 1187840      |
| train/                  |              |
|    approx_kl            | 0.0008515412 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.621        |
|    learning_rate        | 5e-05        |
|    loss                 | 83           |
|    n_updates            | 4620         |
|    policy_gradient_loss | -0.000153    |
|    std                  | 0.659        |
|    value_loss           | 199          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.19         |
|    crash                | 0.264        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 170          |
|    num_episodes         | 5            |
|    out_of_road          | 0.81         |
|    raw_action           | 0.47432497   |
|    route_completion     | 0.536        |
|    success_rate         | 0.1          |
|    total_cost           | 20.5         |
| time/                   |              |
|    total_timesteps      | 1190000      |
| train/                  |              |
|    approx_kl            | 0.0020314339 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.09         |
|    clip_range           | 0.1          |
|    crash                | 0.284        |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.662        |
|    learning_rate        | 5e-05        |
|    loss                 | 92.4         |
|    max_step             | 0            |
|    n_updates            | 4640         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | -0.00117     |
|    route_completion     | 0.473        |
|    std                  | 0.659        |
|    total_cost           | 15           |
|    value_loss           | 214          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 233      |
|    time_elapsed    | 2625     |
|    total_timesteps | 1192960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 306          |
| time/                   |              |
|    fps                  | 455          |
|    iterations           | 234          |
|    time_elapsed         | 2632         |
|    total_timesteps      | 1198080      |
| train/                  |              |
|    approx_kl            | 0.0014559206 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.634        |
|    learning_rate        | 5e-05        |
|    loss                 | 70.6         |
|    n_updates            | 4660         |
|    policy_gradient_loss | -0.000239    |
|    std                  | 0.659        |
|    value_loss           | 151          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.19        |
|    crash                | 0.265       |
|    max_step             | 0           |
|    mean_ep_length       | 146         |
|    mean_reward          | 222         |
|    num_episodes         | 5           |
|    out_of_road          | 0.81        |
|    raw_action           | 0.47432974  |
|    route_completion     | 0.537       |
|    success_rate         | 0.3         |
|    total_cost           | 20.4        |
| time/                   |             |
|    total_timesteps      | 1200000     |
| train/                  |             |
|    approx_kl            | 0.002114122 |
|    arrive_dest          | 0.162       |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.1         |
|    crash                | 0.282       |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.8         |
|    learning_rate        | 5e-05       |
|    loss                 | 50.7        |
|    max_step             | 0           |
|    n_updates            | 4680        |
|    out_of_road          | 0.838       |
|    policy_gradient_loss | 0.00463     |
|    route_completion     | 0.474       |
|    std                  | 0.662       |
|    total_cost           | 15          |
|    value_loss           | 106         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 454      |
|    iterations      | 235      |
|    time_elapsed    | 2649     |
|    total_timesteps | 1203200  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 346         |
|    ep_rew_mean          | 297         |
| time/                   |             |
|    fps                  | 454         |
|    iterations           | 236         |
|    time_elapsed         | 2656        |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.002431053 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.682       |
|    learning_rate        | 5e-05       |
|    loss                 | 113         |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.000227   |
|    std                  | 0.662       |
|    value_loss           | 249         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.192        |
|    crash                | 0.263        |
|    max_step             | 0            |
|    mean_ep_length       | 210          |
|    mean_reward          | 233          |
|    num_episodes         | 5            |
|    out_of_road          | 0.808        |
|    raw_action           | 0.47406667   |
|    route_completion     | 0.538        |
|    success_rate         | 0.2          |
|    total_cost           | 20.4         |
| time/                   |              |
|    total_timesteps      | 1210000      |
| train/                  |              |
|    approx_kl            | 0.0014436247 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.0944       |
|    clip_range           | 0.1          |
|    crash                | 0.283        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.3         |
|    max_step             | 0            |
|    n_updates            | 4720         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | -0.000258    |
|    route_completion     | 0.473        |
|    std                  | 0.66         |
|    total_cost           | 14.9         |
|    value_loss           | 178          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 452      |
|    iterations      | 237      |
|    time_elapsed    | 2682     |
|    total_timesteps | 1213440  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 352         |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 453         |
|    iterations           | 238         |
|    time_elapsed         | 2689        |
|    total_timesteps      | 1218560     |
| train/                  |             |
|    approx_kl            | 0.003200749 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.581       |
|    learning_rate        | 5e-05       |
|    loss                 | 44.7        |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.000321   |
|    std                  | 0.659       |
|    value_loss           | 177         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.19         |
|    crash                | 0.264        |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 196          |
|    num_episodes         | 5            |
|    out_of_road          | 0.81         |
|    raw_action           | 0.4739006    |
|    route_completion     | 0.539        |
|    success_rate         | 0.1          |
|    total_cost           | 20.3         |
| time/                   |              |
|    total_timesteps      | 1220000      |
| train/                  |              |
|    approx_kl            | 0.0028601033 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    crash                | 0.284        |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.731        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.5         |
|    max_step             | 0            |
|    n_updates            | 4760         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | -0.000275    |
|    route_completion     | 0.474        |
|    std                  | 0.659        |
|    total_cost           | 15.2         |
|    value_loss           | 166          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 451      |
|    iterations      | 239      |
|    time_elapsed    | 2713     |
|    total_timesteps | 1223680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 289          |
| time/                   |              |
|    fps                  | 451          |
|    iterations           | 240          |
|    time_elapsed         | 2719         |
|    total_timesteps      | 1228800      |
| train/                  |              |
|    approx_kl            | 0.0017407676 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.573        |
|    learning_rate        | 5e-05        |
|    loss                 | 155          |
|    n_updates            | 4780         |
|    policy_gradient_loss | -0.000122    |
|    std                  | 0.659        |
|    value_loss           | 301          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.19         |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 160          |
|    num_episodes         | 5            |
|    out_of_road          | 0.81         |
|    raw_action           | 0.47355822   |
|    route_completion     | 0.539        |
|    success_rate         | 0.1          |
|    total_cost           | 20.4         |
| time/                   |              |
|    total_timesteps      | 1230000      |
| train/                  |              |
|    approx_kl            | 0.0019508883 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.1          |
|    crash                | 0.281        |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.678        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.6         |
|    max_step             | 0            |
|    n_updates            | 4800         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | 0.000499     |
|    route_completion     | 0.472        |
|    std                  | 0.655        |
|    total_cost           | 15.1         |
|    value_loss           | 184          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 450      |
|    iterations      | 241      |
|    time_elapsed    | 2737     |
|    total_timesteps | 1233920  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 331          |
|    ep_rew_mean          | 287          |
| time/                   |              |
|    fps                  | 451          |
|    iterations           | 242          |
|    time_elapsed         | 2744         |
|    total_timesteps      | 1239040      |
| train/                  |              |
|    approx_kl            | 0.0017525733 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.682        |
|    learning_rate        | 5e-05        |
|    loss                 | 118          |
|    n_updates            | 4820         |
|    policy_gradient_loss | -0.00156     |
|    std                  | 0.655        |
|    value_loss           | 212          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.194        |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 253          |
|    mean_reward          | 295          |
|    num_episodes         | 5            |
|    out_of_road          | 0.806        |
|    raw_action           | 0.47345942   |
|    route_completion     | 0.541        |
|    success_rate         | 0.4          |
|    total_cost           | 20.5         |
| time/                   |              |
|    total_timesteps      | 1240000      |
| train/                  |              |
|    approx_kl            | 0.0012885081 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    crash                | 0.282        |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.803        |
|    learning_rate        | 5e-05        |
|    loss                 | 55.7         |
|    max_step             | 0            |
|    n_updates            | 4840         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | 6.61e-05     |
|    route_completion     | 0.472        |
|    std                  | 0.653        |
|    total_cost           | 15.2         |
|    value_loss           | 98.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 450      |
|    iterations      | 243      |
|    time_elapsed    | 2762     |
|    total_timesteps | 1244160  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 336         |
|    ep_rew_mean          | 298         |
| time/                   |             |
|    fps                  | 450         |
|    iterations           | 244         |
|    time_elapsed         | 2770        |
|    total_timesteps      | 1249280     |
| train/                  |             |
|    approx_kl            | 0.002163294 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.717       |
|    learning_rate        | 5e-05       |
|    loss                 | 105         |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.0002     |
|    std                  | 0.651       |
|    value_loss           | 182         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.194       |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 186         |
|    mean_reward          | 181         |
|    num_episodes         | 5           |
|    out_of_road          | 0.806       |
|    raw_action           | 0.47276646  |
|    route_completion     | 0.541       |
|    success_rate         | 0.3         |
|    total_cost           | 20.6        |
| time/                   |             |
|    total_timesteps      | 1250000     |
| train/                  |             |
|    approx_kl            | 0.003682632 |
|    arrive_dest          | 0.162       |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    crash                | 0.28        |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.783       |
|    learning_rate        | 5e-05       |
|    loss                 | 66          |
|    max_step             | 0           |
|    n_updates            | 4880        |
|    out_of_road          | 0.838       |
|    policy_gradient_loss | 0.000543    |
|    route_completion     | 0.473       |
|    std                  | 0.65        |
|    total_cost           | 15.2        |
|    value_loss           | 155         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 450      |
|    iterations      | 245      |
|    time_elapsed    | 2784     |
|    total_timesteps | 1254400  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 322          |
|    ep_rew_mean          | 288          |
| time/                   |              |
|    fps                  | 451          |
|    iterations           | 246          |
|    time_elapsed         | 2791         |
|    total_timesteps      | 1259520      |
| train/                  |              |
|    approx_kl            | 0.0016149202 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.652        |
|    learning_rate        | 5e-05        |
|    loss                 | 110          |
|    n_updates            | 4900         |
|    policy_gradient_loss | -0.000991    |
|    std                  | 0.65         |
|    value_loss           | 211          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.195        |
|    crash                | 0.263        |
|    max_step             | 0            |
|    mean_ep_length       | 154          |
|    mean_reward          | 217          |
|    num_episodes         | 5            |
|    out_of_road          | 0.805        |
|    raw_action           | 0.4732182    |
|    route_completion     | 0.542        |
|    success_rate         | 0.2          |
|    total_cost           | 20.4         |
| time/                   |              |
|    total_timesteps      | 1260000      |
| train/                  |              |
|    approx_kl            | 0.0020692404 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    crash                | 0.281        |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.635        |
|    learning_rate        | 5e-05        |
|    loss                 | 74           |
|    max_step             | 0            |
|    n_updates            | 4920         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | -0.000435    |
|    route_completion     | 0.474        |
|    std                  | 0.648        |
|    total_cost           | 15.2         |
|    value_loss           | 205          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 450      |
|    iterations      | 247      |
|    time_elapsed    | 2805     |
|    total_timesteps | 1264640  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 335         |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 450         |
|    iterations           | 248         |
|    time_elapsed         | 2821        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.001325861 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.683       |
|    learning_rate        | 5e-05       |
|    loss                 | 126         |
|    n_updates            | 4940        |
|    policy_gradient_loss | -0.00189    |
|    std                  | 0.648       |
|    value_loss           | 203         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.195       |
|    crash                | 0.265       |
|    max_step             | 0           |
|    mean_ep_length       | 158         |
|    mean_reward          | 192         |
|    num_episodes         | 5           |
|    out_of_road          | 0.805       |
|    raw_action           | 0.47352073  |
|    route_completion     | 0.542       |
|    success_rate         | 0.2         |
|    total_cost           | 20.4        |
| time/                   |             |
|    total_timesteps      | 1270000     |
| train/                  |             |
|    approx_kl            | 0.006304552 |
|    arrive_dest          | 0.161       |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.1         |
|    crash                | 0.28        |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5e-05       |
|    loss                 | 97.1        |
|    max_step             | 0           |
|    n_updates            | 4960        |
|    out_of_road          | 0.839       |
|    policy_gradient_loss | 0.00166     |
|    route_completion     | 0.474       |
|    std                  | 0.648       |
|    total_cost           | 15          |
|    value_loss           | 227         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 449      |
|    iterations      | 249      |
|    time_elapsed    | 2836     |
|    total_timesteps | 1274880  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.195       |
|    crash                | 0.264       |
|    max_step             | 0           |
|    mean_ep_length       | 185         |
|    mean_reward          | 217         |
|    num_episodes         | 5           |
|    out_of_road          | 0.805       |
|    raw_action           | 0.473227    |
|    route_completion     | 0.544       |
|    success_rate         | 0.3         |
|    total_cost           | 20.4        |
| time/                   |             |
|    total_timesteps      | 1280000     |
| train/                  |             |
|    approx_kl            | 0.008131602 |
|    arrive_dest          | 0.163       |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.28        |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.578       |
|    learning_rate        | 5e-05       |
|    loss                 | 111         |
|    max_step             | 0           |
|    n_updates            | 4980        |
|    out_of_road          | 0.838       |
|    policy_gradient_loss | -0.00105    |
|    route_completion     | 0.476       |
|    std                  | 0.65        |
|    total_cost           | 15.2        |
|    value_loss           | 229         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 449      |
|    iterations      | 250      |
|    time_elapsed    | 2850     |
|    total_timesteps | 1280000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 317          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 449          |
|    iterations           | 251          |
|    time_elapsed         | 2858         |
|    total_timesteps      | 1285120      |
| train/                  |              |
|    approx_kl            | 0.0045344806 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.609        |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    n_updates            | 5000         |
|    policy_gradient_loss | -0.000312    |
|    std                  | 0.649        |
|    value_loss           | 234          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.195        |
|    crash                | 0.262        |
|    max_step             | 0            |
|    mean_ep_length       | 162          |
|    mean_reward          | 173          |
|    num_episodes         | 5            |
|    out_of_road          | 0.805        |
|    raw_action           | 0.4734423    |
|    route_completion     | 0.544        |
|    success_rate         | 0.1          |
|    total_cost           | 20.3         |
| time/                   |              |
|    total_timesteps      | 1290000      |
| train/                  |              |
|    approx_kl            | 0.0028828664 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    crash                | 0.279        |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.743        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.1         |
|    max_step             | 0            |
|    n_updates            | 5020         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | -0.000902    |
|    route_completion     | 0.474        |
|    std                  | 0.648        |
|    total_cost           | 15.1         |
|    value_loss           | 161          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 449      |
|    iterations      | 252      |
|    time_elapsed    | 2869     |
|    total_timesteps | 1290240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 313          |
|    ep_rew_mean          | 283          |
| time/                   |              |
|    fps                  | 450          |
|    iterations           | 253          |
|    time_elapsed         | 2876         |
|    total_timesteps      | 1295360      |
| train/                  |              |
|    approx_kl            | 0.0017205346 |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.605        |
|    learning_rate        | 5e-05        |
|    loss                 | 84.3         |
|    n_updates            | 5040         |
|    policy_gradient_loss | 0.000952     |
|    std                  | 0.649        |
|    value_loss           | 190          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.194        |
|    crash                | 0.262        |
|    max_step             | 0            |
|    mean_ep_length       | 117          |
|    mean_reward          | 163          |
|    num_episodes         | 5            |
|    out_of_road          | 0.806        |
|    raw_action           | 0.47358704   |
|    route_completion     | 0.543        |
|    success_rate         | 0            |
|    total_cost           | 20.1         |
| time/                   |              |
|    total_timesteps      | 1300000      |
| train/                  |              |
|    approx_kl            | 0.0014807907 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.1          |
|    crash                | 0.28         |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.7          |
|    learning_rate        | 5e-05        |
|    loss                 | 84.2         |
|    max_step             | 0            |
|    n_updates            | 5060         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | 0.000385     |
|    route_completion     | 0.474        |
|    std                  | 0.647        |
|    total_cost           | 15.1         |
|    value_loss           | 188          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 450      |
|    iterations      | 254      |
|    time_elapsed    | 2889     |
|    total_timesteps | 1300480  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 302        |
|    ep_rew_mean          | 272        |
| time/                   |            |
|    fps                  | 450        |
|    iterations           | 255        |
|    time_elapsed         | 2896       |
|    total_timesteps      | 1305600    |
| train/                  |            |
|    approx_kl            | 0.00194866 |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.91      |
|    explained_variance   | 0.632      |
|    learning_rate        | 5e-05      |
|    loss                 | 116        |
|    n_updates            | 5080       |
|    policy_gradient_loss | 0.00063    |
|    std                  | 0.647      |
|    value_loss           | 285        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.195        |
|    crash                | 0.261        |
|    max_step             | 0            |
|    mean_ep_length       | 179          |
|    mean_reward          | 212          |
|    num_episodes         | 5            |
|    out_of_road          | 0.805        |
|    raw_action           | 0.47297385   |
|    route_completion     | 0.544        |
|    success_rate         | 0.4          |
|    total_cost           | 20.1         |
| time/                   |              |
|    total_timesteps      | 1310000      |
| train/                  |              |
|    approx_kl            | 0.0037946287 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.281        |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.669        |
|    learning_rate        | 5e-05        |
|    loss                 | 90.8         |
|    max_step             | 0            |
|    n_updates            | 5100         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | 0.00061      |
|    route_completion     | 0.475        |
|    std                  | 0.645        |
|    total_cost           | 15.1         |
|    value_loss           | 165          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 325      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 449      |
|    iterations      | 256      |
|    time_elapsed    | 2912     |
|    total_timesteps | 1310720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 330          |
|    ep_rew_mean          | 296          |
| time/                   |              |
|    fps                  | 450          |
|    iterations           | 257          |
|    time_elapsed         | 2920         |
|    total_timesteps      | 1315840      |
| train/                  |              |
|    approx_kl            | 0.0015382211 |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.746        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.1         |
|    n_updates            | 5120         |
|    policy_gradient_loss | 0.0017       |
|    std                  | 0.643        |
|    value_loss           | 129          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.197        |
|    crash                | 0.259        |
|    max_step             | 0            |
|    mean_ep_length       | 176          |
|    mean_reward          | 207          |
|    num_episodes         | 5            |
|    out_of_road          | 0.803        |
|    raw_action           | 0.47278157   |
|    route_completion     | 0.546        |
|    success_rate         | 0.3          |
|    total_cost           | 20.1         |
| time/                   |              |
|    total_timesteps      | 1320000      |
| train/                  |              |
|    approx_kl            | 0.0012731032 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    crash                | 0.282        |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.803        |
|    learning_rate        | 5e-05        |
|    loss                 | 56           |
|    max_step             | 0            |
|    n_updates            | 5140         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | -0.00134     |
|    route_completion     | 0.475        |
|    std                  | 0.645        |
|    total_cost           | 15.1         |
|    value_loss           | 150          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 449      |
|    iterations      | 258      |
|    time_elapsed    | 2935     |
|    total_timesteps | 1320960  |
---------------------------------
