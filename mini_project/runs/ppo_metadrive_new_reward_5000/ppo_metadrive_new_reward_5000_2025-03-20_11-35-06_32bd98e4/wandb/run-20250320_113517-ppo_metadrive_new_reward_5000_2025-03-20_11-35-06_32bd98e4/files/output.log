Using cpu device
Loading checkpoint from C:\Users\Colton\Documents\GitHub\cs260r-assignment-2025winter\mini_project\runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_10-44-32_97412f1e\models\rl_model_500000_steps.zip!
Logging to runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4\ppo_metadrive_new_reward_5000_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 863      |
|    iterations      | 1        |
|    time_elapsed    | 5        |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.4          |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 208          |
|    mean_reward          | 250          |
|    num_episodes         | 5            |
|    out_of_road          | 0.6          |
|    raw_action           | 0.5160407    |
|    route_completion     | 0.762        |
|    success_rate         | 0.2          |
|    total_cost           | 18.6         |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0010803773 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    crash                | 0.4          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.763        |
|    learning_rate        | 5e-05        |
|    loss                 | 48           |
|    max_step             | 0            |
|    n_updates            | 20           |
|    out_of_road          | 1            |
|    policy_gradient_loss | 0.00062      |
|    route_completion     | 0.476        |
|    std                  | 0.614        |
|    total_cost           | 2            |
|    value_loss           | 144          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 482      |
|    iterations      | 2        |
|    time_elapsed    | 21       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 349         |
|    ep_rew_mean          | 306         |
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 3           |
|    time_elapsed         | 28          |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.002217526 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.775       |
|    learning_rate        | 5e-05       |
|    loss                 | 85.9        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.000957   |
|    std                  | 0.614       |
|    value_loss           | 182         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.3          |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 140          |
|    mean_reward          | 202          |
|    num_episodes         | 5            |
|    out_of_road          | 0.7          |
|    raw_action           | 0.49996656   |
|    route_completion     | 0.684        |
|    success_rate         | 0.1          |
|    total_cost           | 11.1         |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0027438528 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.268        |
|    clip_range           | 0.1          |
|    crash                | 0.4          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.795        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.3         |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 1            |
|    policy_gradient_loss | 0.00522      |
|    route_completion     | 0.432        |
|    std                  | 0.613        |
|    total_cost           | 3.2          |
|    value_loss           | 158          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 461      |
|    iterations      | 4        |
|    time_elapsed    | 44       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 350         |
|    ep_rew_mean          | 306         |
| time/                   |             |
|    fps                  | 492         |
|    iterations           | 5           |
|    time_elapsed         | 51          |
|    total_timesteps      | 25600       |
| train/                  |             |
|    approx_kl            | 0.001995048 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.82        |
|    learning_rate        | 5e-05       |
|    loss                 | 83.1        |
|    n_updates            | 80          |
|    policy_gradient_loss | 0.00145     |
|    std                  | 0.611       |
|    value_loss           | 174         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.267        |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 210          |
|    mean_reward          | 169          |
|    num_episodes         | 5            |
|    out_of_road          | 0.733        |
|    raw_action           | 0.47544652   |
|    route_completion     | 0.615        |
|    success_rate         | 0.1          |
|    total_cost           | 18.8         |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0062043616 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.214        |
|    clip_range           | 0.1          |
|    crash                | 0.333        |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.729        |
|    learning_rate        | 5e-05        |
|    loss                 | 107          |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 1            |
|    policy_gradient_loss | 0.00464      |
|    route_completion     | 0.42         |
|    std                  | 0.609        |
|    total_cost           | 3.2          |
|    value_loss           | 154          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 352      |
|    ep_rew_mean     | 311      |
| time/              |          |
|    fps             | 422      |
|    iterations      | 6        |
|    time_elapsed    | 72       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 341          |
|    ep_rew_mean          | 300          |
| time/                   |              |
|    fps                  | 444          |
|    iterations           | 7            |
|    time_elapsed         | 80           |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 0.0039655855 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.809        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.9         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000802    |
|    std                  | 0.607        |
|    value_loss           | 152          |
------------------------------------------
