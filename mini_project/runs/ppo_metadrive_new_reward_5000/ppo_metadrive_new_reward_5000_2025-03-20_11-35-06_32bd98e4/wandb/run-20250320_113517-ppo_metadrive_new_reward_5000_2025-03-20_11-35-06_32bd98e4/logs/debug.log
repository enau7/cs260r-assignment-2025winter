2025-03-20 11:35:17,492 INFO    MainThread:7436 [wandb_setup.py:_flush():67] Current SDK version is 0.19.8
2025-03-20 11:35:17,492 INFO    MainThread:7436 [wandb_setup.py:_flush():67] Configure stats pid to 7436
2025-03-20 11:35:17,492 INFO    MainThread:7436 [wandb_setup.py:_flush():67] Loading settings from C:\Users\Colton\.config\wandb\settings
2025-03-20 11:35:17,492 INFO    MainThread:7436 [wandb_setup.py:_flush():67] Loading settings from C:\Users\Colton\Documents\GitHub\cs260r-assignment-2025winter\mini_project\wandb\settings
2025-03-20 11:35:17,493 INFO    MainThread:7436 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-03-20 11:35:17,493 INFO    MainThread:7436 [wandb_init.py:setup_run_log_directory():647] Logging user logs to runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4\wandb\run-20250320_113517-ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4\logs\debug.log
2025-03-20 11:35:17,493 INFO    MainThread:7436 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4\wandb\run-20250320_113517-ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4\logs\debug-internal.log
2025-03-20 11:35:17,493 INFO    MainThread:7436 [wandb_init.py:monkeypatch_ipython():599] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x0000029743197E50>
2025-03-20 11:35:17,497 INFO    MainThread:7436 [wandb_init.py:init():761] calling init triggers
2025-03-20 11:35:17,497 INFO    MainThread:7436 [wandb_init.py:init():766] wandb.init called with sweep_config: {}
config: {'_wandb': {}}
2025-03-20 11:35:17,497 INFO    MainThread:7436 [wandb_init.py:init():784] starting backend
2025-03-20 11:35:17,497 INFO    MainThread:7436 [wandb_init.py:init():788] sending inform_init request
2025-03-20 11:35:17,512 INFO    MainThread:7436 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=spawn, using: spawn
2025-03-20 11:35:17,512 INFO    MainThread:7436 [wandb_init.py:init():798] backend started and connected
2025-03-20 11:35:17,513 INFO    MainThread:7436 [wandb_run.py:_label_probe_notebook():1204] probe notebook
2025-03-20 11:35:17,527 INFO    MainThread:7436 [wandb_init.py:init():891] updated telemetry
2025-03-20 11:35:17,576 INFO    MainThread:7436 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-03-20 11:35:17,862 INFO    MainThread:7436 [wandb_init.py:init():990] starting run threads in backend
2025-03-20 11:35:18,065 INFO    MainThread:7436 [wandb_run.py:_console_start():2375] atexit reg
2025-03-20 11:35:18,065 INFO    MainThread:7436 [wandb_run.py:_redirect():2227] redirect: wrap_raw
2025-03-20 11:35:18,066 INFO    MainThread:7436 [wandb_run.py:_redirect():2292] Wrapping output streams.
2025-03-20 11:35:18,067 INFO    MainThread:7436 [wandb_run.py:_redirect():2315] Redirects installed.
2025-03-20 11:35:18,070 INFO    MainThread:7436 [wandb_init.py:init():1032] run started, returning control to user process
2025-03-20 11:35:18,070 INFO    MainThread:7436 [jupyter.py:save_ipynb():386] not saving jupyter notebook
2025-03-20 11:35:18,070 INFO    MainThread:7436 [wandb_init.py:_pause_backend():564] pausing backend
2025-03-20 11:35:18,075 INFO    MainThread:7436 [wandb_init.py:_resume_backend():569] resuming backend
2025-03-20 11:35:19,080 INFO    MainThread:7436 [jupyter.py:save_ipynb():386] not saving jupyter notebook
2025-03-20 11:35:19,080 INFO    MainThread:7436 [wandb_init.py:_pause_backend():564] pausing backend
2025-03-20 11:35:19,086 INFO    MainThread:7436 [wandb_init.py:_resume_backend():569] resuming backend
2025-03-20 11:35:19,096 INFO    MainThread:7436 [jupyter.py:save_ipynb():386] not saving jupyter notebook
2025-03-20 11:35:19,097 INFO    MainThread:7436 [wandb_init.py:_pause_backend():564] pausing backend
2025-03-20 11:35:19,102 INFO    MainThread:7436 [wandb_init.py:_resume_backend():569] resuming backend
2025-03-20 11:35:19,620 INFO    MainThread:7436 [wandb_run.py:_tensorboard_callback():1449] tensorboard callback: runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4\ppo_metadrive_new_reward_5000_1, True
2025-03-20 11:35:19,625 INFO    MainThread:7436 [wandb_run.py:_config_callback():1261] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 2, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 2000000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1742495719103526100, 'learning_rate': 5e-05, 'tensorboard_log': 'runs\\ppo_metadrive_new_reward_5000\\ppo_metadrive_new_reward_5000_2025-03-20_11-35-06_32bd98e4', '_last_obs': '[[0.4861111  0.09722222 0.5        ... 1.         1.         1.        ]\n [0.29166666 0.29166666 0.5        ... 1.         1.         1.        ]\n [0.29166666 0.29166666 0.5        ... 1.         1.         1.        ]\n ...\n [0.09722222 0.4861111  0.5        ... 1.         1.         1.        ]\n [0.29166666 0.29166666 0.5        ... 1.         1.         1.        ]\n [0.09722222 0.4861111  0.5        ... 1.         1.         1.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x000002974297D350>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-0.0, 1.0, (259,), float32)', 'action_space': 'Box(-1.0, 1.0, (2,), float32)', 'n_envs': 10, 'n_steps': 512, 'gamma': 0.995, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 10.0, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'batch_size': 256, 'n_epochs': 20, 'clip_range': '<function get_schedule_fn.<locals>.<lambda> at 0x00000297473A0FE0>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x00000297392F6020>', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x00000297392DFE50>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=259, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=259, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64, out_features=2, bias=True)\n  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x00000297476256D0>'}
