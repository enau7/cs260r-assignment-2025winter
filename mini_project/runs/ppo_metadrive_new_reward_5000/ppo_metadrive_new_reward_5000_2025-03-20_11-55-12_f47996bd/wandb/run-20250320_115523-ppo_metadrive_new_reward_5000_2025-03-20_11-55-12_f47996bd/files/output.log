Using cpu device
Loading checkpoint from C:\Users\Colton\Documents\GitHub\cs260r-assignment-2025winter\mini_project\runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_10-44-32_97412f1e\models\rl_model_500000_steps.zip!
Logging to runs\ppo_metadrive_new_reward_5000\ppo_metadrive_new_reward_5000_2025-03-20_11-55-12_f47996bd\ppo_metadrive_new_reward_5000_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    fps             | 817      |
|    iterations      | 1        |
|    time_elapsed    | 6        |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 187          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4192786    |
|    route_completion     | 0.529        |
|    success_rate         | 0.2          |
|    total_cost           | 6.8          |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0019392662 |
|    arrive_dest          | 0.4          |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    crash                | 0.4          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.713        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.6         |
|    max_step             | 0            |
|    n_updates            | 20           |
|    out_of_road          | 0.6          |
|    policy_gradient_loss | -0.000147    |
|    route_completion     | 0.614        |
|    std                  | 0.612        |
|    total_cost           | 18.4         |
|    value_loss           | 151          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 382      |
|    iterations      | 2        |
|    time_elapsed    | 26       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 321         |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 449         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.004420843 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.69        |
|    learning_rate        | 5e-05       |
|    loss                 | 148         |
|    n_updates            | 40          |
|    policy_gradient_loss | 0.0021      |
|    std                  | 0.612       |
|    value_loss           | 266         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 165          |
|    mean_reward          | 237          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.41589704   |
|    route_completion     | 0.567        |
|    success_rate         | 0.2          |
|    total_cost           | 5.4          |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0024881274 |
|    arrive_dest          | 0.4          |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.742        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.5         |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 0.6          |
|    policy_gradient_loss | 0.000651     |
|    route_completion     | 0.602        |
|    std                  | 0.611        |
|    total_cost           | 21.8         |
|    value_loss           | 177          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 390      |
|    iterations      | 4        |
|    time_elapsed    | 52       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 332          |
|    ep_rew_mean          | 304          |
| time/                   |              |
|    fps                  | 425          |
|    iterations           | 5            |
|    time_elapsed         | 60           |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0041071256 |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.798        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.9         |
|    n_updates            | 80           |
|    policy_gradient_loss | 0.000395     |
|    std                  | 0.61         |
|    value_loss           | 129          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 187          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.40097898   |
|    route_completion     | 0.542        |
|    success_rate         | 0            |
|    total_cost           | 5.33         |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0072829486 |
|    arrive_dest          | 0.267        |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.739        |
|    learning_rate        | 5e-05        |
|    loss                 | 51           |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 0.733        |
|    policy_gradient_loss | -0.000188    |
|    route_completion     | 0.566        |
|    std                  | 0.608        |
|    total_cost           | 17           |
|    value_loss           | 125          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 317      |
| time/              |          |
|    fps             | 405      |
|    iterations      | 6        |
|    time_elapsed    | 75       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 357         |
|    ep_rew_mean          | 324         |
| time/                   |             |
|    fps                  | 430         |
|    iterations           | 7           |
|    time_elapsed         | 83          |
|    total_timesteps      | 35840       |
| train/                  |             |
|    approx_kl            | 0.002223557 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.685       |
|    learning_rate        | 5e-05       |
|    loss                 | 89.1        |
|    n_updates            | 120         |
|    policy_gradient_loss | 0.0045      |
|    std                  | 0.609       |
|    value_loss           | 192         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.05        |
|    crash                | 0.1         |
|    max_step             | 0           |
|    mean_ep_length       | 112         |
|    mean_reward          | 149         |
|    num_episodes         | 5           |
|    out_of_road          | 0.95        |
|    raw_action           | 0.41580862  |
|    route_completion     | 0.541       |
|    success_rate         | 0.2         |
|    total_cost           | 4.2         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.004256029 |
|    arrive_dest          | 0.25        |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.1         |
|    crash                | 0.15        |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.813       |
|    learning_rate        | 5e-05       |
|    loss                 | 46.7        |
|    max_step             | 0           |
|    n_updates            | 140         |
|    out_of_road          | 0.75        |
|    policy_gradient_loss | 0.00248     |
|    route_completion     | 0.581       |
|    std                  | 0.607       |
|    total_cost           | 15.4        |
|    value_loss           | 114         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 328      |
| time/              |          |
|    fps             | 420      |
|    iterations      | 8        |
|    time_elapsed    | 97       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 351          |
|    ep_rew_mean          | 323          |
| time/                   |              |
|    fps                  | 440          |
|    iterations           | 9            |
|    time_elapsed         | 104          |
|    total_timesteps      | 46080        |
| train/                  |              |
|    approx_kl            | 0.0062632584 |
|    clip_fraction        | 0.197        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.745        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.5         |
|    n_updates            | 160          |
|    policy_gradient_loss | 0.003        |
|    std                  | 0.608        |
|    value_loss           | 184          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.12        |
|    crash                | 0.08        |
|    max_step             | 0           |
|    mean_ep_length       | 165         |
|    mean_reward          | 277         |
|    num_episodes         | 5           |
|    out_of_road          | 0.88        |
|    raw_action           | 0.430748    |
|    route_completion     | 0.584       |
|    success_rate         | 0.3         |
|    total_cost           | 3.76        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.002640241 |
|    arrive_dest          | 0.24        |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.1         |
|    crash                | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.771       |
|    learning_rate        | 5e-05       |
|    loss                 | 104         |
|    max_step             | 0           |
|    n_updates            | 180         |
|    out_of_road          | 0.76        |
|    policy_gradient_loss | -0.000328   |
|    route_completion     | 0.578       |
|    std                  | 0.606       |
|    total_cost           | 12.7        |
|    value_loss           | 178         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 325      |
| time/              |          |
|    fps             | 429      |
|    iterations      | 10       |
|    time_elapsed    | 119      |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 361         |
|    ep_rew_mean          | 328         |
| time/                   |             |
|    fps                  | 444         |
|    iterations           | 11          |
|    time_elapsed         | 126         |
|    total_timesteps      | 56320       |
| train/                  |             |
|    approx_kl            | 0.009926688 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.786       |
|    learning_rate        | 5e-05       |
|    loss                 | 73          |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00035    |
|    std                  | 0.606       |
|    value_loss           | 193         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.1          |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.9          |
|    raw_action           | 0.43759936   |
|    route_completion     | 0.55         |
|    success_rate         | 0.2          |
|    total_cost           | 3.5          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0019584023 |
|    arrive_dest          | 0.267        |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    crash                | 0.233        |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.776        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.2         |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 0.733        |
|    policy_gradient_loss | 0.00165      |
|    route_completion     | 0.594        |
|    std                  | 0.605        |
|    total_cost           | 11.7         |
|    value_loss           | 163          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 332      |
| time/              |          |
|    fps             | 433      |
|    iterations      | 12       |
|    time_elapsed    | 141      |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 330          |
| time/                   |              |
|    fps                  | 447          |
|    iterations           | 13           |
|    time_elapsed         | 148          |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0012989242 |
|    clip_fraction        | 0.191        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.767        |
|    learning_rate        | 5e-05        |
|    loss                 | 91.5         |
|    n_updates            | 240          |
|    policy_gradient_loss | 0.000833     |
|    std                  | 0.604        |
|    value_loss           | 171          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.143       |
|    crash                | 0.143       |
|    max_step             | 0           |
|    mean_ep_length       | 193         |
|    mean_reward          | 328         |
|    num_episodes         | 5           |
|    out_of_road          | 0.857       |
|    raw_action           | 0.44365388  |
|    route_completion     | 0.578       |
|    success_rate         | 0.2         |
|    total_cost           | 3.83        |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.014930877 |
|    arrive_dest          | 0.229       |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.1         |
|    crash                | 0.257       |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.797       |
|    learning_rate        | 5e-05       |
|    loss                 | 52.5        |
|    max_step             | 0           |
|    n_updates            | 260         |
|    out_of_road          | 0.771       |
|    policy_gradient_loss | 0.00109     |
|    route_completion     | 0.562       |
|    std                  | 0.604       |
|    total_cost           | 10.4        |
|    value_loss           | 124         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 313      |
| time/              |          |
|    fps             | 439      |
|    iterations      | 14       |
|    time_elapsed    | 162      |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 342          |
|    ep_rew_mean          | 309          |
| time/                   |              |
|    fps                  | 448          |
|    iterations           | 15           |
|    time_elapsed         | 171          |
|    total_timesteps      | 76800        |
| train/                  |              |
|    approx_kl            | 0.0033342391 |
|    clip_fraction        | 0.226        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 65.3         |
|    n_updates            | 280          |
|    policy_gradient_loss | 0.00282      |
|    std                  | 0.605        |
|    value_loss           | 184          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.2         |
|    crash                | 0.125       |
|    max_step             | 0           |
|    mean_ep_length       | 243         |
|    mean_reward          | 218         |
|    num_episodes         | 5           |
|    out_of_road          | 0.8         |
|    raw_action           | 0.43676195  |
|    route_completion     | 0.602       |
|    success_rate         | 0.3         |
|    total_cost           | 9.97        |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.013463686 |
|    arrive_dest          | 0.2         |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.1         |
|    crash                | 0.25        |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.731       |
|    learning_rate        | 5e-05       |
|    loss                 | 110         |
|    max_step             | 0           |
|    n_updates            | 300         |
|    out_of_road          | 0.8         |
|    policy_gradient_loss | 0.00476     |
|    route_completion     | 0.573       |
|    std                  | 0.606       |
|    total_cost           | 10.2        |
|    value_loss           | 200         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 314      |
| time/              |          |
|    fps             | 430      |
|    iterations      | 16       |
|    time_elapsed    | 190      |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 318          |
| time/                   |              |
|    fps                  | 441          |
|    iterations           | 17           |
|    time_elapsed         | 197          |
|    total_timesteps      | 87040        |
| train/                  |              |
|    approx_kl            | 0.0012348242 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.776        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.8         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.000501    |
|    std                  | 0.606        |
|    value_loss           | 187          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.2          |
|    crash                | 0.111        |
|    max_step             | 0            |
|    mean_ep_length       | 181          |
|    mean_reward          | 232          |
|    num_episodes         | 5            |
|    out_of_road          | 0.8          |
|    raw_action           | 0.4406162    |
|    route_completion     | 0.606        |
|    success_rate         | 0.3          |
|    total_cost           | 10.4         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0023378017 |
|    arrive_dest          | 0.222        |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.783        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.1         |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 0.778        |
|    policy_gradient_loss | -0.000645    |
|    route_completion     | 0.594        |
|    std                  | 0.602        |
|    total_cost           | 12           |
|    value_loss           | 147          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 313      |
| time/              |          |
|    fps             | 431      |
|    iterations      | 18       |
|    time_elapsed    | 213      |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 338          |
|    ep_rew_mean          | 311          |
| time/                   |              |
|    fps                  | 441          |
|    iterations           | 19           |
|    time_elapsed         | 220          |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0022324575 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.789        |
|    learning_rate        | 5e-05        |
|    loss                 | 109          |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.0012      |
|    std                  | 0.6          |
|    value_loss           | 166          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.18        |
|    crash                | 0.16        |
|    max_step             | 0           |
|    mean_ep_length       | 112         |
|    mean_reward          | 118         |
|    num_episodes         | 5           |
|    out_of_road          | 0.82        |
|    raw_action           | 0.44021073  |
|    route_completion     | 0.582       |
|    success_rate         | 0.1         |
|    total_cost           | 9.76        |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.002224509 |
|    arrive_dest          | 0.22        |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.1         |
|    crash                | 0.22        |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.728       |
|    learning_rate        | 5e-05       |
|    loss                 | 70.9        |
|    max_step             | 0           |
|    n_updates            | 380         |
|    out_of_road          | 0.78        |
|    policy_gradient_loss | -0.00102    |
|    route_completion     | 0.589       |
|    std                  | 0.599       |
|    total_cost           | 14          |
|    value_loss           | 188         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | 313      |
| time/              |          |
|    fps             | 429      |
|    iterations      | 20       |
|    time_elapsed    | 238      |
|    total_timesteps | 102400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 340         |
|    ep_rew_mean          | 313         |
| time/                   |             |
|    fps                  | 435         |
|    iterations           | 21          |
|    time_elapsed         | 246         |
|    total_timesteps      | 107520      |
| train/                  |             |
|    approx_kl            | 0.003993041 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.756       |
|    learning_rate        | 5e-05       |
|    loss                 | 57          |
|    n_updates            | 400         |
|    policy_gradient_loss | 0.00187     |
|    std                  | 0.599       |
|    value_loss           | 151         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.145        |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.43850502   |
|    route_completion     | 0.576        |
|    success_rate         | 0.2          |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0014738336 |
|    arrive_dest          | 0.218        |
|    clip_fraction        | 0.0929       |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.815        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.5         |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 0.782        |
|    policy_gradient_loss | -0.00128     |
|    route_completion     | 0.589        |
|    std                  | 0.597        |
|    total_cost           | 13           |
|    value_loss           | 117          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 317      |
| time/              |          |
|    fps             | 426      |
|    iterations      | 22       |
|    time_elapsed    | 264      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 320          |
| time/                   |              |
|    fps                  | 432          |
|    iterations           | 23           |
|    time_elapsed         | 272          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0014879707 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.757        |
|    learning_rate        | 5e-05        |
|    loss                 | 107          |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.000821    |
|    std                  | 0.599        |
|    value_loss           | 206          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.2          |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 173          |
|    mean_reward          | 239          |
|    num_episodes         | 5            |
|    out_of_road          | 0.8          |
|    raw_action           | 0.43669054   |
|    route_completion     | 0.575        |
|    success_rate         | 0.2          |
|    total_cost           | 10.1         |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0029330864 |
|    arrive_dest          | 0.2          |
|    clip_fraction        | 0.194        |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.823        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.4         |
|    max_step             | 0            |
|    n_updates            | 460          |
|    out_of_road          | 0.8          |
|    policy_gradient_loss | 0.00137      |
|    route_completion     | 0.583        |
|    std                  | 0.599        |
|    total_cost           | 12           |
|    value_loss           | 137          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 314      |
| time/              |          |
|    fps             | 419      |
|    iterations      | 24       |
|    time_elapsed    | 292      |
|    total_timesteps | 122880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 312          |
| time/                   |              |
|    fps                  | 422          |
|    iterations           | 25           |
|    time_elapsed         | 302          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0022782371 |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.743        |
|    learning_rate        | 5e-05        |
|    loss                 | 90.5         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.000575    |
|    std                  | 0.599        |
|    value_loss           | 192          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.2          |
|    crash                | 0.154        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 209          |
|    num_episodes         | 5            |
|    out_of_road          | 0.8          |
|    raw_action           | 0.44069767   |
|    route_completion     | 0.575        |
|    success_rate         | 0.2          |
|    total_cost           | 9.42         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0019301183 |
|    arrive_dest          | 0.2          |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.75         |
|    learning_rate        | 5e-05        |
|    loss                 | 86           |
|    max_step             | 0            |
|    n_updates            | 500          |
|    out_of_road          | 0.8          |
|    policy_gradient_loss | -0.000676    |
|    route_completion     | 0.576        |
|    std                  | 0.599        |
|    total_cost           | 11.6         |
|    value_loss           | 231          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 408      |
|    iterations      | 26       |
|    time_elapsed    | 326      |
|    total_timesteps | 133120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 321         |
|    ep_rew_mean          | 302         |
| time/                   |             |
|    fps                  | 414         |
|    iterations           | 27          |
|    time_elapsed         | 333         |
|    total_timesteps      | 138240      |
| train/                  |             |
|    approx_kl            | 0.003482911 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.737       |
|    learning_rate        | 5e-05       |
|    loss                 | 116         |
|    n_updates            | 520         |
|    policy_gradient_loss | 0.000634    |
|    std                  | 0.598       |
|    value_loss           | 221         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.214      |
|    crash                | 0.171      |
|    max_step             | 0          |
|    mean_ep_length       | 133        |
|    mean_reward          | 198        |
|    num_episodes         | 5          |
|    out_of_road          | 0.786      |
|    raw_action           | 0.442912   |
|    route_completion     | 0.574      |
|    success_rate         | 0.4        |
|    total_cost           | 8.94       |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.00876832 |
|    arrive_dest          | 0.214      |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.1        |
|    crash                | 0.257      |
|    entropy_loss         | -1.71      |
|    explained_variance   | 0.824      |
|    learning_rate        | 5e-05      |
|    loss                 | 83.7       |
|    max_step             | 0          |
|    n_updates            | 540        |
|    out_of_road          | 0.786      |
|    policy_gradient_loss | -1.78e-05  |
|    route_completion     | 0.576      |
|    std                  | 0.598      |
|    total_cost           | 11         |
|    value_loss           | 165        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 404      |
|    iterations      | 28       |
|    time_elapsed    | 354      |
|    total_timesteps | 143360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 327         |
|    ep_rew_mean          | 301         |
| time/                   |             |
|    fps                  | 404         |
|    iterations           | 29          |
|    time_elapsed         | 366         |
|    total_timesteps      | 148480      |
| train/                  |             |
|    approx_kl            | 0.004437182 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.725       |
|    learning_rate        | 5e-05       |
|    loss                 | 138         |
|    n_updates            | 560         |
|    policy_gradient_loss | 0.00297     |
|    std                  | 0.6         |
|    value_loss           | 260         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.2          |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 146          |
|    mean_reward          | 205          |
|    num_episodes         | 5            |
|    out_of_road          | 0.8          |
|    raw_action           | 0.44824544   |
|    route_completion     | 0.569        |
|    success_rate         | 0.1          |
|    total_cost           | 8.47         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0015850228 |
|    arrive_dest          | 0.213        |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.835        |
|    learning_rate        | 5e-05        |
|    loss                 | 83           |
|    max_step             | 0            |
|    n_updates            | 580          |
|    out_of_road          | 0.787        |
|    policy_gradient_loss | 0.000572     |
|    route_completion     | 0.58         |
|    std                  | 0.6          |
|    total_cost           | 10.7         |
|    value_loss           | 151          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 30       |
|    time_elapsed    | 384      |
|    total_timesteps | 153600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 330          |
|    ep_rew_mean          | 305          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 31           |
|    time_elapsed         | 396          |
|    total_timesteps      | 158720       |
| train/                  |              |
|    approx_kl            | 0.0012645528 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.669        |
|    learning_rate        | 5e-05        |
|    loss                 | 107          |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00147     |
|    std                  | 0.601        |
|    value_loss           | 240          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.188        |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 186          |
|    mean_reward          | 194          |
|    num_episodes         | 5            |
|    out_of_road          | 0.812        |
|    raw_action           | 0.45182335   |
|    route_completion     | 0.574        |
|    success_rate         | 0.1          |
|    total_cost           | 8.4          |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0019467536 |
|    arrive_dest          | 0.212        |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    crash                | 0.275        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.808        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.7         |
|    max_step             | 0            |
|    n_updates            | 620          |
|    out_of_road          | 0.787        |
|    policy_gradient_loss | 0.00112      |
|    route_completion     | 0.58         |
|    std                  | 0.603        |
|    total_cost           | 10.2         |
|    value_loss           | 153          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 393      |
|    iterations      | 32       |
|    time_elapsed    | 415      |
|    total_timesteps | 163840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 333         |
|    ep_rew_mean          | 309         |
| time/                   |             |
|    fps                  | 396         |
|    iterations           | 33          |
|    time_elapsed         | 425         |
|    total_timesteps      | 168960      |
| train/                  |             |
|    approx_kl            | 0.008714832 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.772       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.1        |
|    n_updates            | 640         |
|    policy_gradient_loss | 0.000666    |
|    std                  | 0.602       |
|    value_loss           | 199         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.176        |
|    crash                | 0.188        |
|    max_step             | 0            |
|    mean_ep_length       | 159          |
|    mean_reward          | 238          |
|    num_episodes         | 5            |
|    out_of_road          | 0.824        |
|    raw_action           | 0.4503776    |
|    route_completion     | 0.576        |
|    success_rate         | 0            |
|    total_cost           | 8.12         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0030855644 |
|    arrive_dest          | 0.2          |
|    clip_fraction        | 0.223        |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.738        |
|    learning_rate        | 5e-05        |
|    loss                 | 145          |
|    max_step             | 0            |
|    n_updates            | 660          |
|    out_of_road          | 0.8          |
|    policy_gradient_loss | 0.00227      |
|    route_completion     | 0.573        |
|    std                  | 0.602        |
|    total_cost           | 9.69         |
|    value_loss           | 193          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 394      |
|    iterations      | 34       |
|    time_elapsed    | 441      |
|    total_timesteps | 174080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 314          |
|    ep_rew_mean          | 292          |
| time/                   |              |
|    fps                  | 393          |
|    iterations           | 35           |
|    time_elapsed         | 455          |
|    total_timesteps      | 179200       |
| train/                  |              |
|    approx_kl            | 0.0028663666 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.751        |
|    learning_rate        | 5e-05        |
|    loss                 | 59           |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.000856    |
|    std                  | 0.6          |
|    value_loss           | 219          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.178       |
|    crash                | 0.189       |
|    max_step             | 0           |
|    mean_ep_length       | 106         |
|    mean_reward          | 142         |
|    num_episodes         | 5           |
|    out_of_road          | 0.822       |
|    raw_action           | 0.44942087  |
|    route_completion     | 0.568       |
|    success_rate         | 0.1         |
|    total_cost           | 7.73        |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.001942008 |
|    arrive_dest          | 0.189       |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.1         |
|    crash                | 0.256       |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.654       |
|    learning_rate        | 5e-05       |
|    loss                 | 78.6        |
|    max_step             | 0           |
|    n_updates            | 700         |
|    out_of_road          | 0.811       |
|    policy_gradient_loss | -0.00123    |
|    route_completion     | 0.573       |
|    std                  | 0.601       |
|    total_cost           | 10.3        |
|    value_loss           | 254         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 285      |
| time/              |          |
|    fps             | 386      |
|    iterations      | 36       |
|    time_elapsed    | 477      |
|    total_timesteps | 184320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 307          |
|    ep_rew_mean          | 293          |
| time/                   |              |
|    fps                  | 388          |
|    iterations           | 37           |
|    time_elapsed         | 487          |
|    total_timesteps      | 189440       |
| train/                  |              |
|    approx_kl            | 0.0034811622 |
|    clip_fraction        | 0.089        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.713        |
|    learning_rate        | 5e-05        |
|    loss                 | 135          |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00198     |
|    std                  | 0.601        |
|    value_loss           | 257          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.168       |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 96          |
|    mean_reward          | 117         |
|    num_episodes         | 5           |
|    out_of_road          | 0.832       |
|    raw_action           | 0.4531758   |
|    route_completion     | 0.554       |
|    success_rate         | 0           |
|    total_cost           | 7.42        |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.012594673 |
|    arrive_dest          | 0.179       |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.1         |
|    crash                | 0.253       |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.795       |
|    learning_rate        | 5e-05       |
|    loss                 | 85          |
|    max_step             | 0           |
|    n_updates            | 740         |
|    out_of_road          | 0.821       |
|    policy_gradient_loss | 0.00144     |
|    route_completion     | 0.563       |
|    std                  | 0.599       |
|    total_cost           | 9.86        |
|    value_loss           | 176         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 384      |
|    iterations      | 38       |
|    time_elapsed    | 505      |
|    total_timesteps | 194560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 291         |
|    ep_rew_mean          | 283         |
| time/                   |             |
|    fps                  | 388         |
|    iterations           | 39          |
|    time_elapsed         | 513         |
|    total_timesteps      | 199680      |
| train/                  |             |
|    approx_kl            | 0.002137159 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.74        |
|    learning_rate        | 5e-05       |
|    loss                 | 79.4        |
|    n_updates            | 760         |
|    policy_gradient_loss | 4.43e-05    |
|    std                  | 0.596       |
|    value_loss           | 219         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.18        |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 182         |
|    mean_reward          | 251         |
|    num_episodes         | 5           |
|    out_of_road          | 0.82        |
|    raw_action           | 0.4534985   |
|    route_completion     | 0.559       |
|    success_rate         | 0.2         |
|    total_cost           | 7.29        |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.006661988 |
|    arrive_dest          | 0.17        |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    crash                | 0.26        |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.793       |
|    learning_rate        | 5e-05       |
|    loss                 | 84.4        |
|    max_step             | 0           |
|    n_updates            | 780         |
|    out_of_road          | 0.83        |
|    policy_gradient_loss | -0.000928   |
|    route_completion     | 0.558       |
|    std                  | 0.596       |
|    total_cost           | 9.44        |
|    value_loss           | 199         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 285      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 386      |
|    iterations      | 40       |
|    time_elapsed    | 529      |
|    total_timesteps | 204800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 285         |
|    ep_rew_mean          | 280         |
| time/                   |             |
|    fps                  | 390         |
|    iterations           | 41          |
|    time_elapsed         | 537         |
|    total_timesteps      | 209920      |
| train/                  |             |
|    approx_kl            | 0.001281118 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.737       |
|    learning_rate        | 5e-05       |
|    loss                 | 103         |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00123    |
|    std                  | 0.595       |
|    value_loss           | 255         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.181        |
|    crash                | 0.19         |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 166          |
|    num_episodes         | 5            |
|    out_of_road          | 0.819        |
|    raw_action           | 0.45351425   |
|    route_completion     | 0.555        |
|    success_rate         | 0.1          |
|    total_cost           | 7.3          |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0015369491 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.257        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.841        |
|    learning_rate        | 5e-05        |
|    loss                 | 100          |
|    max_step             | 0            |
|    n_updates            | 820          |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | -0.00172     |
|    route_completion     | 0.563        |
|    std                  | 0.595        |
|    total_cost           | 9.24         |
|    value_loss           | 233          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 391      |
|    iterations      | 42       |
|    time_elapsed    | 549      |
|    total_timesteps | 215040   |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.182       |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 167         |
|    mean_reward          | 245         |
|    num_episodes         | 5           |
|    out_of_road          | 0.818       |
|    raw_action           | 0.45259148  |
|    route_completion     | 0.557       |
|    success_rate         | 0.1         |
|    total_cost           | 7.11        |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.002243672 |
|    arrive_dest          | 0.155       |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.1         |
|    crash                | 0.245       |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.751       |
|    learning_rate        | 5e-05       |
|    loss                 | 116         |
|    max_step             | 0           |
|    n_updates            | 840         |
|    out_of_road          | 0.845       |
|    policy_gradient_loss | 0.000785    |
|    route_completion     | 0.556       |
|    std                  | 0.595       |
|    total_cost           | 9.13        |
|    value_loss           | 196         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 389      |
|    iterations      | 43       |
|    time_elapsed    | 565      |
|    total_timesteps | 220160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 294          |
|    ep_rew_mean          | 279          |
| time/                   |              |
|    fps                  | 392          |
|    iterations           | 44           |
|    time_elapsed         | 573          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0017723454 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.771        |
|    learning_rate        | 5e-05        |
|    loss                 | 123          |
|    n_updates            | 860          |
|    policy_gradient_loss | 0.000648     |
|    std                  | 0.595        |
|    value_loss           | 208          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.174        |
|    crash                | 0.191        |
|    max_step             | 0            |
|    mean_ep_length       | 165          |
|    mean_reward          | 203          |
|    num_episodes         | 5            |
|    out_of_road          | 0.826        |
|    raw_action           | 0.45384562   |
|    route_completion     | 0.556        |
|    success_rate         | 0            |
|    total_cost           | 7.22         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0014258821 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.844        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.5         |
|    max_step             | 0            |
|    n_updates            | 880          |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | -0.000721    |
|    route_completion     | 0.544        |
|    std                  | 0.596        |
|    total_cost           | 8.77         |
|    value_loss           | 183          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 392      |
|    iterations      | 45       |
|    time_elapsed    | 587      |
|    total_timesteps | 230400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 302         |
|    ep_rew_mean          | 283         |
| time/                   |             |
|    fps                  | 396         |
|    iterations           | 46          |
|    time_elapsed         | 594         |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.011297813 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.76        |
|    learning_rate        | 5e-05       |
|    loss                 | 135         |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.00125     |
|    std                  | 0.595       |
|    value_loss           | 225         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.167       |
|    crash                | 0.192       |
|    max_step             | 0           |
|    mean_ep_length       | 131         |
|    mean_reward          | 177         |
|    num_episodes         | 5           |
|    out_of_road          | 0.833       |
|    raw_action           | 0.45488024  |
|    route_completion     | 0.556       |
|    success_rate         | 0.2         |
|    total_cost           | 7.07        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.008225614 |
|    arrive_dest          | 0.158       |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.1         |
|    crash                | 0.225       |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.818       |
|    learning_rate        | 5e-05       |
|    loss                 | 86.1        |
|    max_step             | 0           |
|    n_updates            | 920         |
|    out_of_road          | 0.842       |
|    policy_gradient_loss | -0.000847   |
|    route_completion     | 0.547       |
|    std                  | 0.595       |
|    total_cost           | 8.63        |
|    value_loss           | 164         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 395      |
|    iterations      | 47       |
|    time_elapsed    | 608      |
|    total_timesteps | 240640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 313         |
|    ep_rew_mean          | 297         |
| time/                   |             |
|    fps                  | 398         |
|    iterations           | 48          |
|    time_elapsed         | 616         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.003565006 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.805       |
|    learning_rate        | 5e-05       |
|    loss                 | 115         |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.00152     |
|    std                  | 0.593       |
|    value_loss           | 217         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.168        |
|    crash                | 0.192        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.832        |
|    raw_action           | 0.45323688   |
|    route_completion     | 0.551        |
|    success_rate         | 0.3          |
|    total_cost           | 6.84         |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0014181237 |
|    arrive_dest          | 0.168        |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    crash                | 0.224        |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.784        |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    max_step             | 0            |
|    n_updates            | 960          |
|    out_of_road          | 0.832        |
|    policy_gradient_loss | -0.000953    |
|    route_completion     | 0.552        |
|    std                  | 0.593        |
|    total_cost           | 9.48         |
|    value_loss           | 221          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 395      |
|    iterations      | 49       |
|    time_elapsed    | 634      |
|    total_timesteps | 250880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 309         |
|    ep_rew_mean          | 300         |
| time/                   |             |
|    fps                  | 397         |
|    iterations           | 50          |
|    time_elapsed         | 643         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.002303085 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5e-05       |
|    loss                 | 87.6        |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.000668   |
|    std                  | 0.592       |
|    value_loss           | 245         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.162        |
|    crash                | 0.192        |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 180          |
|    num_episodes         | 5            |
|    out_of_road          | 0.838        |
|    raw_action           | 0.45334765   |
|    route_completion     | 0.55         |
|    success_rate         | 0            |
|    total_cost           | 6.82         |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0034322478 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    crash                | 0.223        |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.781        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.9         |
|    max_step             | 0            |
|    n_updates            | 1000         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | -0.00232     |
|    route_completion     | 0.548        |
|    std                  | 0.593        |
|    total_cost           | 9.27         |
|    value_loss           | 167          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 396      |
|    iterations      | 51       |
|    time_elapsed    | 658      |
|    total_timesteps | 261120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 301         |
|    ep_rew_mean          | 298         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 52          |
|    time_elapsed         | 666         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.001818428 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.651       |
|    learning_rate        | 5e-05       |
|    loss                 | 130         |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.593       |
|    value_loss           | 303         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.156       |
|    crash                | 0.193       |
|    max_step             | 0           |
|    mean_ep_length       | 154         |
|    mean_reward          | 204         |
|    num_episodes         | 5           |
|    out_of_road          | 0.844       |
|    raw_action           | 0.45525464  |
|    route_completion     | 0.55        |
|    success_rate         | 0           |
|    total_cost           | 6.64        |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.002623463 |
|    arrive_dest          | 0.156       |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.1         |
|    crash                | 0.23        |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.727       |
|    learning_rate        | 5e-05       |
|    loss                 | 88.6        |
|    max_step             | 0           |
|    n_updates            | 1040        |
|    out_of_road          | 0.844       |
|    policy_gradient_loss | -0.000643   |
|    route_completion     | 0.544       |
|    std                  | 0.592       |
|    total_cost           | 8.99        |
|    value_loss           | 191         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 285      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 53       |
|    time_elapsed    | 679      |
|    total_timesteps | 271360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 290          |
|    ep_rew_mean          | 286          |
| time/                   |              |
|    fps                  | 402          |
|    iterations           | 54           |
|    time_elapsed         | 687          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0038316746 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.716        |
|    learning_rate        | 5e-05        |
|    loss                 | 147          |
|    n_updates            | 1060         |
|    policy_gradient_loss | 0.000213     |
|    std                  | 0.591        |
|    value_loss           | 249          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.164        |
|    crash                | 0.193        |
|    max_step             | 0            |
|    mean_ep_length       | 189          |
|    mean_reward          | 227          |
|    num_episodes         | 5            |
|    out_of_road          | 0.836        |
|    raw_action           | 0.45860603   |
|    route_completion     | 0.555        |
|    success_rate         | 0.2          |
|    total_cost           | 6.77         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0049084947 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.674        |
|    learning_rate        | 5e-05        |
|    loss                 | 190          |
|    max_step             | 0            |
|    n_updates            | 1080         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | -0.00117     |
|    route_completion     | 0.535        |
|    std                  | 0.591        |
|    total_cost           | 8.72         |
|    value_loss           | 337          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 401      |
|    iterations      | 55       |
|    time_elapsed    | 700      |
|    total_timesteps | 281600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 290         |
|    ep_rew_mean          | 288         |
| time/                   |             |
|    fps                  | 404         |
|    iterations           | 56          |
|    time_elapsed         | 708         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.006124935 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.712       |
|    learning_rate        | 5e-05       |
|    loss                 | 108         |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00145    |
|    std                  | 0.591       |
|    value_loss           | 244         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.166      |
|    crash                | 0.2        |
|    max_step             | 0          |
|    mean_ep_length       | 158        |
|    mean_reward          | 224        |
|    num_episodes         | 5          |
|    out_of_road          | 0.834      |
|    raw_action           | 0.45813027 |
|    route_completion     | 0.558      |
|    success_rate         | 0.3        |
|    total_cost           | 6.66       |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.00266712 |
|    arrive_dest          | 0.159      |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.1        |
|    crash                | 0.234      |
|    entropy_loss         | -1.68      |
|    explained_variance   | 0.819      |
|    learning_rate        | 5e-05      |
|    loss                 | 73.2       |
|    max_step             | 0          |
|    n_updates            | 1120       |
|    out_of_road          | 0.841      |
|    policy_gradient_loss | 0.0022     |
|    route_completion     | 0.537      |
|    std                  | 0.589      |
|    total_cost           | 8.83       |
|    value_loss           | 183        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 274      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 401      |
|    iterations      | 57       |
|    time_elapsed    | 726      |
|    total_timesteps | 291840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 282          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 403          |
|    iterations           | 58           |
|    time_elapsed         | 735          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0022503685 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.662        |
|    learning_rate        | 5e-05        |
|    loss                 | 116          |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00243     |
|    std                  | 0.59         |
|    value_loss           | 271          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.167        |
|    crash                | 0.213        |
|    max_step             | 0            |
|    mean_ep_length       | 120          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.833        |
|    raw_action           | 0.45859843   |
|    route_completion     | 0.555        |
|    success_rate         | 0.2          |
|    total_cost           | 6.55         |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0035390214 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    crash                | 0.233        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 143          |
|    max_step             | 0            |
|    n_updates            | 1160         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | -0.00151     |
|    route_completion     | 0.539        |
|    std                  | 0.592        |
|    total_cost           | 8.57         |
|    value_loss           | 272          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 275      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 403      |
|    iterations      | 59       |
|    time_elapsed    | 748      |
|    total_timesteps | 302080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 282         |
|    ep_rew_mean          | 277         |
| time/                   |             |
|    fps                  | 405         |
|    iterations           | 60          |
|    time_elapsed         | 756         |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.004284395 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.785       |
|    learning_rate        | 5e-05       |
|    loss                 | 132         |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.000625    |
|    std                  | 0.59        |
|    value_loss           | 200         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.168        |
|    crash                | 0.226        |
|    max_step             | 0            |
|    mean_ep_length       | 156          |
|    mean_reward          | 189          |
|    num_episodes         | 5            |
|    out_of_road          | 0.832        |
|    raw_action           | 0.45871246   |
|    route_completion     | 0.557        |
|    success_rate         | 0.2          |
|    total_cost           | 6.52         |
| time/                   |              |
|    total_timesteps      | 310000       |
| train/                  |              |
|    approx_kl            | 0.0013960882 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.0988       |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.762        |
|    learning_rate        | 5e-05        |
|    loss                 | 90.8         |
|    max_step             | 0            |
|    n_updates            | 1200         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | -0.000527    |
|    route_completion     | 0.542        |
|    std                  | 0.589        |
|    total_cost           | 8.77         |
|    value_loss           | 220          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 404      |
|    iterations      | 61       |
|    time_elapsed    | 771      |
|    total_timesteps | 312320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 280         |
|    ep_rew_mean          | 274         |
| time/                   |             |
|    fps                  | 406         |
|    iterations           | 62          |
|    time_elapsed         | 780         |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.002363925 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.665       |
|    learning_rate        | 5e-05       |
|    loss                 | 98.6        |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00272     |
|    std                  | 0.59        |
|    value_loss           | 331         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.163        |
|    crash                | 0.225        |
|    max_step             | 0            |
|    mean_ep_length       | 89.8         |
|    mean_reward          | 103          |
|    num_episodes         | 5            |
|    out_of_road          | 0.838        |
|    raw_action           | 0.4603327    |
|    route_completion     | 0.55         |
|    success_rate         | 0            |
|    total_cost           | 6.36         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0053291037 |
|    arrive_dest          | 0.156        |
|    clip_fraction        | 0.189        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.775        |
|    learning_rate        | 5e-05        |
|    loss                 | 102          |
|    max_step             | 0            |
|    n_updates            | 1240         |
|    out_of_road          | 0.844        |
|    policy_gradient_loss | 0.000775     |
|    route_completion     | 0.54         |
|    std                  | 0.589        |
|    total_cost           | 8.55         |
|    value_loss           | 234          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 406      |
|    iterations      | 63       |
|    time_elapsed    | 793      |
|    total_timesteps | 322560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 280          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 408          |
|    iterations           | 64           |
|    time_elapsed         | 801          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0022352475 |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.73         |
|    learning_rate        | 5e-05        |
|    loss                 | 151          |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.0024      |
|    std                  | 0.588        |
|    value_loss           | 248          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.164        |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 154          |
|    mean_reward          | 179          |
|    num_episodes         | 5            |
|    out_of_road          | 0.836        |
|    raw_action           | 0.4597344    |
|    route_completion     | 0.552        |
|    success_rate         | 0.1          |
|    total_cost           | 6.67         |
| time/                   |              |
|    total_timesteps      | 330000       |
| train/                  |              |
|    approx_kl            | 0.0021697439 |
|    arrive_dest          | 0.152        |
|    clip_fraction        | 0.176        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.743        |
|    learning_rate        | 5e-05        |
|    loss                 | 122          |
|    max_step             | 0            |
|    n_updates            | 1280         |
|    out_of_road          | 0.848        |
|    policy_gradient_loss | 0.00169      |
|    route_completion     | 0.533        |
|    std                  | 0.587        |
|    total_cost           | 8.33         |
|    value_loss           | 230          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 279      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 407      |
|    iterations      | 65       |
|    time_elapsed    | 817      |
|    total_timesteps | 332800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 290          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 409          |
|    iterations           | 66           |
|    time_elapsed         | 825          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0026267096 |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.738        |
|    learning_rate        | 5e-05        |
|    loss                 | 88.7         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00151     |
|    std                  | 0.586        |
|    value_loss           | 227          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.165        |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 98.8         |
|    mean_reward          | 125          |
|    num_episodes         | 5            |
|    out_of_road          | 0.835        |
|    raw_action           | 0.46219105   |
|    route_completion     | 0.546        |
|    success_rate         | 0.1          |
|    total_cost           | 6.5          |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0058917333 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.191        |
|    clip_range           | 0.1          |
|    crash                | 0.253        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.671        |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    max_step             | 0            |
|    n_updates            | 1320         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.000144     |
|    route_completion     | 0.534        |
|    std                  | 0.585        |
|    total_cost           | 8.3          |
|    value_loss           | 212          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 407      |
|    iterations      | 67       |
|    time_elapsed    | 842      |
|    total_timesteps | 343040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 295          |
|    ep_rew_mean          | 295          |
| time/                   |              |
|    fps                  | 407          |
|    iterations           | 68           |
|    time_elapsed         | 853          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0018137798 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 113          |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.001       |
|    std                  | 0.584        |
|    value_loss           | 282          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.177        |
|    crash                | 0.24         |
|    max_step             | 0            |
|    mean_ep_length       | 200          |
|    mean_reward          | 305          |
|    num_episodes         | 5            |
|    out_of_road          | 0.823        |
|    raw_action           | 0.46271393   |
|    route_completion     | 0.549        |
|    success_rate         | 0.3          |
|    total_cost           | 6.42         |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0016959489 |
|    arrive_dest          | 0.143        |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    crash                | 0.257        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 116          |
|    max_step             | 0            |
|    n_updates            | 1360         |
|    out_of_road          | 0.857        |
|    policy_gradient_loss | -0.00115     |
|    route_completion     | 0.533        |
|    std                  | 0.583        |
|    total_cost           | 8.29         |
|    value_loss           | 233          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 400      |
|    iterations      | 69       |
|    time_elapsed    | 881      |
|    total_timesteps | 353280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 296          |
|    ep_rew_mean          | 289          |
| time/                   |              |
|    fps                  | 401          |
|    iterations           | 70           |
|    time_elapsed         | 892          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0020267789 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.622        |
|    learning_rate        | 5e-05        |
|    loss                 | 152          |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00197     |
|    std                  | 0.581        |
|    value_loss           | 280          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.172        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 240          |
|    mean_reward          | 150          |
|    num_episodes         | 5            |
|    out_of_road          | 0.828        |
|    raw_action           | 0.46476102   |
|    route_completion     | 0.545        |
|    success_rate         | 0            |
|    total_cost           | 7.05         |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0023835795 |
|    arrive_dest          | 0.139        |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.4         |
|    max_step             | 0            |
|    n_updates            | 1400         |
|    out_of_road          | 0.861        |
|    policy_gradient_loss | -0.000891    |
|    route_completion     | 0.528        |
|    std                  | 0.581        |
|    total_cost           | 8.1          |
|    value_loss           | 198          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 290      |
|    ep_rew_mean     | 285      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 71       |
|    time_elapsed    | 912      |
|    total_timesteps | 363520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 281          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 398          |
|    iterations           | 72           |
|    time_elapsed         | 925          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0036359667 |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.643        |
|    learning_rate        | 5e-05        |
|    loss                 | 128          |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00112     |
|    std                  | 0.581        |
|    value_loss           | 259          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.173        |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 187          |
|    num_episodes         | 5            |
|    out_of_road          | 0.827        |
|    raw_action           | 0.46450877   |
|    route_completion     | 0.543        |
|    success_rate         | 0.2          |
|    total_cost           | 7            |
| time/                   |              |
|    total_timesteps      | 370000       |
| train/                  |              |
|    approx_kl            | 0.0034132195 |
|    arrive_dest          | 0.141        |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.767        |
|    learning_rate        | 5e-05        |
|    loss                 | 121          |
|    max_step             | 0            |
|    n_updates            | 1440         |
|    out_of_road          | 0.859        |
|    policy_gradient_loss | -0.00207     |
|    route_completion     | 0.526        |
|    std                  | 0.583        |
|    total_cost           | 8.11         |
|    value_loss           | 230          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 392      |
|    iterations      | 73       |
|    time_elapsed    | 951      |
|    total_timesteps | 373760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 281         |
|    ep_rew_mean          | 269         |
| time/                   |             |
|    fps                  | 393         |
|    iterations           | 74          |
|    time_elapsed         | 961         |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.002126418 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.657       |
|    learning_rate        | 5e-05       |
|    loss                 | 109         |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.00214     |
|    std                  | 0.584       |
|    value_loss           | 304         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.179      |
|    crash                | 0.242      |
|    max_step             | 0          |
|    mean_ep_length       | 187        |
|    mean_reward          | 231        |
|    num_episodes         | 5          |
|    out_of_road          | 0.821      |
|    raw_action           | 0.46558294 |
|    route_completion     | 0.546      |
|    success_rate         | 0.3        |
|    total_cost           | 7.07       |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.00849072 |
|    arrive_dest          | 0.142      |
|    clip_fraction        | 0.225      |
|    clip_range           | 0.1        |
|    crash                | 0.258      |
|    entropy_loss         | -1.65      |
|    explained_variance   | 0.76       |
|    learning_rate        | 5e-05      |
|    loss                 | 156        |
|    max_step             | 0          |
|    n_updates            | 1480       |
|    out_of_road          | 0.858      |
|    policy_gradient_loss | 0.00134    |
|    route_completion     | 0.525      |
|    std                  | 0.584      |
|    total_cost           | 8.02       |
|    value_loss           | 188        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 390      |
|    iterations      | 75       |
|    time_elapsed    | 982      |
|    total_timesteps | 384000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 308          |
|    ep_rew_mean          | 296          |
| time/                   |              |
|    fps                  | 391          |
|    iterations           | 76           |
|    time_elapsed         | 992          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0015146799 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.773        |
|    learning_rate        | 5e-05        |
|    loss                 | 73.6         |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00185     |
|    std                  | 0.583        |
|    value_loss           | 164          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.174       |
|    crash                | 0.246       |
|    max_step             | 0           |
|    mean_ep_length       | 150         |
|    mean_reward          | 194         |
|    num_episodes         | 5           |
|    out_of_road          | 0.826       |
|    raw_action           | 0.4649113   |
|    route_completion     | 0.545       |
|    success_rate         | 0           |
|    total_cost           | 7.12        |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.008401642 |
|    arrive_dest          | 0.138       |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.1         |
|    crash                | 0.262       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.899       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.1        |
|    max_step             | 0           |
|    n_updates            | 1520        |
|    out_of_road          | 0.862       |
|    policy_gradient_loss | 0.00395     |
|    route_completion     | 0.521       |
|    std                  | 0.584       |
|    total_cost           | 7.89        |
|    value_loss           | 126         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 300      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 390      |
|    iterations      | 77       |
|    time_elapsed    | 1010     |
|    total_timesteps | 394240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 309          |
|    ep_rew_mean          | 295          |
| time/                   |              |
|    fps                  | 392          |
|    iterations           | 78           |
|    time_elapsed         | 1018         |
|    total_timesteps      | 399360       |
| train/                  |              |
|    approx_kl            | 0.0024675955 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.716        |
|    learning_rate        | 5e-05        |
|    loss                 | 188          |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00133     |
|    std                  | 0.584        |
|    value_loss           | 312          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.175        |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 178          |
|    num_episodes         | 5            |
|    out_of_road          | 0.825        |
|    raw_action           | 0.464173     |
|    route_completion     | 0.546        |
|    success_rate         | 0.2          |
|    total_cost           | 7.13         |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0030503601 |
|    arrive_dest          | 0.14         |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.765        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.1         |
|    max_step             | 0            |
|    n_updates            | 1560         |
|    out_of_road          | 0.86         |
|    policy_gradient_loss | -0.00153     |
|    route_completion     | 0.519        |
|    std                  | 0.584        |
|    total_cost           | 7.74         |
|    value_loss           | 201          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 390      |
|    iterations      | 79       |
|    time_elapsed    | 1035     |
|    total_timesteps | 404480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 315          |
| time/                   |              |
|    fps                  | 392          |
|    iterations           | 80           |
|    time_elapsed         | 1043         |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0028978775 |
|    clip_fraction        | 0.0978       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.764        |
|    learning_rate        | 5e-05        |
|    loss                 | 111          |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00232     |
|    std                  | 0.585        |
|    value_loss           | 228          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.176       |
|    crash                | 0.249       |
|    max_step             | 0           |
|    mean_ep_length       | 134         |
|    mean_reward          | 193         |
|    num_episodes         | 5           |
|    out_of_road          | 0.824       |
|    raw_action           | 0.46394047  |
|    route_completion     | 0.546       |
|    success_rate         | 0.1         |
|    total_cost           | 7.02        |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.008599068 |
|    arrive_dest          | 0.137       |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.1         |
|    crash                | 0.254       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.82        |
|    learning_rate        | 5e-05       |
|    loss                 | 78.7        |
|    max_step             | 0           |
|    n_updates            | 1600        |
|    out_of_road          | 0.863       |
|    policy_gradient_loss | 0.000382    |
|    route_completion     | 0.518       |
|    std                  | 0.585       |
|    total_cost           | 7.62        |
|    value_loss           | 194         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 391      |
|    iterations      | 81       |
|    time_elapsed    | 1059     |
|    total_timesteps | 414720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 328          |
|    ep_rew_mean          | 311          |
| time/                   |              |
|    fps                  | 393          |
|    iterations           | 82           |
|    time_elapsed         | 1066         |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0020760167 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.621        |
|    learning_rate        | 5e-05        |
|    loss                 | 108          |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.585        |
|    value_loss           | 266          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.181       |
|    crash                | 0.252       |
|    max_step             | 0           |
|    mean_ep_length       | 249         |
|    mean_reward          | 273         |
|    num_episodes         | 5           |
|    out_of_road          | 0.819       |
|    raw_action           | 0.461893    |
|    route_completion     | 0.551       |
|    success_rate         | 0.3         |
|    total_cost           | 7.46        |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.004551529 |
|    arrive_dest          | 0.138       |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.1         |
|    crash                | 0.257       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.784       |
|    learning_rate        | 5e-05       |
|    loss                 | 64.9        |
|    max_step             | 0           |
|    n_updates            | 1640        |
|    out_of_road          | 0.862       |
|    policy_gradient_loss | 0.00297     |
|    route_completion     | 0.519       |
|    std                  | 0.586       |
|    total_cost           | 7.57        |
|    value_loss           | 153         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 390      |
|    iterations      | 83       |
|    time_elapsed    | 1087     |
|    total_timesteps | 424960   |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.186       |
|    crash                | 0.251       |
|    max_step             | 0           |
|    mean_ep_length       | 163         |
|    mean_reward          | 208         |
|    num_episodes         | 5           |
|    out_of_road          | 0.814       |
|    raw_action           | 0.4621051   |
|    route_completion     | 0.553       |
|    success_rate         | 0.3         |
|    total_cost           | 7.53        |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.005225866 |
|    arrive_dest          | 0.14        |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.1         |
|    crash                | 0.26        |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.733       |
|    learning_rate        | 5e-05       |
|    loss                 | 80.2        |
|    max_step             | 0           |
|    n_updates            | 1660        |
|    out_of_road          | 0.86        |
|    policy_gradient_loss | -0.000338   |
|    route_completion     | 0.519       |
|    std                  | 0.587       |
|    total_cost           | 7.6         |
|    value_loss           | 224         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 389      |
|    iterations      | 84       |
|    time_elapsed    | 1102     |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 311         |
|    ep_rew_mean          | 293         |
| time/                   |             |
|    fps                  | 391         |
|    iterations           | 85          |
|    time_elapsed         | 1111        |
|    total_timesteps      | 435200      |
| train/                  |             |
|    approx_kl            | 0.004298783 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.783       |
|    learning_rate        | 5e-05       |
|    loss                 | 95.6        |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.00166    |
|    std                  | 0.586       |
|    value_loss           | 207         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.255        |
|    max_step             | 0            |
|    mean_ep_length       | 97.4         |
|    mean_reward          | 120          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.46373343   |
|    route_completion     | 0.549        |
|    success_rate         | 0            |
|    total_cost           | 7.38         |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0072507383 |
|    arrive_dest          | 0.136        |
|    clip_fraction        | 0.237        |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.824        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.9         |
|    max_step             | 0            |
|    n_updates            | 1700         |
|    out_of_road          | 0.864        |
|    policy_gradient_loss | 0.00419      |
|    route_completion     | 0.519        |
|    std                  | 0.586        |
|    total_cost           | 7.46         |
|    value_loss           | 141          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 391      |
|    iterations      | 86       |
|    time_elapsed    | 1124     |
|    total_timesteps | 440320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 316          |
|    ep_rew_mean          | 292          |
| time/                   |              |
|    fps                  | 393          |
|    iterations           | 87           |
|    time_elapsed         | 1132         |
|    total_timesteps      | 445440       |
| train/                  |              |
|    approx_kl            | 0.0029830015 |
|    clip_fraction        | 0.239        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.767        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.8         |
|    n_updates            | 1720         |
|    policy_gradient_loss | 0.00191      |
|    std                  | 0.588        |
|    value_loss           | 201          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 190          |
|    mean_reward          | 259          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.46368694   |
|    route_completion     | 0.553        |
|    success_rate         | 0.2          |
|    total_cost           | 7.36         |
| time/                   |              |
|    total_timesteps      | 450000       |
| train/                  |              |
|    approx_kl            | 0.0029231706 |
|    arrive_dest          | 0.138        |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.778        |
|    learning_rate        | 5e-05        |
|    loss                 | 77.4         |
|    max_step             | 0            |
|    n_updates            | 1740         |
|    out_of_road          | 0.862        |
|    policy_gradient_loss | -4.17e-06    |
|    route_completion     | 0.52         |
|    std                  | 0.588        |
|    total_cost           | 7.44         |
|    value_loss           | 190          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 391      |
|    iterations      | 88       |
|    time_elapsed    | 1149     |
|    total_timesteps | 450560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 300          |
|    ep_rew_mean          | 279          |
| time/                   |              |
|    fps                  | 393          |
|    iterations           | 89           |
|    time_elapsed         | 1158         |
|    total_timesteps      | 455680       |
| train/                  |              |
|    approx_kl            | 0.0013399173 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.71         |
|    learning_rate        | 5e-05        |
|    loss                 | 133          |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00103     |
|    std                  | 0.585        |
|    value_loss           | 257          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.178       |
|    crash                | 0.248       |
|    max_step             | 0           |
|    mean_ep_length       | 124         |
|    mean_reward          | 142         |
|    num_episodes         | 5           |
|    out_of_road          | 0.822       |
|    raw_action           | 0.46313557  |
|    route_completion     | 0.551       |
|    success_rate         | 0.2         |
|    total_cost           | 7.26        |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.004823956 |
|    arrive_dest          | 0.143       |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.1         |
|    crash                | 0.252       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.774       |
|    learning_rate        | 5e-05       |
|    loss                 | 55.1        |
|    max_step             | 0           |
|    n_updates            | 1780        |
|    out_of_road          | 0.857       |
|    policy_gradient_loss | -0.00164    |
|    route_completion     | 0.524       |
|    std                  | 0.585       |
|    total_cost           | 7.51        |
|    value_loss           | 165         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 392      |
|    iterations      | 90       |
|    time_elapsed    | 1173     |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 320         |
|    ep_rew_mean          | 298         |
| time/                   |             |
|    fps                  | 394         |
|    iterations           | 91          |
|    time_elapsed         | 1180        |
|    total_timesteps      | 465920      |
| train/                  |             |
|    approx_kl            | 0.011081106 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.777       |
|    learning_rate        | 5e-05       |
|    loss                 | 105         |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.00475     |
|    std                  | 0.584       |
|    value_loss           | 205         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.183        |
|    crash                | 0.247        |
|    max_step             | 0            |
|    mean_ep_length       | 226          |
|    mean_reward          | 298          |
|    num_episodes         | 5            |
|    out_of_road          | 0.817        |
|    raw_action           | 0.4626855    |
|    route_completion     | 0.554        |
|    success_rate         | 0.2          |
|    total_cost           | 7.39         |
| time/                   |              |
|    total_timesteps      | 470000       |
| train/                  |              |
|    approx_kl            | 0.0038405093 |
|    arrive_dest          | 0.14         |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    crash                | 0.247        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.784        |
|    learning_rate        | 5e-05        |
|    loss                 | 99.7         |
|    max_step             | 0            |
|    n_updates            | 1820         |
|    out_of_road          | 0.86         |
|    policy_gradient_loss | -0.000946    |
|    route_completion     | 0.52         |
|    std                  | 0.585        |
|    total_cost           | 7.45         |
|    value_loss           | 187          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 393      |
|    iterations      | 92       |
|    time_elapsed    | 1197     |
|    total_timesteps | 471040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 328          |
|    ep_rew_mean          | 307          |
| time/                   |              |
|    fps                  | 395          |
|    iterations           | 93           |
|    time_elapsed         | 1204         |
|    total_timesteps      | 476160       |
| train/                  |              |
|    approx_kl            | 0.0053905672 |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.835        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.2         |
|    n_updates            | 1840         |
|    policy_gradient_loss | 0.00179      |
|    std                  | 0.586        |
|    value_loss           | 153          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.179        |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 126          |
|    mean_reward          | 179          |
|    num_episodes         | 5            |
|    out_of_road          | 0.821        |
|    raw_action           | 0.46204242   |
|    route_completion     | 0.553        |
|    success_rate         | 0.2          |
|    total_cost           | 7.28         |
| time/                   |              |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0014629044 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.246        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.765        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.3         |
|    max_step             | 0            |
|    n_updates            | 1860         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | 0.000269     |
|    route_completion     | 0.526        |
|    std                  | 0.585        |
|    total_cost           | 7.39         |
|    value_loss           | 177          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 395      |
|    iterations      | 94       |
|    time_elapsed    | 1217     |
|    total_timesteps | 481280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 319          |
|    ep_rew_mean          | 300          |
| time/                   |              |
|    fps                  | 396          |
|    iterations           | 95           |
|    time_elapsed         | 1225         |
|    total_timesteps      | 486400       |
| train/                  |              |
|    approx_kl            | 0.0018144579 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.768        |
|    learning_rate        | 5e-05        |
|    loss                 | 102          |
|    n_updates            | 1880         |
|    policy_gradient_loss | -0.000333    |
|    std                  | 0.587        |
|    value_loss           | 211          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.176        |
|    crash                | 0.245        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 181          |
|    num_episodes         | 5            |
|    out_of_road          | 0.824        |
|    raw_action           | 0.46075526   |
|    route_completion     | 0.553        |
|    success_rate         | 0.1          |
|    total_cost           | 7.21         |
| time/                   |              |
|    total_timesteps      | 490000       |
| train/                  |              |
|    approx_kl            | 0.0022887352 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.245        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 131          |
|    max_step             | 0            |
|    n_updates            | 1900         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | -0.000423    |
|    route_completion     | 0.529        |
|    std                  | 0.586        |
|    total_cost           | 7.34         |
|    value_loss           | 216          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 396      |
|    iterations      | 96       |
|    time_elapsed    | 1239     |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 326         |
|    ep_rew_mean          | 301         |
| time/                   |             |
|    fps                  | 398         |
|    iterations           | 97          |
|    time_elapsed         | 1246        |
|    total_timesteps      | 496640      |
| train/                  |             |
|    approx_kl            | 0.033786934 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.792       |
|    learning_rate        | 5e-05       |
|    loss                 | 78.8        |
|    n_updates            | 1920        |
|    policy_gradient_loss | 0.000809    |
|    std                  | 0.589       |
|    value_loss           | 155         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.176       |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 214         |
|    mean_reward          | 251         |
|    num_episodes         | 5           |
|    out_of_road          | 0.824       |
|    raw_action           | 0.46132553  |
|    route_completion     | 0.557       |
|    success_rate         | 0.1         |
|    total_cost           | 7.61        |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.004265571 |
|    arrive_dest          | 0.144       |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    crash                | 0.248       |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.857       |
|    learning_rate        | 5e-05       |
|    loss                 | 70.4        |
|    max_step             | 0           |
|    n_updates            | 1940        |
|    out_of_road          | 0.856       |
|    policy_gradient_loss | -0.000982   |
|    route_completion     | 0.528       |
|    std                  | 0.59        |
|    total_cost           | 7.3         |
|    value_loss           | 134         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 98       |
|    time_elapsed    | 1260     |
|    total_timesteps | 501760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 328          |
|    ep_rew_mean          | 301          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 99           |
|    time_elapsed         | 1267         |
|    total_timesteps      | 506880       |
| train/                  |              |
|    approx_kl            | 0.0033689751 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.777        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.1         |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.000885    |
|    std                  | 0.592        |
|    value_loss           | 193          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.176        |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 150          |
|    num_episodes         | 5            |
|    out_of_road          | 0.824        |
|    raw_action           | 0.46163946   |
|    route_completion     | 0.556        |
|    success_rate         | 0.2          |
|    total_cost           | 7.47         |
| time/                   |              |
|    total_timesteps      | 510000       |
| train/                  |              |
|    approx_kl            | 0.0013109464 |
|    arrive_dest          | 0.145        |
|    clip_fraction        | 0.246        |
|    clip_range           | 0.1          |
|    crash                | 0.251        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.828        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.3         |
|    max_step             | 0            |
|    n_updates            | 1980         |
|    out_of_road          | 0.855        |
|    policy_gradient_loss | 0.00506      |
|    route_completion     | 0.528        |
|    std                  | 0.592        |
|    total_cost           | 7.25         |
|    value_loss           | 120          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 329      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 100      |
|    time_elapsed    | 1283     |
|    total_timesteps | 512000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 319          |
|    ep_rew_mean          | 299          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 101          |
|    time_elapsed         | 1291         |
|    total_timesteps      | 517120       |
| train/                  |              |
|    approx_kl            | 0.0030739312 |
|    clip_fraction        | 0.189        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.796        |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    n_updates            | 2000         |
|    policy_gradient_loss | 0.00194      |
|    std                  | 0.591        |
|    value_loss           | 196          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.177        |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 169          |
|    mean_reward          | 258          |
|    num_episodes         | 5            |
|    out_of_road          | 0.823        |
|    raw_action           | 0.46067753   |
|    route_completion     | 0.557        |
|    success_rate         | 0.2          |
|    total_cost           | 7.48         |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0026662312 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    crash                | 0.246        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.766        |
|    learning_rate        | 5e-05        |
|    loss                 | 89.3         |
|    max_step             | 0            |
|    n_updates            | 2020         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.000792    |
|    route_completion     | 0.526        |
|    std                  | 0.589        |
|    total_cost           | 7.15         |
|    value_loss           | 225          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 102      |
|    time_elapsed    | 1309     |
|    total_timesteps | 522240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 324          |
|    ep_rew_mean          | 303          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 103          |
|    time_elapsed         | 1317         |
|    total_timesteps      | 527360       |
| train/                  |              |
|    approx_kl            | 0.0033658477 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.773        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.4         |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.000201    |
|    std                  | 0.589        |
|    value_loss           | 176          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.181        |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 171          |
|    num_episodes         | 5            |
|    out_of_road          | 0.819        |
|    raw_action           | 0.4613908    |
|    route_completion     | 0.556        |
|    success_rate         | 0.4          |
|    total_cost           | 7.55         |
| time/                   |              |
|    total_timesteps      | 530000       |
| train/                  |              |
|    approx_kl            | 0.0019718278 |
|    arrive_dest          | 0.151        |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    crash                | 0.245        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.793        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.5         |
|    max_step             | 0            |
|    n_updates            | 2060         |
|    out_of_road          | 0.849        |
|    policy_gradient_loss | -0.00128     |
|    route_completion     | 0.531        |
|    std                  | 0.588        |
|    total_cost           | 7.17         |
|    value_loss           | 161          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 104      |
|    time_elapsed    | 1334     |
|    total_timesteps | 532480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 322          |
|    ep_rew_mean          | 305          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 105          |
|    time_elapsed         | 1344         |
|    total_timesteps      | 537600       |
| train/                  |              |
|    approx_kl            | 0.0014976675 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.677        |
|    learning_rate        | 5e-05        |
|    loss                 | 84           |
|    n_updates            | 2080         |
|    policy_gradient_loss | 0.000295     |
|    std                  | 0.587        |
|    value_loss           | 225          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.185        |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 168          |
|    mean_reward          | 235          |
|    num_episodes         | 5            |
|    out_of_road          | 0.815        |
|    raw_action           | 0.46310714   |
|    route_completion     | 0.558        |
|    success_rate         | 0.3          |
|    total_cost           | 7.59         |
| time/                   |              |
|    total_timesteps      | 540000       |
| train/                  |              |
|    approx_kl            | 0.0064330264 |
|    arrive_dest          | 0.152        |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.762        |
|    learning_rate        | 5e-05        |
|    loss                 | 78           |
|    max_step             | 0            |
|    n_updates            | 2100         |
|    out_of_road          | 0.848        |
|    policy_gradient_loss | 0.00179      |
|    route_completion     | 0.532        |
|    std                  | 0.586        |
|    total_cost           | 7.1          |
|    value_loss           | 203          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 106      |
|    time_elapsed    | 1359     |
|    total_timesteps | 542720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 324          |
|    ep_rew_mean          | 303          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 107          |
|    time_elapsed         | 1368         |
|    total_timesteps      | 547840       |
| train/                  |              |
|    approx_kl            | 0.0015524357 |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.654        |
|    learning_rate        | 5e-05        |
|    loss                 | 82           |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.000164    |
|    std                  | 0.587        |
|    value_loss           | 219          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.189       |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 164         |
|    mean_reward          | 266         |
|    num_episodes         | 5           |
|    out_of_road          | 0.811       |
|    raw_action           | 0.46264026  |
|    route_completion     | 0.564       |
|    success_rate         | 0.5         |
|    total_cost           | 7.51        |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.033997178 |
|    arrive_dest          | 0.16        |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.1         |
|    crash                | 0.247       |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.826       |
|    learning_rate        | 5e-05       |
|    loss                 | 54.3        |
|    max_step             | 0           |
|    n_updates            | 2140        |
|    out_of_road          | 0.84        |
|    policy_gradient_loss | 0.00392     |
|    route_completion     | 0.536       |
|    std                  | 0.589       |
|    total_cost           | 7.23        |
|    value_loss           | 133         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 325      |
|    ep_rew_mean     | 304      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 108      |
|    time_elapsed    | 1384     |
|    total_timesteps | 552960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 329          |
|    ep_rew_mean          | 312          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 109          |
|    time_elapsed         | 1393         |
|    total_timesteps      | 558080       |
| train/                  |              |
|    approx_kl            | 0.0011317397 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.772        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.6         |
|    n_updates            | 2160         |
|    policy_gradient_loss | -0.00119     |
|    std                  | 0.589        |
|    value_loss           | 194          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.186        |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 95.8         |
|    mean_reward          | 95.6         |
|    num_episodes         | 5            |
|    out_of_road          | 0.814        |
|    raw_action           | 0.46143547   |
|    route_completion     | 0.559        |
|    success_rate         | 0.1          |
|    total_cost           | 7.4          |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0010914836 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    crash                | 0.243        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.793        |
|    learning_rate        | 5e-05        |
|    loss                 | 104          |
|    max_step             | 0            |
|    n_updates            | 2180         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | -0.00172     |
|    route_completion     | 0.534        |
|    std                  | 0.588        |
|    total_cost           | 7.27         |
|    value_loss           | 215          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 329      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 110      |
|    time_elapsed    | 1414     |
|    total_timesteps | 563200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 333          |
|    ep_rew_mean          | 311          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 111          |
|    time_elapsed         | 1423         |
|    total_timesteps      | 568320       |
| train/                  |              |
|    approx_kl            | 0.0017095137 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.715        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.6         |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.000703    |
|    std                  | 0.587        |
|    value_loss           | 292          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.186       |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 177         |
|    mean_reward          | 232         |
|    num_episodes         | 5           |
|    out_of_road          | 0.814       |
|    raw_action           | 0.46093756  |
|    route_completion     | 0.56        |
|    success_rate         | 0.2         |
|    total_cost           | 7.56        |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.001458122 |
|    arrive_dest          | 0.161       |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    crash                | 0.246       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.738       |
|    learning_rate        | 5e-05       |
|    loss                 | 153         |
|    max_step             | 0           |
|    n_updates            | 2220        |
|    out_of_road          | 0.839       |
|    policy_gradient_loss | 0.00107     |
|    route_completion     | 0.536       |
|    std                  | 0.588       |
|    total_cost           | 7.2         |
|    value_loss           | 216         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 329      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 112      |
|    time_elapsed    | 1441     |
|    total_timesteps | 573440   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 339           |
|    ep_rew_mean          | 316           |
| time/                   |               |
|    fps                  | 399           |
|    iterations           | 113           |
|    time_elapsed         | 1449          |
|    total_timesteps      | 578560        |
| train/                  |               |
|    approx_kl            | 0.00094506034 |
|    clip_fraction        | 0.0837        |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.65         |
|    explained_variance   | 0.735         |
|    learning_rate        | 5e-05         |
|    loss                 | 129           |
|    n_updates            | 2240          |
|    policy_gradient_loss | -0.00132      |
|    std                  | 0.589         |
|    value_loss           | 250           |
-------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.186       |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 162         |
|    mean_reward          | 240         |
|    num_episodes         | 5           |
|    out_of_road          | 0.814       |
|    raw_action           | 0.46137646  |
|    route_completion     | 0.562       |
|    success_rate         | 0.3         |
|    total_cost           | 7.48        |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.004194683 |
|    arrive_dest          | 0.166       |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.1         |
|    crash                | 0.241       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.825       |
|    learning_rate        | 5e-05       |
|    loss                 | 85.7        |
|    max_step             | 0           |
|    n_updates            | 2260        |
|    out_of_road          | 0.834       |
|    policy_gradient_loss | 0.000799    |
|    route_completion     | 0.537       |
|    std                  | 0.587       |
|    total_cost           | 7.12        |
|    value_loss           | 145         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 114      |
|    time_elapsed    | 1466     |
|    total_timesteps | 583680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 321          |
|    ep_rew_mean          | 299          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 115          |
|    time_elapsed         | 1474         |
|    total_timesteps      | 588800       |
| train/                  |              |
|    approx_kl            | 0.0022242903 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.64         |
|    learning_rate        | 5e-05        |
|    loss                 | 131          |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.000397    |
|    std                  | 0.587        |
|    value_loss           | 316          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.183        |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 128          |
|    mean_reward          | 162          |
|    num_episodes         | 5            |
|    out_of_road          | 0.817        |
|    raw_action           | 0.46150288   |
|    route_completion     | 0.559        |
|    success_rate         | 0            |
|    total_cost           | 7.39         |
| time/                   |              |
|    total_timesteps      | 590000       |
| train/                  |              |
|    approx_kl            | 0.0027176465 |
|    arrive_dest          | 0.163        |
|    clip_fraction        | 0.191        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.701        |
|    learning_rate        | 5e-05        |
|    loss                 | 114          |
|    max_step             | 0            |
|    n_updates            | 2300         |
|    out_of_road          | 0.837        |
|    policy_gradient_loss | 0.0014       |
|    route_completion     | 0.535        |
|    std                  | 0.586        |
|    total_cost           | 7.02         |
|    value_loss           | 213          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 309      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 116      |
|    time_elapsed    | 1488     |
|    total_timesteps | 593920   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 324         |
|    ep_rew_mean          | 304         |
| time/                   |             |
|    fps                  | 400         |
|    iterations           | 117         |
|    time_elapsed         | 1497        |
|    total_timesteps      | 599040      |
| train/                  |             |
|    approx_kl            | 0.003137251 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.663       |
|    learning_rate        | 5e-05       |
|    loss                 | 110         |
|    n_updates            | 2320        |
|    policy_gradient_loss | 0.000379    |
|    std                  | 0.585       |
|    value_loss           | 242         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.187       |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 168         |
|    mean_reward          | 235         |
|    num_episodes         | 5           |
|    out_of_road          | 0.813       |
|    raw_action           | 0.46104568  |
|    route_completion     | 0.56        |
|    success_rate         | 0.3         |
|    total_cost           | 7.31        |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.020624587 |
|    arrive_dest          | 0.163       |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.1         |
|    crash                | 0.233       |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.79        |
|    learning_rate        | 5e-05       |
|    loss                 | 91.9        |
|    max_step             | 0           |
|    n_updates            | 2340        |
|    out_of_road          | 0.837       |
|    policy_gradient_loss | 0.00197     |
|    route_completion     | 0.536       |
|    std                  | 0.584       |
|    total_cost           | 6.94        |
|    value_loss           | 184         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 300      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 118      |
|    time_elapsed    | 1516     |
|    total_timesteps | 604160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 310          |
|    ep_rew_mean          | 294          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 119          |
|    time_elapsed         | 1525         |
|    total_timesteps      | 609280       |
| train/                  |              |
|    approx_kl            | 0.0073690005 |
|    clip_fraction        | 0.235        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.595        |
|    learning_rate        | 5e-05        |
|    loss                 | 139          |
|    n_updates            | 2360         |
|    policy_gradient_loss | 0.00548      |
|    std                  | 0.584        |
|    value_loss           | 336          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.19        |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 183         |
|    mean_reward          | 289         |
|    num_episodes         | 5           |
|    out_of_road          | 0.81        |
|    raw_action           | 0.46056807  |
|    route_completion     | 0.563       |
|    success_rate         | 0.3         |
|    total_cost           | 7.26        |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.001163459 |
|    arrive_dest          | 0.164       |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    crash                | 0.23        |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.722       |
|    learning_rate        | 5e-05       |
|    loss                 | 72.3        |
|    max_step             | 0           |
|    n_updates            | 2380        |
|    out_of_road          | 0.836       |
|    policy_gradient_loss | 0.000224    |
|    route_completion     | 0.534       |
|    std                  | 0.586       |
|    total_cost           | 7.05        |
|    value_loss           | 164         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 120      |
|    time_elapsed    | 1541     |
|    total_timesteps | 614400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 325         |
|    ep_rew_mean          | 302         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 121         |
|    time_elapsed         | 1550        |
|    total_timesteps      | 619520      |
| train/                  |             |
|    approx_kl            | 0.002420011 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.677       |
|    learning_rate        | 5e-05       |
|    loss                 | 75.3        |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.585       |
|    value_loss           | 197         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.19         |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 165          |
|    mean_reward          | 232          |
|    num_episodes         | 5            |
|    out_of_road          | 0.81         |
|    raw_action           | 0.4593806    |
|    route_completion     | 0.565        |
|    success_rate         | 0.2          |
|    total_cost           | 7.2          |
| time/                   |              |
|    total_timesteps      | 620000       |
| train/                  |              |
|    approx_kl            | 0.0031162684 |
|    arrive_dest          | 0.165        |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.819        |
|    learning_rate        | 5e-05        |
|    loss                 | 81.9         |
|    max_step             | 0            |
|    n_updates            | 2420         |
|    out_of_road          | 0.835        |
|    policy_gradient_loss | -0.000463    |
|    route_completion     | 0.537        |
|    std                  | 0.586        |
|    total_cost           | 7.27         |
|    value_loss           | 152          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 122      |
|    time_elapsed    | 1568     |
|    total_timesteps | 624640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 322          |
|    ep_rew_mean          | 300          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 123          |
|    time_elapsed         | 1576         |
|    total_timesteps      | 629760       |
| train/                  |              |
|    approx_kl            | 0.0017997768 |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 133          |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.00103     |
|    std                  | 0.585        |
|    value_loss           | 263          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.19         |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 116          |
|    mean_reward          | 161          |
|    num_episodes         | 5            |
|    out_of_road          | 0.81         |
|    raw_action           | 0.45895258   |
|    route_completion     | 0.562        |
|    success_rate         | 0.1          |
|    total_cost           | 7.11         |
| time/                   |              |
|    total_timesteps      | 630000       |
| train/                  |              |
|    approx_kl            | 0.0028685217 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.778        |
|    learning_rate        | 5e-05        |
|    loss                 | 84.1         |
|    max_step             | 0            |
|    n_updates            | 2460         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | -0.0012      |
|    route_completion     | 0.536        |
|    std                  | 0.585        |
|    total_cost           | 7.18         |
|    value_loss           | 203          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 308      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 124      |
|    time_elapsed    | 1591     |
|    total_timesteps | 634880   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.188        |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 106          |
|    mean_reward          | 110          |
|    num_episodes         | 5            |
|    out_of_road          | 0.812        |
|    raw_action           | 0.45918268   |
|    route_completion     | 0.559        |
|    success_rate         | 0            |
|    total_cost           | 7.08         |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0032017604 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.185        |
|    clip_range           | 0.1          |
|    crash                | 0.228        |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.585        |
|    learning_rate        | 5e-05        |
|    loss                 | 161          |
|    max_step             | 0            |
|    n_updates            | 2480         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | 0.00143      |
|    route_completion     | 0.532        |
|    std                  | 0.585        |
|    total_cost           | 7.11         |
|    value_loss           | 304          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 125      |
|    time_elapsed    | 1606     |
|    total_timesteps | 640000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 297         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 126         |
|    time_elapsed         | 1613        |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.001868913 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.749       |
|    learning_rate        | 5e-05       |
|    loss                 | 61.4        |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00166    |
|    std                  | 0.584       |
|    value_loss           | 183         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.185       |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 88          |
|    mean_reward          | 95.3        |
|    num_episodes         | 5           |
|    out_of_road          | 0.815       |
|    raw_action           | 0.4593584   |
|    route_completion     | 0.555       |
|    success_rate         | 0           |
|    total_cost           | 6.99        |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.004487893 |
|    arrive_dest          | 0.157       |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.1         |
|    crash                | 0.228       |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.805       |
|    learning_rate        | 5e-05       |
|    loss                 | 60.3        |
|    max_step             | 0           |
|    n_updates            | 2520        |
|    out_of_road          | 0.843       |
|    policy_gradient_loss | 0.00154     |
|    route_completion     | 0.532       |
|    std                  | 0.586       |
|    total_cost           | 7.04        |
|    value_loss           | 134         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 127      |
|    time_elapsed    | 1627     |
|    total_timesteps | 650240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 314          |
|    ep_rew_mean          | 296          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 128          |
|    time_elapsed         | 1635         |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0025272032 |
|    clip_fraction        | 0.241        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.755        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.5         |
|    n_updates            | 2540         |
|    policy_gradient_loss | 0.00363      |
|    std                  | 0.584        |
|    value_loss           | 184          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.185        |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 180          |
|    num_episodes         | 5            |
|    out_of_road          | 0.815        |
|    raw_action           | 0.45969748   |
|    route_completion     | 0.553        |
|    success_rate         | 0.2          |
|    total_cost           | 6.96         |
| time/                   |              |
|    total_timesteps      | 660000       |
| train/                  |              |
|    approx_kl            | 0.0012485588 |
|    arrive_dest          | 0.158        |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    crash                | 0.224        |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.722        |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    max_step             | 0            |
|    n_updates            | 2560         |
|    out_of_road          | 0.842        |
|    policy_gradient_loss | -0.00127     |
|    route_completion     | 0.53         |
|    std                  | 0.583        |
|    total_cost           | 6.96         |
|    value_loss           | 208          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 129      |
|    time_elapsed    | 1652     |
|    total_timesteps | 660480   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 306         |
|    ep_rew_mean          | 290         |
| time/                   |             |
|    fps                  | 400         |
|    iterations           | 130         |
|    time_elapsed         | 1661        |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.004239061 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.62       |
|    explained_variance   | 0.694       |
|    learning_rate        | 5e-05       |
|    loss                 | 163         |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.000607   |
|    std                  | 0.582       |
|    value_loss           | 306         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.185        |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 148          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.815        |
|    raw_action           | 0.45951384   |
|    route_completion     | 0.554        |
|    success_rate         | 0.1          |
|    total_cost           | 6.94         |
| time/                   |              |
|    total_timesteps      | 670000       |
| train/                  |              |
|    approx_kl            | 0.0015016538 |
|    arrive_dest          | 0.155        |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.227        |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.798        |
|    learning_rate        | 5e-05        |
|    loss                 | 81.9         |
|    max_step             | 0            |
|    n_updates            | 2600         |
|    out_of_road          | 0.845        |
|    policy_gradient_loss | 0.000764     |
|    route_completion     | 0.527        |
|    std                  | 0.579        |
|    total_cost           | 6.92         |
|    value_loss           | 179          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 400      |
|    iterations      | 131      |
|    time_elapsed    | 1674     |
|    total_timesteps | 670720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 311          |
|    ep_rew_mean          | 295          |
| time/                   |              |
|    fps                  | 401          |
|    iterations           | 132          |
|    time_elapsed         | 1682         |
|    total_timesteps      | 675840       |
| train/                  |              |
|    approx_kl            | 0.0012678932 |
|    clip_fraction        | 0.22         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 104          |
|    n_updates            | 2620         |
|    policy_gradient_loss | 0.00383      |
|    std                  | 0.579        |
|    value_loss           | 224          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 171          |
|    mean_reward          | 222          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.45884204   |
|    route_completion     | 0.555        |
|    success_rate         | 0.2          |
|    total_cost           | 6.97         |
| time/                   |              |
|    total_timesteps      | 680000       |
| train/                  |              |
|    approx_kl            | 0.0024365047 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    crash                | 0.229        |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.792        |
|    learning_rate        | 5e-05        |
|    loss                 | 70.6         |
|    max_step             | 0            |
|    n_updates            | 2640         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | 0.000332     |
|    route_completion     | 0.53         |
|    std                  | 0.582        |
|    total_cost           | 7.04         |
|    value_loss           | 176          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 133      |
|    time_elapsed    | 1703     |
|    total_timesteps | 680960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 301          |
|    ep_rew_mean          | 293          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 134          |
|    time_elapsed         | 1711         |
|    total_timesteps      | 686080       |
| train/                  |              |
|    approx_kl            | 0.0011536174 |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.778        |
|    learning_rate        | 5e-05        |
|    loss                 | 92.9         |
|    n_updates            | 2660         |
|    policy_gradient_loss | 0.000648     |
|    std                  | 0.581        |
|    value_loss           | 203          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.186        |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 165          |
|    mean_reward          | 215          |
|    num_episodes         | 5            |
|    out_of_road          | 0.814        |
|    raw_action           | 0.45836085   |
|    route_completion     | 0.555        |
|    success_rate         | 0.3          |
|    total_cost           | 6.97         |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0028224082 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.208        |
|    clip_range           | 0.1          |
|    crash                | 0.226        |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.808        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.4         |
|    max_step             | 0            |
|    n_updates            | 2680         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | 0.0043       |
|    route_completion     | 0.53         |
|    std                  | 0.58         |
|    total_cost           | 7            |
|    value_loss           | 155          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 135      |
|    time_elapsed    | 1731     |
|    total_timesteps | 691200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 305          |
|    ep_rew_mean          | 301          |
| time/                   |              |
|    fps                  | 400          |
|    iterations           | 136          |
|    time_elapsed         | 1740         |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 0.0018897026 |
|    clip_fraction        | 0.18         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.733        |
|    learning_rate        | 5e-05        |
|    loss                 | 94           |
|    n_updates            | 2700         |
|    policy_gradient_loss | -2.99e-05    |
|    std                  | 0.578        |
|    value_loss           | 229          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.189        |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 153          |
|    mean_reward          | 219          |
|    num_episodes         | 5            |
|    out_of_road          | 0.811        |
|    raw_action           | 0.45914117   |
|    route_completion     | 0.555        |
|    success_rate         | 0.3          |
|    total_cost           | 6.91         |
| time/                   |              |
|    total_timesteps      | 700000       |
| train/                  |              |
|    approx_kl            | 0.0054875514 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    crash                | 0.223        |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.779        |
|    learning_rate        | 5e-05        |
|    loss                 | 81.9         |
|    max_step             | 0            |
|    n_updates            | 2720         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | -0.000648    |
|    route_completion     | 0.528        |
|    std                  | 0.578        |
|    total_cost           | 6.91         |
|    value_loss           | 176          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 400      |
|    iterations      | 137      |
|    time_elapsed    | 1753     |
|    total_timesteps | 701440   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 312         |
|    ep_rew_mean          | 311         |
| time/                   |             |
|    fps                  | 400         |
|    iterations           | 138         |
|    time_elapsed         | 1764        |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.002421521 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.793       |
|    learning_rate        | 5e-05       |
|    loss                 | 112         |
|    n_updates            | 2740        |
|    policy_gradient_loss | 1.22e-05    |
|    std                  | 0.579       |
|    value_loss           | 184         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.186      |
|    crash                | 0.234      |
|    max_step             | 0          |
|    mean_ep_length       | 152        |
|    mean_reward          | 218        |
|    num_episodes         | 5          |
|    out_of_road          | 0.814      |
|    raw_action           | 0.45827666 |
|    route_completion     | 0.557      |
|    success_rate         | 0.3        |
|    total_cost           | 6.91       |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.00713012 |
|    arrive_dest          | 0.166      |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.1        |
|    crash                | 0.22       |
|    entropy_loss         | -1.6       |
|    explained_variance   | 0.795      |
|    learning_rate        | 5e-05      |
|    loss                 | 87.1       |
|    max_step             | 0          |
|    n_updates            | 2760       |
|    out_of_road          | 0.834      |
|    policy_gradient_loss | 0.00111    |
|    route_completion     | 0.53       |
|    std                  | 0.578      |
|    total_cost           | 7.08       |
|    value_loss           | 204        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 305      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 139      |
|    time_elapsed    | 1781     |
|    total_timesteps | 711680   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 309         |
|    ep_rew_mean          | 304         |
| time/                   |             |
|    fps                  | 400         |
|    iterations           | 140         |
|    time_elapsed         | 1791        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.003742097 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.724       |
|    learning_rate        | 5e-05       |
|    loss                 | 101         |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.00152    |
|    std                  | 0.578       |
|    value_loss           | 255         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.189      |
|    crash                | 0.236      |
|    max_step             | 0          |
|    mean_ep_length       | 158        |
|    mean_reward          | 146        |
|    num_episodes         | 5          |
|    out_of_road          | 0.811      |
|    raw_action           | 0.45783743 |
|    route_completion     | 0.557      |
|    success_rate         | 0.3        |
|    total_cost           | 7.19       |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.00802718 |
|    arrive_dest          | 0.167      |
|    clip_fraction        | 0.156      |
|    clip_range           | 0.1        |
|    crash                | 0.219      |
|    entropy_loss         | -1.6       |
|    explained_variance   | 0.797      |
|    learning_rate        | 5e-05      |
|    loss                 | 74.5       |
|    max_step             | 0          |
|    n_updates            | 2800       |
|    out_of_road          | 0.833      |
|    policy_gradient_loss | 0.00054    |
|    route_completion     | 0.529      |
|    std                  | 0.576      |
|    total_cost           | 7.05       |
|    value_loss           | 190        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 141      |
|    time_elapsed    | 1811     |
|    total_timesteps | 721920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 309          |
|    ep_rew_mean          | 301          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 142          |
|    time_elapsed         | 1820         |
|    total_timesteps      | 727040       |
| train/                  |              |
|    approx_kl            | 0.0075122193 |
|    clip_fraction        | 0.196        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.59        |
|    explained_variance   | 0.708        |
|    learning_rate        | 5e-05        |
|    loss                 | 96.2         |
|    n_updates            | 2820         |
|    policy_gradient_loss | 0.0013       |
|    std                  | 0.574        |
|    value_loss           | 241          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.189       |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 126         |
|    mean_reward          | 186         |
|    num_episodes         | 5           |
|    out_of_road          | 0.811       |
|    raw_action           | 0.4576696   |
|    route_completion     | 0.557       |
|    success_rate         | 0.2         |
|    total_cost           | 7.1         |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.002396827 |
|    arrive_dest          | 0.167       |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.1         |
|    crash                | 0.216       |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.784       |
|    learning_rate        | 5e-05       |
|    loss                 | 72.5        |
|    max_step             | 0           |
|    n_updates            | 2840        |
|    out_of_road          | 0.833       |
|    policy_gradient_loss | -0.00165    |
|    route_completion     | 0.531       |
|    std                  | 0.573       |
|    total_cost           | 7.07        |
|    value_loss           | 194         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 143      |
|    time_elapsed    | 1837     |
|    total_timesteps | 732160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 278          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 144          |
|    time_elapsed         | 1847         |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 0.0044903294 |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.658        |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    n_updates            | 2860         |
|    policy_gradient_loss | -0.000936    |
|    std                  | 0.572        |
|    value_loss           | 308          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.189        |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 210          |
|    mean_reward          | 271          |
|    num_episodes         | 5            |
|    out_of_road          | 0.811        |
|    raw_action           | 0.45716718   |
|    route_completion     | 0.559        |
|    success_rate         | 0.2          |
|    total_cost           | 7.17         |
| time/                   |              |
|    total_timesteps      | 740000       |
| train/                  |              |
|    approx_kl            | 0.0033824597 |
|    arrive_dest          | 0.168        |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    crash                | 0.222        |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.694        |
|    learning_rate        | 5e-05        |
|    loss                 | 123          |
|    max_step             | 0            |
|    n_updates            | 2880         |
|    out_of_road          | 0.832        |
|    policy_gradient_loss | -0.000952    |
|    route_completion     | 0.532        |
|    std                  | 0.574        |
|    total_cost           | 7.01         |
|    value_loss           | 266          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 145      |
|    time_elapsed    | 1863     |
|    total_timesteps | 742400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 274         |
|    ep_rew_mean          | 269         |
| time/                   |             |
|    fps                  | 398         |
|    iterations           | 146         |
|    time_elapsed         | 1875        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.003470833 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.747       |
|    learning_rate        | 5e-05       |
|    loss                 | 107         |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.000431   |
|    std                  | 0.575       |
|    value_loss           | 242         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.189        |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 149          |
|    mean_reward          | 194          |
|    num_episodes         | 5            |
|    out_of_road          | 0.811        |
|    raw_action           | 0.45800897   |
|    route_completion     | 0.559        |
|    success_rate         | 0.2          |
|    total_cost           | 7.11         |
| time/                   |              |
|    total_timesteps      | 750000       |
| train/                  |              |
|    approx_kl            | 0.0010839865 |
|    arrive_dest          | 0.168        |
|    clip_fraction        | 0.0956       |
|    clip_range           | 0.1          |
|    crash                | 0.219        |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.764        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.8         |
|    max_step             | 0            |
|    n_updates            | 2920         |
|    out_of_road          | 0.832        |
|    policy_gradient_loss | -0.000534    |
|    route_completion     | 0.531        |
|    std                  | 0.573        |
|    total_cost           | 6.95         |
|    value_loss           | 242          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 273      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 147      |
|    time_elapsed    | 1894     |
|    total_timesteps | 752640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 272          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 398          |
|    iterations           | 148          |
|    time_elapsed         | 1902         |
|    total_timesteps      | 757760       |
| train/                  |              |
|    approx_kl            | 0.0043203607 |
|    clip_fraction        | 0.17         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 77.2         |
|    n_updates            | 2940         |
|    policy_gradient_loss | 3.35e-05     |
|    std                  | 0.573        |
|    value_loss           | 201          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.189        |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 192          |
|    mean_reward          | 227          |
|    num_episodes         | 5            |
|    out_of_road          | 0.811        |
|    raw_action           | 0.45816624   |
|    route_completion     | 0.56         |
|    success_rate         | 0.2          |
|    total_cost           | 7.27         |
| time/                   |              |
|    total_timesteps      | 760000       |
| train/                  |              |
|    approx_kl            | 0.0025514413 |
|    arrive_dest          | 0.168        |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    crash                | 0.224        |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.812        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.9         |
|    max_step             | 0            |
|    n_updates            | 2960         |
|    out_of_road          | 0.832        |
|    policy_gradient_loss | -0.000225    |
|    route_completion     | 0.532        |
|    std                  | 0.573        |
|    total_cost           | 6.93         |
|    value_loss           | 164          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 149      |
|    time_elapsed    | 1919     |
|    total_timesteps | 762880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 293         |
|    ep_rew_mean          | 303         |
| time/                   |             |
|    fps                  | 397         |
|    iterations           | 150         |
|    time_elapsed         | 1931        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.005717442 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.756       |
|    learning_rate        | 5e-05       |
|    loss                 | 104         |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00211    |
|    std                  | 0.572       |
|    value_loss           | 180         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.187       |
|    crash                | 0.231       |
|    max_step             | 0           |
|    mean_ep_length       | 129         |
|    mean_reward          | 185         |
|    num_episodes         | 5           |
|    out_of_road          | 0.813       |
|    raw_action           | 0.45797265  |
|    route_completion     | 0.56        |
|    success_rate         | 0.1         |
|    total_cost           | 7.19        |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.009393013 |
|    arrive_dest          | 0.169       |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.1         |
|    crash                | 0.226       |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.712       |
|    learning_rate        | 5e-05       |
|    loss                 | 84.8        |
|    max_step             | 0           |
|    n_updates            | 3000        |
|    out_of_road          | 0.831       |
|    policy_gradient_loss | 0.000113    |
|    route_completion     | 0.535       |
|    std                  | 0.572       |
|    total_cost           | 6.94        |
|    value_loss           | 195         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 396      |
|    iterations      | 151      |
|    time_elapsed    | 1947     |
|    total_timesteps | 773120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 294          |
|    ep_rew_mean          | 307          |
| time/                   |              |
|    fps                  | 397          |
|    iterations           | 152          |
|    time_elapsed         | 1955         |
|    total_timesteps      | 778240       |
| train/                  |              |
|    approx_kl            | 0.0024291077 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 133          |
|    n_updates            | 3020         |
|    policy_gradient_loss | -0.00121     |
|    std                  | 0.572        |
|    value_loss           | 291          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.187       |
|    crash                | 0.228       |
|    max_step             | 0           |
|    mean_ep_length       | 110         |
|    mean_reward          | 149         |
|    num_episodes         | 5           |
|    out_of_road          | 0.813       |
|    raw_action           | 0.45765933  |
|    route_completion     | 0.56        |
|    success_rate         | 0.1         |
|    total_cost           | 7.12        |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.002433387 |
|    arrive_dest          | 0.167       |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.1         |
|    crash                | 0.223       |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.781       |
|    learning_rate        | 5e-05       |
|    loss                 | 99.3        |
|    max_step             | 0           |
|    n_updates            | 3040        |
|    out_of_road          | 0.833       |
|    policy_gradient_loss | 0.00183     |
|    route_completion     | 0.532       |
|    std                  | 0.571       |
|    total_cost           | 6.87        |
|    value_loss           | 188         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 294      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 153      |
|    time_elapsed    | 1970     |
|    total_timesteps | 783360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 302         |
|    ep_rew_mean          | 308         |
| time/                   |             |
|    fps                  | 398         |
|    iterations           | 154         |
|    time_elapsed         | 1980        |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.002464537 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.716       |
|    learning_rate        | 5e-05       |
|    loss                 | 127         |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.000752   |
|    std                  | 0.573       |
|    value_loss           | 218         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.185       |
|    crash                | 0.228       |
|    max_step             | 0           |
|    mean_ep_length       | 92.6        |
|    mean_reward          | 107         |
|    num_episodes         | 5           |
|    out_of_road          | 0.815       |
|    raw_action           | 0.45727503  |
|    route_completion     | 0.557       |
|    success_rate         | 0           |
|    total_cost           | 7.05        |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.002651831 |
|    arrive_dest          | 0.165       |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.1         |
|    crash                | 0.22        |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.737       |
|    learning_rate        | 5e-05       |
|    loss                 | 93.7        |
|    max_step             | 0           |
|    n_updates            | 3080        |
|    out_of_road          | 0.835       |
|    policy_gradient_loss | -0.000269   |
|    route_completion     | 0.532       |
|    std                  | 0.573       |
|    total_cost           | 6.88        |
|    value_loss           | 197         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 155      |
|    time_elapsed    | 1996     |
|    total_timesteps | 793600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 282          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 398          |
|    iterations           | 156          |
|    time_elapsed         | 2005         |
|    total_timesteps      | 798720       |
| train/                  |              |
|    approx_kl            | 0.0019096911 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.772        |
|    learning_rate        | 5e-05        |
|    loss                 | 91.4         |
|    n_updates            | 3100         |
|    policy_gradient_loss | -0.000949    |
|    std                  | 0.572        |
|    value_loss           | 208          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.188        |
|    crash                | 0.228        |
|    max_step             | 0            |
|    mean_ep_length       | 198          |
|    mean_reward          | 292          |
|    num_episodes         | 5            |
|    out_of_road          | 0.812        |
|    raw_action           | 0.45672798   |
|    route_completion     | 0.559        |
|    success_rate         | 0.2          |
|    total_cost           | 7.01         |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0028300178 |
|    arrive_dest          | 0.163        |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    crash                | 0.22         |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.679        |
|    learning_rate        | 5e-05        |
|    loss                 | 140          |
|    max_step             | 0            |
|    n_updates            | 3120         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | -0.00239     |
|    route_completion     | 0.53         |
|    std                  | 0.572        |
|    total_cost           | 6.83         |
|    value_loss           | 315          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 157      |
|    time_elapsed    | 2019     |
|    total_timesteps | 803840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 283          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 398          |
|    iterations           | 158          |
|    time_elapsed         | 2028         |
|    total_timesteps      | 808960       |
| train/                  |              |
|    approx_kl            | 0.0036941175 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.695        |
|    learning_rate        | 5e-05        |
|    loss                 | 128          |
|    n_updates            | 3140         |
|    policy_gradient_loss | -0.000977    |
|    std                  | 0.572        |
|    value_loss           | 229          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.188        |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 231          |
|    num_episodes         | 5            |
|    out_of_road          | 0.812        |
|    raw_action           | 0.45655614   |
|    route_completion     | 0.559        |
|    success_rate         | 0.2          |
|    total_cost           | 6.95         |
| time/                   |              |
|    total_timesteps      | 810000       |
| train/                  |              |
|    approx_kl            | 0.0040876484 |
|    arrive_dest          | 0.163        |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    crash                | 0.22         |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.739        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.1         |
|    max_step             | 0            |
|    n_updates            | 3160         |
|    out_of_road          | 0.837        |
|    policy_gradient_loss | -0.000416    |
|    route_completion     | 0.531        |
|    std                  | 0.572        |
|    total_cost           | 6.78         |
|    value_loss           | 228          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 280      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 159      |
|    time_elapsed    | 2043     |
|    total_timesteps | 814080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 293          |
|    ep_rew_mean          | 288          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 160          |
|    time_elapsed         | 2052         |
|    total_timesteps      | 819200       |
| train/                  |              |
|    approx_kl            | 0.0025950684 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.683        |
|    learning_rate        | 5e-05        |
|    loss                 | 102          |
|    n_updates            | 3180         |
|    policy_gradient_loss | -0.000685    |
|    std                  | 0.572        |
|    value_loss           | 236          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.19        |
|    crash                | 0.229       |
|    max_step             | 0           |
|    mean_ep_length       | 211         |
|    mean_reward          | 287         |
|    num_episodes         | 5           |
|    out_of_road          | 0.81        |
|    raw_action           | 0.4562228   |
|    route_completion     | 0.562       |
|    success_rate         | 0.2         |
|    total_cost           | 7           |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.002202006 |
|    arrive_dest          | 0.161       |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.1         |
|    crash                | 0.224       |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.748       |
|    learning_rate        | 5e-05       |
|    loss                 | 150         |
|    max_step             | 0           |
|    n_updates            | 3200        |
|    out_of_road          | 0.839       |
|    policy_gradient_loss | 0.00335     |
|    route_completion     | 0.531       |
|    std                  | 0.572       |
|    total_cost           | 6.76        |
|    value_loss           | 225         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 161      |
|    time_elapsed    | 2067     |
|    total_timesteps | 824320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 309          |
|    ep_rew_mean          | 310          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 162          |
|    time_elapsed         | 2076         |
|    total_timesteps      | 829440       |
| train/                  |              |
|    approx_kl            | 0.0026489345 |
|    clip_fraction        | 0.16         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.727        |
|    learning_rate        | 5e-05        |
|    loss                 | 102          |
|    n_updates            | 3220         |
|    policy_gradient_loss | -0.000988    |
|    std                  | 0.574        |
|    value_loss           | 225          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.188        |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 94.4         |
|    mean_reward          | 113          |
|    num_episodes         | 5            |
|    out_of_road          | 0.812        |
|    raw_action           | 0.45672977   |
|    route_completion     | 0.559        |
|    success_rate         | 0.1          |
|    total_cost           | 6.94         |
| time/                   |              |
|    total_timesteps      | 830000       |
| train/                  |              |
|    approx_kl            | 0.0022544237 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.206        |
|    clip_range           | 0.1          |
|    crash                | 0.222        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.809        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.3         |
|    max_step             | 0            |
|    n_updates            | 3240         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | 0.00231      |
|    route_completion     | 0.531        |
|    std                  | 0.575        |
|    total_cost           | 6.77         |
|    value_loss           | 173          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 301      |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 163      |
|    time_elapsed    | 2094     |
|    total_timesteps | 834560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 293         |
|    ep_rew_mean          | 301         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 164         |
|    time_elapsed         | 2103        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.002640313 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.686       |
|    learning_rate        | 5e-05       |
|    loss                 | 104         |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.00113    |
|    std                  | 0.575       |
|    value_loss           | 283         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.186        |
|    crash                | 0.224        |
|    max_step             | 0            |
|    mean_ep_length       | 137          |
|    mean_reward          | 195          |
|    num_episodes         | 5            |
|    out_of_road          | 0.814        |
|    raw_action           | 0.4568248    |
|    route_completion     | 0.558        |
|    success_rate         | 0.2          |
|    total_cost           | 6.89         |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0029693784 |
|    arrive_dest          | 0.164        |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    crash                | 0.224        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.752        |
|    learning_rate        | 5e-05        |
|    loss                 | 106          |
|    max_step             | 0            |
|    n_updates            | 3280         |
|    out_of_road          | 0.836        |
|    policy_gradient_loss | 0.00076      |
|    route_completion     | 0.533        |
|    std                  | 0.576        |
|    total_cost           | 6.81         |
|    value_loss           | 307          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 165      |
|    time_elapsed    | 2120     |
|    total_timesteps | 844800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 272         |
|    ep_rew_mean          | 285         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 166         |
|    time_elapsed         | 2129        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.001562554 |
|    clip_fraction        | 0.0938      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.648       |
|    learning_rate        | 5e-05       |
|    loss                 | 163         |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.00104    |
|    std                  | 0.575       |
|    value_loss           | 327         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.186        |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 178          |
|    mean_reward          | 253          |
|    num_episodes         | 5            |
|    out_of_road          | 0.814        |
|    raw_action           | 0.45694727   |
|    route_completion     | 0.559        |
|    success_rate         | 0.1          |
|    total_cost           | 6.86         |
| time/                   |              |
|    total_timesteps      | 850000       |
| train/                  |              |
|    approx_kl            | 0.0018807736 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    crash                | 0.226        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.797        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.8         |
|    max_step             | 0            |
|    n_updates            | 3320         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | 0.000116     |
|    route_completion     | 0.533        |
|    std                  | 0.575        |
|    total_cost           | 6.77         |
|    value_loss           | 195          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 260      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 167      |
|    time_elapsed    | 2145     |
|    total_timesteps | 855040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.186        |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 237          |
|    num_episodes         | 5            |
|    out_of_road          | 0.814        |
|    raw_action           | 0.4571343    |
|    route_completion     | 0.56         |
|    success_rate         | 0.1          |
|    total_cost           | 6.81         |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0035094204 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    crash                | 0.228        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 177          |
|    max_step             | 0            |
|    n_updates            | 3340         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | 0.000354     |
|    route_completion     | 0.532        |
|    std                  | 0.574        |
|    total_cost           | 6.71         |
|    value_loss           | 310          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 255      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 168      |
|    time_elapsed    | 2157     |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 261         |
|    ep_rew_mean          | 272         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 169         |
|    time_elapsed         | 2165        |
|    total_timesteps      | 865280      |
| train/                  |             |
|    approx_kl            | 0.002255765 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.751       |
|    learning_rate        | 5e-05       |
|    loss                 | 87.5        |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.000404    |
|    std                  | 0.575       |
|    value_loss           | 283         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.184        |
|    crash                | 0.223        |
|    max_step             | 0            |
|    mean_ep_length       | 110          |
|    mean_reward          | 146          |
|    num_episodes         | 5            |
|    out_of_road          | 0.816        |
|    raw_action           | 0.45759726   |
|    route_completion     | 0.558        |
|    success_rate         | 0            |
|    total_cost           | 6.75         |
| time/                   |              |
|    total_timesteps      | 870000       |
| train/                  |              |
|    approx_kl            | 0.0060878564 |
|    arrive_dest          | 0.159        |
|    clip_fraction        | 0.195        |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.805        |
|    learning_rate        | 5e-05        |
|    loss                 | 96           |
|    max_step             | 0            |
|    n_updates            | 3380         |
|    out_of_road          | 0.841        |
|    policy_gradient_loss | 0.00151      |
|    route_completion     | 0.53         |
|    std                  | 0.574        |
|    total_cost           | 6.66         |
|    value_loss           | 191          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 267      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 170      |
|    time_elapsed    | 2181     |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 274         |
|    ep_rew_mean          | 284         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 171         |
|    time_elapsed         | 2189        |
|    total_timesteps      | 875520      |
| train/                  |             |
|    approx_kl            | 0.010986305 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.688       |
|    learning_rate        | 5e-05       |
|    loss                 | 94.1        |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.00128    |
|    std                  | 0.571       |
|    value_loss           | 319         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.182       |
|    crash                | 0.225       |
|    max_step             | 0           |
|    mean_ep_length       | 109         |
|    mean_reward          | 129         |
|    num_episodes         | 5           |
|    out_of_road          | 0.818       |
|    raw_action           | 0.45754415  |
|    route_completion     | 0.556       |
|    success_rate         | 0.2         |
|    total_cost           | 6.69        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.003799548 |
|    arrive_dest          | 0.161       |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.1         |
|    crash                | 0.232       |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.802       |
|    learning_rate        | 5e-05       |
|    loss                 | 67.4        |
|    max_step             | 0           |
|    n_updates            | 3420        |
|    out_of_road          | 0.839       |
|    policy_gradient_loss | -0.00011    |
|    route_completion     | 0.533       |
|    std                  | 0.57        |
|    total_cost           | 6.73        |
|    value_loss           | 155         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 172      |
|    time_elapsed    | 2208     |
|    total_timesteps | 880640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 294          |
|    ep_rew_mean          | 298          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 173          |
|    time_elapsed         | 2216         |
|    total_timesteps      | 885760       |
| train/                  |              |
|    approx_kl            | 0.0024461166 |
|    clip_fraction        | 0.186        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.807        |
|    learning_rate        | 5e-05        |
|    loss                 | 114          |
|    n_updates            | 3440         |
|    policy_gradient_loss | 0.00113      |
|    std                  | 0.573        |
|    value_loss           | 189          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.182       |
|    crash                | 0.225       |
|    max_step             | 0           |
|    mean_ep_length       | 171         |
|    mean_reward          | 221         |
|    num_episodes         | 5           |
|    out_of_road          | 0.818       |
|    raw_action           | 0.4576194   |
|    route_completion     | 0.556       |
|    success_rate         | 0.2         |
|    total_cost           | 6.75        |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.005227592 |
|    arrive_dest          | 0.162       |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.1         |
|    crash                | 0.234       |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.754       |
|    learning_rate        | 5e-05       |
|    loss                 | 80.6        |
|    max_step             | 0           |
|    n_updates            | 3460        |
|    out_of_road          | 0.838       |
|    policy_gradient_loss | 5.67e-05    |
|    route_completion     | 0.535       |
|    std                  | 0.573       |
|    total_cost           | 6.75        |
|    value_loss           | 223         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 299      |
|    ep_rew_mean     | 304      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 174      |
|    time_elapsed    | 2232     |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 315         |
|    ep_rew_mean          | 321         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 175         |
|    time_elapsed         | 2244        |
|    total_timesteps      | 896000      |
| train/                  |             |
|    approx_kl            | 0.003914794 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.682       |
|    learning_rate        | 5e-05       |
|    loss                 | 87.1        |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.000168   |
|    std                  | 0.573       |
|    value_loss           | 289         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.18         |
|    crash                | 0.224        |
|    max_step             | 0            |
|    mean_ep_length       | 132          |
|    mean_reward          | 186          |
|    num_episodes         | 5            |
|    out_of_road          | 0.82         |
|    raw_action           | 0.45740965   |
|    route_completion     | 0.555        |
|    success_rate         | 0            |
|    total_cost           | 6.7          |
| time/                   |              |
|    total_timesteps      | 900000       |
| train/                  |              |
|    approx_kl            | 0.0036385837 |
|    arrive_dest          | 0.16         |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 94           |
|    max_step             | 0            |
|    n_updates            | 3500         |
|    out_of_road          | 0.84         |
|    policy_gradient_loss | 0.000445     |
|    route_completion     | 0.533        |
|    std                  | 0.571        |
|    total_cost           | 6.73         |
|    value_loss           | 204          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 176      |
|    time_elapsed    | 2257     |
|    total_timesteps | 901120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 313          |
|    ep_rew_mean          | 314          |
| time/                   |              |
|    fps                  | 399          |
|    iterations           | 177          |
|    time_elapsed         | 2266         |
|    total_timesteps      | 906240       |
| train/                  |              |
|    approx_kl            | 0.0023255597 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.701        |
|    learning_rate        | 5e-05        |
|    loss                 | 121          |
|    n_updates            | 3520         |
|    policy_gradient_loss | -0.00255     |
|    std                  | 0.572        |
|    value_loss           | 328          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.182        |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.818        |
|    raw_action           | 0.45752248   |
|    route_completion     | 0.555        |
|    success_rate         | 0.2          |
|    total_cost           | 6.64         |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0016452273 |
|    arrive_dest          | 0.158        |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    crash                | 0.233        |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.806        |
|    learning_rate        | 5e-05        |
|    loss                 | 100          |
|    max_step             | 0            |
|    n_updates            | 3540         |
|    out_of_road          | 0.842        |
|    policy_gradient_loss | 0.00169      |
|    route_completion     | 0.53         |
|    std                  | 0.572        |
|    total_cost           | 6.67         |
|    value_loss           | 220          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 294      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 178      |
|    time_elapsed    | 2280     |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 283         |
|    ep_rew_mean          | 287         |
| time/                   |             |
|    fps                  | 400         |
|    iterations           | 179         |
|    time_elapsed         | 2289        |
|    total_timesteps      | 916480      |
| train/                  |             |
|    approx_kl            | 0.006382546 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.648       |
|    learning_rate        | 5e-05       |
|    loss                 | 186         |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.000673   |
|    std                  | 0.572       |
|    value_loss           | 327         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.18         |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 134          |
|    num_episodes         | 5            |
|    out_of_road          | 0.82         |
|    raw_action           | 0.45777765   |
|    route_completion     | 0.553        |
|    success_rate         | 0.2          |
|    total_cost           | 6.59         |
| time/                   |              |
|    total_timesteps      | 920000       |
| train/                  |              |
|    approx_kl            | 0.0014192781 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.08         |
|    clip_range           | 0.1          |
|    crash                | 0.23         |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.777        |
|    learning_rate        | 5e-05        |
|    loss                 | 107          |
|    max_step             | 0            |
|    n_updates            | 3580         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | -0.00142     |
|    route_completion     | 0.531        |
|    std                  | 0.573        |
|    total_cost           | 6.73         |
|    value_loss           | 259          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 274      |
|    ep_rew_mean     | 277      |
| time/              |          |
|    fps             | 399      |
|    iterations      | 180      |
|    time_elapsed    | 2308     |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 278         |
|    ep_rew_mean          | 276         |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 181         |
|    time_elapsed         | 2320        |
|    total_timesteps      | 926720      |
| train/                  |             |
|    approx_kl            | 0.002063898 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.7         |
|    learning_rate        | 5e-05       |
|    loss                 | 88          |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.000946   |
|    std                  | 0.572       |
|    value_loss           | 213         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.185        |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 251          |
|    mean_reward          | 329          |
|    num_episodes         | 5            |
|    out_of_road          | 0.815        |
|    raw_action           | 0.45784992   |
|    route_completion     | 0.556        |
|    success_rate         | 0.5          |
|    total_cost           | 6.69         |
| time/                   |              |
|    total_timesteps      | 930000       |
| train/                  |              |
|    approx_kl            | 0.0020361405 |
|    arrive_dest          | 0.163        |
|    clip_fraction        | 0.225        |
|    clip_range           | 0.1          |
|    crash                | 0.228        |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.737        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.8         |
|    max_step             | 0            |
|    n_updates            | 3620         |
|    out_of_road          | 0.837        |
|    policy_gradient_loss | 0.00442      |
|    route_completion     | 0.532        |
|    std                  | 0.571        |
|    total_cost           | 6.73         |
|    value_loss           | 243          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 398      |
|    iterations      | 182      |
|    time_elapsed    | 2341     |
|    total_timesteps | 931840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 296          |
|    ep_rew_mean          | 300          |
| time/                   |              |
|    fps                  | 398          |
|    iterations           | 183          |
|    time_elapsed         | 2350         |
|    total_timesteps      | 936960       |
| train/                  |              |
|    approx_kl            | 0.0043165684 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 95.8         |
|    n_updates            | 3640         |
|    policy_gradient_loss | -0.00111     |
|    std                  | 0.572        |
|    value_loss           | 276          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.185       |
|    crash                | 0.221       |
|    max_step             | 0           |
|    mean_ep_length       | 121         |
|    mean_reward          | 117         |
|    num_episodes         | 5           |
|    out_of_road          | 0.815       |
|    raw_action           | 0.4582326   |
|    route_completion     | 0.555       |
|    success_rate         | 0.2         |
|    total_cost           | 6.76        |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.006038968 |
|    arrive_dest          | 0.164       |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.1         |
|    crash                | 0.23        |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.739       |
|    learning_rate        | 5e-05       |
|    loss                 | 126         |
|    max_step             | 0           |
|    n_updates            | 3660        |
|    out_of_road          | 0.836       |
|    policy_gradient_loss | 0.000619    |
|    route_completion     | 0.532       |
|    std                  | 0.572       |
|    total_cost           | 6.72        |
|    value_loss           | 268         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 184      |
|    time_elapsed    | 2369     |
|    total_timesteps | 942080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 302          |
|    ep_rew_mean          | 307          |
| time/                   |              |
|    fps                  | 398          |
|    iterations           | 185          |
|    time_elapsed         | 2377         |
|    total_timesteps      | 947200       |
| train/                  |              |
|    approx_kl            | 0.0023958536 |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.769        |
|    learning_rate        | 5e-05        |
|    loss                 | 122          |
|    n_updates            | 3680         |
|    policy_gradient_loss | -0.000537    |
|    std                  | 0.575        |
|    value_loss           | 257          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.189        |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 159          |
|    mean_reward          | 247          |
|    num_episodes         | 5            |
|    out_of_road          | 0.811        |
|    raw_action           | 0.45815206   |
|    route_completion     | 0.556        |
|    success_rate         | 0.3          |
|    total_cost           | 6.75         |
| time/                   |              |
|    total_timesteps      | 950000       |
| train/                  |              |
|    approx_kl            | 0.0030639847 |
|    arrive_dest          | 0.162        |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    crash                | 0.229        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.9         |
|    max_step             | 0            |
|    n_updates            | 3700         |
|    out_of_road          | 0.838        |
|    policy_gradient_loss | -0.000769    |
|    route_completion     | 0.531        |
|    std                  | 0.574        |
|    total_cost           | 6.68         |
|    value_loss           | 227          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 301      |
|    ep_rew_mean     | 310      |
| time/              |          |
|    fps             | 397      |
|    iterations      | 186      |
|    time_elapsed    | 2392     |
|    total_timesteps | 952320   |
---------------------------------
