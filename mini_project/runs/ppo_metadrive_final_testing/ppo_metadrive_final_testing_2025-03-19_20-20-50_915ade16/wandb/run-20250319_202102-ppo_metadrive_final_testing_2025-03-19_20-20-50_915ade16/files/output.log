Using cpu device
Logging to runs\ppo_metadrive_final_testing\ppo_metadrive_final_testing_2025-03-19_20-20-50_915ade16\ppo_metadrive_final_testing_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | -2.18    |
| time/              |          |
|    fps             | 1580     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 245          |
|    mean_reward          | 67.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.034462124  |
|    route_completion     | 0.238        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0034863823 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.199        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0184       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0395       |
|    max_step             | 0            |
|    n_updates            | 20           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00802     |
|    route_completion     | 0.158        |
|    std                  | 1            |
|    total_cost           | 1            |
|    value_loss           | 0.0517       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 584      |
|    ep_rew_mean     | 1.9      |
| time/              |          |
|    fps             | 686      |
|    iterations      | 2        |
|    time_elapsed    | 14       |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 427          |
|    ep_rew_mean          | 4.7          |
| time/                   |              |
|    fps                  | 752          |
|    iterations           | 3            |
|    time_elapsed         | 20           |
|    total_timesteps      | 15360        |
| train/                  |              |
|    approx_kl            | 0.0031309729 |
|    clip_fraction        | 0.202        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00622      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00816     |
|    std                  | 0.994        |
|    value_loss           | 0.0653       |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 129          |
|    mean_reward          | 51.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.067642845  |
|    route_completion     | 0.191        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0023895553 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.82        |
|    explained_variance   | -0.0028      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00835      |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00378     |
|    route_completion     | 0.21         |
|    std                  | 0.99         |
|    total_cost           | 1.9          |
|    value_loss           | 0.195        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 444      |
|    ep_rew_mean     | 11       |
| time/              |          |
|    fps             | 634      |
|    iterations      | 4        |
|    time_elapsed    | 32       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 401          |
|    ep_rew_mean          | 11.7         |
| time/                   |              |
|    fps                  | 681          |
|    iterations           | 5            |
|    time_elapsed         | 37           |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0025116997 |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0507       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0801       |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00422     |
|    std                  | 0.987        |
|    value_loss           | 0.321        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 76.6         |
|    mean_reward          | 29.9         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.086597145  |
|    route_completion     | 0.166        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0023433103 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0371       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0656       |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00314     |
|    route_completion     | 0.189        |
|    std                  | 0.982        |
|    total_cost           | 1.6          |
|    value_loss           | 0.285        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 440      |
|    ep_rew_mean     | 20.2     |
| time/              |          |
|    fps             | 638      |
|    iterations      | 6        |
|    time_elapsed    | 48       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 427          |
|    ep_rew_mean          | 19.5         |
| time/                   |              |
|    fps                  | 679          |
|    iterations           | 7            |
|    time_elapsed         | 52           |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 0.0030366397 |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.0141       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.57         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00382     |
|    std                  | 0.978        |
|    value_loss           | 0.732        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 67.2         |
|    mean_reward          | 31           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.108840145  |
|    route_completion     | 0.15         |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0028624877 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.196        |
|    clip_range           | 0.1          |
|    crash                | 0.05         |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.0731       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.172        |
|    max_step             | 0            |
|    n_updates            | 140          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0065      |
|    route_completion     | 0.182        |
|    std                  | 0.968        |
|    total_cost           | 1.45         |
|    value_loss           | 0.317        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 19.2     |
| time/              |          |
|    fps             | 657      |
|    iterations      | 8        |
|    time_elapsed    | 62       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 449          |
|    ep_rew_mean          | 20.7         |
| time/                   |              |
|    fps                  | 683          |
|    iterations           | 9            |
|    time_elapsed         | 67           |
|    total_timesteps      | 46080        |
| train/                  |              |
|    approx_kl            | 0.0022975956 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.0236       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.255        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00355     |
|    std                  | 0.961        |
|    value_loss           | 0.802        |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0           |
|    max_step             | 0           |
|    mean_ep_length       | 82.2        |
|    mean_reward          | 52.3        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.13464828  |
|    route_completion     | 0.153       |
|    success_rate         | 0           |
|    total_cost           | 1           |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.002366459 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.1         |
|    crash                | 0.04        |
|    entropy_loss         | -2.75       |
|    explained_variance   | 0.0622      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.202       |
|    max_step             | 0           |
|    n_updates            | 180         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00367    |
|    route_completion     | 0.183       |
|    std                  | 0.954       |
|    total_cost           | 1.36        |
|    value_loss           | 0.566       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 24.8     |
| time/              |          |
|    fps             | 666      |
|    iterations      | 10       |
|    time_elapsed    | 76       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 411          |
|    ep_rew_mean          | 24.1         |
| time/                   |              |
|    fps                  | 673          |
|    iterations           | 11           |
|    time_elapsed         | 83           |
|    total_timesteps      | 56320        |
| train/                  |              |
|    approx_kl            | 0.0021037958 |
|    clip_fraction        | 0.0792       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.0512       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.593        |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00218     |
|    std                  | 0.952        |
|    value_loss           | 1.27         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 60.2         |
|    mean_reward          | 39.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.15552117   |
|    route_completion     | 0.149        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0021576744 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    crash                | 0.0333       |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.043        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.53         |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00304     |
|    route_completion     | 0.178        |
|    std                  | 0.946        |
|    total_cost           | 1.3          |
|    value_loss           | 1.32         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 22.7     |
| time/              |          |
|    fps             | 645      |
|    iterations      | 12       |
|    time_elapsed    | 95       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 21           |
| time/                   |              |
|    fps                  | 648          |
|    iterations           | 13           |
|    time_elapsed         | 102          |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0018001059 |
|    clip_fraction        | 0.0884       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.0479       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.993        |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00226     |
|    std                  | 0.942        |
|    value_loss           | 2.32         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0286       |
|    max_step             | 0            |
|    mean_ep_length       | 64.4         |
|    mean_reward          | 46           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1765947    |
|    route_completion     | 0.155        |
|    success_rate         | 0            |
|    total_cost           | 1.2          |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0019219054 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    crash                | 0.0286       |
|    entropy_loss         | -2.71        |
|    explained_variance   | -0.000678    |
|    learning_rate        | 5e-05        |
|    loss                 | 1.34         |
|    max_step             | 0            |
|    n_updates            | 260          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00262     |
|    route_completion     | 0.173        |
|    std                  | 0.939        |
|    total_cost           | 1.31         |
|    value_loss           | 2.16         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 20.5     |
| time/              |          |
|    fps             | 613      |
|    iterations      | 14       |
|    time_elapsed    | 116      |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 232          |
|    ep_rew_mean          | 17.1         |
| time/                   |              |
|    fps                  | 611          |
|    iterations           | 15           |
|    time_elapsed         | 125          |
|    total_timesteps      | 76800        |
| train/                  |              |
|    approx_kl            | 0.0017877849 |
|    clip_fraction        | 0.0743       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.0585       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.38         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00244     |
|    std                  | 0.934        |
|    value_loss           | 5.26         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.025        |
|    max_step             | 0            |
|    mean_ep_length       | 53.4         |
|    mean_reward          | 35           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.19720368   |
|    route_completion     | 0.154        |
|    success_rate         | 0            |
|    total_cost           | 1.25         |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0012551362 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0487       |
|    clip_range           | 0.1          |
|    crash                | 0.075        |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.0307       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.53         |
|    max_step             | 0            |
|    n_updates            | 300          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00153     |
|    route_completion     | 0.176        |
|    std                  | 0.93         |
|    total_cost           | 1.27         |
|    value_loss           | 3.18         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 15.4     |
| time/              |          |
|    fps             | 592      |
|    iterations      | 16       |
|    time_elapsed    | 138      |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 201          |
|    ep_rew_mean          | 15.1         |
| time/                   |              |
|    fps                  | 586          |
|    iterations           | 17           |
|    time_elapsed         | 148          |
|    total_timesteps      | 87040        |
| train/                  |              |
|    approx_kl            | 0.0009627605 |
|    clip_fraction        | 0.0519       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.0201       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.65         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.0018      |
|    std                  | 0.927        |
|    value_loss           | 3.46         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0222       |
|    max_step             | 0            |
|    mean_ep_length       | 56.6         |
|    mean_reward          | 42.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.2190573    |
|    route_completion     | 0.154        |
|    success_rate         | 0            |
|    total_cost           | 1.22         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0009041655 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0122       |
|    clip_range           | 0.1          |
|    crash                | 0.0889       |
|    entropy_loss         | -2.68        |
|    explained_variance   | 0.0684       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.79         |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000545    |
|    route_completion     | 0.176        |
|    std                  | 0.92         |
|    total_cost           | 1.44         |
|    value_loss           | 3.9          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 13.4     |
| time/              |          |
|    fps             | 560      |
|    iterations      | 18       |
|    time_elapsed    | 164      |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 160          |
|    ep_rew_mean          | 14.6         |
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 19           |
|    time_elapsed         | 175          |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0011405993 |
|    clip_fraction        | 0.0284       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.97         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.000743    |
|    std                  | 0.916        |
|    value_loss           | 6.91         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.02        |
|    max_step             | 0           |
|    mean_ep_length       | 46.6        |
|    mean_reward          | 28          |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.23205638  |
|    route_completion     | 0.149       |
|    success_rate         | 0           |
|    total_cost           | 1.2         |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.001317972 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0575      |
|    clip_range           | 0.1         |
|    crash                | 0.08        |
|    entropy_loss         | -2.66       |
|    explained_variance   | 0.161       |
|    learning_rate        | 5e-05       |
|    loss                 | 2.05        |
|    max_step             | 0           |
|    n_updates            | 380         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00185    |
|    route_completion     | 0.169       |
|    std                  | 0.916       |
|    total_cost           | 1.4         |
|    value_loss           | 5.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | 12.8     |
| time/              |          |
|    fps             | 527      |
|    iterations      | 20       |
|    time_elapsed    | 193      |
|    total_timesteps | 102400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 146          |
|    ep_rew_mean          | 15.3         |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 21           |
|    time_elapsed         | 206          |
|    total_timesteps      | 107520       |
| train/                  |              |
|    approx_kl            | 0.0018241256 |
|    clip_fraction        | 0.0668       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.0777       |
|    learning_rate        | 5e-05        |
|    loss                 | 4.02         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00246     |
|    std                  | 0.912        |
|    value_loss           | 7.72         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0364       |
|    max_step             | 0            |
|    mean_ep_length       | 73.6         |
|    mean_reward          | 76           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.25326297   |
|    route_completion     | 0.159        |
|    success_rate         | 0            |
|    total_cost           | 1.18         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0009501961 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.00883      |
|    clip_range           | 0.1          |
|    crash                | 0.0909       |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0611       |
|    learning_rate        | 5e-05        |
|    loss                 | 4            |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000272    |
|    route_completion     | 0.178        |
|    std                  | 0.909        |
|    total_cost           | 1.51         |
|    value_loss           | 7.08         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 123      |
|    ep_rew_mean     | 15.8     |
| time/              |          |
|    fps             | 509      |
|    iterations      | 22       |
|    time_elapsed    | 221      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 128          |
|    ep_rew_mean          | 16.3         |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 23           |
|    time_elapsed         | 235          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0019076584 |
|    clip_fraction        | 0.0465       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.64        |
|    explained_variance   | 0.115        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.24         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00157     |
|    std                  | 0.905        |
|    value_loss           | 8.45         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0333       |
|    max_step             | 0            |
|    mean_ep_length       | 46.4         |
|    mean_reward          | 26.4         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.26677704   |
|    route_completion     | 0.154        |
|    success_rate         | 0            |
|    total_cost           | 1.17         |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0007080353 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0193       |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.0946       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.38         |
|    max_step             | 0            |
|    n_updates            | 460          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000946    |
|    route_completion     | 0.178        |
|    std                  | 0.901        |
|    total_cost           | 1.47         |
|    value_loss           | 9.13         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 106      |
|    ep_rew_mean     | 12.7     |
| time/              |          |
|    fps             | 486      |
|    iterations      | 24       |
|    time_elapsed    | 252      |
|    total_timesteps | 122880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 107          |
|    ep_rew_mean          | 14.1         |
| time/                   |              |
|    fps                  | 483          |
|    iterations           | 25           |
|    time_elapsed         | 264          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0014148961 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.122        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.06         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00121     |
|    std                  | 0.898        |
|    value_loss           | 9.68         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0308       |
|    max_step             | 0            |
|    mean_ep_length       | 61.2         |
|    mean_reward          | 51.4         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.278626     |
|    route_completion     | 0.156        |
|    success_rate         | 0            |
|    total_cost           | 1.15         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0017028762 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0325       |
|    clip_range           | 0.1          |
|    crash                | 0.108        |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.173        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.09         |
|    max_step             | 0            |
|    n_updates            | 500          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00172     |
|    route_completion     | 0.177        |
|    std                  | 0.889        |
|    total_cost           | 1.43         |
|    value_loss           | 8.56         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 107      |
|    ep_rew_mean     | 15.9     |
| time/              |          |
|    fps             | 474      |
|    iterations      | 26       |
|    time_elapsed    | 280      |
|    total_timesteps | 133120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 115          |
|    ep_rew_mean          | 17.4         |
| time/                   |              |
|    fps                  | 471          |
|    iterations           | 27           |
|    time_elapsed         | 293          |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0010502177 |
|    clip_fraction        | 0.0353       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.081        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.5          |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00153     |
|    std                  | 0.887        |
|    value_loss           | 10.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0714       |
|    max_step             | 0            |
|    mean_ep_length       | 87.8         |
|    mean_reward          | 101          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.2994874    |
|    route_completion     | 0.169        |
|    success_rate         | 0            |
|    total_cost           | 1.14         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0011159691 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0501       |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.0941       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.68         |
|    max_step             | 0            |
|    n_updates            | 540          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00233     |
|    route_completion     | 0.179        |
|    std                  | 0.887        |
|    total_cost           | 2.54         |
|    value_loss           | 9.3          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 110      |
|    ep_rew_mean     | 18.8     |
| time/              |          |
|    fps             | 452      |
|    iterations      | 28       |
|    time_elapsed    | 316      |
|    total_timesteps | 143360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 121          |
|    ep_rew_mean          | 22.9         |
| time/                   |              |
|    fps                  | 448          |
|    iterations           | 29           |
|    time_elapsed         | 330          |
|    total_timesteps      | 148480       |
| train/                  |              |
|    approx_kl            | 0.0009882641 |
|    clip_fraction        | 0.0154       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.117        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.65         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.883        |
|    value_loss           | 14           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 128          |
|    mean_reward          | 93           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.31827226   |
|    route_completion     | 0.18         |
|    success_rate         | 0            |
|    total_cost           | 2.35         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0008109074 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0221       |
|    clip_range           | 0.1          |
|    crash                | 0.12         |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.229        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.05         |
|    max_step             | 0            |
|    n_updates            | 580          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00248     |
|    route_completion     | 0.194        |
|    std                  | 0.879        |
|    total_cost           | 3.88         |
|    value_loss           | 12.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 110      |
|    ep_rew_mean     | 22.3     |
| time/              |          |
|    fps             | 434      |
|    iterations      | 30       |
|    time_elapsed    | 353      |
|    total_timesteps | 153600   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 115           |
|    ep_rew_mean          | 23.7          |
| time/                   |               |
|    fps                  | 435           |
|    iterations           | 31            |
|    time_elapsed         | 364           |
|    total_timesteps      | 158720        |
| train/                  |               |
|    approx_kl            | 0.00095177506 |
|    clip_fraction        | 0.0267        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.174         |
|    learning_rate        | 5e-05         |
|    loss                 | 9.41          |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.00166      |
|    std                  | 0.876         |
|    value_loss           | 18.1          |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0875       |
|    max_step             | 0            |
|    mean_ep_length       | 98.2         |
|    mean_reward          | 105          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3290283    |
|    route_completion     | 0.19         |
|    success_rate         | 0            |
|    total_cost           | 2.61         |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0013039596 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0537       |
|    clip_range           | 0.1          |
|    crash                | 0.113        |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.267        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.54         |
|    max_step             | 0            |
|    n_updates            | 620          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00361     |
|    route_completion     | 0.199        |
|    std                  | 0.875        |
|    total_cost           | 3.76         |
|    value_loss           | 9.54         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | 32.3     |
| time/              |          |
|    fps             | 429      |
|    iterations      | 32       |
|    time_elapsed    | 381      |
|    total_timesteps | 163840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 154         |
|    ep_rew_mean          | 36.3        |
| time/                   |             |
|    fps                  | 431         |
|    iterations           | 33          |
|    time_elapsed         | 391         |
|    total_timesteps      | 168960      |
| train/                  |             |
|    approx_kl            | 0.001164526 |
|    clip_fraction        | 0.0376      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.338       |
|    learning_rate        | 5e-05       |
|    loss                 | 7.33        |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00189    |
|    std                  | 0.871       |
|    value_loss           | 19.4        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.106        |
|    max_step             | 0            |
|    mean_ep_length       | 76.6         |
|    mean_reward          | 74.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.34187496   |
|    route_completion     | 0.193        |
|    success_rate         | 0            |
|    total_cost           | 2.56         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0016350861 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0587       |
|    clip_range           | 0.1          |
|    crash                | 0.106        |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.28         |
|    learning_rate        | 5e-05        |
|    loss                 | 8.7          |
|    max_step             | 0            |
|    n_updates            | 660          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00389     |
|    route_completion     | 0.213        |
|    std                  | 0.866        |
|    total_cost           | 4.06         |
|    value_loss           | 14.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 158      |
|    ep_rew_mean     | 41.4     |
| time/              |          |
|    fps             | 426      |
|    iterations      | 34       |
|    time_elapsed    | 408      |
|    total_timesteps | 174080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 165          |
|    ep_rew_mean          | 45.8         |
| time/                   |              |
|    fps                  | 430          |
|    iterations           | 35           |
|    time_elapsed         | 416          |
|    total_timesteps      | 179200       |
| train/                  |              |
|    approx_kl            | 0.0015119055 |
|    clip_fraction        | 0.0771       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.318        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.3         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00312     |
|    std                  | 0.864        |
|    value_loss           | 19           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 80           |
|    mean_reward          | 83.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.35084498   |
|    route_completion     | 0.198        |
|    success_rate         | 0            |
|    total_cost           | 2.5          |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0023450227 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.09         |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.262        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.82         |
|    max_step             | 0            |
|    n_updates            | 700          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00364     |
|    route_completion     | 0.216        |
|    std                  | 0.857        |
|    total_cost           | 4.54         |
|    value_loss           | 13.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 48.5     |
| time/              |          |
|    fps             | 429      |
|    iterations      | 36       |
|    time_elapsed    | 429      |
|    total_timesteps | 184320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 55.8         |
| time/                   |              |
|    fps                  | 432          |
|    iterations           | 37           |
|    time_elapsed         | 437          |
|    total_timesteps      | 189440       |
| train/                  |              |
|    approx_kl            | 0.0010108283 |
|    clip_fraction        | 0.0725       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.311        |
|    learning_rate        | 5e-05        |
|    loss                 | 8.79         |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00257     |
|    std                  | 0.854        |
|    value_loss           | 21.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.137        |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 115          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.36172825   |
|    route_completion     | 0.208        |
|    success_rate         | 0            |
|    total_cost           | 2.67         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0016565891 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0697       |
|    clip_range           | 0.1          |
|    crash                | 0.116        |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.341        |
|    learning_rate        | 5e-05        |
|    loss                 | 8.99         |
|    max_step             | 0            |
|    n_updates            | 740          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00391     |
|    route_completion     | 0.222        |
|    std                  | 0.849        |
|    total_cost           | 4.54         |
|    value_loss           | 17.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 64       |
| time/              |          |
|    fps             | 430      |
|    iterations      | 38       |
|    time_elapsed    | 452      |
|    total_timesteps | 194560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 203          |
|    ep_rew_mean          | 72.1         |
| time/                   |              |
|    fps                  | 433          |
|    iterations           | 39           |
|    time_elapsed         | 460          |
|    total_timesteps      | 199680       |
| train/                  |              |
|    approx_kl            | 0.0009120526 |
|    clip_fraction        | 0.0575       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.234        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.6         |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00257     |
|    std                  | 0.846        |
|    value_loss           | 23.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.14         |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 124          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.37164262   |
|    route_completion     | 0.216        |
|    success_rate         | 0            |
|    total_cost           | 2.64         |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0019701053 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0669       |
|    clip_range           | 0.1          |
|    crash                | 0.12         |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.296        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.54         |
|    max_step             | 0            |
|    n_updates            | 780          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00337     |
|    route_completion     | 0.231        |
|    std                  | 0.841        |
|    total_cost           | 4.95         |
|    value_loss           | 21.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 80.1     |
| time/              |          |
|    fps             | 431      |
|    iterations      | 40       |
|    time_elapsed    | 474      |
|    total_timesteps | 204800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 231          |
|    ep_rew_mean          | 88.7         |
| time/                   |              |
|    fps                  | 435          |
|    iterations           | 41           |
|    time_elapsed         | 481          |
|    total_timesteps      | 209920       |
| train/                  |              |
|    approx_kl            | 0.0011979474 |
|    clip_fraction        | 0.0964       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.237        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.48         |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00105     |
|    std                  | 0.837        |
|    value_loss           | 24.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00952      |
|    crash                | 0.152        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 52.3         |
|    num_episodes         | 5            |
|    out_of_road          | 0.99         |
|    raw_action           | 0.37959003   |
|    route_completion     | 0.228        |
|    success_rate         | 0.1          |
|    total_cost           | 4.85         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0017571987 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0687       |
|    clip_range           | 0.1          |
|    crash                | 0.124        |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.416        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.1         |
|    max_step             | 0            |
|    n_updates            | 820          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00358     |
|    route_completion     | 0.236        |
|    std                  | 0.833        |
|    total_cost           | 4.98         |
|    value_loss           | 23.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 96.8     |
| time/              |          |
|    fps             | 432      |
|    iterations      | 42       |
|    time_elapsed    | 497      |
|    total_timesteps | 215040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00909      |
|    crash                | 0.173        |
|    max_step             | 0            |
|    mean_ep_length       | 80.4         |
|    mean_reward          | 73.7         |
|    num_episodes         | 5            |
|    out_of_road          | 0.991        |
|    raw_action           | 0.3844303    |
|    route_completion     | 0.23         |
|    success_rate         | 0            |
|    total_cost           | 4.69         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0012659202 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0601       |
|    clip_range           | 0.1          |
|    crash                | 0.136        |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.307        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.2         |
|    max_step             | 0            |
|    n_updates            | 840          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00175     |
|    route_completion     | 0.24         |
|    std                  | 0.829        |
|    total_cost           | 4.8          |
|    value_loss           | 46.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 98.1     |
| time/              |          |
|    fps             | 433      |
|    iterations      | 43       |
|    time_elapsed    | 507      |
|    total_timesteps | 220160   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 250           |
|    ep_rew_mean          | 107           |
| time/                   |               |
|    fps                  | 436           |
|    iterations           | 44            |
|    time_elapsed         | 515           |
|    total_timesteps      | 225280        |
| train/                  |               |
|    approx_kl            | 0.00089877594 |
|    clip_fraction        | 0.0736        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.46         |
|    explained_variance   | 0.383         |
|    learning_rate        | 5e-05         |
|    loss                 | 16.3          |
|    n_updates            | 860           |
|    policy_gradient_loss | -0.00136      |
|    std                  | 0.824         |
|    value_loss           | 25.6          |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0087       |
|    crash                | 0.183        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.991        |
|    raw_action           | 0.39086518   |
|    route_completion     | 0.235        |
|    success_rate         | 0            |
|    total_cost           | 4.6          |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0013491331 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0687       |
|    clip_range           | 0.1          |
|    crash                | 0.148        |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.452        |
|    learning_rate        | 5e-05        |
|    loss                 | 15.1         |
|    max_step             | 0            |
|    n_updates            | 880          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0028      |
|    route_completion     | 0.244        |
|    std                  | 0.819        |
|    total_cost           | 5.36         |
|    value_loss           | 25.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | 119      |
| time/              |          |
|    fps             | 434      |
|    iterations      | 45       |
|    time_elapsed    | 530      |
|    total_timesteps | 230400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 269          |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 438          |
|    iterations           | 46           |
|    time_elapsed         | 537          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0029861128 |
|    clip_fraction        | 0.0744       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.348        |
|    learning_rate        | 5e-05        |
|    loss                 | 10.3         |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00268     |
|    std                  | 0.817        |
|    value_loss           | 25.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00833      |
|    crash                | 0.183        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.992        |
|    raw_action           | 0.39494792   |
|    route_completion     | 0.241        |
|    success_rate         | 0            |
|    total_cost           | 4.7          |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0009547891 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0586       |
|    clip_range           | 0.1          |
|    crash                | 0.142        |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.552        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.03         |
|    max_step             | 0            |
|    n_updates            | 920          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00233     |
|    route_completion     | 0.243        |
|    std                  | 0.816        |
|    total_cost           | 5.59         |
|    value_loss           | 21.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 437      |
|    iterations      | 47       |
|    time_elapsed    | 549      |
|    total_timesteps | 240640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 271          |
|    ep_rew_mean          | 130          |
| time/                   |              |
|    fps                  | 441          |
|    iterations           | 48           |
|    time_elapsed         | 556          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0013239642 |
|    clip_fraction        | 0.0611       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.401        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.4         |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.00279     |
|    std                  | 0.811        |
|    value_loss           | 36.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.008        |
|    crash                | 0.192        |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.992        |
|    raw_action           | 0.40046504   |
|    route_completion     | 0.246        |
|    success_rate         | 0            |
|    total_cost           | 4.9          |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0011963891 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0836       |
|    clip_range           | 0.1          |
|    crash                | 0.152        |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.74         |
|    learning_rate        | 5e-05        |
|    loss                 | 11.8         |
|    max_step             | 0            |
|    n_updates            | 960          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00183     |
|    route_completion     | 0.25         |
|    std                  | 0.806        |
|    total_cost           | 5.82         |
|    value_loss           | 24.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 136      |
| time/              |          |
|    fps             | 439      |
|    iterations      | 49       |
|    time_elapsed    | 570      |
|    total_timesteps | 250880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 294          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 443          |
|    iterations           | 50           |
|    time_elapsed         | 577          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0010424651 |
|    clip_fraction        | 0.06         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.741        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.5         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00168     |
|    std                  | 0.803        |
|    value_loss           | 44           |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.00769     |
|    crash                | 0.192       |
|    max_step             | 0           |
|    mean_ep_length       | 88.2        |
|    mean_reward          | 73.6        |
|    num_episodes         | 5           |
|    out_of_road          | 0.992       |
|    raw_action           | 0.40604433  |
|    route_completion     | 0.246       |
|    success_rate         | 0           |
|    total_cost           | 4.92        |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.001232077 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0775      |
|    clip_range           | 0.1         |
|    crash                | 0.154       |
|    entropy_loss         | -2.39       |
|    explained_variance   | 0.479       |
|    learning_rate        | 5e-05       |
|    loss                 | 12.1        |
|    max_step             | 0           |
|    n_updates            | 1000        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00239    |
|    route_completion     | 0.256       |
|    std                  | 0.798       |
|    total_cost           | 5.88        |
|    value_loss           | 23.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 308      |
|    ep_rew_mean     | 158      |
| time/              |          |
|    fps             | 441      |
|    iterations      | 51       |
|    time_elapsed    | 591      |
|    total_timesteps | 261120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 309          |
|    ep_rew_mean          | 164          |
| time/                   |              |
|    fps                  | 445          |
|    iterations           | 52           |
|    time_elapsed         | 598          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0012700591 |
|    clip_fraction        | 0.0721       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.441        |
|    learning_rate        | 5e-05        |
|    loss                 | 19           |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00177     |
|    std                  | 0.796        |
|    value_loss           | 43           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00741      |
|    crash                | 0.193        |
|    max_step             | 0            |
|    mean_ep_length       | 1.06e+03     |
|    mean_reward          | -426         |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.4099015    |
|    route_completion     | 0.252        |
|    success_rate         | 0            |
|    total_cost           | 25.3         |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0009002859 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    crash                | 0.163        |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.329        |
|    learning_rate        | 5e-05        |
|    loss                 | 14.1         |
|    max_step             | 0            |
|    n_updates            | 1040         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0018      |
|    route_completion     | 0.26         |
|    std                  | 0.792        |
|    total_cost           | 6.31         |
|    value_loss           | 28.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 175      |
| time/              |          |
|    fps             | 418      |
|    iterations      | 53       |
|    time_elapsed    | 648      |
|    total_timesteps | 271360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 317          |
|    ep_rew_mean          | 176          |
| time/                   |              |
|    fps                  | 422          |
|    iterations           | 54           |
|    time_elapsed         | 655          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0023964648 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.281        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.6         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.788        |
|    value_loss           | 42.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00714      |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 113          |
|    mean_reward          | 128          |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.4110097    |
|    route_completion     | 0.259        |
|    success_rate         | 0            |
|    total_cost           | 24.6         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0015639346 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0616       |
|    clip_range           | 0.1          |
|    crash                | 0.179        |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.245        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.5         |
|    max_step             | 0            |
|    n_updates            | 1080         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00123     |
|    route_completion     | 0.262        |
|    std                  | 0.785        |
|    total_cost           | 6.29         |
|    value_loss           | 30.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 190      |
| time/              |          |
|    fps             | 423      |
|    iterations      | 55       |
|    time_elapsed    | 665      |
|    total_timesteps | 281600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 338          |
|    ep_rew_mean          | 193          |
| time/                   |              |
|    fps                  | 427          |
|    iterations           | 56           |
|    time_elapsed         | 671          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0054453784 |
|    clip_fraction        | 0.09         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.155        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.3         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.000733    |
|    std                  | 0.78         |
|    value_loss           | 40.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0138       |
|    crash                | 0.207        |
|    max_step             | 0            |
|    mean_ep_length       | 138          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.41601044   |
|    route_completion     | 0.266        |
|    success_rate         | 0.2          |
|    total_cost           | 24.1         |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0019186562 |
|    arrive_dest          | 0.0069       |
|    clip_fraction        | 0.0859       |
|    clip_range           | 0.1          |
|    crash                | 0.193        |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.468        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.9         |
|    max_step             | 0            |
|    n_updates            | 1120         |
|    out_of_road          | 0.993        |
|    policy_gradient_loss | -0.00136     |
|    route_completion     | 0.269        |
|    std                  | 0.776        |
|    total_cost           | 6.5          |
|    value_loss           | 34.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 195      |
| time/              |          |
|    fps             | 424      |
|    iterations      | 57       |
|    time_elapsed    | 688      |
|    total_timesteps | 291840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 352          |
|    ep_rew_mean          | 206          |
| time/                   |              |
|    fps                  | 426          |
|    iterations           | 58           |
|    time_elapsed         | 696          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0025269664 |
|    clip_fraction        | 0.0954       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.419        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.9         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00111     |
|    std                  | 0.773        |
|    value_loss           | 49.1         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0133      |
|    crash                | 0.213       |
|    max_step             | 0           |
|    mean_ep_length       | 168         |
|    mean_reward          | 187         |
|    num_episodes         | 5           |
|    out_of_road          | 0.987       |
|    raw_action           | 0.41757497  |
|    route_completion     | 0.275       |
|    success_rate         | 0           |
|    total_cost           | 23.9        |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.001096383 |
|    arrive_dest          | 0.00667     |
|    clip_fraction        | 0.0704      |
|    clip_range           | 0.1         |
|    crash                | 0.193       |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.678       |
|    learning_rate        | 5e-05       |
|    loss                 | 17.9        |
|    max_step             | 0           |
|    n_updates            | 1160        |
|    out_of_road          | 0.993       |
|    policy_gradient_loss | -0.00128    |
|    route_completion     | 0.269       |
|    std                  | 0.77        |
|    total_cost           | 6.36        |
|    value_loss           | 40.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 196      |
| time/              |          |
|    fps             | 426      |
|    iterations      | 59       |
|    time_elapsed    | 707      |
|    total_timesteps | 302080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 430          |
|    iterations           | 60           |
|    time_elapsed         | 713          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0043382747 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.398        |
|    learning_rate        | 5e-05        |
|    loss                 | 19           |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.765        |
|    value_loss           | 42.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0129      |
|    crash                | 0.206       |
|    max_step             | 0           |
|    mean_ep_length       | 164         |
|    mean_reward          | 106         |
|    num_episodes         | 5           |
|    out_of_road          | 0.987       |
|    raw_action           | 0.41875526  |
|    route_completion     | 0.281       |
|    success_rate         | 0           |
|    total_cost           | 24.2        |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.004275772 |
|    arrive_dest          | 0.00645     |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.1         |
|    crash                | 0.194       |
|    entropy_loss         | -2.3        |
|    explained_variance   | 0.096       |
|    learning_rate        | 5e-05       |
|    loss                 | 15.2        |
|    max_step             | 0           |
|    n_updates            | 1200        |
|    out_of_road          | 0.994       |
|    policy_gradient_loss | 0.000408    |
|    route_completion     | 0.27        |
|    std                  | 0.761       |
|    total_cost           | 6.25        |
|    value_loss           | 44.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 191      |
| time/              |          |
|    fps             | 429      |
|    iterations      | 61       |
|    time_elapsed    | 726      |
|    total_timesteps | 312320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 433          |
|    iterations           | 62           |
|    time_elapsed         | 732          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0012724592 |
|    clip_fraction        | 0.0933       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.107        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.2         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00253     |
|    std                  | 0.759        |
|    value_loss           | 53.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0125       |
|    crash                | 0.206        |
|    max_step             | 0            |
|    mean_ep_length       | 135          |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.421323     |
|    route_completion     | 0.286        |
|    success_rate         | 0            |
|    total_cost           | 23.8         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0016517981 |
|    arrive_dest          | 0.00625      |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.349        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.8          |
|    max_step             | 0            |
|    n_updates            | 1240         |
|    out_of_road          | 0.994        |
|    policy_gradient_loss | -0.000791    |
|    route_completion     | 0.275        |
|    std                  | 0.755        |
|    total_cost           | 6.14         |
|    value_loss           | 26.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    fps             | 433      |
|    iterations      | 63       |
|    time_elapsed    | 744      |
|    total_timesteps | 322560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 211          |
| time/                   |              |
|    fps                  | 436          |
|    iterations           | 64           |
|    time_elapsed         | 751          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0024552217 |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.0908       |
|    learning_rate        | 5e-05        |
|    loss                 | 26.3         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.754        |
|    value_loss           | 53.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0182      |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 139         |
|    mean_reward          | 82.5        |
|    num_episodes         | 5           |
|    out_of_road          | 0.982       |
|    raw_action           | 0.4271211   |
|    route_completion     | 0.291       |
|    success_rate         | 0.2         |
|    total_cost           | 24          |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.002000263 |
|    arrive_dest          | 0.0121      |
|    clip_fraction        | 0.0866      |
|    clip_range           | 0.1         |
|    crash                | 0.212       |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.254       |
|    learning_rate        | 5e-05       |
|    loss                 | 20.7        |
|    max_step             | 0           |
|    n_updates            | 1280        |
|    out_of_road          | 0.988       |
|    policy_gradient_loss | -0.0013     |
|    route_completion     | 0.283       |
|    std                  | 0.753       |
|    total_cost           | 6.92        |
|    value_loss           | 36          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 205      |
| time/              |          |
|    fps             | 434      |
|    iterations      | 65       |
|    time_elapsed    | 766      |
|    total_timesteps | 332800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 437          |
|    iterations           | 66           |
|    time_elapsed         | 772          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0009089446 |
|    clip_fraction        | 0.0803       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.369        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.7         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00117     |
|    std                  | 0.751        |
|    value_loss           | 46.3         |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.0176        |
|    crash                | 0.2           |
|    max_step             | 0             |
|    mean_ep_length       | 140           |
|    mean_reward          | 142           |
|    num_episodes         | 5             |
|    out_of_road          | 0.982         |
|    raw_action           | 0.4333641     |
|    route_completion     | 0.297         |
|    success_rate         | 0.2           |
|    total_cost           | 23.5          |
| time/                   |               |
|    total_timesteps      | 340000        |
| train/                  |               |
|    approx_kl            | 0.00088937196 |
|    arrive_dest          | 0.0235        |
|    clip_fraction        | 0.0676        |
|    clip_range           | 0.1           |
|    crash                | 0.212         |
|    entropy_loss         | -2.26         |
|    explained_variance   | 0.708         |
|    learning_rate        | 5e-05         |
|    loss                 | 12.7          |
|    max_step             | 0             |
|    n_updates            | 1320          |
|    out_of_road          | 0.976         |
|    policy_gradient_loss | -0.00126      |
|    route_completion     | 0.293         |
|    std                  | 0.749         |
|    total_cost           | 7.79          |
|    value_loss           | 42.1          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 434      |
|    iterations      | 67       |
|    time_elapsed    | 790      |
|    total_timesteps | 343040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 223          |
| time/                   |              |
|    fps                  | 436          |
|    iterations           | 68           |
|    time_elapsed         | 797          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0011800628 |
|    clip_fraction        | 0.0473       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.655        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.8         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00172     |
|    std                  | 0.749        |
|    value_loss           | 61.7         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0171      |
|    crash                | 0.206       |
|    max_step             | 0           |
|    mean_ep_length       | 124         |
|    mean_reward          | 129         |
|    num_episodes         | 5           |
|    out_of_road          | 0.983       |
|    raw_action           | 0.43498328  |
|    route_completion     | 0.299       |
|    success_rate         | 0           |
|    total_cost           | 23          |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.002288683 |
|    arrive_dest          | 0.0229      |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.1         |
|    crash                | 0.206       |
|    entropy_loss         | -2.26       |
|    explained_variance   | 0.4         |
|    learning_rate        | 5e-05       |
|    loss                 | 15.6        |
|    max_step             | 0           |
|    n_updates            | 1360        |
|    out_of_road          | 0.977       |
|    policy_gradient_loss | -0.000285   |
|    route_completion     | 0.296       |
|    std                  | 0.746       |
|    total_cost           | 7.59        |
|    value_loss           | 31.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 219      |
| time/              |          |
|    fps             | 437      |
|    iterations      | 69       |
|    time_elapsed    | 808      |
|    total_timesteps | 353280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 363          |
|    ep_rew_mean          | 229          |
| time/                   |              |
|    fps                  | 440          |
|    iterations           | 70           |
|    time_elapsed         | 814          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0023716784 |
|    clip_fraction        | 0.0833       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.333        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.2         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00184     |
|    std                  | 0.744        |
|    value_loss           | 37.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0167       |
|    crash                | 0.211        |
|    max_step             | 0            |
|    mean_ep_length       | 85.8         |
|    mean_reward          | 89.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.983        |
|    raw_action           | 0.4369758    |
|    route_completion     | 0.299        |
|    success_rate         | 0.1          |
|    total_cost           | 22.4         |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0021261727 |
|    arrive_dest          | 0.0278       |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.287        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.6         |
|    max_step             | 0            |
|    n_updates            | 1400         |
|    out_of_road          | 0.972        |
|    policy_gradient_loss | -0.00141     |
|    route_completion     | 0.299        |
|    std                  | 0.742        |
|    total_cost           | 7.52         |
|    value_loss           | 40.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 439      |
|    iterations      | 71       |
|    time_elapsed    | 826      |
|    total_timesteps | 363520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 234          |
| time/                   |              |
|    fps                  | 442          |
|    iterations           | 72           |
|    time_elapsed         | 832          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0026752504 |
|    clip_fraction        | 0.0942       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.352        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.6         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00136     |
|    std                  | 0.74         |
|    value_loss           | 61.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0162       |
|    crash                | 0.211        |
|    max_step             | 0            |
|    mean_ep_length       | 121          |
|    mean_reward          | 127          |
|    num_episodes         | 5            |
|    out_of_road          | 0.984        |
|    raw_action           | 0.4409584    |
|    route_completion     | 0.301        |
|    success_rate         | 0.2          |
|    total_cost           | 22           |
| time/                   |              |
|    total_timesteps      | 370000       |
| train/                  |              |
|    approx_kl            | 0.0026777186 |
|    arrive_dest          | 0.0378       |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.211        |
|    learning_rate        | 5e-05        |
|    loss                 | 18.1         |
|    max_step             | 0            |
|    n_updates            | 1440         |
|    out_of_road          | 0.962        |
|    policy_gradient_loss | -0.000582    |
|    route_completion     | 0.31         |
|    std                  | 0.736        |
|    total_cost           | 7.77         |
|    value_loss           | 47.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 228      |
| time/              |          |
|    fps             | 441      |
|    iterations      | 73       |
|    time_elapsed    | 847      |
|    total_timesteps | 373760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 353          |
|    ep_rew_mean          | 237          |
| time/                   |              |
|    fps                  | 443          |
|    iterations           | 74           |
|    time_elapsed         | 854          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0013183705 |
|    clip_fraction        | 0.097        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.323        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.8         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00197     |
|    std                  | 0.733        |
|    value_loss           | 46.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0158       |
|    crash                | 0.211        |
|    max_step             | 0            |
|    mean_ep_length       | 103          |
|    mean_reward          | 124          |
|    num_episodes         | 5            |
|    out_of_road          | 0.984        |
|    raw_action           | 0.44252816   |
|    route_completion     | 0.302        |
|    success_rate         | 0            |
|    total_cost           | 21.5         |
| time/                   |              |
|    total_timesteps      | 380000       |
| train/                  |              |
|    approx_kl            | 0.0013965884 |
|    arrive_dest          | 0.0368       |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.205        |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.346        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.3         |
|    max_step             | 0            |
|    n_updates            | 1480         |
|    out_of_road          | 0.963        |
|    policy_gradient_loss | 0.00112      |
|    route_completion     | 0.312        |
|    std                  | 0.729        |
|    total_cost           | 7.81         |
|    value_loss           | 56.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 233      |
| time/              |          |
|    fps             | 442      |
|    iterations      | 75       |
|    time_elapsed    | 867      |
|    total_timesteps | 384000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 354          |
|    ep_rew_mean          | 245          |
| time/                   |              |
|    fps                  | 445          |
|    iterations           | 76           |
|    time_elapsed         | 874          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0008123084 |
|    clip_fraction        | 0.0852       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.522        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.3         |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00147     |
|    std                  | 0.727        |
|    value_loss           | 50.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0154       |
|    crash                | 0.21         |
|    max_step             | 0            |
|    mean_ep_length       | 104          |
|    mean_reward          | 106          |
|    num_episodes         | 5            |
|    out_of_road          | 0.985        |
|    raw_action           | 0.44232628   |
|    route_completion     | 0.304        |
|    success_rate         | 0            |
|    total_cost           | 21           |
| time/                   |              |
|    total_timesteps      | 390000       |
| train/                  |              |
|    approx_kl            | 0.0031768065 |
|    arrive_dest          | 0.0359       |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.391        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.5         |
|    max_step             | 0            |
|    n_updates            | 1520         |
|    out_of_road          | 0.964        |
|    policy_gradient_loss | 0.00029      |
|    route_completion     | 0.314        |
|    std                  | 0.724        |
|    total_cost           | 7.66         |
|    value_loss           | 43.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 244      |
| time/              |          |
|    fps             | 444      |
|    iterations      | 77       |
|    time_elapsed    | 887      |
|    total_timesteps | 394240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 446          |
|    iterations           | 78           |
|    time_elapsed         | 893          |
|    total_timesteps      | 399360       |
| train/                  |              |
|    approx_kl            | 0.0010541112 |
|    clip_fraction        | 0.0739       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.358        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.6         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00161     |
|    std                  | 0.723        |
|    value_loss           | 62.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.015        |
|    crash                | 0.21         |
|    max_step             | 0            |
|    mean_ep_length       | 99.2         |
|    mean_reward          | 104          |
|    num_episodes         | 5            |
|    out_of_road          | 0.985        |
|    raw_action           | 0.4451263    |
|    route_completion     | 0.304        |
|    success_rate         | 0            |
|    total_cost           | 20.6         |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0009563326 |
|    arrive_dest          | 0.035        |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.318        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.7         |
|    max_step             | 0            |
|    n_updates            | 1560         |
|    out_of_road          | 0.965        |
|    policy_gradient_loss | 0.000165     |
|    route_completion     | 0.319        |
|    std                  | 0.719        |
|    total_cost           | 7.71         |
|    value_loss           | 57.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 251      |
| time/              |          |
|    fps             | 445      |
|    iterations      | 79       |
|    time_elapsed    | 908      |
|    total_timesteps | 404480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 447          |
|    iterations           | 80           |
|    time_elapsed         | 915          |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0007906073 |
|    clip_fraction        | 0.0875       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.304        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.8         |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.719        |
|    value_loss           | 56.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0244       |
|    crash                | 0.21         |
|    max_step             | 0            |
|    mean_ep_length       | 271          |
|    mean_reward          | 196          |
|    num_episodes         | 5            |
|    out_of_road          | 0.976        |
|    raw_action           | 0.44629225   |
|    route_completion     | 0.315        |
|    success_rate         | 0.2          |
|    total_cost           | 21.4         |
| time/                   |              |
|    total_timesteps      | 410000       |
| train/                  |              |
|    approx_kl            | 0.0010098026 |
|    arrive_dest          | 0.0341       |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.368        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.8         |
|    max_step             | 0            |
|    n_updates            | 1600         |
|    out_of_road          | 0.966        |
|    policy_gradient_loss | -0.00211     |
|    route_completion     | 0.324        |
|    std                  | 0.718        |
|    total_cost           | 7.8          |
|    value_loss           | 52.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 444      |
|    iterations      | 81       |
|    time_elapsed    | 932      |
|    total_timesteps | 414720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 248          |
| time/                   |              |
|    fps                  | 447          |
|    iterations           | 82           |
|    time_elapsed         | 939          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0014676304 |
|    clip_fraction        | 0.0774       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.417        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.3         |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.00217     |
|    std                  | 0.717        |
|    value_loss           | 66.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0286       |
|    crash                | 0.21         |
|    max_step             | 0            |
|    mean_ep_length       | 186          |
|    mean_reward          | 181          |
|    num_episodes         | 5            |
|    out_of_road          | 0.971        |
|    raw_action           | 0.44833174   |
|    route_completion     | 0.322        |
|    success_rate         | 0.1          |
|    total_cost           | 21.4         |
| time/                   |              |
|    total_timesteps      | 420000       |
| train/                  |              |
|    approx_kl            | 0.0029798145 |
|    arrive_dest          | 0.0333       |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.473        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.8         |
|    max_step             | 0            |
|    n_updates            | 1640         |
|    out_of_road          | 0.967        |
|    policy_gradient_loss | -0.000905    |
|    route_completion     | 0.325        |
|    std                  | 0.716        |
|    total_cost           | 7.67         |
|    value_loss           | 48.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 446      |
|    iterations      | 83       |
|    time_elapsed    | 952      |
|    total_timesteps | 424960   |
---------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.0279        |
|    crash                | 0.214         |
|    max_step             | 0             |
|    mean_ep_length       | 90.8          |
|    mean_reward          | 90.1          |
|    num_episodes         | 5             |
|    out_of_road          | 0.972         |
|    raw_action           | 0.45230654    |
|    route_completion     | 0.322         |
|    success_rate         | 0.2           |
|    total_cost           | 21            |
| time/                   |               |
|    total_timesteps      | 430000        |
| train/                  |               |
|    approx_kl            | 0.00085277064 |
|    arrive_dest          | 0.0419        |
|    clip_fraction        | 0.0787        |
|    clip_range           | 0.1           |
|    crash                | 0.209         |
|    entropy_loss         | -2.16         |
|    explained_variance   | 0.374         |
|    learning_rate        | 5e-05         |
|    loss                 | 46.7          |
|    max_step             | 0             |
|    n_updates            | 1660          |
|    out_of_road          | 0.958         |
|    policy_gradient_loss | -0.00134      |
|    route_completion     | 0.332         |
|    std                  | 0.714         |
|    total_cost           | 8.1           |
|    value_loss           | 75.1          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 249      |
| time/              |          |
|    fps             | 445      |
|    iterations      | 84       |
|    time_elapsed    | 965      |
|    total_timesteps | 430080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 333          |
|    ep_rew_mean          | 245          |
| time/                   |              |
|    fps                  | 447          |
|    iterations           | 85           |
|    time_elapsed         | 973          |
|    total_timesteps      | 435200       |
| train/                  |              |
|    approx_kl            | 0.0027718663 |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.535        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.2         |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.00134     |
|    std                  | 0.712        |
|    value_loss           | 58.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0273      |
|    crash                | 0.214       |
|    max_step             | 0           |
|    mean_ep_length       | 116         |
|    mean_reward          | 125         |
|    num_episodes         | 5           |
|    out_of_road          | 0.973       |
|    raw_action           | 0.45405582  |
|    route_completion     | 0.325       |
|    success_rate         | 0.1         |
|    total_cost           | 20.6        |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.003492133 |
|    arrive_dest          | 0.0455      |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.1         |
|    crash                | 0.214       |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.56        |
|    learning_rate        | 5e-05       |
|    loss                 | 21.7        |
|    max_step             | 0           |
|    n_updates            | 1700        |
|    out_of_road          | 0.955       |
|    policy_gradient_loss | -0.000389   |
|    route_completion     | 0.337       |
|    std                  | 0.71        |
|    total_cost           | 7.98        |
|    value_loss           | 54.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 446      |
|    iterations      | 86       |
|    time_elapsed    | 986      |
|    total_timesteps | 440320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 327          |
|    ep_rew_mean          | 245          |
| time/                   |              |
|    fps                  | 448          |
|    iterations           | 87           |
|    time_elapsed         | 994          |
|    total_timesteps      | 445440       |
| train/                  |              |
|    approx_kl            | 0.0009892011 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.423        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.4         |
|    n_updates            | 1720         |
|    policy_gradient_loss | -0.00132     |
|    std                  | 0.707        |
|    value_loss           | 74.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0267       |
|    crash                | 0.218        |
|    max_step             | 0            |
|    mean_ep_length       | 136          |
|    mean_reward          | 150          |
|    num_episodes         | 5            |
|    out_of_road          | 0.973        |
|    raw_action           | 0.4553613    |
|    route_completion     | 0.328        |
|    success_rate         | 0.1          |
|    total_cost           | 20.3         |
| time/                   |              |
|    total_timesteps      | 450000       |
| train/                  |              |
|    approx_kl            | 0.0023442958 |
|    arrive_dest          | 0.0489       |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    crash                | 0.209        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.279        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.8         |
|    max_step             | 0            |
|    n_updates            | 1740         |
|    out_of_road          | 0.951        |
|    policy_gradient_loss | -0.00143     |
|    route_completion     | 0.34         |
|    std                  | 0.704        |
|    total_cost           | 7.88         |
|    value_loss           | 74.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 446      |
|    iterations      | 88       |
|    time_elapsed    | 1008     |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 327         |
|    ep_rew_mean          | 250         |
| time/                   |             |
|    fps                  | 448         |
|    iterations           | 89          |
|    time_elapsed         | 1014        |
|    total_timesteps      | 455680      |
| train/                  |             |
|    approx_kl            | 0.010502073 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.505       |
|    learning_rate        | 5e-05       |
|    loss                 | 36.6        |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.000509   |
|    std                  | 0.702       |
|    value_loss           | 83.4        |
-----------------------------------------
