Using cpu device
Logging to runs\ppo_metadrive_final_testing\ppo_metadrive_final_testing_2025-03-19_22-32-37_32b96a95\ppo_metadrive_final_testing_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 265      |
|    ep_rew_mean     | -2.63    |
| time/              |          |
|    fps             | 1668     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 174          |
|    mean_reward          | 35.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.04615658   |
|    route_completion     | 0.156        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0031311729 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.188        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0839      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.00386     |
|    max_step             | 0            |
|    n_updates            | 20           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00784     |
|    route_completion     | 0.169        |
|    std                  | 0.998        |
|    total_cost           | 1            |
|    value_loss           | 0.0437       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | -0.305   |
| time/              |          |
|    fps             | 991      |
|    iterations      | 2        |
|    time_elapsed    | 10       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 432         |
|    ep_rew_mean          | 0.55        |
| time/                   |             |
|    fps                  | 1091        |
|    iterations           | 3           |
|    time_elapsed         | 14          |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.003277731 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.0146      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0567      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00677    |
|    std                  | 0.996       |
|    value_loss           | 0.0824      |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 37.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.07203949   |
|    route_completion     | 0.15         |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0028829274 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.0146       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0991       |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00428     |
|    route_completion     | 0.132        |
|    std                  | 0.99         |
|    total_cost           | 1            |
|    value_loss           | 0.168        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    fps             | 995      |
|    iterations      | 4        |
|    time_elapsed    | 20       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 374          |
|    ep_rew_mean          | 0.462        |
| time/                   |              |
|    fps                  | 1038         |
|    iterations           | 5            |
|    time_elapsed         | 24           |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0035495847 |
|    clip_fraction        | 0.244        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0332       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00188      |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0092      |
|    std                  | 0.986        |
|    value_loss           | 0.112        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 63.4         |
|    mean_reward          | 18.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.09695454   |
|    route_completion     | 0.124        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0033212318 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.203        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.0248       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0404       |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00785     |
|    route_completion     | 0.108        |
|    std                  | 0.976        |
|    total_cost           | 1            |
|    value_loss           | 0.127        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 2.89     |
| time/              |          |
|    fps             | 1013     |
|    iterations      | 6        |
|    time_elapsed    | 30       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 352         |
|    ep_rew_mean          | 2.67        |
| time/                   |             |
|    fps                  | 1045        |
|    iterations           | 7           |
|    time_elapsed         | 34          |
|    total_timesteps      | 35840       |
| train/                  |             |
|    approx_kl            | 0.003346005 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.78       |
|    explained_variance   | -0.0032     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.159       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00688    |
|    std                  | 0.971       |
|    value_loss           | 0.179       |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.05         |
|    max_step             | 0            |
|    mean_ep_length       | 31.2         |
|    mean_reward          | 2.82         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.120750494  |
|    route_completion     | 0.101        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0019414604 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.0134       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.178        |
|    max_step             | 0            |
|    n_updates            | 140          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00384     |
|    route_completion     | 0.0946       |
|    std                  | 0.966        |
|    total_cost           | 1            |
|    value_loss           | 0.536        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 5.89     |
| time/              |          |
|    fps             | 1027     |
|    iterations      | 8        |
|    time_elapsed    | 39       |
|    total_timesteps | 40960    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 415        |
|    ep_rew_mean          | 7.48       |
| time/                   |            |
|    fps                  | 1054       |
|    iterations           | 9          |
|    time_elapsed         | 43         |
|    total_timesteps      | 46080      |
| train/                  |            |
|    approx_kl            | 0.00223403 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.77      |
|    explained_variance   | 0.0355     |
|    learning_rate        | 5e-05      |
|    loss                 | 0.19       |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.00388   |
|    std                  | 0.963      |
|    value_loss           | 0.619      |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.04         |
|    max_step             | 0            |
|    mean_ep_length       | 45.2         |
|    mean_reward          | 14.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.14492677   |
|    route_completion     | 0.0936       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0031003584 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.138        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.162        |
|    max_step             | 0            |
|    n_updates            | 180          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00453     |
|    route_completion     | 0.0884       |
|    std                  | 0.958        |
|    total_cost           | 1            |
|    value_loss           | 0.551        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 7.85     |
| time/              |          |
|    fps             | 1030     |
|    iterations      | 10       |
|    time_elapsed    | 49       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 368          |
|    ep_rew_mean          | 8.95         |
| time/                   |              |
|    fps                  | 1049         |
|    iterations           | 11           |
|    time_elapsed         | 53           |
|    total_timesteps      | 56320        |
| train/                  |              |
|    approx_kl            | 0.0019542242 |
|    clip_fraction        | 0.0549       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.163        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.532        |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00175     |
|    std                  | 0.949        |
|    value_loss           | 1.22         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0333       |
|    max_step             | 0            |
|    mean_ep_length       | 35.4         |
|    mean_reward          | 9.33         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.16644311   |
|    route_completion     | 0.0873       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0022322424 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0958       |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.283        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.464        |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00298     |
|    route_completion     | 0.0823       |
|    std                  | 0.941        |
|    total_cost           | 1            |
|    value_loss           | 0.873        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 9.47     |
| time/              |          |
|    fps             | 1031     |
|    iterations      | 12       |
|    time_elapsed    | 59       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 10.2         |
| time/                   |              |
|    fps                  | 1044         |
|    iterations           | 13           |
|    time_elapsed         | 63           |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0026178781 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.188        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.706        |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.0038      |
|    std                  | 0.934        |
|    value_loss           | 1.42         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0286       |
|    max_step             | 0            |
|    mean_ep_length       | 31.8         |
|    mean_reward          | 8.17         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1878533    |
|    route_completion     | 0.0821       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0022155445 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.43         |
|    learning_rate        | 5e-05        |
|    loss                 | 0.551        |
|    max_step             | 0            |
|    n_updates            | 260          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00358     |
|    route_completion     | 0.0781       |
|    std                  | 0.929        |
|    total_cost           | 1            |
|    value_loss           | 1.2          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 299      |
|    ep_rew_mean     | 12       |
| time/              |          |
|    fps             | 1023     |
|    iterations      | 14       |
|    time_elapsed    | 70       |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 240         |
|    ep_rew_mean          | 11.8        |
| time/                   |             |
|    fps                  | 1029        |
|    iterations           | 15          |
|    time_elapsed         | 74          |
|    total_timesteps      | 76800       |
| train/                  |             |
|    approx_kl            | 0.001158483 |
|    clip_fraction        | 0.0525      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.68       |
|    explained_variance   | 0.339       |
|    learning_rate        | 5e-05       |
|    loss                 | 1.34        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00178    |
|    std                  | 0.925       |
|    value_loss           | 2.75        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.025       |
|    max_step             | 0           |
|    mean_ep_length       | 36.6        |
|    mean_reward          | 13.2        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.20818514  |
|    route_completion     | 0.0821      |
|    success_rate         | 0           |
|    total_cost           | 1           |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.002327148 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0868      |
|    clip_range           | 0.1         |
|    crash                | 0           |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0.599       |
|    learning_rate        | 5e-05       |
|    loss                 | 1.25        |
|    max_step             | 0           |
|    n_updates            | 300         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00309    |
|    route_completion     | 0.0751      |
|    std                  | 0.918       |
|    total_cost           | 1           |
|    value_loss           | 1.74        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 12.1     |
| time/              |          |
|    fps             | 1013     |
|    iterations      | 16       |
|    time_elapsed    | 80       |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 12.5         |
| time/                   |              |
|    fps                  | 1016         |
|    iterations           | 17           |
|    time_elapsed         | 85           |
|    total_timesteps      | 87040        |
| train/                  |              |
|    approx_kl            | 0.0015887171 |
|    clip_fraction        | 0.0567       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.54         |
|    learning_rate        | 5e-05        |
|    loss                 | 1.34         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00186     |
|    std                  | 0.913        |
|    value_loss           | 2.49         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0222       |
|    max_step             | 0            |
|    mean_ep_length       | 61.4         |
|    mean_reward          | 49.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.22801748   |
|    route_completion     | 0.0923       |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0017508107 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0979       |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.486        |
|    learning_rate        | 5e-05        |
|    loss                 | 1.5          |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00448     |
|    route_completion     | 0.0741       |
|    std                  | 0.906        |
|    total_cost           | 1            |
|    value_loss           | 3.39         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 12.8     |
| time/              |          |
|    fps             | 997      |
|    iterations      | 18       |
|    time_elapsed    | 92       |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 166          |
|    ep_rew_mean          | 13.7         |
| time/                   |              |
|    fps                  | 1000         |
|    iterations           | 19           |
|    time_elapsed         | 97           |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0013999905 |
|    clip_fraction        | 0.05         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.37         |
|    learning_rate        | 5e-05        |
|    loss                 | 1.67         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00304     |
|    std                  | 0.901        |
|    value_loss           | 4.14         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.02         |
|    max_step             | 0            |
|    mean_ep_length       | 73.8         |
|    mean_reward          | 75.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.24462081   |
|    route_completion     | 0.104        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0017451033 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0799       |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.315        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.4          |
|    max_step             | 0            |
|    n_updates            | 380          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00431     |
|    route_completion     | 0.072        |
|    std                  | 0.897        |
|    total_cost           | 1            |
|    value_loss           | 3.9          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | 16.6     |
| time/              |          |
|    fps             | 985      |
|    iterations      | 20       |
|    time_elapsed    | 103      |
|    total_timesteps | 102400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 170          |
|    ep_rew_mean          | 18.3         |
| time/                   |              |
|    fps                  | 990          |
|    iterations           | 21           |
|    time_elapsed         | 108          |
|    total_timesteps      | 107520       |
| train/                  |              |
|    approx_kl            | 0.0020954227 |
|    clip_fraction        | 0.083        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.428        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.27         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00369     |
|    std                  | 0.89         |
|    value_loss           | 4.56         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0182       |
|    max_step             | 0            |
|    mean_ep_length       | 81.4         |
|    mean_reward          | 87.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3157195    |
|    route_completion     | 0.128        |
|    success_rate         | 0            |
|    total_cost           | 1.15         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0023852827 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    crash                | 0.0182       |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.284        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.34         |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00551     |
|    route_completion     | 0.121        |
|    std                  | 0.881        |
|    total_cost           | 8.4          |
|    value_loss           | 6.86         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 21.9     |
| time/              |          |
|    fps             | 956      |
|    iterations      | 22       |
|    time_elapsed    | 117      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 210          |
|    ep_rew_mean          | 25.2         |
| time/                   |              |
|    fps                  | 955          |
|    iterations           | 23           |
|    time_elapsed         | 123          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0018691116 |
|    clip_fraction        | 0.0854       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.322        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.28         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00392     |
|    std                  | 0.872        |
|    value_loss           | 5.57         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.05        |
|    max_step             | 0           |
|    mean_ep_length       | 82.6        |
|    mean_reward          | 86.4        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.33867082  |
|    route_completion     | 0.144       |
|    success_rate         | 0           |
|    total_cost           | 1.18        |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.002060488 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0553      |
|    clip_range           | 0.1         |
|    crash                | 0.05        |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.142       |
|    learning_rate        | 5e-05       |
|    loss                 | 5.57        |
|    max_step             | 0           |
|    n_updates            | 460         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00432    |
|    route_completion     | 0.145       |
|    std                  | 0.867       |
|    total_cost           | 10.2        |
|    value_loss           | 16.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 213      |
|    ep_rew_mean     | 35.9     |
| time/              |          |
|    fps             | 927      |
|    iterations      | 24       |
|    time_elapsed    | 132      |
|    total_timesteps | 122880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 217          |
|    ep_rew_mean          | 40.8         |
| time/                   |              |
|    fps                  | 930          |
|    iterations           | 25           |
|    time_elapsed         | 137          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0016548298 |
|    clip_fraction        | 0.0556       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.181        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.29         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00279     |
|    std                  | 0.862        |
|    value_loss           | 15.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0615       |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 115          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.35123107   |
|    route_completion     | 0.165        |
|    success_rate         | 0            |
|    total_cost           | 1.51         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0018209316 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.051        |
|    clip_range           | 0.1          |
|    crash                | 0.0462       |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.404        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.36         |
|    max_step             | 0            |
|    n_updates            | 500          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00399     |
|    route_completion     | 0.156        |
|    std                  | 0.859        |
|    total_cost           | 9.68         |
|    value_loss           | 14.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 47.7     |
| time/              |          |
|    fps             | 915      |
|    iterations      | 26       |
|    time_elapsed    | 145      |
|    total_timesteps | 133120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 203          |
|    ep_rew_mean          | 47.3         |
| time/                   |              |
|    fps                  | 918          |
|    iterations           | 27           |
|    time_elapsed         | 150          |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0022995202 |
|    clip_fraction        | 0.0817       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.281        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.3          |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00394     |
|    std                  | 0.852        |
|    value_loss           | 16.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0571       |
|    max_step             | 0            |
|    mean_ep_length       | 85.2         |
|    mean_reward          | 93.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.36199528   |
|    route_completion     | 0.173        |
|    success_rate         | 0            |
|    total_cost           | 1.47         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0018697673 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0723       |
|    clip_range           | 0.1          |
|    crash                | 0.0429       |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.368        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.16         |
|    max_step             | 0            |
|    n_updates            | 540          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00353     |
|    route_completion     | 0.16         |
|    std                  | 0.846        |
|    total_cost           | 9.11         |
|    value_loss           | 12.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 57.3     |
| time/              |          |
|    fps             | 908      |
|    iterations      | 28       |
|    time_elapsed    | 157      |
|    total_timesteps | 143360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 224          |
|    ep_rew_mean          | 69.2         |
| time/                   |              |
|    fps                  | 910          |
|    iterations           | 29           |
|    time_elapsed         | 163          |
|    total_timesteps      | 148480       |
| train/                  |              |
|    approx_kl            | 0.0015912957 |
|    clip_fraction        | 0.0697       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.376        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.8         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00327     |
|    std                  | 0.845        |
|    value_loss           | 22.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0533       |
|    max_step             | 0            |
|    mean_ep_length       | 121          |
|    mean_reward          | 128          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.37191254   |
|    route_completion     | 0.188        |
|    success_rate         | 0            |
|    total_cost           | 1.69         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0012579445 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.067        |
|    clip_range           | 0.1          |
|    crash                | 0.107        |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.212        |
|    learning_rate        | 5e-05        |
|    loss                 | 8.81         |
|    max_step             | 0            |
|    n_updates            | 580          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00415     |
|    route_completion     | 0.17         |
|    std                  | 0.836        |
|    total_cost           | 8.71         |
|    value_loss           | 16.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 70.5     |
| time/              |          |
|    fps             | 899      |
|    iterations      | 30       |
|    time_elapsed    | 170      |
|    total_timesteps | 153600   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | 76.1          |
| time/                   |               |
|    fps                  | 902           |
|    iterations           | 31            |
|    time_elapsed         | 175           |
|    total_timesteps      | 158720        |
| train/                  |               |
|    approx_kl            | 0.00084900175 |
|    clip_fraction        | 0.0681        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.47         |
|    explained_variance   | 0.261         |
|    learning_rate        | 5e-05         |
|    loss                 | 7.88          |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.0038       |
|    std                  | 0.832         |
|    value_loss           | 13.4          |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.05         |
|    max_step             | 0            |
|    mean_ep_length       | 92           |
|    mean_reward          | 98.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.38071185   |
|    route_completion     | 0.192        |
|    success_rate         | 0            |
|    total_cost           | 1.75         |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0018476818 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0782       |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.229        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.31         |
|    max_step             | 0            |
|    n_updates            | 620          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00283     |
|    route_completion     | 0.181        |
|    std                  | 0.825        |
|    total_cost           | 8.47         |
|    value_loss           | 16           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | 85.4     |
| time/              |          |
|    fps             | 893      |
|    iterations      | 32       |
|    time_elapsed    | 183      |
|    total_timesteps | 163840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 295          |
|    ep_rew_mean          | 98.3         |
| time/                   |              |
|    fps                  | 896          |
|    iterations           | 33           |
|    time_elapsed         | 188          |
|    total_timesteps      | 168960       |
| train/                  |              |
|    approx_kl            | 0.0016361729 |
|    clip_fraction        | 0.0772       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.0319       |
|    learning_rate        | 5e-05        |
|    loss                 | 9.95         |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.816        |
|    value_loss           | 12.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0588       |
|    max_step             | 0            |
|    mean_ep_length       | 84.6         |
|    mean_reward          | 90.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.38778278   |
|    route_completion     | 0.197        |
|    success_rate         | 0            |
|    total_cost           | 1.71         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0014176832 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0945       |
|    clip_range           | 0.1          |
|    crash                | 0.141        |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.0117       |
|    learning_rate        | 5e-05        |
|    loss                 | 10.8         |
|    max_step             | 0            |
|    n_updates            | 660          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.003       |
|    route_completion     | 0.187        |
|    std                  | 0.808        |
|    total_cost           | 8.04         |
|    value_loss           | 19.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 102      |
| time/              |          |
|    fps             | 890      |
|    iterations      | 34       |
|    time_elapsed    | 195      |
|    total_timesteps | 174080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 314          |
|    ep_rew_mean          | 107          |
| time/                   |              |
|    fps                  | 892          |
|    iterations           | 35           |
|    time_elapsed         | 200          |
|    total_timesteps      | 179200       |
| train/                  |              |
|    approx_kl            | 0.0011491103 |
|    clip_fraction        | 0.0547       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.0131       |
|    learning_rate        | 5e-05        |
|    loss                 | 11.2         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00209     |
|    std                  | 0.804        |
|    value_loss           | 18.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 101          |
|    mean_reward          | 103          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.39405257   |
|    route_completion     | 0.203        |
|    success_rate         | 0            |
|    total_cost           | 1.73         |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0017480148 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0845       |
|    clip_range           | 0.1          |
|    crash                | 0.167        |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.0701       |
|    learning_rate        | 5e-05        |
|    loss                 | 10.1         |
|    max_step             | 0            |
|    n_updates            | 700          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00231     |
|    route_completion     | 0.195        |
|    std                  | 0.8          |
|    total_cost           | 7.73         |
|    value_loss           | 24.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 118      |
| time/              |          |
|    fps             | 882      |
|    iterations      | 36       |
|    time_elapsed    | 208      |
|    total_timesteps | 184320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 341          |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 885          |
|    iterations           | 37           |
|    time_elapsed         | 214          |
|    total_timesteps      | 189440       |
| train/                  |              |
|    approx_kl            | 0.0014997934 |
|    clip_fraction        | 0.0536       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.0548       |
|    learning_rate        | 5e-05        |
|    loss                 | 11.6         |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00198     |
|    std                  | 0.796        |
|    value_loss           | 31.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0632       |
|    max_step             | 0            |
|    mean_ep_length       | 85.8         |
|    mean_reward          | 89.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.39849794   |
|    route_completion     | 0.208        |
|    success_rate         | 0            |
|    total_cost           | 1.69         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0017659625 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0914       |
|    clip_range           | 0.1          |
|    crash                | 0.158        |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.0705       |
|    learning_rate        | 5e-05        |
|    loss                 | 10.2         |
|    max_step             | 0            |
|    n_updates            | 740          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00262     |
|    route_completion     | 0.2          |
|    std                  | 0.793        |
|    total_cost           | 7.38         |
|    value_loss           | 31.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 134      |
| time/              |          |
|    fps             | 881      |
|    iterations      | 38       |
|    time_elapsed    | 220      |
|    total_timesteps | 194560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 882          |
|    iterations           | 39           |
|    time_elapsed         | 226          |
|    total_timesteps      | 199680       |
| train/                  |              |
|    approx_kl            | 0.0031067566 |
|    clip_fraction        | 0.0777       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.158        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.09         |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.79         |
|    value_loss           | 22.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.08         |
|    max_step             | 0            |
|    mean_ep_length       | 83           |
|    mean_reward          | 81.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.40223542   |
|    route_completion     | 0.209        |
|    success_rate         | 0            |
|    total_cost           | 1.68         |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0018606891 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    crash                | 0.15         |
|    entropy_loss         | -2.35        |
|    explained_variance   | -0.0105      |
|    learning_rate        | 5e-05        |
|    loss                 | 26.3         |
|    max_step             | 0            |
|    n_updates            | 780          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00349     |
|    route_completion     | 0.198        |
|    std                  | 0.781        |
|    total_cost           | 7.06         |
|    value_loss           | 38.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 877      |
|    iterations      | 40       |
|    time_elapsed    | 233      |
|    total_timesteps | 204800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 390          |
|    ep_rew_mean          | 168          |
| time/                   |              |
|    fps                  | 878          |
|    iterations           | 41           |
|    time_elapsed         | 238          |
|    total_timesteps      | 209920       |
| train/                  |              |
|    approx_kl            | 0.0014018903 |
|    clip_fraction        | 0.059        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.0629       |
|    learning_rate        | 5e-05        |
|    loss                 | 4.69         |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.775        |
|    value_loss           | 13.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0857       |
|    max_step             | 0            |
|    mean_ep_length       | 88.4         |
|    mean_reward          | 91.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.40632442   |
|    route_completion     | 0.215        |
|    success_rate         | 0            |
|    total_cost           | 1.68         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0015497054 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0971       |
|    clip_range           | 0.1          |
|    crash                | 0.143        |
|    entropy_loss         | -2.32        |
|    explained_variance   | -0.00125     |
|    learning_rate        | 5e-05        |
|    loss                 | 20.1         |
|    max_step             | 0            |
|    n_updates            | 820          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00267     |
|    route_completion     | 0.202        |
|    std                  | 0.768        |
|    total_cost           | 6.77         |
|    value_loss           | 30.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 172      |
| time/              |          |
|    fps             | 872      |
|    iterations      | 42       |
|    time_elapsed    | 246      |
|    total_timesteps | 215040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 85.2         |
|    mean_reward          | 84.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.411067     |
|    route_completion     | 0.219        |
|    success_rate         | 0            |
|    total_cost           | 1.71         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0014688896 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.075        |
|    clip_range           | 0.1          |
|    crash                | 0.182        |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.000295     |
|    learning_rate        | 5e-05        |
|    loss                 | 6.1          |
|    max_step             | 0            |
|    n_updates            | 840          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00214     |
|    route_completion     | 0.208        |
|    std                  | 0.766        |
|    total_cost           | 6.87         |
|    value_loss           | 24.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 403      |
|    ep_rew_mean     | 190      |
| time/              |          |
|    fps             | 867      |
|    iterations      | 43       |
|    time_elapsed    | 253      |
|    total_timesteps | 220160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 384          |
|    ep_rew_mean          | 186          |
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 44           |
|    time_elapsed         | 258          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0034906096 |
|    clip_fraction        | 0.0882       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.3         |
|    explained_variance   | -0.000112    |
|    learning_rate        | 5e-05        |
|    loss                 | 21.6         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.000103    |
|    std                  | 0.762        |
|    value_loss           | 35           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0957       |
|    max_step             | 0            |
|    mean_ep_length       | 131          |
|    mean_reward          | 162          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.41392228   |
|    route_completion     | 0.23         |
|    success_rate         | 0            |
|    total_cost           | 1.74         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0034510754 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0901       |
|    clip_range           | 0.1          |
|    crash                | 0.174        |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.000402     |
|    learning_rate        | 5e-05        |
|    loss                 | 12           |
|    max_step             | 0            |
|    n_updates            | 880          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000959    |
|    route_completion     | 0.211        |
|    std                  | 0.758        |
|    total_cost           | 6.65         |
|    value_loss           | 27.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 399      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    fps             | 862      |
|    iterations      | 45       |
|    time_elapsed    | 267      |
|    total_timesteps | 230400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 398          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 863          |
|    iterations           | 46           |
|    time_elapsed         | 272          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0011993472 |
|    clip_fraction        | 0.0792       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.0435       |
|    learning_rate        | 5e-05        |
|    loss                 | 17.8         |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00108     |
|    std                  | 0.757        |
|    value_loss           | 25.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 81.4         |
|    mean_reward          | 80.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4171666    |
|    route_completion     | 0.23         |
|    success_rate         | 0            |
|    total_cost           | 1.71         |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0019866563 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    crash                | 0.167        |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.00842      |
|    learning_rate        | 5e-05        |
|    loss                 | 4.59         |
|    max_step             | 0            |
|    n_updates            | 920          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00226     |
|    route_completion     | 0.214        |
|    std                  | 0.752        |
|    total_cost           | 6.42         |
|    value_loss           | 23.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    fps             | 858      |
|    iterations      | 47       |
|    time_elapsed    | 280      |
|    total_timesteps | 240640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 440          |
|    ep_rew_mean          | 234          |
| time/                   |              |
|    fps                  | 859          |
|    iterations           | 48           |
|    time_elapsed         | 285          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0014597627 |
|    clip_fraction        | 0.078        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.00356     |
|    learning_rate        | 5e-05        |
|    loss                 | 12.5         |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.0015      |
|    std                  | 0.748        |
|    value_loss           | 37.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.104        |
|    max_step             | 0            |
|    mean_ep_length       | 101          |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.42014045   |
|    route_completion     | 0.237        |
|    success_rate         | 0            |
|    total_cost           | 1.77         |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0026319087 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    crash                | 0.184        |
|    entropy_loss         | -2.25        |
|    explained_variance   | -9.54e-07    |
|    learning_rate        | 5e-05        |
|    loss                 | 14.5         |
|    max_step             | 0            |
|    n_updates            | 960          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00166     |
|    route_completion     | 0.219        |
|    std                  | 0.741        |
|    total_cost           | 6.43         |
|    value_loss           | 33.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 444      |
|    ep_rew_mean     | 241      |
| time/              |          |
|    fps             | 855      |
|    iterations      | 49       |
|    time_elapsed    | 293      |
|    total_timesteps | 250880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 450          |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 856          |
|    iterations           | 50           |
|    time_elapsed         | 298          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0021053965 |
|    clip_fraction        | 0.0845       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.000627     |
|    learning_rate        | 5e-05        |
|    loss                 | 32.9         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.0012      |
|    std                  | 0.736        |
|    value_loss           | 56.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.123        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 151          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.42314786   |
|    route_completion     | 0.248        |
|    success_rate         | 0            |
|    total_cost           | 1.82         |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0016731387 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0688       |
|    clip_range           | 0.1          |
|    crash                | 0.185        |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.00412      |
|    learning_rate        | 5e-05        |
|    loss                 | 19.2         |
|    max_step             | 0            |
|    n_updates            | 1000         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0011      |
|    route_completion     | 0.223        |
|    std                  | 0.733        |
|    total_cost           | 6.28         |
|    value_loss           | 41.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 850      |
|    iterations      | 51       |
|    time_elapsed    | 307      |
|    total_timesteps | 261120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 450          |
|    ep_rew_mean          | 263          |
| time/                   |              |
|    fps                  | 851          |
|    iterations           | 52           |
|    time_elapsed         | 312          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0019856151 |
|    clip_fraction        | 0.0736       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.00311      |
|    learning_rate        | 5e-05        |
|    loss                 | 16.5         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00186     |
|    std                  | 0.731        |
|    value_loss           | 45.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.126       |
|    max_step             | 0           |
|    mean_ep_length       | 77.8        |
|    mean_reward          | 73.8        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.4261569   |
|    route_completion     | 0.249       |
|    success_rate         | 0           |
|    total_cost           | 1.79        |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.001253628 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0788      |
|    clip_range           | 0.1         |
|    crash                | 0.207       |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.00844     |
|    learning_rate        | 5e-05       |
|    loss                 | 19.3        |
|    max_step             | 0           |
|    n_updates            | 1040        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00398    |
|    route_completion     | 0.225       |
|    std                  | 0.729       |
|    total_cost           | 6.09        |
|    value_loss           | 42.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 849      |
|    iterations      | 53       |
|    time_elapsed    | 319      |
|    total_timesteps | 271360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 456          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 850          |
|    iterations           | 54           |
|    time_elapsed         | 325          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0015264289 |
|    clip_fraction        | 0.0931       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.00791      |
|    learning_rate        | 5e-05        |
|    loss                 | 10.6         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.000908    |
|    std                  | 0.724        |
|    value_loss           | 40.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.136        |
|    max_step             | 0            |
|    mean_ep_length       | 88.8         |
|    mean_reward          | 87.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4285761    |
|    route_completion     | 0.251        |
|    success_rate         | 0            |
|    total_cost           | 1.78         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0025315257 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    crash                | 0.214        |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.0786       |
|    learning_rate        | 5e-05        |
|    loss                 | 13.2         |
|    max_step             | 0            |
|    n_updates            | 1080         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00138     |
|    route_completion     | 0.228        |
|    std                  | 0.721        |
|    total_cost           | 5.96         |
|    value_loss           | 39.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 458      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 847      |
|    iterations      | 55       |
|    time_elapsed    | 332      |
|    total_timesteps | 281600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 463          |
|    ep_rew_mean          | 288          |
| time/                   |              |
|    fps                  | 848          |
|    iterations           | 56           |
|    time_elapsed         | 338          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0026444625 |
|    clip_fraction        | 0.0873       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.0803       |
|    learning_rate        | 5e-05        |
|    loss                 | 12.5         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00123     |
|    std                  | 0.717        |
|    value_loss           | 38.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.138        |
|    max_step             | 0            |
|    mean_ep_length       | 127          |
|    mean_reward          | 169          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.43087855   |
|    route_completion     | 0.256        |
|    success_rate         | 0            |
|    total_cost           | 1.82         |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0021069103 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    crash                | 0.221        |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.000551     |
|    learning_rate        | 5e-05        |
|    loss                 | 15.3         |
|    max_step             | 0            |
|    n_updates            | 1120         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00179     |
|    route_completion     | 0.231        |
|    std                  | 0.715        |
|    total_cost           | 5.83         |
|    value_loss           | 32.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 843      |
|    iterations      | 57       |
|    time_elapsed    | 346      |
|    total_timesteps | 291840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 477          |
|    ep_rew_mean          | 303          |
| time/                   |              |
|    fps                  | 844          |
|    iterations           | 58           |
|    time_elapsed         | 351          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0033778946 |
|    clip_fraction        | 0.0955       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.00132      |
|    learning_rate        | 5e-05        |
|    loss                 | 20.4         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.711        |
|    value_loss           | 45.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.16         |
|    max_step             | 0            |
|    mean_ep_length       | 95.4         |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.43021825   |
|    route_completion     | 0.262        |
|    success_rate         | 0            |
|    total_cost           | 1.85         |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0022088806 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    crash                | 0.227        |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.0694       |
|    learning_rate        | 5e-05        |
|    loss                 | 25.9         |
|    max_step             | 0            |
|    n_updates            | 1160         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00104     |
|    route_completion     | 0.238        |
|    std                  | 0.709        |
|    total_cost           | 5.87         |
|    value_loss           | 53.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 472      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 840      |
|    iterations      | 59       |
|    time_elapsed    | 359      |
|    total_timesteps | 302080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 452          |
|    ep_rew_mean          | 292          |
| time/                   |              |
|    fps                  | 841          |
|    iterations           | 60           |
|    time_elapsed         | 365          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0010716591 |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.0381       |
|    learning_rate        | 5e-05        |
|    loss                 | 21           |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.706        |
|    value_loss           | 34.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.161        |
|    max_step             | 0            |
|    mean_ep_length       | 93.4         |
|    mean_reward          | 101          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.43210348   |
|    route_completion     | 0.264        |
|    success_rate         | 0            |
|    total_cost           | 1.88         |
| time/                   |              |
|    total_timesteps      | 310000       |
| train/                  |              |
|    approx_kl            | 0.0013925988 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.061        |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.053        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.4         |
|    max_step             | 0            |
|    n_updates            | 1200         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00276     |
|    route_completion     | 0.238        |
|    std                  | 0.704        |
|    total_cost           | 5.72         |
|    value_loss           | 56           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 837      |
|    iterations      | 61       |
|    time_elapsed    | 372      |
|    total_timesteps | 312320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 467          |
|    ep_rew_mean          | 311          |
| time/                   |              |
|    fps                  | 838          |
|    iterations           | 62           |
|    time_elapsed         | 378          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0012459973 |
|    clip_fraction        | 0.0683       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.0826       |
|    learning_rate        | 5e-05        |
|    loss                 | 44.1         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00268     |
|    std                  | 0.703        |
|    value_loss           | 61.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.175        |
|    max_step             | 0            |
|    mean_ep_length       | 98           |
|    mean_reward          | 103          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.43416703   |
|    route_completion     | 0.267        |
|    success_rate         | 0            |
|    total_cost           | 1.88         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0010229172 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0773       |
|    clip_range           | 0.1          |
|    crash                | 0.225        |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.236        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.7         |
|    max_step             | 0            |
|    n_updates            | 1240         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00152     |
|    route_completion     | 0.239        |
|    std                  | 0.702        |
|    total_cost           | 5.57         |
|    value_loss           | 54.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 836      |
|    iterations      | 63       |
|    time_elapsed    | 385      |
|    total_timesteps | 322560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 464          |
|    ep_rew_mean          | 313          |
| time/                   |              |
|    fps                  | 837          |
|    iterations           | 64           |
|    time_elapsed         | 391          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0023363435 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.0599       |
|    learning_rate        | 5e-05        |
|    loss                 | 20.1         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00121     |
|    std                  | 0.701        |
|    value_loss           | 37.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.17         |
|    max_step             | 0            |
|    mean_ep_length       | 83.8         |
|    mean_reward          | 80.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4358502    |
|    route_completion     | 0.267        |
|    success_rate         | 0            |
|    total_cost           | 1.88         |
| time/                   |              |
|    total_timesteps      | 330000       |
| train/                  |              |
|    approx_kl            | 0.0028504448 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.096        |
|    clip_range           | 0.1          |
|    crash                | 0.224        |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.114        |
|    learning_rate        | 5e-05        |
|    loss                 | 32           |
|    max_step             | 0            |
|    n_updates            | 1280         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000931    |
|    route_completion     | 0.24         |
|    std                  | 0.7          |
|    total_cost           | 5.48         |
|    value_loss           | 59           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 313      |
| time/              |          |
|    fps             | 835      |
|    iterations      | 65       |
|    time_elapsed    | 398      |
|    total_timesteps | 332800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 460          |
|    ep_rew_mean          | 318          |
| time/                   |              |
|    fps                  | 835          |
|    iterations           | 66           |
|    time_elapsed         | 404          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0019523508 |
|    clip_fraction        | 0.0979       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.306        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.5         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00174     |
|    std                  | 0.699        |
|    value_loss           | 39.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.176        |
|    max_step             | 0            |
|    mean_ep_length       | 99           |
|    mean_reward          | 108          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.43757087   |
|    route_completion     | 0.267        |
|    success_rate         | 0            |
|    total_cost           | 1.93         |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0009965012 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0818       |
|    clip_range           | 0.1          |
|    crash                | 0.224        |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.223        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.4         |
|    max_step             | 0            |
|    n_updates            | 1320         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00201     |
|    route_completion     | 0.243        |
|    std                  | 0.697        |
|    total_cost           | 5.43         |
|    value_loss           | 63.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 443      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 832      |
|    iterations      | 67       |
|    time_elapsed    | 411      |
|    total_timesteps | 343040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 440          |
|    ep_rew_mean          | 310          |
| time/                   |              |
|    fps                  | 833          |
|    iterations           | 68           |
|    time_elapsed         | 417          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0016914407 |
|    clip_fraction        | 0.0864       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.389        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.9         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00179     |
|    std                  | 0.694        |
|    value_loss           | 42.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.183       |
|    max_step             | 0           |
|    mean_ep_length       | 148         |
|    mean_reward          | 164         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.4392936   |
|    route_completion     | 0.276       |
|    success_rate         | 0           |
|    total_cost           | 2.17        |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.002369672 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.217       |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.443       |
|    learning_rate        | 5e-05       |
|    loss                 | 22.4        |
|    max_step             | 0           |
|    n_updates            | 1360        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.0012     |
|    route_completion     | 0.245       |
|    std                  | 0.693       |
|    total_cost           | 5.45        |
|    value_loss           | 54.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 440      |
|    ep_rew_mean     | 311      |
| time/              |          |
|    fps             | 827      |
|    iterations      | 69       |
|    time_elapsed    | 426      |
|    total_timesteps | 353280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 449          |
|    ep_rew_mean          | 322          |
| time/                   |              |
|    fps                  | 828          |
|    iterations           | 70           |
|    time_elapsed         | 432          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0028233768 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.283        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.9         |
|    n_updates            | 1380         |
|    policy_gradient_loss | 0.000111     |
|    std                  | 0.689        |
|    value_loss           | 33           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.178        |
|    max_step             | 0            |
|    mean_ep_length       | 90.4         |
|    mean_reward          | 97.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.44046825   |
|    route_completion     | 0.275        |
|    success_rate         | 0            |
|    total_cost           | 2.18         |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0010555914 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.086        |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.41         |
|    learning_rate        | 5e-05        |
|    loss                 | 34.6         |
|    max_step             | 0            |
|    n_updates            | 1400         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000733    |
|    route_completion     | 0.245        |
|    std                  | 0.689        |
|    total_cost           | 5.32         |
|    value_loss           | 58.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 454      |
|    ep_rew_mean     | 328      |
| time/              |          |
|    fps             | 825      |
|    iterations      | 71       |
|    time_elapsed    | 440      |
|    total_timesteps | 363520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 462          |
|    ep_rew_mean          | 338          |
| time/                   |              |
|    fps                  | 826          |
|    iterations           | 72           |
|    time_elapsed         | 446          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0028398687 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.37         |
|    learning_rate        | 5e-05        |
|    loss                 | 14.1         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000968    |
|    std                  | 0.685        |
|    value_loss           | 40.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.189       |
|    max_step             | 0           |
|    mean_ep_length       | 98.2        |
|    mean_reward          | 106         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.4412583   |
|    route_completion     | 0.278       |
|    success_rate         | 0           |
|    total_cost           | 2.24        |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.002067007 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0877      |
|    clip_range           | 0.1         |
|    crash                | 0.211       |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.521       |
|    learning_rate        | 5e-05       |
|    loss                 | 46.8        |
|    max_step             | 0           |
|    n_updates            | 1440        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00209    |
|    route_completion     | 0.247       |
|    std                  | 0.686       |
|    total_cost           | 5.31        |
|    value_loss           | 56.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 341      |
| time/              |          |
|    fps             | 823      |
|    iterations      | 73       |
|    time_elapsed    | 453      |
|    total_timesteps | 373760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 466          |
|    ep_rew_mean          | 343          |
| time/                   |              |
|    fps                  | 824          |
|    iterations           | 74           |
|    time_elapsed         | 459          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0021949173 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.473        |
|    learning_rate        | 5e-05        |
|    loss                 | 14.5         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.000624    |
|    std                  | 0.683        |
|    value_loss           | 44.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.189        |
|    max_step             | 0            |
|    mean_ep_length       | 121          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.44324195   |
|    route_completion     | 0.282        |
|    success_rate         | 0            |
|    total_cost           | 2.52         |
| time/                   |              |
|    total_timesteps      | 380000       |
| train/                  |              |
|    approx_kl            | 0.0027133853 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.205        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.411        |
|    learning_rate        | 5e-05        |
|    loss                 | 34           |
|    max_step             | 0            |
|    n_updates            | 1480         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00106     |
|    route_completion     | 0.249        |
|    std                  | 0.681        |
|    total_cost           | 5.36         |
|    value_loss           | 59.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 327      |
| time/              |          |
|    fps             | 819      |
|    iterations      | 75       |
|    time_elapsed    | 468      |
|    total_timesteps | 384000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 437          |
|    ep_rew_mean          | 326          |
| time/                   |              |
|    fps                  | 819          |
|    iterations           | 76           |
|    time_elapsed         | 474          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0031640674 |
|    clip_fraction        | 0.0996       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.274        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.3         |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.678        |
|    value_loss           | 84.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.195        |
|    max_step             | 0            |
|    mean_ep_length       | 106          |
|    mean_reward          | 130          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4448583    |
|    route_completion     | 0.284        |
|    success_rate         | 0            |
|    total_cost           | 2.52         |
| time/                   |              |
|    total_timesteps      | 390000       |
| train/                  |              |
|    approx_kl            | 0.0020937398 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.097        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.5          |
|    learning_rate        | 5e-05        |
|    loss                 | 35.9         |
|    max_step             | 0            |
|    n_updates            | 1520         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00268     |
|    route_completion     | 0.248        |
|    std                  | 0.677        |
|    total_cost           | 5.25         |
|    value_loss           | 68.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 326      |
| time/              |          |
|    fps             | 816      |
|    iterations      | 77       |
|    time_elapsed    | 482      |
|    total_timesteps | 394240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 452          |
|    ep_rew_mean          | 341          |
| time/                   |              |
|    fps                  | 817          |
|    iterations           | 78           |
|    time_elapsed         | 488          |
|    total_timesteps      | 399360       |
| train/                  |              |
|    approx_kl            | 0.0079803355 |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.514        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.8         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -2.39e-05    |
|    std                  | 0.676        |
|    value_loss           | 28.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.195        |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 107          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.44635352   |
|    route_completion     | 0.287        |
|    success_rate         | 0            |
|    total_cost           | 2.6          |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0016820754 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.53         |
|    learning_rate        | 5e-05        |
|    loss                 | 20.6         |
|    max_step             | 0            |
|    n_updates            | 1560         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000807    |
|    route_completion     | 0.25         |
|    std                  | 0.674        |
|    total_cost           | 5.27         |
|    value_loss           | 38.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 336      |
| time/              |          |
|    fps             | 813      |
|    iterations      | 79       |
|    time_elapsed    | 496      |
|    total_timesteps | 404480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 443          |
|    ep_rew_mean          | 338          |
| time/                   |              |
|    fps                  | 814          |
|    iterations           | 80           |
|    time_elapsed         | 502          |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0025575177 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.444        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.2         |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00114     |
|    std                  | 0.673        |
|    value_loss           | 64.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.195        |
|    max_step             | 0            |
|    mean_ep_length       | 113          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.44748038   |
|    route_completion     | 0.291        |
|    success_rate         | 0            |
|    total_cost           | 2.64         |
| time/                   |              |
|    total_timesteps      | 410000       |
| train/                  |              |
|    approx_kl            | 0.0013376479 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0987       |
|    clip_range           | 0.1          |
|    crash                | 0.21         |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.577        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.3         |
|    max_step             | 0            |
|    n_updates            | 1600         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00184     |
|    route_completion     | 0.251        |
|    std                  | 0.672        |
|    total_cost           | 5.2          |
|    value_loss           | 60.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 331      |
| time/              |          |
|    fps             | 812      |
|    iterations      | 81       |
|    time_elapsed    | 510      |
|    total_timesteps | 414720   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 427         |
|    ep_rew_mean          | 330         |
| time/                   |             |
|    fps                  | 812         |
|    iterations           | 82          |
|    time_elapsed         | 516         |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.001647681 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.638       |
|    learning_rate        | 5e-05       |
|    loss                 | 23.8        |
|    n_updates            | 1620        |
|    policy_gradient_loss | 0.000153    |
|    std                  | 0.67        |
|    value_loss           | 47.7        |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0          |
|    crash                | 0.205      |
|    max_step             | 0          |
|    mean_ep_length       | 98.4       |
|    mean_reward          | 111        |
|    num_episodes         | 5          |
|    out_of_road          | 1          |
|    raw_action           | 0.4484181  |
|    route_completion     | 0.293      |
|    success_rate         | 0          |
|    total_cost           | 2.64       |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.00568501 |
|    arrive_dest          | 0          |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.1        |
|    crash                | 0.205      |
|    entropy_loss         | -2.03      |
|    explained_variance   | 0.513      |
|    learning_rate        | 5e-05      |
|    loss                 | 17         |
|    max_step             | 0          |
|    n_updates            | 1640       |
|    out_of_road          | 1          |
|    policy_gradient_loss | -0.00121   |
|    route_completion     | 0.253      |
|    std                  | 0.667      |
|    total_cost           | 5.22       |
|    value_loss           | 69.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 324      |
| time/              |          |
|    fps             | 810      |
|    iterations      | 83       |
|    time_elapsed    | 524      |
|    total_timesteps | 424960   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.209        |
|    max_step             | 0            |
|    mean_ep_length       | 93.2         |
|    mean_reward          | 93.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4499742    |
|    route_completion     | 0.294        |
|    success_rate         | 0            |
|    total_cost           | 2.71         |
| time/                   |              |
|    total_timesteps      | 430000       |
| train/                  |              |
|    approx_kl            | 0.0019188782 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    crash                | 0.209        |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.551        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.4         |
|    max_step             | 0            |
|    n_updates            | 1660         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0011      |
|    route_completion     | 0.255        |
|    std                  | 0.664        |
|    total_cost           | 5.25         |
|    value_loss           | 66.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 410      |
|    ep_rew_mean     | 321      |
| time/              |          |
|    fps             | 808      |
|    iterations      | 84       |
|    time_elapsed    | 532      |
|    total_timesteps | 430080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 416          |
|    ep_rew_mean          | 326          |
| time/                   |              |
|    fps                  | 809          |
|    iterations           | 85           |
|    time_elapsed         | 537          |
|    total_timesteps      | 435200       |
| train/                  |              |
|    approx_kl            | 0.0013106434 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.354        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.6         |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.00251     |
|    std                  | 0.664        |
|    value_loss           | 88.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.218        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 166          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.45071724   |
|    route_completion     | 0.299        |
|    success_rate         | 0            |
|    total_cost           | 2.94         |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0009756485 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0941       |
|    clip_range           | 0.1          |
|    crash                | 0.205        |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.548        |
|    learning_rate        | 5e-05        |
|    loss                 | 24           |
|    max_step             | 0            |
|    n_updates            | 1700         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00217     |
|    route_completion     | 0.256        |
|    std                  | 0.663        |
|    total_cost           | 5.24         |
|    value_loss           | 59.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 328      |
| time/              |          |
|    fps             | 805      |
|    iterations      | 86       |
|    time_elapsed    | 546      |
|    total_timesteps | 440320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 378          |
|    ep_rew_mean          | 306          |
| time/                   |              |
|    fps                  | 806          |
|    iterations           | 87           |
|    time_elapsed         | 552          |
|    total_timesteps      | 445440       |
| train/                  |              |
|    approx_kl            | 0.0010810333 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.392        |
|    learning_rate        | 5e-05        |
|    loss                 | 50           |
|    n_updates            | 1720         |
|    policy_gradient_loss | -0.000986    |
|    std                  | 0.662        |
|    value_loss           | 98.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.227       |
|    max_step             | 0           |
|    mean_ep_length       | 91          |
|    mean_reward          | 93.8        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.45135936  |
|    route_completion     | 0.299       |
|    success_rate         | 0           |
|    total_cost           | 2.92        |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.003928031 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    crash                | 0.204       |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.538       |
|    learning_rate        | 5e-05       |
|    loss                 | 36.3        |
|    max_step             | 0           |
|    n_updates            | 1740        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.000809   |
|    route_completion     | 0.257       |
|    std                  | 0.661       |
|    total_cost           | 5.19        |
|    value_loss           | 78.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 803      |
|    iterations      | 88       |
|    time_elapsed    | 560      |
|    total_timesteps | 450560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 293          |
| time/                   |              |
|    fps                  | 804          |
|    iterations           | 89           |
|    time_elapsed         | 566          |
|    total_timesteps      | 455680       |
| train/                  |              |
|    approx_kl            | 0.0059984224 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.337        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.6         |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00017     |
|    std                  | 0.659        |
|    value_loss           | 100          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 79.6         |
|    mean_reward          | 77.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.4515883    |
|    route_completion     | 0.297        |
|    success_rate         | 0            |
|    total_cost           | 2.88         |
| time/                   |              |
|    total_timesteps      | 460000       |
| train/                  |              |
|    approx_kl            | 0.0021554234 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.204        |
|    entropy_loss         | -2           |
|    explained_variance   | 0.492        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.7         |
|    max_step             | 0            |
|    n_updates            | 1780         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000175    |
|    route_completion     | 0.259        |
|    std                  | 0.659        |
|    total_cost           | 5.4          |
|    value_loss           | 77.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 801      |
|    iterations      | 90       |
|    time_elapsed    | 574      |
|    total_timesteps | 460800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 289          |
| time/                   |              |
|    fps                  | 802          |
|    iterations           | 91           |
|    time_elapsed         | 580          |
|    total_timesteps      | 465920       |
| train/                  |              |
|    approx_kl            | 0.0016940308 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.421        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.1         |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.000867    |
|    std                  | 0.657        |
|    value_loss           | 75.6         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0          |
|    crash                | 0.217      |
|    max_step             | 0          |
|    mean_ep_length       | 124        |
|    mean_reward          | 145        |
|    num_episodes         | 5          |
|    out_of_road          | 1          |
|    raw_action           | 0.45223758 |
|    route_completion     | 0.301      |
|    success_rate         | 0          |
|    total_cost           | 2.91       |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.0061264  |
|    arrive_dest          | 0          |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.1        |
|    crash                | 0.204      |
|    entropy_loss         | -1.99      |
|    explained_variance   | 0.661      |
|    learning_rate        | 5e-05      |
|    loss                 | 24.6       |
|    max_step             | 0          |
|    n_updates            | 1820       |
|    out_of_road          | 1          |
|    policy_gradient_loss | -0.000737  |
|    route_completion     | 0.26       |
|    std                  | 0.657      |
|    total_cost           | 5.44       |
|    value_loss           | 47.2       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 798      |
|    iterations      | 92       |
|    time_elapsed    | 589      |
|    total_timesteps | 471040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 363          |
|    ep_rew_mean          | 303          |
| time/                   |              |
|    fps                  | 799          |
|    iterations           | 93           |
|    time_elapsed         | 595          |
|    total_timesteps      | 476160       |
| train/                  |              |
|    approx_kl            | 0.0012488985 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.546        |
|    learning_rate        | 5e-05        |
|    loss                 | 37.1         |
|    n_updates            | 1840         |
|    policy_gradient_loss | -0.000846    |
|    std                  | 0.655        |
|    value_loss           | 76.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 133          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.45255244   |
|    route_completion     | 0.301        |
|    success_rate         | 0            |
|    total_cost           | 2.9          |
| time/                   |              |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0029745086 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.208        |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.651        |
|    learning_rate        | 5e-05        |
|    loss                 | 15.3         |
|    max_step             | 0            |
|    n_updates            | 1860         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00271     |
|    route_completion     | 0.262        |
|    std                  | 0.654        |
|    total_cost           | 5.56         |
|    value_loss           | 58.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 796      |
|    iterations      | 94       |
|    time_elapsed    | 604      |
|    total_timesteps | 481280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 310          |
| time/                   |              |
|    fps                  | 797          |
|    iterations           | 95           |
|    time_elapsed         | 609          |
|    total_timesteps      | 486400       |
| train/                  |              |
|    approx_kl            | 0.0017197954 |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.574        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.7         |
|    n_updates            | 1880         |
|    policy_gradient_loss | -0.00114     |
|    std                  | 0.654        |
|    value_loss           | 97.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.22        |
|    max_step             | 0           |
|    mean_ep_length       | 88.2        |
|    mean_reward          | 97.6        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.4536763   |
|    route_completion     | 0.301       |
|    success_rate         | 0           |
|    total_cost           | 2.86        |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.012020463 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.1         |
|    crash                | 0.204       |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.787       |
|    learning_rate        | 5e-05       |
|    loss                 | 19.2        |
|    max_step             | 0           |
|    n_updates            | 1900        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.000924   |
|    route_completion     | 0.261       |
|    std                  | 0.655       |
|    total_cost           | 5.47        |
|    value_loss           | 48.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 376      |
|    ep_rew_mean     | 317      |
| time/              |          |
|    fps             | 796      |
|    iterations      | 96       |
|    time_elapsed    | 617      |
|    total_timesteps | 491520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 392          |
|    ep_rew_mean          | 332          |
| time/                   |              |
|    fps                  | 796          |
|    iterations           | 97           |
|    time_elapsed         | 623          |
|    total_timesteps      | 496640       |
| train/                  |              |
|    approx_kl            | 0.0028241908 |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.715        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.8         |
|    n_updates            | 1920         |
|    policy_gradient_loss | 0.00196      |
|    std                  | 0.654        |
|    value_loss           | 45.2         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.224       |
|    max_step             | 0           |
|    mean_ep_length       | 127         |
|    mean_reward          | 132         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.45401227  |
|    route_completion     | 0.303       |
|    success_rate         | 0           |
|    total_cost           | 3           |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.002120625 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.208       |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.702       |
|    learning_rate        | 5e-05       |
|    loss                 | 25.2        |
|    max_step             | 0           |
|    n_updates            | 1940        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.0029     |
|    route_completion     | 0.264       |
|    std                  | 0.654       |
|    total_cost           | 5.82        |
|    value_loss           | 66.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 327      |
| time/              |          |
|    fps             | 792      |
|    iterations      | 98       |
|    time_elapsed    | 632      |
|    total_timesteps | 501760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 378          |
|    ep_rew_mean          | 324          |
| time/                   |              |
|    fps                  | 793          |
|    iterations           | 99           |
|    time_elapsed         | 638          |
|    total_timesteps      | 506880       |
| train/                  |              |
|    approx_kl            | 0.0015711554 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.608        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.7         |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.00171     |
|    std                  | 0.651        |
|    value_loss           | 71.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.227       |
|    max_step             | 0           |
|    mean_ep_length       | 113         |
|    mean_reward          | 136         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.45436266  |
|    route_completion     | 0.305       |
|    success_rate         | 0           |
|    total_cost           | 3.02        |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.004232212 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.216       |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.722       |
|    learning_rate        | 5e-05       |
|    loss                 | 42          |
|    max_step             | 0           |
|    n_updates            | 1980        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00141    |
|    route_completion     | 0.267       |
|    std                  | 0.651       |
|    total_cost           | 6.35        |
|    value_loss           | 66.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 329      |
| time/              |          |
|    fps             | 789      |
|    iterations      | 100      |
|    time_elapsed    | 648      |
|    total_timesteps | 512000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 374          |
|    ep_rew_mean          | 322          |
| time/                   |              |
|    fps                  | 790          |
|    iterations           | 101          |
|    time_elapsed         | 654          |
|    total_timesteps      | 517120       |
| train/                  |              |
|    approx_kl            | 0.0017958864 |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.694        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.8         |
|    n_updates            | 2000         |
|    policy_gradient_loss | -0.00153     |
|    std                  | 0.649        |
|    value_loss           | 72.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.45444095   |
|    route_completion     | 0.309        |
|    success_rate         | 0            |
|    total_cost           | 3.17         |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0017554729 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    crash                | 0.212        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.765        |
|    learning_rate        | 5e-05        |
|    loss                 | 38           |
|    max_step             | 0            |
|    n_updates            | 2020         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0018      |
|    route_completion     | 0.268        |
|    std                  | 0.648        |
|    total_cost           | 6.28         |
|    value_loss           | 60.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 387      |
|    ep_rew_mean     | 332      |
| time/              |          |
|    fps             | 787      |
|    iterations      | 102      |
|    time_elapsed    | 663      |
|    total_timesteps | 522240   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 332         |
| time/                   |             |
|    fps                  | 787         |
|    iterations           | 103         |
|    time_elapsed         | 670         |
|    total_timesteps      | 527360      |
| train/                  |             |
|    approx_kl            | 0.005661265 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.794       |
|    learning_rate        | 5e-05       |
|    loss                 | 16.3        |
|    n_updates            | 2040        |
|    policy_gradient_loss | 0.00332     |
|    std                  | 0.647       |
|    value_loss           | 33.7        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.00755     |
|    crash                | 0.226       |
|    max_step             | 0           |
|    mean_ep_length       | 157         |
|    mean_reward          | 190         |
|    num_episodes         | 5           |
|    out_of_road          | 0.992       |
|    raw_action           | 0.45470288  |
|    route_completion     | 0.315       |
|    success_rate         | 0.2         |
|    total_cost           | 3.24        |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.003189904 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0992      |
|    clip_range           | 0.1         |
|    crash                | 0.208       |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.748       |
|    learning_rate        | 5e-05       |
|    loss                 | 22.9        |
|    max_step             | 0           |
|    n_updates            | 2060        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00218    |
|    route_completion     | 0.269       |
|    std                  | 0.647       |
|    total_cost           | 6.26        |
|    value_loss           | 69.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 337      |
| time/              |          |
|    fps             | 784      |
|    iterations      | 104      |
|    time_elapsed    | 679      |
|    total_timesteps | 532480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 404          |
|    ep_rew_mean          | 345          |
| time/                   |              |
|    fps                  | 783          |
|    iterations           | 105          |
|    time_elapsed         | 686          |
|    total_timesteps      | 537600       |
| train/                  |              |
|    approx_kl            | 0.0074399104 |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.807        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.5         |
|    n_updates            | 2080         |
|    policy_gradient_loss | 0.000249     |
|    std                  | 0.644        |
|    value_loss           | 53.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.00741     |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 143         |
|    mean_reward          | 164         |
|    num_episodes         | 5           |
|    out_of_road          | 0.993       |
|    raw_action           | 0.45515338  |
|    route_completion     | 0.319       |
|    success_rate         | 0           |
|    total_cost           | 3.31        |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.002178476 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.1         |
|    crash                | 0.204       |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.845       |
|    learning_rate        | 5e-05       |
|    loss                 | 31.2        |
|    max_step             | 0           |
|    n_updates            | 2100        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00307    |
|    route_completion     | 0.27        |
|    std                  | 0.643       |
|    total_cost           | 6.26        |
|    value_loss           | 57.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 398      |
|    ep_rew_mean     | 339      |
| time/              |          |
|    fps             | 781      |
|    iterations      | 106      |
|    time_elapsed    | 694      |
|    total_timesteps | 542720   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 333         |
| time/                   |             |
|    fps                  | 781         |
|    iterations           | 107         |
|    time_elapsed         | 701         |
|    total_timesteps      | 547840      |
| train/                  |             |
|    approx_kl            | 0.001532578 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.766       |
|    learning_rate        | 5e-05       |
|    loss                 | 30.1        |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.00098    |
|    std                  | 0.641       |
|    value_loss           | 57.1        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00727      |
|    crash                | 0.229        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 173          |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.45467085   |
|    route_completion     | 0.322        |
|    success_rate         | 0            |
|    total_cost           | 3.34         |
| time/                   |              |
|    total_timesteps      | 550000       |
| train/                  |              |
|    approx_kl            | 0.0019608152 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    crash                | 0.204        |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.742        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.9         |
|    max_step             | 0            |
|    n_updates            | 2140         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00189     |
|    route_completion     | 0.272        |
|    std                  | 0.64         |
|    total_cost           | 6.28         |
|    value_loss           | 89.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 406      |
|    ep_rew_mean     | 343      |
| time/              |          |
|    fps             | 779      |
|    iterations      | 108      |
|    time_elapsed    | 709      |
|    total_timesteps | 552960   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 412         |
|    ep_rew_mean          | 348         |
| time/                   |             |
|    fps                  | 779         |
|    iterations           | 109         |
|    time_elapsed         | 715         |
|    total_timesteps      | 558080      |
| train/                  |             |
|    approx_kl            | 0.012250721 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.796       |
|    learning_rate        | 5e-05       |
|    loss                 | 22.2        |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.000551   |
|    std                  | 0.638       |
|    value_loss           | 60          |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0107       |
|    crash                | 0.229        |
|    max_step             | 0            |
|    mean_ep_length       | 131          |
|    mean_reward          | 110          |
|    num_episodes         | 5            |
|    out_of_road          | 0.989        |
|    raw_action           | 0.4549819    |
|    route_completion     | 0.325        |
|    success_rate         | 0.1          |
|    total_cost           | 3.61         |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0010546633 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.854        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.2         |
|    max_step             | 0            |
|    n_updates            | 2180         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00236     |
|    route_completion     | 0.273        |
|    std                  | 0.637        |
|    total_cost           | 6.24         |
|    value_loss           | 54.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 412      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    fps             | 778      |
|    iterations      | 110      |
|    time_elapsed    | 723      |
|    total_timesteps | 563200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 406          |
|    ep_rew_mean          | 340          |
| time/                   |              |
|    fps                  | 778          |
|    iterations           | 111          |
|    time_elapsed         | 730          |
|    total_timesteps      | 568320       |
| train/                  |              |
|    approx_kl            | 0.0035793013 |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.842        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.4         |
|    n_updates            | 2200         |
|    policy_gradient_loss | 0.000119     |
|    std                  | 0.636        |
|    value_loss           | 45.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0105       |
|    crash                | 0.228        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.989        |
|    raw_action           | 0.4550831    |
|    route_completion     | 0.327        |
|    success_rate         | 0            |
|    total_cost           | 3.61         |
| time/                   |              |
|    total_timesteps      | 570000       |
| train/                  |              |
|    approx_kl            | 0.0018531285 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    crash                | 0.196        |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.781        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.4         |
|    max_step             | 0            |
|    n_updates            | 2220         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0024      |
|    route_completion     | 0.274        |
|    std                  | 0.635        |
|    total_cost           | 6.2          |
|    value_loss           | 81.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 405      |
|    ep_rew_mean     | 338      |
| time/              |          |
|    fps             | 776      |
|    iterations      | 112      |
|    time_elapsed    | 738      |
|    total_timesteps | 573440   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 391          |
|    ep_rew_mean          | 329          |
| time/                   |              |
|    fps                  | 777          |
|    iterations           | 113          |
|    time_elapsed         | 744          |
|    total_timesteps      | 578560       |
| train/                  |              |
|    approx_kl            | 0.0030684613 |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.802        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.2         |
|    n_updates            | 2240         |
|    policy_gradient_loss | -0.00059     |
|    std                  | 0.632        |
|    value_loss           | 69.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0138       |
|    crash                | 0.224        |
|    max_step             | 0            |
|    mean_ep_length       | 162          |
|    mean_reward          | 209          |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.45509917   |
|    route_completion     | 0.331        |
|    success_rate         | 0.1          |
|    total_cost           | 3.68         |
| time/                   |              |
|    total_timesteps      | 580000       |
| train/                  |              |
|    approx_kl            | 0.0022578076 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0846       |
|    clip_range           | 0.1          |
|    crash                | 0.193        |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.825        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.7         |
|    max_step             | 0            |
|    n_updates            | 2260         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00289     |
|    route_completion     | 0.275        |
|    std                  | 0.63         |
|    total_cost           | 6.11         |
|    value_loss           | 61.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 325      |
| time/              |          |
|    fps             | 774      |
|    iterations      | 114      |
|    time_elapsed    | 753      |
|    total_timesteps | 583680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 394          |
|    ep_rew_mean          | 328          |
| time/                   |              |
|    fps                  | 775          |
|    iterations           | 115          |
|    time_elapsed         | 759          |
|    total_timesteps      | 588800       |
| train/                  |              |
|    approx_kl            | 0.0015812438 |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.759        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.2         |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.00203     |
|    std                  | 0.626        |
|    value_loss           | 85.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0136       |
|    crash                | 0.224        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.4551357    |
|    route_completion     | 0.332        |
|    success_rate         | 0            |
|    total_cost           | 3.71         |
| time/                   |              |
|    total_timesteps      | 590000       |
| train/                  |              |
|    approx_kl            | 0.0026710657 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    crash                | 0.19         |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.831        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.2         |
|    max_step             | 0            |
|    n_updates            | 2300         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00129     |
|    route_completion     | 0.276        |
|    std                  | 0.626        |
|    total_cost           | 6.1          |
|    value_loss           | 54.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 328      |
| time/              |          |
|    fps             | 773      |
|    iterations      | 116      |
|    time_elapsed    | 767      |
|    total_timesteps | 593920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 388          |
|    ep_rew_mean          | 327          |
| time/                   |              |
|    fps                  | 774          |
|    iterations           | 117          |
|    time_elapsed         | 773          |
|    total_timesteps      | 599040       |
| train/                  |              |
|    approx_kl            | 0.0013072706 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.821        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.6         |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.00385     |
|    std                  | 0.624        |
|    value_loss           | 54.3         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0133      |
|    crash                | 0.223       |
|    max_step             | 0           |
|    mean_ep_length       | 88.2        |
|    mean_reward          | 93.6        |
|    num_episodes         | 5           |
|    out_of_road          | 0.987       |
|    raw_action           | 0.45471367  |
|    route_completion     | 0.331       |
|    success_rate         | 0           |
|    total_cost           | 3.69        |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.011763055 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.1         |
|    crash                | 0.187       |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.815       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.4        |
|    max_step             | 0           |
|    n_updates            | 2340        |
|    out_of_road          | 1           |
|    policy_gradient_loss | 0.000153    |
|    route_completion     | 0.281       |
|    std                  | 0.624       |
|    total_cost           | 6.22        |
|    value_loss           | 65.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 329      |
| time/              |          |
|    fps             | 772      |
|    iterations      | 118      |
|    time_elapsed    | 782      |
|    total_timesteps | 604160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 327         |
| time/                   |             |
|    fps                  | 772         |
|    iterations           | 119         |
|    time_elapsed         | 788         |
|    total_timesteps      | 609280      |
| train/                  |             |
|    approx_kl            | 0.004496157 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.779       |
|    learning_rate        | 5e-05       |
|    loss                 | 39.3        |
|    n_updates            | 2360        |
|    policy_gradient_loss | 5.78e-05    |
|    std                  | 0.622       |
|    value_loss           | 66.5        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0131       |
|    crash                | 0.223        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 182          |
|    num_episodes         | 5            |
|    out_of_road          | 0.987        |
|    raw_action           | 0.4542824    |
|    route_completion     | 0.333        |
|    success_rate         | 0            |
|    total_cost           | 3.76         |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0014429009 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    crash                | 0.184        |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.791        |
|    learning_rate        | 5e-05        |
|    loss                 | 21.6         |
|    max_step             | 0            |
|    n_updates            | 2380         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00193     |
|    route_completion     | 0.282        |
|    std                  | 0.621        |
|    total_cost           | 6.18         |
|    value_loss           | 65.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 324      |
| time/              |          |
|    fps             | 770      |
|    iterations      | 120      |
|    time_elapsed    | 797      |
|    total_timesteps | 614400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 389          |
|    ep_rew_mean          | 334          |
| time/                   |              |
|    fps                  | 771          |
|    iterations           | 121          |
|    time_elapsed         | 803          |
|    total_timesteps      | 619520       |
| train/                  |              |
|    approx_kl            | 0.0026945516 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.809        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.3         |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.00157     |
|    std                  | 0.62         |
|    value_loss           | 56           |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0129      |
|    crash                | 0.223       |
|    max_step             | 0           |
|    mean_ep_length       | 145         |
|    mean_reward          | 132         |
|    num_episodes         | 5           |
|    out_of_road          | 0.987       |
|    raw_action           | 0.45396772  |
|    route_completion     | 0.335       |
|    success_rate         | 0           |
|    total_cost           | 4.04        |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.036502752 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.1         |
|    crash                | 0.181       |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.854       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.5        |
|    max_step             | 0           |
|    n_updates            | 2420        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00129    |
|    route_completion     | 0.283       |
|    std                  | 0.621       |
|    total_cost           | 6.11        |
|    value_loss           | 54.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 335      |
| time/              |          |
|    fps             | 768      |
|    iterations      | 122      |
|    time_elapsed    | 812      |
|    total_timesteps | 624640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 404          |
|    ep_rew_mean          | 343          |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 123          |
|    time_elapsed         | 818          |
|    total_timesteps      | 629760       |
| train/                  |              |
|    approx_kl            | 0.0015687223 |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.842        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.4         |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.00304     |
|    std                  | 0.619        |
|    value_loss           | 44.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0127       |
|    crash                | 0.219        |
|    max_step             | 0            |
|    mean_ep_length       | 293          |
|    mean_reward          | 226          |
|    num_episodes         | 5            |
|    out_of_road          | 0.987        |
|    raw_action           | 0.45318684   |
|    route_completion     | 0.342        |
|    success_rate         | 0            |
|    total_cost           | 4.9          |
| time/                   |              |
|    total_timesteps      | 630000       |
| train/                  |              |
|    approx_kl            | 0.0016130876 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    crash                | 0.181        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.743        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.1         |
|    max_step             | 0            |
|    n_updates            | 2460         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00239     |
|    route_completion     | 0.286        |
|    std                  | 0.618        |
|    total_cost           | 6.33         |
|    value_loss           | 91           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 336      |
| time/              |          |
|    fps             | 763      |
|    iterations      | 124      |
|    time_elapsed    | 831      |
|    total_timesteps | 634880   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0125       |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 196          |
|    mean_reward          | 216          |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.45345387   |
|    route_completion     | 0.348        |
|    success_rate         | 0            |
|    total_cost           | 5.15         |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0026119994 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.178        |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.717        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.2         |
|    max_step             | 0            |
|    n_updates            | 2480         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0016      |
|    route_completion     | 0.286        |
|    std                  | 0.617        |
|    total_cost           | 6.25         |
|    value_loss           | 91.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    fps             | 761      |
|    iterations      | 125      |
|    time_elapsed    | 840      |
|    total_timesteps | 640000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 404          |
|    ep_rew_mean          | 345          |
| time/                   |              |
|    fps                  | 762          |
|    iterations           | 126          |
|    time_elapsed         | 845          |
|    total_timesteps      | 645120       |
| train/                  |              |
|    approx_kl            | 0.0031784778 |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.829        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.1         |
|    n_updates            | 2500         |
|    policy_gradient_loss | -5.92e-06    |
|    std                  | 0.614        |
|    value_loss           | 46.6         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0123     |
|    crash                | 0.215      |
|    max_step             | 0          |
|    mean_ep_length       | 117        |
|    mean_reward          | 130        |
|    num_episodes         | 5          |
|    out_of_road          | 0.988      |
|    raw_action           | 0.45357996 |
|    route_completion     | 0.349      |
|    success_rate         | 0          |
|    total_cost           | 5.15       |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.00301733 |
|    arrive_dest          | 0          |
|    clip_fraction        | 0.164      |
|    clip_range           | 0.1        |
|    crash                | 0.175      |
|    entropy_loss         | -1.84      |
|    explained_variance   | 0.865      |
|    learning_rate        | 5e-05      |
|    loss                 | 20.8       |
|    max_step             | 0          |
|    n_updates            | 2520       |
|    out_of_road          | 1          |
|    policy_gradient_loss | -0.00286   |
|    route_completion     | 0.287      |
|    std                  | 0.612      |
|    total_cost           | 6.22       |
|    value_loss           | 44         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    fps             | 760      |
|    iterations      | 127      |
|    time_elapsed    | 854      |
|    total_timesteps | 650240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 399          |
|    ep_rew_mean          | 338          |
| time/                   |              |
|    fps                  | 761          |
|    iterations           | 128          |
|    time_elapsed         | 860          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0025715674 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.82         |
|    learning_rate        | 5e-05        |
|    loss                 | 26.4         |
|    n_updates            | 2540         |
|    policy_gradient_loss | -0.00109     |
|    std                  | 0.61         |
|    value_loss           | 59.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0152       |
|    crash                | 0.212        |
|    max_step             | 0            |
|    mean_ep_length       | 145          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.985        |
|    raw_action           | 0.4542268    |
|    route_completion     | 0.352        |
|    success_rate         | 0.1          |
|    total_cost           | 5.24         |
| time/                   |              |
|    total_timesteps      | 660000       |
| train/                  |              |
|    approx_kl            | 0.0044349236 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.1          |
|    crash                | 0.173        |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.845        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.5         |
|    max_step             | 0            |
|    n_updates            | 2560         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00283     |
|    route_completion     | 0.287        |
|    std                  | 0.608        |
|    total_cost           | 6.19         |
|    value_loss           | 39.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 358      |
| time/              |          |
|    fps             | 759      |
|    iterations      | 129      |
|    time_elapsed    | 869      |
|    total_timesteps | 660480   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 424         |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 760         |
|    iterations           | 130         |
|    time_elapsed         | 875         |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.003727038 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.79        |
|    learning_rate        | 5e-05       |
|    loss                 | 26.7        |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.000566    |
|    std                  | 0.608       |
|    value_loss           | 49.5        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0149      |
|    crash                | 0.218       |
|    max_step             | 0           |
|    mean_ep_length       | 147         |
|    mean_reward          | 154         |
|    num_episodes         | 5           |
|    out_of_road          | 0.985       |
|    raw_action           | 0.45382744  |
|    route_completion     | 0.355       |
|    success_rate         | 0           |
|    total_cost           | 5.34        |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.004333186 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.1         |
|    crash                | 0.17        |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.744       |
|    learning_rate        | 5e-05       |
|    loss                 | 25.6        |
|    max_step             | 0           |
|    n_updates            | 2600        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00136    |
|    route_completion     | 0.288       |
|    std                  | 0.608       |
|    total_cost           | 6.16        |
|    value_loss           | 72          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 360      |
| time/              |          |
|    fps             | 758      |
|    iterations      | 131      |
|    time_elapsed    | 883      |
|    total_timesteps | 670720   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 416         |
|    ep_rew_mean          | 352         |
| time/                   |             |
|    fps                  | 759         |
|    iterations           | 132         |
|    time_elapsed         | 890         |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.019346934 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.734       |
|    learning_rate        | 5e-05       |
|    loss                 | 30.2        |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.00313     |
|    std                  | 0.605       |
|    value_loss           | 62.6        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0206       |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 199          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 0.979        |
|    raw_action           | 0.45345286   |
|    route_completion     | 0.359        |
|    success_rate         | 0.2          |
|    total_cost           | 5.91         |
| time/                   |              |
|    total_timesteps      | 680000       |
| train/                  |              |
|    approx_kl            | 0.0025711078 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.168        |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.591        |
|    learning_rate        | 5e-05        |
|    loss                 | 49           |
|    max_step             | 0            |
|    n_updates            | 2640         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0019      |
|    route_completion     | 0.29         |
|    std                  | 0.606        |
|    total_cost           | 6.16         |
|    value_loss           | 103          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 416      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    fps             | 757      |
|    iterations      | 133      |
|    time_elapsed    | 899      |
|    total_timesteps | 680960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 420          |
|    ep_rew_mean          | 354          |
| time/                   |              |
|    fps                  | 757          |
|    iterations           | 134          |
|    time_elapsed         | 905          |
|    total_timesteps      | 686080       |
| train/                  |              |
|    approx_kl            | 0.0015535755 |
|    clip_fraction        | 0.226        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 18           |
|    n_updates            | 2660         |
|    policy_gradient_loss | 0.00249      |
|    std                  | 0.607        |
|    value_loss           | 63.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0203      |
|    crash                | 0.223       |
|    max_step             | 0           |
|    mean_ep_length       | 178         |
|    mean_reward          | 151         |
|    num_episodes         | 5           |
|    out_of_road          | 0.98        |
|    raw_action           | 0.45336553  |
|    route_completion     | 0.36        |
|    success_rate         | 0           |
|    total_cost           | 6.2         |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.002535502 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.1         |
|    crash                | 0.165       |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.588       |
|    learning_rate        | 5e-05       |
|    loss                 | 61          |
|    max_step             | 0           |
|    n_updates            | 2680        |
|    out_of_road          | 1           |
|    policy_gradient_loss | 7.55e-05    |
|    route_completion     | 0.291       |
|    std                  | 0.608       |
|    total_cost           | 6.13        |
|    value_loss           | 101         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 405      |
|    ep_rew_mean     | 341      |
| time/              |          |
|    fps             | 755      |
|    iterations      | 135      |
|    time_elapsed    | 914      |
|    total_timesteps | 691200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 390          |
|    ep_rew_mean          | 326          |
| time/                   |              |
|    fps                  | 756          |
|    iterations           | 136          |
|    time_elapsed         | 920          |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 0.0029180206 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.616        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.3         |
|    n_updates            | 2700         |
|    policy_gradient_loss | -0.000676    |
|    std                  | 0.606        |
|    value_loss           | 85.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.02         |
|    crash                | 0.226        |
|    max_step             | 0            |
|    mean_ep_length       | 190          |
|    mean_reward          | 163          |
|    num_episodes         | 5            |
|    out_of_road          | 0.98         |
|    raw_action           | 0.45187068   |
|    route_completion     | 0.363        |
|    success_rate         | 0            |
|    total_cost           | 6.46         |
| time/                   |              |
|    total_timesteps      | 700000       |
| train/                  |              |
|    approx_kl            | 0.0019371513 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0901       |
|    clip_range           | 0.1          |
|    crash                | 0.166        |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.476        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.4         |
|    max_step             | 0            |
|    n_updates            | 2720         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00289     |
|    route_completion     | 0.294        |
|    std                  | 0.603        |
|    total_cost           | 6.2          |
|    value_loss           | 139          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 321      |
| time/              |          |
|    fps             | 752      |
|    iterations      | 137      |
|    time_elapsed    | 931      |
|    total_timesteps | 701440   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 374         |
|    ep_rew_mean          | 317         |
| time/                   |             |
|    fps                  | 753         |
|    iterations           | 138         |
|    time_elapsed         | 938         |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.003387079 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.667       |
|    learning_rate        | 5e-05       |
|    loss                 | 27.5        |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00119    |
|    std                  | 0.603       |
|    value_loss           | 71.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0197       |
|    crash                | 0.225        |
|    max_step             | 0            |
|    mean_ep_length       | 123          |
|    mean_reward          | 150          |
|    num_episodes         | 5            |
|    out_of_road          | 0.98         |
|    raw_action           | 0.45118865   |
|    route_completion     | 0.365        |
|    success_rate         | 0            |
|    total_cost           | 6.42         |
| time/                   |              |
|    total_timesteps      | 710000       |
| train/                  |              |
|    approx_kl            | 0.0019346991 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.166        |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.684        |
|    learning_rate        | 5e-05        |
|    loss                 | 34           |
|    max_step             | 0            |
|    n_updates            | 2760         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00249     |
|    route_completion     | 0.298        |
|    std                  | 0.603        |
|    total_cost           | 6.24         |
|    value_loss           | 76.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 750      |
|    iterations      | 139      |
|    time_elapsed    | 948      |
|    total_timesteps | 711680   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 348         |
|    ep_rew_mean          | 300         |
| time/                   |             |
|    fps                  | 750         |
|    iterations           | 140         |
|    time_elapsed         | 954         |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.001645574 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.695       |
|    learning_rate        | 5e-05       |
|    loss                 | 32.9        |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.00278    |
|    std                  | 0.602       |
|    value_loss           | 80.1        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0194       |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 100          |
|    mean_reward          | 108          |
|    num_episodes         | 5            |
|    out_of_road          | 0.981        |
|    raw_action           | 0.45062473   |
|    route_completion     | 0.364        |
|    success_rate         | 0            |
|    total_cost           | 6.38         |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0039489884 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    crash                | 0.164        |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.793        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.3         |
|    max_step             | 0            |
|    n_updates            | 2800         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00193     |
|    route_completion     | 0.299        |
|    std                  | 0.601        |
|    total_cost           | 6.26         |
|    value_loss           | 62.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 748      |
|    iterations      | 141      |
|    time_elapsed    | 964      |
|    total_timesteps | 721920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 351          |
|    ep_rew_mean          | 306          |
| time/                   |              |
|    fps                  | 748          |
|    iterations           | 142          |
|    time_elapsed         | 970          |
|    total_timesteps      | 727040       |
| train/                  |              |
|    approx_kl            | 0.0041605993 |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.6         |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.000128    |
|    std                  | 0.602        |
|    value_loss           | 85.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0247      |
|    crash                | 0.225       |
|    max_step             | 0           |
|    mean_ep_length       | 190         |
|    mean_reward          | 156         |
|    num_episodes         | 5           |
|    out_of_road          | 0.975       |
|    raw_action           | 0.45050958  |
|    route_completion     | 0.368       |
|    success_rate         | 0.2         |
|    total_cost           | 6.8         |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.002406769 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.1         |
|    crash                | 0.162       |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.543       |
|    learning_rate        | 5e-05       |
|    loss                 | 45          |
|    max_step             | 0           |
|    n_updates            | 2840        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00167    |
|    route_completion     | 0.3         |
|    std                  | 0.6         |
|    total_cost           | 6.19        |
|    value_loss           | 111         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 747      |
|    iterations      | 143      |
|    time_elapsed    | 979      |
|    total_timesteps | 732160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 304          |
| time/                   |              |
|    fps                  | 747          |
|    iterations           | 144          |
|    time_elapsed         | 986          |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 0.0041329362 |
|    clip_fraction        | 0.202        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.475        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.9         |
|    n_updates            | 2860         |
|    policy_gradient_loss | -0.000738    |
|    std                  | 0.599        |
|    value_loss           | 111          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0297      |
|    crash                | 0.224       |
|    max_step             | 0           |
|    mean_ep_length       | 238         |
|    mean_reward          | 292         |
|    num_episodes         | 5           |
|    out_of_road          | 0.97        |
|    raw_action           | 0.44915903  |
|    route_completion     | 0.373       |
|    success_rate         | 0.2         |
|    total_cost           | 7           |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.017261337 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.1         |
|    crash                | 0.159       |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.671       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.9        |
|    max_step             | 0           |
|    n_updates            | 2880        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.002      |
|    route_completion     | 0.304       |
|    std                  | 0.598       |
|    total_cost           | 6.12        |
|    value_loss           | 85.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 744      |
|    iterations      | 145      |
|    time_elapsed    | 997      |
|    total_timesteps | 742400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 351         |
|    ep_rew_mean          | 306         |
| time/                   |             |
|    fps                  | 744         |
|    iterations           | 146         |
|    time_elapsed         | 1003        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.004480517 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.654       |
|    learning_rate        | 5e-05       |
|    loss                 | 32.5        |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.000862   |
|    std                  | 0.596       |
|    value_loss           | 69.6        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0293      |
|    crash                | 0.224       |
|    max_step             | 0           |
|    mean_ep_length       | 75.6        |
|    mean_reward          | 65.4        |
|    num_episodes         | 5           |
|    out_of_road          | 0.971       |
|    raw_action           | 0.44909123  |
|    route_completion     | 0.371       |
|    success_rate         | 0           |
|    total_cost           | 6.94        |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.002753696 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.1         |
|    crash                | 0.157       |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.569       |
|    learning_rate        | 5e-05       |
|    loss                 | 61.9        |
|    max_step             | 0           |
|    n_updates            | 2920        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.000921   |
|    route_completion     | 0.305       |
|    std                  | 0.596       |
|    total_cost           | 6.05        |
|    value_loss           | 121         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 744      |
|    iterations      | 147      |
|    time_elapsed    | 1011     |
|    total_timesteps | 752640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 370         |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 744         |
|    iterations           | 148         |
|    time_elapsed         | 1017        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.004572388 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.651       |
|    learning_rate        | 5e-05       |
|    loss                 | 34          |
|    n_updates            | 2940        |
|    policy_gradient_loss | 0.000669    |
|    std                  | 0.594       |
|    value_loss           | 53.3        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0316      |
|    crash                | 0.226       |
|    max_step             | 0           |
|    mean_ep_length       | 130         |
|    mean_reward          | 171         |
|    num_episodes         | 5           |
|    out_of_road          | 0.968       |
|    raw_action           | 0.44903842  |
|    route_completion     | 0.371       |
|    success_rate         | 0.1         |
|    total_cost           | 6.88        |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.018530874 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.1         |
|    crash                | 0.155       |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.725       |
|    learning_rate        | 5e-05       |
|    loss                 | 25.6        |
|    max_step             | 0           |
|    n_updates            | 2960        |
|    out_of_road          | 1           |
|    policy_gradient_loss | 0.00126     |
|    route_completion     | 0.307       |
|    std                  | 0.592       |
|    total_cost           | 5.99        |
|    value_loss           | 64          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 741      |
|    iterations      | 149      |
|    time_elapsed    | 1028     |
|    total_timesteps | 762880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 363          |
|    ep_rew_mean          | 321          |
| time/                   |              |
|    fps                  | 742          |
|    iterations           | 150          |
|    time_elapsed         | 1034         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 0.0015910987 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.499        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.7         |
|    n_updates            | 2980         |
|    policy_gradient_loss | -0.00233     |
|    std                  | 0.591        |
|    value_loss           | 122          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0312       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.44836965   |
|    route_completion     | 0.372        |
|    success_rate         | 0            |
|    total_cost           | 6.81         |
| time/                   |              |
|    total_timesteps      | 770000       |
| train/                  |              |
|    approx_kl            | 0.0036252644 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.1          |
|    crash                | 0.153        |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.728        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.7         |
|    max_step             | 0            |
|    n_updates            | 3000         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00092     |
|    route_completion     | 0.309        |
|    std                  | 0.593        |
|    total_cost           | 5.94         |
|    value_loss           | 61.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 315      |
| time/              |          |
|    fps             | 740      |
|    iterations      | 151      |
|    time_elapsed    | 1044     |
|    total_timesteps | 773120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 329          |
| time/                   |              |
|    fps                  | 740          |
|    iterations           | 152          |
|    time_elapsed         | 1051         |
|    total_timesteps      | 778240       |
| train/                  |              |
|    approx_kl            | 0.0024848396 |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.599        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.8         |
|    n_updates            | 3020         |
|    policy_gradient_loss | -9.82e-05    |
|    std                  | 0.591        |
|    value_loss           | 108          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0308      |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 99.2        |
|    mean_reward          | 111         |
|    num_episodes         | 5           |
|    out_of_road          | 0.969       |
|    raw_action           | 0.44813064  |
|    route_completion     | 0.373       |
|    success_rate         | 0           |
|    total_cost           | 6.77        |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.008192791 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.1         |
|    crash                | 0.151       |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.715       |
|    learning_rate        | 5e-05       |
|    loss                 | 46.6        |
|    max_step             | 0           |
|    n_updates            | 3040        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00176    |
|    route_completion     | 0.309       |
|    std                  | 0.591       |
|    total_cost           | 5.88        |
|    value_loss           | 82.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 322      |
| time/              |          |
|    fps             | 739      |
|    iterations      | 153      |
|    time_elapsed    | 1058     |
|    total_timesteps | 783360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 367          |
|    ep_rew_mean          | 329          |
| time/                   |              |
|    fps                  | 740          |
|    iterations           | 154          |
|    time_elapsed         | 1064         |
|    total_timesteps      | 788480       |
| train/                  |              |
|    approx_kl            | 0.0020226354 |
|    clip_fraction        | 0.266        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.698        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.1         |
|    n_updates            | 3060         |
|    policy_gradient_loss | 0.00413      |
|    std                  | 0.591        |
|    value_loss           | 84.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0304       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 120          |
|    mean_reward          | 144          |
|    num_episodes         | 5            |
|    out_of_road          | 0.97         |
|    raw_action           | 0.44782978   |
|    route_completion     | 0.373        |
|    success_rate         | 0            |
|    total_cost           | 6.7          |
| time/                   |              |
|    total_timesteps      | 790000       |
| train/                  |              |
|    approx_kl            | 0.0041185985 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.138        |
|    clip_range           | 0.1          |
|    crash                | 0.149        |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.729        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.3         |
|    max_step             | 0            |
|    n_updates            | 3080         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00268     |
|    route_completion     | 0.31         |
|    std                  | 0.591        |
|    total_cost           | 5.82         |
|    value_loss           | 76.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 322      |
| time/              |          |
|    fps             | 739      |
|    iterations      | 155      |
|    time_elapsed    | 1073     |
|    total_timesteps | 793600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 316          |
| time/                   |              |
|    fps                  | 739          |
|    iterations           | 156          |
|    time_elapsed         | 1079         |
|    total_timesteps      | 798720       |
| train/                  |              |
|    approx_kl            | 0.0069239265 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.536        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.6         |
|    n_updates            | 3100         |
|    policy_gradient_loss | -0.00171     |
|    std                  | 0.589        |
|    value_loss           | 105          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.03         |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 96.6         |
|    mean_reward          | 98.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.97         |
|    raw_action           | 0.44727284   |
|    route_completion     | 0.372        |
|    success_rate         | 0            |
|    total_cost           | 6.65         |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0045058653 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.203        |
|    clip_range           | 0.1          |
|    crash                | 0.147        |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.4         |
|    max_step             | 0            |
|    n_updates            | 3120         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000368    |
|    route_completion     | 0.313        |
|    std                  | 0.586        |
|    total_cost           | 5.76         |
|    value_loss           | 82.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 352      |
|    ep_rew_mean     | 323      |
| time/              |          |
|    fps             | 738      |
|    iterations      | 157      |
|    time_elapsed    | 1088     |
|    total_timesteps | 803840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 333          |
| time/                   |              |
|    fps                  | 738          |
|    iterations           | 158          |
|    time_elapsed         | 1095         |
|    total_timesteps      | 808960       |
| train/                  |              |
|    approx_kl            | 0.0020482065 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.514        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.9         |
|    n_updates            | 3140         |
|    policy_gradient_loss | -0.00185     |
|    std                  | 0.585        |
|    value_loss           | 92.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0296       |
|    crash                | 0.24         |
|    max_step             | 0            |
|    mean_ep_length       | 83.2         |
|    mean_reward          | 79.6         |
|    num_episodes         | 5            |
|    out_of_road          | 0.97         |
|    raw_action           | 0.44666728   |
|    route_completion     | 0.371        |
|    success_rate         | 0            |
|    total_cost           | 6.59         |
| time/                   |              |
|    total_timesteps      | 810000       |
| train/                  |              |
|    approx_kl            | 0.0028962293 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    crash                | 0.146        |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.699        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.6         |
|    max_step             | 0            |
|    n_updates            | 3160         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00176     |
|    route_completion     | 0.316        |
|    std                  | 0.585        |
|    total_cost           | 5.73         |
|    value_loss           | 69.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 330      |
| time/              |          |
|    fps             | 737      |
|    iterations      | 159      |
|    time_elapsed    | 1104     |
|    total_timesteps | 814080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 370          |
|    ep_rew_mean          | 339          |
| time/                   |              |
|    fps                  | 737          |
|    iterations           | 160          |
|    time_elapsed         | 1110         |
|    total_timesteps      | 819200       |
| train/                  |              |
|    approx_kl            | 0.0029696866 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.65         |
|    learning_rate        | 5e-05        |
|    loss                 | 30.9         |
|    n_updates            | 3180         |
|    policy_gradient_loss | -0.00226     |
|    std                  | 0.584        |
|    value_loss           | 76.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0293      |
|    crash                | 0.241       |
|    max_step             | 0           |
|    mean_ep_length       | 145         |
|    mean_reward          | 136         |
|    num_episodes         | 5           |
|    out_of_road          | 0.971       |
|    raw_action           | 0.44674075  |
|    route_completion     | 0.373       |
|    success_rate         | 0           |
|    total_cost           | 6.7         |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.006853845 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.1         |
|    crash                | 0.144       |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.701       |
|    learning_rate        | 5e-05       |
|    loss                 | 60.2        |
|    max_step             | 0           |
|    n_updates            | 3200        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00205    |
|    route_completion     | 0.316       |
|    std                  | 0.584       |
|    total_cost           | 5.67        |
|    value_loss           | 84.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 344      |
| time/              |          |
|    fps             | 736      |
|    iterations      | 161      |
|    time_elapsed    | 1119     |
|    total_timesteps | 824320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 370         |
|    ep_rew_mean          | 350         |
| time/                   |             |
|    fps                  | 736         |
|    iterations           | 162         |
|    time_elapsed         | 1126        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.006661718 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.682       |
|    learning_rate        | 5e-05       |
|    loss                 | 26.3        |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.583       |
|    value_loss           | 69.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0313       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 224          |
|    mean_reward          | 179          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.44652742   |
|    route_completion     | 0.375        |
|    success_rate         | 0.1          |
|    total_cost           | 7.04         |
| time/                   |              |
|    total_timesteps      | 830000       |
| train/                  |              |
|    approx_kl            | 0.0020156337 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    crash                | 0.142        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.663        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.1         |
|    max_step             | 0            |
|    n_updates            | 3240         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00273     |
|    route_completion     | 0.317        |
|    std                  | 0.584        |
|    total_cost           | 5.62         |
|    value_loss           | 105          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 342      |
| time/              |          |
|    fps             | 734      |
|    iterations      | 163      |
|    time_elapsed    | 1136     |
|    total_timesteps | 834560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 376        |
|    ep_rew_mean          | 361        |
| time/                   |            |
|    fps                  | 734        |
|    iterations           | 164        |
|    time_elapsed         | 1143       |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.01092665 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.72      |
|    explained_variance   | 0.732      |
|    learning_rate        | 5e-05      |
|    loss                 | 29         |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.00343   |
|    std                  | 0.582      |
|    value_loss           | 50.8       |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.031       |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 76.2        |
|    mean_reward          | 72.8        |
|    num_episodes         | 5           |
|    out_of_road          | 0.969       |
|    raw_action           | 0.4458326   |
|    route_completion     | 0.374       |
|    success_rate         | 0           |
|    total_cost           | 6.97        |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.005877241 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.1         |
|    crash                | 0.14        |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.726       |
|    learning_rate        | 5e-05       |
|    loss                 | 49.5        |
|    max_step             | 0           |
|    n_updates            | 3280        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00111    |
|    route_completion     | 0.319       |
|    std                  | 0.579       |
|    total_cost           | 5.58        |
|    value_loss           | 72.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 375      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    fps             | 733      |
|    iterations      | 165      |
|    time_elapsed    | 1152     |
|    total_timesteps | 844800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 373         |
|    ep_rew_mean          | 367         |
| time/                   |             |
|    fps                  | 733         |
|    iterations           | 166         |
|    time_elapsed         | 1158        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.002618629 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.616       |
|    learning_rate        | 5e-05       |
|    loss                 | 42          |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.000997   |
|    std                  | 0.577       |
|    value_loss           | 95.9        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0306       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 79.6         |
|    mean_reward          | 81.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.44540632   |
|    route_completion     | 0.372        |
|    success_rate         | 0            |
|    total_cost           | 6.9          |
| time/                   |              |
|    total_timesteps      | 850000       |
| train/                  |              |
|    approx_kl            | 0.0018764341 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    crash                | 0.139        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.5         |
|    max_step             | 0            |
|    n_updates            | 3320         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00118     |
|    route_completion     | 0.321        |
|    std                  | 0.578        |
|    total_cost           | 5.56         |
|    value_loss           | 111          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 360      |
| time/              |          |
|    fps             | 732      |
|    iterations      | 167      |
|    time_elapsed    | 1167     |
|    total_timesteps | 855040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0326       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 123          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.967        |
|    raw_action           | 0.4453387    |
|    route_completion     | 0.373        |
|    success_rate         | 0.1          |
|    total_cost           | 6.85         |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0018917837 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.137        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.579        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.5         |
|    max_step             | 0            |
|    n_updates            | 3340         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000757    |
|    route_completion     | 0.322        |
|    std                  | 0.576        |
|    total_cost           | 5.51         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 362      |
| time/              |          |
|    fps             | 730      |
|    iterations      | 168      |
|    time_elapsed    | 1177     |
|    total_timesteps | 860160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 354          |
| time/                   |              |
|    fps                  | 731          |
|    iterations           | 169          |
|    time_elapsed         | 1183         |
|    total_timesteps      | 865280       |
| train/                  |              |
|    approx_kl            | 0.0045703007 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.726        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.8         |
|    n_updates            | 3360         |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.577        |
|    value_loss           | 83.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0322       |
|    crash                | 0.228        |
|    max_step             | 0            |
|    mean_ep_length       | 155          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.968        |
|    raw_action           | 0.44488472   |
|    route_completion     | 0.374        |
|    success_rate         | 0            |
|    total_cost           | 7.08         |
| time/                   |              |
|    total_timesteps      | 870000       |
| train/                  |              |
|    approx_kl            | 0.0052780067 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    crash                | 0.136        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.549        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.4         |
|    max_step             | 0            |
|    n_updates            | 3380         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00226     |
|    route_completion     | 0.323        |
|    std                  | 0.577        |
|    total_cost           | 5.47         |
|    value_loss           | 143          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 365      |
| time/              |          |
|    fps             | 729      |
|    iterations      | 170      |
|    time_elapsed    | 1193     |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 340         |
|    ep_rew_mean          | 358         |
| time/                   |             |
|    fps                  | 730         |
|    iterations           | 171         |
|    time_elapsed         | 1199        |
|    total_timesteps      | 875520      |
| train/                  |             |
|    approx_kl            | 0.003021088 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.706       |
|    learning_rate        | 5e-05       |
|    loss                 | 50.6        |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.576       |
|    value_loss           | 73.7        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0318      |
|    crash                | 0.227       |
|    max_step             | 0           |
|    mean_ep_length       | 135         |
|    mean_reward          | 160         |
|    num_episodes         | 5           |
|    out_of_road          | 0.968       |
|    raw_action           | 0.44434628  |
|    route_completion     | 0.375       |
|    success_rate         | 0           |
|    total_cost           | 7.04        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.003466674 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.1         |
|    crash                | 0.134       |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.544       |
|    learning_rate        | 5e-05       |
|    loss                 | 46          |
|    max_step             | 0           |
|    n_updates            | 3420        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00122    |
|    route_completion     | 0.325       |
|    std                  | 0.576       |
|    total_cost           | 5.42        |
|    value_loss           | 134         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 357      |
| time/              |          |
|    fps             | 728      |
|    iterations      | 172      |
|    time_elapsed    | 1208     |
|    total_timesteps | 880640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 350          |
| time/                   |              |
|    fps                  | 728          |
|    iterations           | 173          |
|    time_elapsed         | 1215         |
|    total_timesteps      | 885760       |
| train/                  |              |
|    approx_kl            | 0.0035330765 |
|    clip_fraction        | 0.183        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.606        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.7         |
|    n_updates            | 3440         |
|    policy_gradient_loss | -0.00024     |
|    std                  | 0.574        |
|    value_loss           | 129          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0315       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 132          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.44407314   |
|    route_completion     | 0.377        |
|    success_rate         | 0            |
|    total_cost           | 6.97         |
| time/                   |              |
|    total_timesteps      | 890000       |
| train/                  |              |
|    approx_kl            | 0.0036025103 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.705        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.2         |
|    max_step             | 0            |
|    n_updates            | 3460         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00263     |
|    route_completion     | 0.326        |
|    std                  | 0.573        |
|    total_cost           | 5.38         |
|    value_loss           | 109          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 362      |
| time/              |          |
|    fps             | 728      |
|    iterations      | 174      |
|    time_elapsed    | 1223     |
|    total_timesteps | 890880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 365          |
| time/                   |              |
|    fps                  | 728          |
|    iterations           | 175          |
|    time_elapsed         | 1230         |
|    total_timesteps      | 896000       |
| train/                  |              |
|    approx_kl            | 0.0024770417 |
|    clip_fraction        | 0.19         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.878        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.8         |
|    n_updates            | 3480         |
|    policy_gradient_loss | 0.000599     |
|    std                  | 0.573        |
|    value_loss           | 63.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0311       |
|    crash                | 0.229        |
|    max_step             | 0            |
|    mean_ep_length       | 93.6         |
|    mean_reward          | 105          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.4433265    |
|    route_completion     | 0.376        |
|    success_rate         | 0            |
|    total_cost           | 6.9          |
| time/                   |              |
|    total_timesteps      | 900000       |
| train/                  |              |
|    approx_kl            | 0.0039848466 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.131        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.611        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.2         |
|    max_step             | 0            |
|    n_updates            | 3500         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00305     |
|    route_completion     | 0.328        |
|    std                  | 0.57         |
|    total_cost           | 5.33         |
|    value_loss           | 113          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    fps             | 727      |
|    iterations      | 176      |
|    time_elapsed    | 1238     |
|    total_timesteps | 901120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 352          |
|    ep_rew_mean          | 358          |
| time/                   |              |
|    fps                  | 727          |
|    iterations           | 177          |
|    time_elapsed         | 1245         |
|    total_timesteps      | 906240       |
| train/                  |              |
|    approx_kl            | 0.0019483641 |
|    clip_fraction        | 0.183        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.721        |
|    learning_rate        | 5e-05        |
|    loss                 | 37.1         |
|    n_updates            | 3520         |
|    policy_gradient_loss | 0.000613     |
|    std                  | 0.569        |
|    value_loss           | 66.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0308       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 104          |
|    mean_reward          | 119          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.44279075   |
|    route_completion     | 0.376        |
|    success_rate         | 0            |
|    total_cost           | 6.84         |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0019849283 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    crash                | 0.13         |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.632        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.9         |
|    max_step             | 0            |
|    n_updates            | 3540         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00106     |
|    route_completion     | 0.33         |
|    std                  | 0.567        |
|    total_cost           | 5.31         |
|    value_loss           | 118          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    fps             | 726      |
|    iterations      | 178      |
|    time_elapsed    | 1254     |
|    total_timesteps | 911360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 359          |
| time/                   |              |
|    fps                  | 726          |
|    iterations           | 179          |
|    time_elapsed         | 1261         |
|    total_timesteps      | 916480       |
| train/                  |              |
|    approx_kl            | 0.0015919369 |
|    clip_fraction        | 0.0997       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.675        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.8         |
|    n_updates            | 3560         |
|    policy_gradient_loss | -0.00353     |
|    std                  | 0.565        |
|    value_loss           | 110          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0304       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 172          |
|    num_episodes         | 5            |
|    out_of_road          | 0.97         |
|    raw_action           | 0.44287467   |
|    route_completion     | 0.378        |
|    success_rate         | 0            |
|    total_cost           | 6.9          |
| time/                   |              |
|    total_timesteps      | 920000       |
| train/                  |              |
|    approx_kl            | 0.0035896436 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    crash                | 0.128        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.757        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.1         |
|    max_step             | 0            |
|    n_updates            | 3580         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00109     |
|    route_completion     | 0.331        |
|    std                  | 0.565        |
|    total_cost           | 5.26         |
|    value_loss           | 71.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 364      |
| time/              |          |
|    fps             | 725      |
|    iterations      | 180      |
|    time_elapsed    | 1270     |
|    total_timesteps | 921600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 373          |
| time/                   |              |
|    fps                  | 725          |
|    iterations           | 181          |
|    time_elapsed         | 1277         |
|    total_timesteps      | 926720       |
| train/                  |              |
|    approx_kl            | 0.0028942486 |
|    clip_fraction        | 0.196        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.7         |
|    n_updates            | 3600         |
|    policy_gradient_loss | -0.00124     |
|    std                  | 0.563        |
|    value_loss           | 75.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0301      |
|    crash                | 0.232       |
|    max_step             | 0           |
|    mean_ep_length       | 111         |
|    mean_reward          | 143         |
|    num_episodes         | 5           |
|    out_of_road          | 0.97        |
|    raw_action           | 0.4428393   |
|    route_completion     | 0.379       |
|    success_rate         | 0           |
|    total_cost           | 6.84        |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.003273423 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.1         |
|    crash                | 0.127       |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.849       |
|    learning_rate        | 5e-05       |
|    loss                 | 26.4        |
|    max_step             | 0           |
|    n_updates            | 3620        |
|    out_of_road          | 1           |
|    policy_gradient_loss | 0.000844    |
|    route_completion     | 0.332       |
|    std                  | 0.563       |
|    total_cost           | 5.22        |
|    value_loss           | 58.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 373      |
| time/              |          |
|    fps             | 724      |
|    iterations      | 182      |
|    time_elapsed    | 1285     |
|    total_timesteps | 931840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 371          |
| time/                   |              |
|    fps                  | 725          |
|    iterations           | 183          |
|    time_elapsed         | 1292         |
|    total_timesteps      | 936960       |
| train/                  |              |
|    approx_kl            | 0.0023347281 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.713        |
|    learning_rate        | 5e-05        |
|    loss                 | 48           |
|    n_updates            | 3640         |
|    policy_gradient_loss | -0.00197     |
|    std                  | 0.561        |
|    value_loss           | 102          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0319       |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 198          |
|    mean_reward          | 241          |
|    num_episodes         | 5            |
|    out_of_road          | 0.968        |
|    raw_action           | 0.44286045   |
|    route_completion     | 0.382        |
|    success_rate         | 0.1          |
|    total_cost           | 6.87         |
| time/                   |              |
|    total_timesteps      | 940000       |
| train/                  |              |
|    approx_kl            | 0.0051046726 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    crash                | 0.126        |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.782        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.4         |
|    max_step             | 0            |
|    n_updates            | 3660         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00282     |
|    route_completion     | 0.332        |
|    std                  | 0.56         |
|    total_cost           | 5.18         |
|    value_loss           | 71.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    fps             | 724      |
|    iterations      | 184      |
|    time_elapsed    | 1300     |
|    total_timesteps | 942080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 369         |
|    ep_rew_mean          | 383         |
| time/                   |             |
|    fps                  | 724         |
|    iterations           | 185         |
|    time_elapsed         | 1307        |
|    total_timesteps      | 947200      |
| train/                  |             |
|    approx_kl            | 0.010859369 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.808       |
|    learning_rate        | 5e-05       |
|    loss                 | 38.6        |
|    n_updates            | 3680        |
|    policy_gradient_loss | 0.00475     |
|    std                  | 0.559       |
|    value_loss           | 72.2        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0358      |
|    crash                | 0.232       |
|    max_step             | 0           |
|    mean_ep_length       | 194         |
|    mean_reward          | 246         |
|    num_episodes         | 5           |
|    out_of_road          | 0.964       |
|    raw_action           | 0.4424764   |
|    route_completion     | 0.386       |
|    success_rate         | 0.2         |
|    total_cost           | 6.89        |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.011392862 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.1         |
|    crash                | 0.124       |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.847       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.9        |
|    max_step             | 0           |
|    n_updates            | 3700        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00286    |
|    route_completion     | 0.334       |
|    std                  | 0.561       |
|    total_cost           | 5.13        |
|    value_loss           | 67.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 381      |
| time/              |          |
|    fps             | 722      |
|    iterations      | 186      |
|    time_elapsed    | 1317     |
|    total_timesteps | 952320   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 378           |
|    ep_rew_mean          | 393           |
| time/                   |               |
|    fps                  | 723           |
|    iterations           | 187           |
|    time_elapsed         | 1323          |
|    total_timesteps      | 957440        |
| train/                  |               |
|    approx_kl            | 0.00091235695 |
|    clip_fraction        | 0.192         |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.63         |
|    explained_variance   | 0.778         |
|    learning_rate        | 5e-05         |
|    loss                 | 33.5          |
|    n_updates            | 3720          |
|    policy_gradient_loss | 0.00321       |
|    std                  | 0.559         |
|    value_loss           | 59.8          |
-------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0354      |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 122         |
|    mean_reward          | 156         |
|    num_episodes         | 5           |
|    out_of_road          | 0.965       |
|    raw_action           | 0.44194546  |
|    route_completion     | 0.386       |
|    success_rate         | 0           |
|    total_cost           | 6.84        |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.006431482 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.1         |
|    crash                | 0.123       |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.815       |
|    learning_rate        | 5e-05       |
|    loss                 | 34.1        |
|    max_step             | 0           |
|    n_updates            | 3740        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00331    |
|    route_completion     | 0.336       |
|    std                  | 0.557       |
|    total_cost           | 5.09        |
|    value_loss           | 64.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 390      |
| time/              |          |
|    fps             | 721      |
|    iterations      | 188      |
|    time_elapsed    | 1333     |
|    total_timesteps | 962560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 376          |
|    ep_rew_mean          | 392          |
| time/                   |              |
|    fps                  | 722          |
|    iterations           | 189          |
|    time_elapsed         | 1339         |
|    total_timesteps      | 967680       |
| train/                  |              |
|    approx_kl            | 0.0019699887 |
|    clip_fraction        | 0.2          |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.695        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.2         |
|    n_updates            | 3760         |
|    policy_gradient_loss | -0.000403    |
|    std                  | 0.556        |
|    value_loss           | 95.4         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0351      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 89.6        |
|    mean_reward          | 95.9        |
|    num_episodes         | 5           |
|    out_of_road          | 0.965       |
|    raw_action           | 0.4416378   |
|    route_completion     | 0.385       |
|    success_rate         | 0           |
|    total_cost           | 6.78        |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.004622376 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.1         |
|    crash                | 0.122       |
|    entropy_loss         | -1.62       |
|    explained_variance   | 0.822       |
|    learning_rate        | 5e-05       |
|    loss                 | 36.7        |
|    max_step             | 0           |
|    n_updates            | 3780        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.000953   |
|    route_completion     | 0.337       |
|    std                  | 0.557       |
|    total_cost           | 5.05        |
|    value_loss           | 71.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 383      |
| time/              |          |
|    fps             | 721      |
|    iterations      | 190      |
|    time_elapsed    | 1348     |
|    total_timesteps | 972800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 379         |
|    ep_rew_mean          | 395         |
| time/                   |             |
|    fps                  | 721         |
|    iterations           | 191         |
|    time_elapsed         | 1354        |
|    total_timesteps      | 977920      |
| train/                  |             |
|    approx_kl            | 0.002315694 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.62       |
|    explained_variance   | 0.696       |
|    learning_rate        | 5e-05       |
|    loss                 | 41.1        |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.0018     |
|    std                  | 0.556       |
|    value_loss           | 98.7        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0347      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 152         |
|    mean_reward          | 179         |
|    num_episodes         | 5           |
|    out_of_road          | 0.965       |
|    raw_action           | 0.4413469   |
|    route_completion     | 0.386       |
|    success_rate         | 0           |
|    total_cost           | 6.79        |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.018388651 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    crash                | 0.12        |
|    entropy_loss         | -1.62       |
|    explained_variance   | 0.838       |
|    learning_rate        | 5e-05       |
|    loss                 | 17.8        |
|    max_step             | 0           |
|    n_updates            | 3820        |
|    out_of_road          | 1           |
|    policy_gradient_loss | 0.0012      |
|    route_completion     | 0.338       |
|    std                  | 0.555       |
|    total_cost           | 5.02        |
|    value_loss           | 50.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 386      |
| time/              |          |
|    fps             | 720      |
|    iterations      | 192      |
|    time_elapsed    | 1364     |
|    total_timesteps | 983040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 372          |
|    ep_rew_mean          | 388          |
| time/                   |              |
|    fps                  | 720          |
|    iterations           | 193          |
|    time_elapsed         | 1371         |
|    total_timesteps      | 988160       |
| train/                  |              |
|    approx_kl            | 0.0026161124 |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.555        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.5         |
|    n_updates            | 3840         |
|    policy_gradient_loss | -0.000678    |
|    std                  | 0.555        |
|    value_loss           | 123          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0343       |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 148          |
|    mean_reward          | 165          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.44108373   |
|    route_completion     | 0.387        |
|    success_rate         | 0            |
|    total_cost           | 6.86         |
| time/                   |              |
|    total_timesteps      | 990000       |
| train/                  |              |
|    approx_kl            | 0.0017829153 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.094        |
|    clip_range           | 0.1          |
|    crash                | 0.119        |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.771        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.9         |
|    max_step             | 0            |
|    n_updates            | 3860         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0039      |
|    route_completion     | 0.339        |
|    std                  | 0.555        |
|    total_cost           | 4.98         |
|    value_loss           | 76.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 365      |
|    ep_rew_mean     | 382      |
| time/              |          |
|    fps             | 719      |
|    iterations      | 194      |
|    time_elapsed    | 1380     |
|    total_timesteps | 993280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 379          |
|    ep_rew_mean          | 392          |
| time/                   |              |
|    fps                  | 719          |
|    iterations           | 195          |
|    time_elapsed         | 1386         |
|    total_timesteps      | 998400       |
| train/                  |              |
|    approx_kl            | 0.0024661021 |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.3         |
|    n_updates            | 3880         |
|    policy_gradient_loss | -0.00143     |
|    std                  | 0.554        |
|    value_loss           | 78.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.034        |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 151          |
|    mean_reward          | 167          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.44068626   |
|    route_completion     | 0.387        |
|    success_rate         | 0            |
|    total_cost           | 6.86         |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0037723973 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.202        |
|    clip_range           | 0.1          |
|    crash                | 0.118        |
|    entropy_loss         | -1.6         |
|    explained_variance   | 0.828        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.7         |
|    max_step             | 0            |
|    n_updates            | 3900         |
|    out_of_road          | 1            |
|    policy_gradient_loss | 0.00098      |
|    route_completion     | 0.34         |
|    std                  | 0.552        |
|    total_cost           | 4.94         |
|    value_loss           | 56.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    fps             | 718      |
|    iterations      | 196      |
|    time_elapsed    | 1396     |
|    total_timesteps | 1003520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 375          |
|    ep_rew_mean          | 391          |
| time/                   |              |
|    fps                  | 719          |
|    iterations           | 197          |
|    time_elapsed         | 1402         |
|    total_timesteps      | 1008640      |
| train/                  |              |
|    approx_kl            | 0.0036264912 |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.6         |
|    explained_variance   | 0.687        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.2         |
|    n_updates            | 3920         |
|    policy_gradient_loss | -0.000877    |
|    std                  | 0.551        |
|    value_loss           | 88.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0337       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 100          |
|    mean_reward          | 108          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.44087705   |
|    route_completion     | 0.387        |
|    success_rate         | 0            |
|    total_cost           | 6.8          |
| time/                   |              |
|    total_timesteps      | 1010000      |
| train/                  |              |
|    approx_kl            | 0.0061584515 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    crash                | 0.119        |
|    entropy_loss         | -1.59        |
|    explained_variance   | 0.827        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.7         |
|    max_step             | 0            |
|    n_updates            | 3940         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00291     |
|    route_completion     | 0.341        |
|    std                  | 0.55         |
|    total_cost           | 4.91         |
|    value_loss           | 62.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    fps             | 717      |
|    iterations      | 198      |
|    time_elapsed    | 1413     |
|    total_timesteps | 1013760  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 363        |
|    ep_rew_mean          | 383        |
| time/                   |            |
|    fps                  | 717        |
|    iterations           | 199        |
|    time_elapsed         | 1419       |
|    total_timesteps      | 1018880    |
| train/                  |            |
|    approx_kl            | 0.02002823 |
|    clip_fraction        | 0.149      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.59      |
|    explained_variance   | 0.694      |
|    learning_rate        | 5e-05      |
|    loss                 | 38.4       |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.00161   |
|    std                  | 0.549      |
|    value_loss           | 101        |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0333      |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 107         |
|    mean_reward          | 135         |
|    num_episodes         | 5           |
|    out_of_road          | 0.967       |
|    raw_action           | 0.44068238  |
|    route_completion     | 0.386       |
|    success_rate         | 0           |
|    total_cost           | 6.75        |
| time/                   |             |
|    total_timesteps      | 1020000     |
| train/                  |             |
|    approx_kl            | 0.010242401 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.1         |
|    crash                | 0.12        |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.835       |
|    learning_rate        | 5e-05       |
|    loss                 | 40.6        |
|    max_step             | 0           |
|    n_updates            | 3980        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00238    |
|    route_completion     | 0.343       |
|    std                  | 0.55        |
|    total_cost           | 4.91        |
|    value_loss           | 71.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    fps             | 716      |
|    iterations      | 200      |
|    time_elapsed    | 1429     |
|    total_timesteps | 1024000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 344         |
|    ep_rew_mean          | 370         |
| time/                   |             |
|    fps                  | 716         |
|    iterations           | 201         |
|    time_elapsed         | 1435        |
|    total_timesteps      | 1029120     |
| train/                  |             |
|    approx_kl            | 0.008814286 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.632       |
|    learning_rate        | 5e-05       |
|    loss                 | 55.5        |
|    n_updates            | 4000        |
|    policy_gradient_loss | -0.00164    |
|    std                  | 0.55        |
|    value_loss           | 112         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.035        |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 150          |
|    mean_reward          | 186          |
|    num_episodes         | 5            |
|    out_of_road          | 0.965        |
|    raw_action           | 0.44062915   |
|    route_completion     | 0.389        |
|    success_rate         | 0.1          |
|    total_cost           | 6.73         |
| time/                   |              |
|    total_timesteps      | 1030000      |
| train/                  |              |
|    approx_kl            | 0.0025348044 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    crash                | 0.118        |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.3         |
|    max_step             | 0            |
|    n_updates            | 4020         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00185     |
|    route_completion     | 0.346        |
|    std                  | 0.548        |
|    total_cost           | 4.89         |
|    value_loss           | 109          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    fps             | 714      |
|    iterations      | 202      |
|    time_elapsed    | 1446     |
|    total_timesteps | 1034240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 329          |
|    ep_rew_mean          | 360          |
| time/                   |              |
|    fps                  | 715          |
|    iterations           | 203          |
|    time_elapsed         | 1453         |
|    total_timesteps      | 1039360      |
| train/                  |              |
|    approx_kl            | 0.0043086885 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.678        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.4         |
|    n_updates            | 4040         |
|    policy_gradient_loss | -0.00054     |
|    std                  | 0.548        |
|    value_loss           | 120          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0346      |
|    crash                | 0.244       |
|    max_step             | 0           |
|    mean_ep_length       | 116         |
|    mean_reward          | 142         |
|    num_episodes         | 5           |
|    out_of_road          | 0.965       |
|    raw_action           | 0.44058877  |
|    route_completion     | 0.389       |
|    success_rate         | 0           |
|    total_cost           | 6.68        |
| time/                   |             |
|    total_timesteps      | 1040000     |
| train/                  |             |
|    approx_kl            | 0.005309089 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.1         |
|    crash                | 0.117       |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.801       |
|    learning_rate        | 5e-05       |
|    loss                 | 34.7        |
|    max_step             | 0           |
|    n_updates            | 4060        |
|    out_of_road          | 1           |
|    policy_gradient_loss | 0.00061     |
|    route_completion     | 0.346       |
|    std                  | 0.548       |
|    total_cost           | 4.85        |
|    value_loss           | 77.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 367      |
| time/              |          |
|    fps             | 714      |
|    iterations      | 204      |
|    time_elapsed    | 1461     |
|    total_timesteps | 1044480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 363          |
| time/                   |              |
|    fps                  | 715          |
|    iterations           | 205          |
|    time_elapsed         | 1467         |
|    total_timesteps      | 1049600      |
| train/                  |              |
|    approx_kl            | 0.0028550266 |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.719        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.9         |
|    n_updates            | 4080         |
|    policy_gradient_loss | -0.0012      |
|    std                  | 0.547        |
|    value_loss           | 91.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0343       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 89.4         |
|    mean_reward          | 102          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.44040588   |
|    route_completion     | 0.388        |
|    success_rate         | 0            |
|    total_cost           | 6.63         |
| time/                   |              |
|    total_timesteps      | 1050000      |
| train/                  |              |
|    approx_kl            | 0.0014250804 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.2          |
|    clip_range           | 0.1          |
|    crash                | 0.116        |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.852        |
|    learning_rate        | 5e-05        |
|    loss                 | 21.9         |
|    max_step             | 0            |
|    n_updates            | 4100         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000372    |
|    route_completion     | 0.349        |
|    std                  | 0.548        |
|    total_cost           | 4.84         |
|    value_loss           | 61.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 373      |
| time/              |          |
|    fps             | 714      |
|    iterations      | 206      |
|    time_elapsed    | 1476     |
|    total_timesteps | 1054720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 347          |
|    ep_rew_mean          | 375          |
| time/                   |              |
|    fps                  | 714          |
|    iterations           | 207          |
|    time_elapsed         | 1483         |
|    total_timesteps      | 1059840      |
| train/                  |              |
|    approx_kl            | 0.0018960114 |
|    clip_fraction        | 0.2          |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.755        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.7         |
|    n_updates            | 4120         |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.549        |
|    value_loss           | 87.1         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.034       |
|    crash                | 0.242       |
|    max_step             | 0           |
|    mean_ep_length       | 103         |
|    mean_reward          | 135         |
|    num_episodes         | 5           |
|    out_of_road          | 0.966       |
|    raw_action           | 0.44022745  |
|    route_completion     | 0.388       |
|    success_rate         | 0           |
|    total_cost           | 6.58        |
| time/                   |             |
|    total_timesteps      | 1060000     |
| train/                  |             |
|    approx_kl            | 0.002682587 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.1         |
|    crash                | 0.115       |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.842       |
|    learning_rate        | 5e-05       |
|    loss                 | 30.5        |
|    max_step             | 0           |
|    n_updates            | 4140        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00177    |
|    route_completion     | 0.35        |
|    std                  | 0.548       |
|    total_cost           | 4.81        |
|    value_loss           | 69.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    fps             | 713      |
|    iterations      | 208      |
|    time_elapsed    | 1492     |
|    total_timesteps | 1064960  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0336      |
|    crash                | 0.241       |
|    max_step             | 0           |
|    mean_ep_length       | 90.8        |
|    mean_reward          | 99          |
|    num_episodes         | 5           |
|    out_of_road          | 0.966       |
|    raw_action           | 0.44000077  |
|    route_completion     | 0.388       |
|    success_rate         | 0           |
|    total_cost           | 6.53        |
| time/                   |             |
|    total_timesteps      | 1070000     |
| train/                  |             |
|    approx_kl            | 0.003353187 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.1         |
|    crash                | 0.114       |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.77        |
|    learning_rate        | 5e-05       |
|    loss                 | 31.6        |
|    max_step             | 0           |
|    n_updates            | 4160        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.000783   |
|    route_completion     | 0.351       |
|    std                  | 0.551       |
|    total_cost           | 4.77        |
|    value_loss           | 80.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 385      |
| time/              |          |
|    fps             | 712      |
|    iterations      | 209      |
|    time_elapsed    | 1501     |
|    total_timesteps | 1070080  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 356         |
|    ep_rew_mean          | 387         |
| time/                   |             |
|    fps                  | 712         |
|    iterations           | 210         |
|    time_elapsed         | 1508        |
|    total_timesteps      | 1075200     |
| train/                  |             |
|    approx_kl            | 0.015020059 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.839       |
|    learning_rate        | 5e-05       |
|    loss                 | 22.6        |
|    n_updates            | 4180        |
|    policy_gradient_loss | -0.000606   |
|    std                  | 0.549       |
|    value_loss           | 63.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0333       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 152          |
|    mean_reward          | 161          |
|    num_episodes         | 5            |
|    out_of_road          | 0.967        |
|    raw_action           | 0.43975785   |
|    route_completion     | 0.389        |
|    success_rate         | 0            |
|    total_cost           | 6.59         |
| time/                   |              |
|    total_timesteps      | 1080000      |
| train/                  |              |
|    approx_kl            | 0.0029403921 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    crash                | 0.113        |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0.717        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.8         |
|    max_step             | 0            |
|    n_updates            | 4200         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0014      |
|    route_completion     | 0.352        |
|    std                  | 0.547        |
|    total_cost           | 4.75         |
|    value_loss           | 112          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 390      |
| time/              |          |
|    fps             | 711      |
|    iterations      | 211      |
|    time_elapsed    | 1518     |
|    total_timesteps | 1080320  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 359          |
|    ep_rew_mean          | 391          |
| time/                   |              |
|    fps                  | 711          |
|    iterations           | 212          |
|    time_elapsed         | 1525         |
|    total_timesteps      | 1085440      |
| train/                  |              |
|    approx_kl            | 0.0047032805 |
|    clip_fraction        | 0.248        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.766        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.1         |
|    n_updates            | 4220         |
|    policy_gradient_loss | 0.00202      |
|    std                  | 0.547        |
|    value_loss           | 98           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.033        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 246          |
|    num_episodes         | 5            |
|    out_of_road          | 0.967        |
|    raw_action           | 0.43972      |
|    route_completion     | 0.392        |
|    success_rate         | 0            |
|    total_cost           | 6.54         |
| time/                   |              |
|    total_timesteps      | 1090000      |
| train/                  |              |
|    approx_kl            | 0.0059253825 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.112        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.813        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.4         |
|    max_step             | 0            |
|    n_updates            | 4240         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00146     |
|    route_completion     | 0.352        |
|    std                  | 0.547        |
|    total_cost           | 4.71         |
|    value_loss           | 79.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 367      |
|    ep_rew_mean     | 398      |
| time/              |          |
|    fps             | 710      |
|    iterations      | 213      |
|    time_elapsed    | 1534     |
|    total_timesteps | 1090560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 373          |
|    ep_rew_mean          | 405          |
| time/                   |              |
|    fps                  | 710          |
|    iterations           | 214          |
|    time_elapsed         | 1541         |
|    total_timesteps      | 1095680      |
| train/                  |              |
|    approx_kl            | 0.0030935768 |
|    clip_fraction        | 0.249        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.788        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.1         |
|    n_updates            | 4260         |
|    policy_gradient_loss | 0.0038       |
|    std                  | 0.544        |
|    value_loss           | 70.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0327      |
|    crash                | 0.247       |
|    max_step             | 0           |
|    mean_ep_length       | 116         |
|    mean_reward          | 139         |
|    num_episodes         | 5           |
|    out_of_road          | 0.967       |
|    raw_action           | 0.43948045  |
|    route_completion     | 0.392       |
|    success_rate         | 0           |
|    total_cost           | 6.5         |
| time/                   |             |
|    total_timesteps      | 1100000     |
| train/                  |             |
|    approx_kl            | 0.028027881 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    crash                | 0.111       |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.867       |
|    learning_rate        | 5e-05       |
|    loss                 | 15.4        |
|    max_step             | 0           |
|    n_updates            | 4280        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00114    |
|    route_completion     | 0.354       |
|    std                  | 0.543       |
|    total_cost           | 4.68        |
|    value_loss           | 47.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 406      |
| time/              |          |
|    fps             | 709      |
|    iterations      | 215      |
|    time_elapsed    | 1550     |
|    total_timesteps | 1100800  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 370          |
|    ep_rew_mean          | 397          |
| time/                   |              |
|    fps                  | 710          |
|    iterations           | 216          |
|    time_elapsed         | 1556         |
|    total_timesteps      | 1105920      |
| train/                  |              |
|    approx_kl            | 0.0025896484 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.55        |
|    explained_variance   | 0.815        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.9         |
|    n_updates            | 4300         |
|    policy_gradient_loss | 0.000119     |
|    std                  | 0.542        |
|    value_loss           | 67.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0324      |
|    crash                | 0.245       |
|    max_step             | 0           |
|    mean_ep_length       | 185         |
|    mean_reward          | 219         |
|    num_episodes         | 5           |
|    out_of_road          | 0.968       |
|    raw_action           | 0.43941608  |
|    route_completion     | 0.395       |
|    success_rate         | 0           |
|    total_cost           | 6.61        |
| time/                   |             |
|    total_timesteps      | 1110000     |
| train/                  |             |
|    approx_kl            | 0.011958864 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    crash                | 0.11        |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.768       |
|    learning_rate        | 5e-05       |
|    loss                 | 32.4        |
|    max_step             | 0           |
|    n_updates            | 4320        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00157    |
|    route_completion     | 0.354       |
|    std                  | 0.541       |
|    total_cost           | 4.65        |
|    value_loss           | 78.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 392      |
|    ep_rew_mean     | 412      |
| time/              |          |
|    fps             | 709      |
|    iterations      | 217      |
|    time_elapsed    | 1566     |
|    total_timesteps | 1111040  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 414         |
| time/                   |             |
|    fps                  | 708         |
|    iterations           | 218         |
|    time_elapsed         | 1574        |
|    total_timesteps      | 1116160     |
| train/                  |             |
|    approx_kl            | 0.017101262 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.875       |
|    learning_rate        | 5e-05       |
|    loss                 | 12.7        |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.00206     |
|    std                  | 0.542       |
|    value_loss           | 48.1        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0339       |
|    crash                | 0.245        |
|    max_step             | 0            |
|    mean_ep_length       | 140          |
|    mean_reward          | 125          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.4390629    |
|    route_completion     | 0.396        |
|    success_rate         | 0.1          |
|    total_cost           | 6.72         |
| time/                   |              |
|    total_timesteps      | 1120000      |
| train/                  |              |
|    approx_kl            | 0.0016098308 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.109        |
|    entropy_loss         | -1.55        |
|    explained_variance   | 0.811        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.2         |
|    max_step             | 0            |
|    n_updates            | 4360         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00137     |
|    route_completion     | 0.356        |
|    std                  | 0.542        |
|    total_cost           | 4.63         |
|    value_loss           | 52           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 395      |
|    ep_rew_mean     | 412      |
| time/              |          |
|    fps             | 707      |
|    iterations      | 219      |
|    time_elapsed    | 1585     |
|    total_timesteps | 1121280  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 406         |
| time/                   |             |
|    fps                  | 707         |
|    iterations           | 220         |
|    time_elapsed         | 1592        |
|    total_timesteps      | 1126400     |
| train/                  |             |
|    approx_kl            | 0.001732061 |
|    clip_fraction        | 0.0752      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.756       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.2        |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.00301    |
|    std                  | 0.542       |
|    value_loss           | 82.3        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0336       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 203          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.4391021    |
|    route_completion     | 0.398        |
|    success_rate         | 0            |
|    total_cost           | 6.68         |
| time/                   |              |
|    total_timesteps      | 1130000      |
| train/                  |              |
|    approx_kl            | 0.0020718877 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.1          |
|    crash                | 0.108        |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.8         |
|    max_step             | 0            |
|    n_updates            | 4400         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00122     |
|    route_completion     | 0.358        |
|    std                  | 0.54         |
|    total_cost           | 4.63         |
|    value_loss           | 96.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 393      |
| time/              |          |
|    fps             | 705      |
|    iterations      | 221      |
|    time_elapsed    | 1602     |
|    total_timesteps | 1131520  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 367         |
|    ep_rew_mean          | 391         |
| time/                   |             |
|    fps                  | 706         |
|    iterations           | 222         |
|    time_elapsed         | 1609        |
|    total_timesteps      | 1136640     |
| train/                  |             |
|    approx_kl            | 0.003175411 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.756       |
|    learning_rate        | 5e-05       |
|    loss                 | 54.8        |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.00203    |
|    std                  | 0.54        |
|    value_loss           | 119         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0333       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 153          |
|    mean_reward          | 209          |
|    num_episodes         | 5            |
|    out_of_road          | 0.967        |
|    raw_action           | 0.43906066   |
|    route_completion     | 0.399        |
|    success_rate         | 0            |
|    total_cost           | 6.66         |
| time/                   |              |
|    total_timesteps      | 1140000      |
| train/                  |              |
|    approx_kl            | 0.0024144887 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.1          |
|    crash                | 0.107        |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.801        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.1         |
|    max_step             | 0            |
|    n_updates            | 4440         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00145     |
|    route_completion     | 0.359        |
|    std                  | 0.541        |
|    total_cost           | 4.6          |
|    value_loss           | 83.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 384      |
| time/              |          |
|    fps             | 705      |
|    iterations      | 223      |
|    time_elapsed    | 1619     |
|    total_timesteps | 1141760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 367          |
|    ep_rew_mean          | 399          |
| time/                   |              |
|    fps                  | 705          |
|    iterations           | 224          |
|    time_elapsed         | 1626         |
|    total_timesteps      | 1146880      |
| train/                  |              |
|    approx_kl            | 0.0019822759 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.79         |
|    learning_rate        | 5e-05        |
|    loss                 | 37.7         |
|    n_updates            | 4460         |
|    policy_gradient_loss | -0.00213     |
|    std                  | 0.541        |
|    value_loss           | 82.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0348       |
|    crash                | 0.247        |
|    max_step             | 0            |
|    mean_ep_length       | 128          |
|    mean_reward          | 143          |
|    num_episodes         | 5            |
|    out_of_road          | 0.965        |
|    raw_action           | 0.4389124    |
|    route_completion     | 0.4          |
|    success_rate         | 0.1          |
|    total_cost           | 6.67         |
| time/                   |              |
|    total_timesteps      | 1150000      |
| train/                  |              |
|    approx_kl            | 0.0029460578 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.233        |
|    clip_range           | 0.1          |
|    crash                | 0.106        |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.814        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.6         |
|    max_step             | 0            |
|    n_updates            | 4480         |
|    out_of_road          | 1            |
|    policy_gradient_loss | 0.00106      |
|    route_completion     | 0.36         |
|    std                  | 0.54         |
|    total_cost           | 4.58         |
|    value_loss           | 66.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 338      |
|    ep_rew_mean     | 375      |
| time/              |          |
|    fps             | 704      |
|    iterations      | 225      |
|    time_elapsed    | 1635     |
|    total_timesteps | 1152000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 329         |
|    ep_rew_mean          | 367         |
| time/                   |             |
|    fps                  | 704         |
|    iterations           | 226         |
|    time_elapsed         | 1642        |
|    total_timesteps      | 1157120     |
| train/                  |             |
|    approx_kl            | 0.009644417 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.717       |
|    learning_rate        | 5e-05       |
|    loss                 | 43.9        |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.000847   |
|    std                  | 0.54        |
|    value_loss           | 110         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0345       |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 134          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.43897244   |
|    route_completion     | 0.4          |
|    success_rate         | 0            |
|    total_cost           | 6.62         |
| time/                   |              |
|    total_timesteps      | 1160000      |
| train/                  |              |
|    approx_kl            | 0.0018256005 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.169        |
|    clip_range           | 0.1          |
|    crash                | 0.105        |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.774        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.4         |
|    max_step             | 0            |
|    n_updates            | 4520         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00208     |
|    route_completion     | 0.36         |
|    std                  | 0.541        |
|    total_cost           | 4.55         |
|    value_loss           | 94.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    fps             | 704      |
|    iterations      | 227      |
|    time_elapsed    | 1650     |
|    total_timesteps | 1162240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 333         |
|    ep_rew_mean          | 370         |
| time/                   |             |
|    fps                  | 704         |
|    iterations           | 228         |
|    time_elapsed         | 1657        |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.005688964 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.743       |
|    learning_rate        | 5e-05       |
|    loss                 | 35.8        |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.00295    |
|    std                  | 0.538       |
|    value_loss           | 83.2        |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0342     |
|    crash                | 0.25       |
|    max_step             | 0          |
|    mean_ep_length       | 102        |
|    mean_reward          | 128        |
|    num_episodes         | 5          |
|    out_of_road          | 0.966      |
|    raw_action           | 0.43857437 |
|    route_completion     | 0.4        |
|    success_rate         | 0          |
|    total_cost           | 6.57       |
| time/                   |            |
|    total_timesteps      | 1170000    |
| train/                  |            |
|    approx_kl            | 0.03198114 |
|    arrive_dest          | 0          |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.1        |
|    crash                | 0.104      |
|    entropy_loss         | -1.53      |
|    explained_variance   | 0.853      |
|    learning_rate        | 5e-05      |
|    loss                 | 22.3       |
|    max_step             | 0          |
|    n_updates            | 4560       |
|    out_of_road          | 1          |
|    policy_gradient_loss | -0.00149   |
|    route_completion     | 0.362      |
|    std                  | 0.537      |
|    total_cost           | 4.54       |
|    value_loss           | 60.6       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    fps             | 703      |
|    iterations      | 229      |
|    time_elapsed    | 1666     |
|    total_timesteps | 1172480  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 342         |
|    ep_rew_mean          | 376         |
| time/                   |             |
|    fps                  | 703         |
|    iterations           | 230         |
|    time_elapsed         | 1673        |
|    total_timesteps      | 1177600     |
| train/                  |             |
|    approx_kl            | 0.015268266 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.676       |
|    learning_rate        | 5e-05       |
|    loss                 | 23.4        |
|    n_updates            | 4580        |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.537       |
|    value_loss           | 101         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0339       |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 126          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.4383056    |
|    route_completion     | 0.4          |
|    success_rate         | 0            |
|    total_cost           | 6.53         |
| time/                   |              |
|    total_timesteps      | 1180000      |
| train/                  |              |
|    approx_kl            | 0.0015479979 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    crash                | 0.103        |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.763        |
|    learning_rate        | 5e-05        |
|    loss                 | 48           |
|    max_step             | 0            |
|    n_updates            | 4600         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00235     |
|    route_completion     | 0.363        |
|    std                  | 0.539        |
|    total_cost           | 4.52         |
|    value_loss           | 92.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    fps             | 702      |
|    iterations      | 231      |
|    time_elapsed    | 1682     |
|    total_timesteps | 1182720  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 342         |
|    ep_rew_mean          | 376         |
| time/                   |             |
|    fps                  | 703         |
|    iterations           | 232         |
|    time_elapsed         | 1688        |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.008551331 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.739       |
|    learning_rate        | 5e-05       |
|    loss                 | 32.9        |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.00118    |
|    std                  | 0.539       |
|    value_loss           | 102         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0336       |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 117          |
|    mean_reward          | 142          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.4381533    |
|    route_completion     | 0.401        |
|    success_rate         | 0            |
|    total_cost           | 6.5          |
| time/                   |              |
|    total_timesteps      | 1190000      |
| train/                  |              |
|    approx_kl            | 0.0068211234 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.1          |
|    crash                | 0.103        |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.812        |
|    learning_rate        | 5e-05        |
|    loss                 | 19.4         |
|    max_step             | 0            |
|    n_updates            | 4640         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000443    |
|    route_completion     | 0.363        |
|    std                  | 0.539        |
|    total_cost           | 4.49         |
|    value_loss           | 59.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 367      |
| time/              |          |
|    fps             | 702      |
|    iterations      | 233      |
|    time_elapsed    | 1697     |
|    total_timesteps | 1192960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 356          |
|    ep_rew_mean          | 390          |
| time/                   |              |
|    fps                  | 703          |
|    iterations           | 234          |
|    time_elapsed         | 1703         |
|    total_timesteps      | 1198080      |
| train/                  |              |
|    approx_kl            | 0.0023140586 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.2         |
|    n_updates            | 4660         |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.538        |
|    value_loss           | 96.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0333       |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 138          |
|    mean_reward          | 195          |
|    num_episodes         | 5            |
|    out_of_road          | 0.967        |
|    raw_action           | 0.43850285   |
|    route_completion     | 0.402        |
|    success_rate         | 0            |
|    total_cost           | 6.46         |
| time/                   |              |
|    total_timesteps      | 1200000      |
| train/                  |              |
|    approx_kl            | 0.0027117073 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.263        |
|    clip_range           | 0.1          |
|    crash                | 0.103        |
|    entropy_loss         | -1.52        |
|    explained_variance   | 0.852        |
|    learning_rate        | 5e-05        |
|    loss                 | 13.6         |
|    max_step             | 0            |
|    n_updates            | 4680         |
|    out_of_road          | 1            |
|    policy_gradient_loss | 0.00503      |
|    route_completion     | 0.365        |
|    std                  | 0.537        |
|    total_cost           | 4.47         |
|    value_loss           | 52.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 392      |
| time/              |          |
|    fps             | 701      |
|    iterations      | 235      |
|    time_elapsed    | 1714     |
|    total_timesteps | 1203200  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 364         |
|    ep_rew_mean          | 402         |
| time/                   |             |
|    fps                  | 702         |
|    iterations           | 236         |
|    time_elapsed         | 1720        |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.003005714 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.785       |
|    learning_rate        | 5e-05       |
|    loss                 | 70.1        |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.00175    |
|    std                  | 0.539       |
|    value_loss           | 113         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0331      |
|    crash                | 0.255       |
|    max_step             | 0           |
|    mean_ep_length       | 112         |
|    mean_reward          | 136         |
|    num_episodes         | 5           |
|    out_of_road          | 0.967       |
|    raw_action           | 0.43844086  |
|    route_completion     | 0.402       |
|    success_rate         | 0           |
|    total_cost           | 6.42        |
| time/                   |             |
|    total_timesteps      | 1210000     |
| train/                  |             |
|    approx_kl            | 0.002826163 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.1         |
|    crash                | 0.102       |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.868       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.1        |
|    max_step             | 0           |
|    n_updates            | 4720        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00167    |
|    route_completion     | 0.365       |
|    std                  | 0.538       |
|    total_cost           | 4.44        |
|    value_loss           | 66.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 398      |
| time/              |          |
|    fps             | 702      |
|    iterations      | 237      |
|    time_elapsed    | 1728     |
|    total_timesteps | 1213440  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 374          |
|    ep_rew_mean          | 413          |
| time/                   |              |
|    fps                  | 702          |
|    iterations           | 238          |
|    time_elapsed         | 1734         |
|    total_timesteps      | 1218560      |
| train/                  |              |
|    approx_kl            | 0.0054668384 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.51        |
|    explained_variance   | 0.768        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.6         |
|    n_updates            | 4740         |
|    policy_gradient_loss | -0.00275     |
|    std                  | 0.535        |
|    value_loss           | 79.6         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0328     |
|    crash                | 0.252      |
|    max_step             | 0          |
|    mean_ep_length       | 95.2       |
|    mean_reward          | 107        |
|    num_episodes         | 5          |
|    out_of_road          | 0.967      |
|    raw_action           | 0.43800098 |
|    route_completion     | 0.402      |
|    success_rate         | 0          |
|    total_cost           | 6.39       |
| time/                   |            |
|    total_timesteps      | 1220000    |
| train/                  |            |
|    approx_kl            | 0.00552746 |
|    arrive_dest          | 0          |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.1        |
|    crash                | 0.102      |
|    entropy_loss         | -1.51      |
|    explained_variance   | 0.835      |
|    learning_rate        | 5e-05      |
|    loss                 | 34.8       |
|    max_step             | 0          |
|    n_updates            | 4760       |
|    out_of_road          | 1          |
|    policy_gradient_loss | -0.00168   |
|    route_completion     | 0.367      |
|    std                  | 0.535      |
|    total_cost           | 4.42       |
|    value_loss           | 73.3       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 402      |
| time/              |          |
|    fps             | 701      |
|    iterations      | 239      |
|    time_elapsed    | 1743     |
|    total_timesteps | 1223680  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 369         |
|    ep_rew_mean          | 408         |
| time/                   |             |
|    fps                  | 702         |
|    iterations           | 240         |
|    time_elapsed         | 1750        |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.002641397 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.806       |
|    learning_rate        | 5e-05       |
|    loss                 | 58.2        |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.00161    |
|    std                  | 0.533       |
|    value_loss           | 89.2        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0341       |
|    crash                | 0.254        |
|    max_step             | 0            |
|    mean_ep_length       | 160          |
|    mean_reward          | 233          |
|    num_episodes         | 5            |
|    out_of_road          | 0.966        |
|    raw_action           | 0.4380627    |
|    route_completion     | 0.403        |
|    success_rate         | 0.1          |
|    total_cost           | 6.36         |
| time/                   |              |
|    total_timesteps      | 1230000      |
| train/                  |              |
|    approx_kl            | 0.0022631811 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.101        |
|    entropy_loss         | -1.5         |
|    explained_variance   | 0.777        |
|    learning_rate        | 5e-05        |
|    loss                 | 56           |
|    max_step             | 0            |
|    n_updates            | 4800         |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00089     |
|    route_completion     | 0.367        |
|    std                  | 0.532        |
|    total_cost           | 4.39         |
|    value_loss           | 117          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    fps             | 701      |
|    iterations      | 241      |
|    time_elapsed    | 1759     |
|    total_timesteps | 1233920  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 365          |
|    ep_rew_mean          | 404          |
| time/                   |              |
|    fps                  | 701          |
|    iterations           | 242          |
|    time_elapsed         | 1765         |
|    total_timesteps      | 1239040      |
| train/                  |              |
|    approx_kl            | 0.0019475261 |
|    clip_fraction        | 0.18         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.5         |
|    explained_variance   | 0.699        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.1         |
|    n_updates            | 4820         |
|    policy_gradient_loss | -1.13e-05    |
|    std                  | 0.532        |
|    value_loss           | 113          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0355       |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 179          |
|    mean_reward          | 258          |
|    num_episodes         | 5            |
|    out_of_road          | 0.965        |
|    raw_action           | 0.4380198    |
|    route_completion     | 0.406        |
|    success_rate         | 0.1          |
|    total_cost           | 6.36         |
| time/                   |              |
|    total_timesteps      | 1240000      |
| train/                  |              |
|    approx_kl            | 0.0026436923 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.204        |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -1.49        |
|    explained_variance   | 0.779        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.2         |
|    max_step             | 0            |
|    n_updates            | 4840         |
|    out_of_road          | 1            |
|    policy_gradient_loss | 5.9e-05      |
|    route_completion     | 0.367        |
|    std                  | 0.532        |
|    total_cost           | 4.36         |
|    value_loss           | 107          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 395      |
| time/              |          |
|    fps             | 700      |
|    iterations      | 243      |
|    time_elapsed    | 1775     |
|    total_timesteps | 1244160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 396          |
| time/                   |              |
|    fps                  | 701          |
|    iterations           | 244          |
|    time_elapsed         | 1781         |
|    total_timesteps      | 1249280      |
| train/                  |              |
|    approx_kl            | 0.0032285112 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.49        |
|    explained_variance   | 0.821        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.2         |
|    n_updates            | 4860         |
|    policy_gradient_loss | -0.00434     |
|    std                  | 0.53         |
|    value_loss           | 51.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0352      |
|    crash                | 0.256       |
|    max_step             | 0           |
|    mean_ep_length       | 136         |
|    mean_reward          | 158         |
|    num_episodes         | 5           |
|    out_of_road          | 0.965       |
|    raw_action           | 0.4378072   |
|    route_completion     | 0.407       |
|    success_rate         | 0           |
|    total_cost           | 6.35        |
| time/                   |             |
|    total_timesteps      | 1250000     |
| train/                  |             |
|    approx_kl            | 0.008208254 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.1         |
|    crash                | 0.0992      |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.825       |
|    learning_rate        | 5e-05       |
|    loss                 | 36.2        |
|    max_step             | 0           |
|    n_updates            | 4880        |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.0012     |
|    route_completion     | 0.369       |
|    std                  | 0.53        |
|    total_cost           | 4.34        |
|    value_loss           | 88.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 395      |
| time/              |          |
|    fps             | 700      |
|    iterations      | 245      |
|    time_elapsed    | 1791     |
|    total_timesteps | 1254400  |
---------------------------------
