Using cpu device
Logging to runs\ppo_metadrive_final_testing\ppo_metadrive_final_testing_2025-03-19_20-51-58_42b6ed17\ppo_metadrive_final_testing_1
-----------------------------
| time/              |      |
|    fps             | 1636 |
|    iterations      | 1    |
|    time_elapsed    | 3    |
|    total_timesteps | 5120 |
-----------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0           |
|    max_step             | 0           |
|    mean_ep_length       | 266         |
|    mean_reward          | 109         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.04870801  |
|    route_completion     | 0.312       |
|    success_rate         | 0           |
|    total_cost           | 1           |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.003864111 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.1         |
|    crash                | 0           |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.0391      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00522    |
|    max_step             | 0           |
|    n_updates            | 20          |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.0146     |
|    route_completion     | 0.184       |
|    std                  | 0.996       |
|    total_cost           | 1           |
|    value_loss           | 0.0167      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 621      |
|    ep_rew_mean     | 30       |
| time/              |          |
|    fps             | 669      |
|    iterations      | 2        |
|    time_elapsed    | 15       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 511         |
|    ep_rew_mean          | 18.6        |
| time/                   |             |
|    fps                  | 778         |
|    iterations           | 3           |
|    time_elapsed         | 19          |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.002812487 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.0189      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0363      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00393    |
|    std                  | 0.993       |
|    value_loss           | 0.146       |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 55           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.077937685  |
|    route_completion     | 0.253        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0030129426 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.192        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.82        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.00291      |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0062      |
|    route_completion     | 0.231        |
|    std                  | 0.989        |
|    total_cost           | 2.7          |
|    value_loss           | 0.124        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 542      |
|    ep_rew_mean     | 14.5     |
| time/              |          |
|    fps             | 664      |
|    iterations      | 4        |
|    time_elapsed    | 30       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 481         |
|    ep_rew_mean          | 14.2        |
| time/                   |             |
|    fps                  | 707         |
|    iterations           | 5           |
|    time_elapsed         | 36          |
|    total_timesteps      | 25600       |
| train/                  |             |
|    approx_kl            | 0.002076075 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0.016       |
|    learning_rate        | 5e-05       |
|    loss                 | 0.254       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00274    |
|    std                  | 0.984       |
|    value_loss           | 0.455       |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 61.6         |
|    mean_reward          | 15.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.101357445  |
|    route_completion     | 0.187        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0031100644 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.0667       |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.021        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.209        |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00428     |
|    route_completion     | 0.214        |
|    std                  | 0.983        |
|    total_cost           | 2.53         |
|    value_loss           | 0.304        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 16.7     |
| time/              |          |
|    fps             | 667      |
|    iterations      | 6        |
|    time_elapsed    | 46       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 439          |
|    ep_rew_mean          | 14.5         |
| time/                   |              |
|    fps                  | 704          |
|    iterations           | 7            |
|    time_elapsed         | 50           |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 0.0026964606 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.0121       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.131        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00402     |
|    std                  | 0.98         |
|    value_loss           | 0.468        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 92.2         |
|    mean_reward          | 56.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.12344192   |
|    route_completion     | 0.183        |
|    success_rate         | 0            |
|    total_cost           | 1.1          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0032949564 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.05         |
|    entropy_loss         | -2.8         |
|    explained_variance   | -0.00128     |
|    learning_rate        | 5e-05        |
|    loss                 | 0.245        |
|    max_step             | 0            |
|    n_updates            | 140          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00486     |
|    route_completion     | 0.194        |
|    std                  | 0.978        |
|    total_cost           | 2.15         |
|    value_loss           | 0.375        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 15.9     |
| time/              |          |
|    fps             | 680      |
|    iterations      | 8        |
|    time_elapsed    | 60       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 417          |
|    ep_rew_mean          | 15.1         |
| time/                   |              |
|    fps                  | 708          |
|    iterations           | 9            |
|    time_elapsed         | 64           |
|    total_timesteps      | 46080        |
| train/                  |              |
|    approx_kl            | 0.0023622848 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0126       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.582        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00334     |
|    std                  | 0.976        |
|    value_loss           | 0.935        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.04         |
|    max_step             | 0            |
|    mean_ep_length       | 77.4         |
|    mean_reward          | 49.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.14077993   |
|    route_completion     | 0.181        |
|    success_rate         | 0            |
|    total_cost           | 1.08         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0025045872 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    crash                | 0.04         |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.0504       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.227        |
|    max_step             | 0            |
|    n_updates            | 180          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00366     |
|    route_completion     | 0.173        |
|    std                  | 0.969        |
|    total_cost           | 1.92         |
|    value_loss           | 0.502        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 15.5     |
| time/              |          |
|    fps             | 683      |
|    iterations      | 10       |
|    time_elapsed    | 74       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 381          |
|    ep_rew_mean          | 15.4         |
| time/                   |              |
|    fps                  | 698          |
|    iterations           | 11           |
|    time_elapsed         | 80           |
|    total_timesteps      | 56320        |
| train/                  |              |
|    approx_kl            | 0.0017640723 |
|    clip_fraction        | 0.0649       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.0409       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.592        |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00181     |
|    std                  | 0.961        |
|    value_loss           | 1.51         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 68           |
|    mean_reward          | 44.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.16209592   |
|    route_completion     | 0.179        |
|    success_rate         | 0            |
|    total_cost           | 1.1          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0028996312 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    crash                | 0.0333       |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.152        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.538        |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0054      |
|    route_completion     | 0.166        |
|    std                  | 0.952        |
|    total_cost           | 1.77         |
|    value_loss           | 0.966        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 16.2     |
| time/              |          |
|    fps             | 664      |
|    iterations      | 12       |
|    time_elapsed    | 92       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 325          |
|    ep_rew_mean          | 15.6         |
| time/                   |              |
|    fps                  | 660          |
|    iterations           | 13           |
|    time_elapsed         | 100          |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0020041936 |
|    clip_fraction        | 0.0568       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0722       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.925        |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00207     |
|    std                  | 0.946        |
|    value_loss           | 1.94         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.114        |
|    max_step             | 0            |
|    mean_ep_length       | 52.4         |
|    mean_reward          | 31.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.18053189   |
|    route_completion     | 0.172        |
|    success_rate         | 0            |
|    total_cost           | 1.09         |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0015064774 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.1          |
|    crash                | 0.0286       |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.0457       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.26         |
|    max_step             | 0            |
|    n_updates            | 260          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00128     |
|    route_completion     | 0.159        |
|    std                  | 0.944        |
|    total_cost           | 1.66         |
|    value_loss           | 2.16         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | 14.2     |
| time/              |          |
|    fps             | 631      |
|    iterations      | 14       |
|    time_elapsed    | 113      |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 198          |
|    ep_rew_mean          | 13.1         |
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 15           |
|    time_elapsed         | 121          |
|    total_timesteps      | 76800        |
| train/                  |              |
|    approx_kl            | 0.0010373917 |
|    clip_fraction        | 0.0456       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.72        |
|    explained_variance   | -0.00555     |
|    learning_rate        | 5e-05        |
|    loss                 | 1.9          |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.0017      |
|    std                  | 0.94         |
|    value_loss           | 3.78         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 58.2         |
|    mean_reward          | 41.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.20010774   |
|    route_completion     | 0.17         |
|    success_rate         | 0            |
|    total_cost           | 1.07         |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0012645028 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0525       |
|    clip_range           | 0.1          |
|    crash                | 0.025        |
|    entropy_loss         | -2.71        |
|    explained_variance   | -0.00288     |
|    learning_rate        | 5e-05        |
|    loss                 | 0.862        |
|    max_step             | 0            |
|    n_updates            | 300          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00158     |
|    route_completion     | 0.153        |
|    std                  | 0.937        |
|    total_cost           | 1.57         |
|    value_loss           | 2.67         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 14.2     |
| time/              |          |
|    fps             | 625      |
|    iterations      | 16       |
|    time_elapsed    | 130      |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 13.9        |
| time/                   |             |
|    fps                  | 616         |
|    iterations           | 17          |
|    time_elapsed         | 141         |
|    total_timesteps      | 87040       |
| train/                  |             |
|    approx_kl            | 0.001837334 |
|    clip_fraction        | 0.0724      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.7        |
|    explained_variance   | 0.0252      |
|    learning_rate        | 5e-05       |
|    loss                 | 1.22        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.93        |
|    value_loss           | 2.78        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.111        |
|    max_step             | 0            |
|    mean_ep_length       | 36.4         |
|    mean_reward          | 14.4         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.21329612   |
|    route_completion     | 0.16         |
|    success_rate         | 0            |
|    total_cost           | 1.07         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0014904672 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0538       |
|    clip_range           | 0.1          |
|    crash                | 0.0222       |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.0113       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.1          |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00163     |
|    route_completion     | 0.145        |
|    std                  | 0.927        |
|    total_cost           | 1.51         |
|    value_loss           | 4.6          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 163      |
|    ep_rew_mean     | 14       |
| time/              |          |
|    fps             | 601      |
|    iterations      | 18       |
|    time_elapsed    | 153      |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 164          |
|    ep_rew_mean          | 15.4         |
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 19           |
|    time_elapsed         | 163          |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0014673376 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.68        |
|    explained_variance   | 0.023        |
|    learning_rate        | 5e-05        |
|    loss                 | 2.45         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00203     |
|    std                  | 0.92         |
|    value_loss           | 4.66         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.14         |
|    max_step             | 0            |
|    mean_ep_length       | 62           |
|    mean_reward          | 49.4         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.22996162   |
|    route_completion     | 0.163        |
|    success_rate         | 0            |
|    total_cost           | 1.06         |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0015837427 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0401       |
|    clip_range           | 0.1          |
|    crash                | 0.02         |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.0816       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.52         |
|    max_step             | 0            |
|    n_updates            | 380          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00266     |
|    route_completion     | 0.143        |
|    std                  | 0.913        |
|    total_cost           | 1.46         |
|    value_loss           | 8.71         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | 13.1     |
| time/              |          |
|    fps             | 578      |
|    iterations      | 20       |
|    time_elapsed    | 176      |
|    total_timesteps | 102400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 136          |
|    ep_rew_mean          | 13.9         |
| time/                   |              |
|    fps                  | 573          |
|    iterations           | 21           |
|    time_elapsed         | 187          |
|    total_timesteps      | 107520       |
| train/                  |              |
|    approx_kl            | 0.0010383099 |
|    clip_fraction        | 0.0307       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0809       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.47         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00115     |
|    std                  | 0.91         |
|    value_loss           | 7.93         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.164        |
|    max_step             | 0            |
|    mean_ep_length       | 134          |
|    mean_reward          | 96.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.25067186   |
|    route_completion     | 0.183        |
|    success_rate         | 0            |
|    total_cost           | 3.15         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0016796186 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.082        |
|    clip_range           | 0.1          |
|    crash                | 0.0727       |
|    entropy_loss         | -2.64        |
|    explained_variance   | -0.0469      |
|    learning_rate        | 5e-05        |
|    loss                 | 3.81         |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00306     |
|    route_completion     | 0.152        |
|    std                  | 0.908        |
|    total_cost           | 1.42         |
|    value_loss           | 6.97         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 123      |
|    ep_rew_mean     | 15.4     |
| time/              |          |
|    fps             | 553      |
|    iterations      | 22       |
|    time_elapsed    | 203      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 142          |
|    ep_rew_mean          | 18.1         |
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 23           |
|    time_elapsed         | 212          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0017043339 |
|    clip_fraction        | 0.0468       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.0171       |
|    learning_rate        | 5e-05        |
|    loss                 | 3.09         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00203     |
|    std                  | 0.899        |
|    value_loss           | 7.17         |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0             |
|    crash                | 0.167         |
|    max_step             | 0             |
|    mean_ep_length       | 106           |
|    mean_reward          | 87.6          |
|    num_episodes         | 5             |
|    out_of_road          | 1             |
|    raw_action           | 0.28065422    |
|    route_completion     | 0.196         |
|    success_rate         | 0             |
|    total_cost           | 3.83          |
| time/                   |               |
|    total_timesteps      | 120000        |
| train/                  |               |
|    approx_kl            | 0.00087742775 |
|    arrive_dest          | 0             |
|    clip_fraction        | 0.0301        |
|    clip_range           | 0.1           |
|    crash                | 0.1           |
|    entropy_loss         | -2.62         |
|    explained_variance   | 0.174         |
|    learning_rate        | 5e-05         |
|    loss                 | 4.95          |
|    max_step             | 0             |
|    n_updates            | 460           |
|    out_of_road          | 1             |
|    policy_gradient_loss | -0.00269      |
|    route_completion     | 0.177         |
|    std                  | 0.895         |
|    total_cost           | 3.67          |
|    value_loss           | 8.55          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 152      |
|    ep_rew_mean     | 28.6     |
| time/              |          |
|    fps             | 531      |
|    iterations      | 24       |
|    time_elapsed    | 231      |
|    total_timesteps | 122880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 29.7         |
| time/                   |              |
|    fps                  | 529          |
|    iterations           | 25           |
|    time_elapsed         | 241          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0012472384 |
|    clip_fraction        | 0.0357       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.0616       |
|    learning_rate        | 5e-05        |
|    loss                 | 12.8         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00239     |
|    std                  | 0.893        |
|    value_loss           | 21.2         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.185       |
|    max_step             | 0           |
|    mean_ep_length       | 89          |
|    mean_reward          | 93.6        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.29707655  |
|    route_completion     | 0.205       |
|    success_rate         | 0           |
|    total_cost           | 3.91        |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.002017791 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0376      |
|    clip_range           | 0.1         |
|    crash                | 0.108       |
|    entropy_loss         | -2.6        |
|    explained_variance   | 0.0895      |
|    learning_rate        | 5e-05       |
|    loss                 | 6.5         |
|    max_step             | 0           |
|    n_updates            | 500         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00232    |
|    route_completion     | 0.183       |
|    std                  | 0.887       |
|    total_cost           | 3.52        |
|    value_loss           | 10.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 34.1     |
| time/              |          |
|    fps             | 522      |
|    iterations      | 26       |
|    time_elapsed    | 254      |
|    total_timesteps | 133120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 161          |
|    ep_rew_mean          | 38.4         |
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 27           |
|    time_elapsed         | 262          |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0011372333 |
|    clip_fraction        | 0.0428       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.0926       |
|    learning_rate        | 5e-05        |
|    loss                 | 6.59         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00252     |
|    std                  | 0.882        |
|    value_loss           | 14.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.186        |
|    max_step             | 0            |
|    mean_ep_length       | 80.4         |
|    mean_reward          | 87.9         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.31323028   |
|    route_completion     | 0.215        |
|    success_rate         | 0            |
|    total_cost           | 3.76         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0013657396 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0495       |
|    clip_range           | 0.1          |
|    crash                | 0.114        |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.182        |
|    learning_rate        | 5e-05        |
|    loss                 | 3.33         |
|    max_step             | 0            |
|    n_updates            | 540          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00228     |
|    route_completion     | 0.196        |
|    std                  | 0.878        |
|    total_cost           | 3.34         |
|    value_loss           | 9.08         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 40.4     |
| time/              |          |
|    fps             | 518      |
|    iterations      | 28       |
|    time_elapsed    | 276      |
|    total_timesteps | 143360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 45.8         |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 29           |
|    time_elapsed         | 285          |
|    total_timesteps      | 148480       |
| train/                  |              |
|    approx_kl            | 0.0014095855 |
|    clip_fraction        | 0.0579       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.133        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.34         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.003       |
|    std                  | 0.872        |
|    value_loss           | 12.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.187        |
|    max_step             | 0            |
|    mean_ep_length       | 78.4         |
|    mean_reward          | 71           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3269729    |
|    route_completion     | 0.217        |
|    success_rate         | 0            |
|    total_cost           | 3.71         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0018978125 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0885       |
|    clip_range           | 0.1          |
|    crash                | 0.107        |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.131        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.71         |
|    max_step             | 0            |
|    n_updates            | 580          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00478     |
|    route_completion     | 0.207        |
|    std                  | 0.866        |
|    total_cost           | 3.19         |
|    value_loss           | 11.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 46.9     |
| time/              |          |
|    fps             | 514      |
|    iterations      | 30       |
|    time_elapsed    | 298      |
|    total_timesteps | 153600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 196          |
|    ep_rew_mean          | 52.3         |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 31           |
|    time_elapsed         | 305          |
|    total_timesteps      | 158720       |
| train/                  |              |
|    approx_kl            | 0.0016804759 |
|    clip_fraction        | 0.0694       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.122        |
|    learning_rate        | 5e-05        |
|    loss                 | 7.85         |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.861        |
|    value_loss           | 17           |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.188       |
|    max_step             | 0           |
|    mean_ep_length       | 117         |
|    mean_reward          | 130         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.3379125   |
|    route_completion     | 0.233       |
|    success_rate         | 0           |
|    total_cost           | 3.88        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.001424343 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.1         |
|    crash                | 0.125       |
|    entropy_loss         | -2.53       |
|    explained_variance   | 0.224       |
|    learning_rate        | 5e-05       |
|    loss                 | 8.19        |
|    max_step             | 0           |
|    n_updates            | 620         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00348    |
|    route_completion     | 0.212       |
|    std                  | 0.857       |
|    total_cost           | 3.29        |
|    value_loss           | 15          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 54.6     |
| time/              |          |
|    fps             | 515      |
|    iterations      | 32       |
|    time_elapsed    | 317      |
|    total_timesteps | 163840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 231          |
|    ep_rew_mean          | 66.3         |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 33           |
|    time_elapsed         | 325          |
|    total_timesteps      | 168960       |
| train/                  |              |
|    approx_kl            | 0.0016610572 |
|    clip_fraction        | 0.0671       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.197        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.31         |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00191     |
|    std                  | 0.852        |
|    value_loss           | 22.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 113          |
|    mean_reward          | 139          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.35287213   |
|    route_completion     | 0.247        |
|    success_rate         | 0            |
|    total_cost           | 3.88         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0014659439 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0746       |
|    clip_range           | 0.1          |
|    crash                | 0.129        |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.214        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.3          |
|    max_step             | 0            |
|    n_updates            | 660          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00295     |
|    route_completion     | 0.221        |
|    std                  | 0.847        |
|    total_cost           | 3.21         |
|    value_loss           | 17.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 216      |
|    ep_rew_mean     | 69.2     |
| time/              |          |
|    fps             | 516      |
|    iterations      | 34       |
|    time_elapsed    | 337      |
|    total_timesteps | 174080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 240          |
|    ep_rew_mean          | 81.9         |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 35           |
|    time_elapsed         | 345          |
|    total_timesteps      | 179200       |
| train/                  |              |
|    approx_kl            | 0.0014408719 |
|    clip_fraction        | 0.0645       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.117        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.2         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00378     |
|    std                  | 0.843        |
|    value_loss           | 25.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.189        |
|    max_step             | 0            |
|    mean_ep_length       | 93.2         |
|    mean_reward          | 90           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.36347982   |
|    route_completion     | 0.249        |
|    success_rate         | 0            |
|    total_cost           | 3.96         |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0014068552 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0643       |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.184        |
|    learning_rate        | 5e-05        |
|    loss                 | 9.28         |
|    max_step             | 0            |
|    n_updates            | 700          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00268     |
|    route_completion     | 0.23         |
|    std                  | 0.839        |
|    total_cost           | 3.33         |
|    value_loss           | 20.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | 93.4     |
| time/              |          |
|    fps             | 515      |
|    iterations      | 36       |
|    time_elapsed    | 357      |
|    total_timesteps | 184320   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 275       |
|    ep_rew_mean          | 106       |
| time/                   |           |
|    fps                  | 521       |
|    iterations           | 37        |
|    time_elapsed         | 363       |
|    total_timesteps      | 189440    |
| train/                  |           |
|    approx_kl            | 0.0012929 |
|    clip_fraction        | 0.0429    |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.48     |
|    explained_variance   | 0.213     |
|    learning_rate        | 5e-05     |
|    loss                 | 13.2      |
|    n_updates            | 720       |
|    policy_gradient_loss | -0.00197  |
|    std                  | 0.835     |
|    value_loss           | 26.4      |
---------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 189          |
|    mean_reward          | 162          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.36927044   |
|    route_completion     | 0.267        |
|    success_rate         | 0            |
|    total_cost           | 5.72         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0011220191 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0492       |
|    clip_range           | 0.1          |
|    crash                | 0.147        |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.142        |
|    learning_rate        | 5e-05        |
|    loss                 | 5.59         |
|    max_step             | 0            |
|    n_updates            | 740          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000463    |
|    route_completion     | 0.232        |
|    std                  | 0.828        |
|    total_cost           | 3.21         |
|    value_loss           | 20.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 114      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 38       |
|    time_elapsed    | 377      |
|    total_timesteps | 194560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 290          |
|    ep_rew_mean          | 124          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 39           |
|    time_elapsed         | 383          |
|    total_timesteps      | 199680       |
| train/                  |              |
|    approx_kl            | 0.0016352783 |
|    clip_fraction        | 0.0618       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.0987       |
|    learning_rate        | 5e-05        |
|    loss                 | 17.4         |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00217     |
|    std                  | 0.825        |
|    value_loss           | 32.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 101         |
|    mean_reward          | 115         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.37764826  |
|    route_completion     | 0.273       |
|    success_rate         | 0           |
|    total_cost           | 5.56        |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.001022948 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.0949      |
|    clip_range           | 0.1         |
|    crash                | 0.15        |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.0698      |
|    learning_rate        | 5e-05       |
|    loss                 | 8.55        |
|    max_step             | 0           |
|    n_updates            | 780         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00148    |
|    route_completion     | 0.243       |
|    std                  | 0.821       |
|    total_cost           | 3.5         |
|    value_loss           | 25.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 279      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 40       |
|    time_elapsed    | 395      |
|    total_timesteps | 204800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 289          |
|    ep_rew_mean          | 135          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 41           |
|    time_elapsed         | 402          |
|    total_timesteps      | 209920       |
| train/                  |              |
|    approx_kl            | 0.0021446748 |
|    clip_fraction        | 0.062        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.0672       |
|    learning_rate        | 5e-05        |
|    loss                 | 12.6         |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00245     |
|    std                  | 0.816        |
|    value_loss           | 36.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 99.9         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3830476    |
|    route_completion     | 0.282        |
|    success_rate         | 0.1          |
|    total_cost           | 6.91         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0011557003 |
|    arrive_dest          | 0.00952      |
|    clip_fraction        | 0.0655       |
|    clip_range           | 0.1          |
|    crash                | 0.171        |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.227        |
|    learning_rate        | 5e-05        |
|    loss                 | 15.2         |
|    max_step             | 0            |
|    n_updates            | 820          |
|    out_of_road          | 0.99         |
|    policy_gradient_loss | -0.00266     |
|    route_completion     | 0.254        |
|    std                  | 0.814        |
|    total_cost           | 3.43         |
|    value_loss           | 29.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 137      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 42       |
|    time_elapsed    | 415      |
|    total_timesteps | 215040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 129          |
|    mean_reward          | 97.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.38990775   |
|    route_completion     | 0.287        |
|    success_rate         | 0.1          |
|    total_cost           | 7.6          |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0014089844 |
|    arrive_dest          | 0.0182       |
|    clip_fraction        | 0.0871       |
|    clip_range           | 0.1          |
|    crash                | 0.164        |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.24         |
|    learning_rate        | 5e-05        |
|    loss                 | 21.3         |
|    max_step             | 0            |
|    n_updates            | 840          |
|    out_of_road          | 0.982        |
|    policy_gradient_loss | -0.00256     |
|    route_completion     | 0.268        |
|    std                  | 0.812        |
|    total_cost           | 3.39         |
|    value_loss           | 39           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 139      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 43       |
|    time_elapsed    | 428      |
|    total_timesteps | 220160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 271          |
|    ep_rew_mean          | 139          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 44           |
|    time_elapsed         | 433          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0011386574 |
|    clip_fraction        | 0.0546       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.328        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.5         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00132     |
|    std                  | 0.809        |
|    value_loss           | 34.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.209        |
|    max_step             | 0            |
|    mean_ep_length       | 215          |
|    mean_reward          | 143          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.39658502   |
|    route_completion     | 0.301        |
|    success_rate         | 0.1          |
|    total_cost           | 9.52         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0012497087 |
|    arrive_dest          | 0.0261       |
|    clip_fraction        | 0.0832       |
|    clip_range           | 0.1          |
|    crash                | 0.165        |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.347        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.5         |
|    max_step             | 0            |
|    n_updates            | 880          |
|    out_of_road          | 0.974        |
|    policy_gradient_loss | -0.00264     |
|    route_completion     | 0.285        |
|    std                  | 0.805        |
|    total_cost           | 4.81         |
|    value_loss           | 24.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 153      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 45       |
|    time_elapsed    | 449      |
|    total_timesteps | 230400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 287          |
|    ep_rew_mean          | 149          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 46           |
|    time_elapsed         | 456          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0029469763 |
|    clip_fraction        | 0.0925       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.388        |
|    learning_rate        | 5e-05        |
|    loss                 | 18.6         |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00196     |
|    std                  | 0.805        |
|    value_loss           | 31.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.225       |
|    max_step             | 0           |
|    mean_ep_length       | 96          |
|    mean_reward          | 112         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.4006219   |
|    route_completion     | 0.303       |
|    success_rate         | 0           |
|    total_cost           | 9.25        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.003049299 |
|    arrive_dest          | 0.025       |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.1         |
|    crash                | 0.158       |
|    entropy_loss         | -2.4        |
|    explained_variance   | 0.16        |
|    learning_rate        | 5e-05       |
|    loss                 | 12.3        |
|    max_step             | 0           |
|    n_updates            | 920         |
|    out_of_road          | 0.975       |
|    policy_gradient_loss | -0.00172    |
|    route_completion     | 0.288       |
|    std                  | 0.802       |
|    total_cost           | 4.94        |
|    value_loss           | 28.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 304      |
|    ep_rew_mean     | 155      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 47       |
|    time_elapsed    | 468      |
|    total_timesteps | 240640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 313          |
|    ep_rew_mean          | 163          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 48           |
|    time_elapsed         | 473          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0028384095 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.137        |
|    learning_rate        | 5e-05        |
|    loss                 | 16.7         |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.00293     |
|    std                  | 0.799        |
|    value_loss           | 43.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 80           |
|    mean_reward          | 81.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.40213066   |
|    route_completion     | 0.301        |
|    success_rate         | 0            |
|    total_cost           | 8.92         |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0021736869 |
|    arrive_dest          | 0.024        |
|    clip_fraction        | 0.0988       |
|    clip_range           | 0.1          |
|    crash                | 0.152        |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.151        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.7         |
|    max_step             | 0            |
|    n_updates            | 960          |
|    out_of_road          | 0.976        |
|    policy_gradient_loss | -0.00152     |
|    route_completion     | 0.286        |
|    std                  | 0.791        |
|    total_cost           | 4.81         |
|    value_loss           | 21.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 175      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 49       |
|    time_elapsed    | 483      |
|    total_timesteps | 250880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 181          |
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 50           |
|    time_elapsed         | 489          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0015832523 |
|    clip_fraction        | 0.074        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.181        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.8         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.0014      |
|    std                  | 0.787        |
|    value_loss           | 35.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.208        |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 107          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.40552437   |
|    route_completion     | 0.303        |
|    success_rate         | 0            |
|    total_cost           | 8.85         |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0035911247 |
|    arrive_dest          | 0.0231       |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    crash                | 0.154        |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.164        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.73         |
|    max_step             | 0            |
|    n_updates            | 1000         |
|    out_of_road          | 0.977        |
|    policy_gradient_loss | -0.000988    |
|    route_completion     | 0.286        |
|    std                  | 0.784        |
|    total_cost           | 4.71         |
|    value_loss           | 23.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 185      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 51       |
|    time_elapsed    | 501      |
|    total_timesteps | 261120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 342          |
|    ep_rew_mean          | 182          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 52           |
|    time_elapsed         | 507          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0011318089 |
|    clip_fraction        | 0.0678       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.104        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.4         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.000431    |
|    std                  | 0.779        |
|    value_loss           | 43.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00741      |
|    crash                | 0.207        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 171          |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.40967813   |
|    route_completion     | 0.315        |
|    success_rate         | 0.1          |
|    total_cost           | 8.81         |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0012841284 |
|    arrive_dest          | 0.0222       |
|    clip_fraction        | 0.0621       |
|    clip_range           | 0.1          |
|    crash                | 0.163        |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.167        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.4         |
|    max_step             | 0            |
|    n_updates            | 1040         |
|    out_of_road          | 0.978        |
|    policy_gradient_loss | -0.0016      |
|    route_completion     | 0.293        |
|    std                  | 0.777        |
|    total_cost           | 4.69         |
|    value_loss           | 38.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 174      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 53       |
|    time_elapsed    | 520      |
|    total_timesteps | 271360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 322          |
|    ep_rew_mean          | 182          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 54           |
|    time_elapsed         | 526          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0014843342 |
|    clip_fraction        | 0.0606       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.317        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.1         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00264     |
|    std                  | 0.775        |
|    value_loss           | 47.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00714      |
|    crash                | 0.214        |
|    max_step             | 0            |
|    mean_ep_length       | 231          |
|    mean_reward          | 181          |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.4150597    |
|    route_completion     | 0.327        |
|    success_rate         | 0.1          |
|    total_cost           | 10.2         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0014186956 |
|    arrive_dest          | 0.0286       |
|    clip_fraction        | 0.0883       |
|    clip_range           | 0.1          |
|    crash                | 0.171        |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.384        |
|    learning_rate        | 5e-05        |
|    loss                 | 12.7         |
|    max_step             | 0            |
|    n_updates            | 1080         |
|    out_of_road          | 0.971        |
|    policy_gradient_loss | -0.00156     |
|    route_completion     | 0.303        |
|    std                  | 0.772        |
|    total_cost           | 4.59         |
|    value_loss           | 26.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 193      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 55       |
|    time_elapsed    | 542      |
|    total_timesteps | 281600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 339         |
|    ep_rew_mean          | 200         |
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 56          |
|    time_elapsed         | 548         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.004167837 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.318       |
|    learning_rate        | 5e-05       |
|    loss                 | 30.9        |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.000427   |
|    std                  | 0.769       |
|    value_loss           | 53.1        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0069       |
|    crash                | 0.207        |
|    max_step             | 0            |
|    mean_ep_length       | 78.4         |
|    mean_reward          | 82           |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.41774246   |
|    route_completion     | 0.323        |
|    success_rate         | 0            |
|    total_cost           | 9.92         |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0009277885 |
|    arrive_dest          | 0.0276       |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    crash                | 0.179        |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.217        |
|    learning_rate        | 5e-05        |
|    loss                 | 10.4         |
|    max_step             | 0            |
|    n_updates            | 1120         |
|    out_of_road          | 0.972        |
|    policy_gradient_loss | -0.000632    |
|    route_completion     | 0.302        |
|    std                  | 0.768        |
|    total_cost           | 4.46         |
|    value_loss           | 29.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 196      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 57       |
|    time_elapsed    | 559      |
|    total_timesteps | 291840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 329          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 58           |
|    time_elapsed         | 566          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0013860625 |
|    clip_fraction        | 0.0794       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.165        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.7         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00168     |
|    std                  | 0.765        |
|    value_loss           | 50.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00667      |
|    crash                | 0.213        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 140          |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.42038915   |
|    route_completion     | 0.327        |
|    success_rate         | 0            |
|    total_cost           | 9.73         |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0011329554 |
|    arrive_dest          | 0.0267       |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    crash                | 0.187        |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.232        |
|    learning_rate        | 5e-05        |
|    loss                 | 10.6         |
|    max_step             | 0            |
|    n_updates            | 1160         |
|    out_of_road          | 0.973        |
|    policy_gradient_loss | -0.00229     |
|    route_completion     | 0.303        |
|    std                  | 0.76         |
|    total_cost           | 4.41         |
|    value_loss           | 29.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 59       |
|    time_elapsed    | 578      |
|    total_timesteps | 302080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 339          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 60           |
|    time_elapsed         | 584          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0008153486 |
|    clip_fraction        | 0.0477       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.501        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.7         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.757        |
|    value_loss           | 56.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0129       |
|    crash                | 0.206        |
|    max_step             | 0            |
|    mean_ep_length       | 166          |
|    mean_reward          | 189          |
|    num_episodes         | 5            |
|    out_of_road          | 0.987        |
|    raw_action           | 0.42461923   |
|    route_completion     | 0.334        |
|    success_rate         | 0.2          |
|    total_cost           | 9.84         |
| time/                   |              |
|    total_timesteps      | 310000       |
| train/                  |              |
|    approx_kl            | 0.0016816657 |
|    arrive_dest          | 0.0323       |
|    clip_fraction        | 0.0897       |
|    clip_range           | 0.1          |
|    crash                | 0.194        |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.516        |
|    learning_rate        | 5e-05        |
|    loss                 | 11.9         |
|    max_step             | 0            |
|    n_updates            | 1200         |
|    out_of_road          | 0.968        |
|    policy_gradient_loss | -0.00164     |
|    route_completion     | 0.31         |
|    std                  | 0.753        |
|    total_cost           | 4.95         |
|    value_loss           | 26.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 61       |
|    time_elapsed    | 598      |
|    total_timesteps | 312320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 359          |
|    ep_rew_mean          | 235          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 62           |
|    time_elapsed         | 605          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0012728998 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.204        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.4         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.752        |
|    value_loss           | 60.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0125       |
|    crash                | 0.206        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 142          |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.4287591    |
|    route_completion     | 0.34         |
|    success_rate         | 0            |
|    total_cost           | 9.78         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0010507798 |
|    arrive_dest          | 0.0312       |
|    clip_fraction        | 0.0967       |
|    clip_range           | 0.1          |
|    crash                | 0.188        |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.196        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.3         |
|    max_step             | 0            |
|    n_updates            | 1240         |
|    out_of_road          | 0.969        |
|    policy_gradient_loss | -0.000948    |
|    route_completion     | 0.312        |
|    std                  | 0.751        |
|    total_cost           | 5.15         |
|    value_loss           | 38.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 231      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 63       |
|    time_elapsed    | 617      |
|    total_timesteps | 322560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 240          |
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 64           |
|    time_elapsed         | 623          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0031779937 |
|    clip_fraction        | 0.0944       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.316        |
|    learning_rate        | 5e-05        |
|    loss                 | 18.3         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.000792    |
|    std                  | 0.748        |
|    value_loss           | 39.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0242      |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 179         |
|    mean_reward          | 165         |
|    num_episodes         | 5           |
|    out_of_road          | 0.976       |
|    raw_action           | 0.43313724  |
|    route_completion     | 0.348       |
|    success_rate         | 0.3         |
|    total_cost           | 10.2        |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.001463406 |
|    arrive_dest          | 0.0364      |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.1         |
|    crash                | 0.188       |
|    entropy_loss         | -2.25       |
|    explained_variance   | 0.506       |
|    learning_rate        | 5e-05       |
|    loss                 | 16.1        |
|    max_step             | 0           |
|    n_updates            | 1280        |
|    out_of_road          | 0.964       |
|    policy_gradient_loss | -0.0014     |
|    route_completion     | 0.32        |
|    std                  | 0.745       |
|    total_cost           | 5.85        |
|    value_loss           | 43.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 237      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 65       |
|    time_elapsed    | 637      |
|    total_timesteps | 332800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 382          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 66           |
|    time_elapsed         | 644          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0010888481 |
|    clip_fraction        | 0.0804       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.267        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.4         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.74         |
|    value_loss           | 49           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0235       |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 91.4         |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.976        |
|    raw_action           | 0.43382925   |
|    route_completion     | 0.351        |
|    success_rate         | 0.1          |
|    total_cost           | 9.95         |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0013460253 |
|    arrive_dest          | 0.0412       |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    crash                | 0.188        |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.159        |
|    learning_rate        | 5e-05        |
|    loss                 | 18.2         |
|    max_step             | 0            |
|    n_updates            | 1320         |
|    out_of_road          | 0.959        |
|    policy_gradient_loss | -0.00128     |
|    route_completion     | 0.329        |
|    std                  | 0.738        |
|    total_cost           | 6.16         |
|    value_loss           | 46.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 367      |
|    ep_rew_mean     | 249      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 67       |
|    time_elapsed    | 656      |
|    total_timesteps | 343040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 371          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 68           |
|    time_elapsed         | 663          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0015686254 |
|    clip_fraction        | 0.0888       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.361        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.1         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00155     |
|    std                  | 0.737        |
|    value_loss           | 55.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0229       |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 177          |
|    mean_reward          | 164          |
|    num_episodes         | 5            |
|    out_of_road          | 0.977        |
|    raw_action           | 0.43449104   |
|    route_completion     | 0.358        |
|    success_rate         | 0.1          |
|    total_cost           | 10.5         |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0018594766 |
|    arrive_dest          | 0.0457       |
|    clip_fraction        | 0.0986       |
|    clip_range           | 0.1          |
|    crash                | 0.194        |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.267        |
|    learning_rate        | 5e-05        |
|    loss                 | 18.1         |
|    max_step             | 0            |
|    n_updates            | 1360         |
|    out_of_road          | 0.954        |
|    policy_gradient_loss | -0.00153     |
|    route_completion     | 0.336        |
|    std                  | 0.735        |
|    total_cost           | 6.77         |
|    value_loss           | 52.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 69       |
|    time_elapsed    | 678      |
|    total_timesteps | 353280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 373         |
|    ep_rew_mean          | 255         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 70          |
|    time_elapsed         | 684         |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.005518646 |
|    clip_fraction        | 0.0978      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.203       |
|    learning_rate        | 5e-05       |
|    loss                 | 22.4        |
|    n_updates            | 1380        |
|    policy_gradient_loss | -1.18e-05   |
|    std                  | 0.733       |
|    value_loss           | 71.3        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0222      |
|    crash                | 0.211       |
|    max_step             | 0           |
|    mean_ep_length       | 128         |
|    mean_reward          | 164         |
|    num_episodes         | 5           |
|    out_of_road          | 0.978       |
|    raw_action           | 0.434773    |
|    route_completion     | 0.361       |
|    success_rate         | 0           |
|    total_cost           | 10.2        |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.001455293 |
|    arrive_dest          | 0.0444      |
|    clip_fraction        | 0.0992      |
|    clip_range           | 0.1         |
|    crash                | 0.194       |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.365       |
|    learning_rate        | 5e-05       |
|    loss                 | 18.3        |
|    max_step             | 0           |
|    n_updates            | 1400        |
|    out_of_road          | 0.956       |
|    policy_gradient_loss | -0.000102   |
|    route_completion     | 0.338       |
|    std                  | 0.727       |
|    total_cost           | 6.65        |
|    value_loss           | 31.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 71       |
|    time_elapsed    | 699      |
|    total_timesteps | 363520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 363         |
|    ep_rew_mean          | 253         |
| time/                   |             |
|    fps                  | 521         |
|    iterations           | 72          |
|    time_elapsed         | 706         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.001772901 |
|    clip_fraction        | 0.0986      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.3         |
|    learning_rate        | 5e-05       |
|    loss                 | 25.7        |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.000551   |
|    std                  | 0.726       |
|    value_loss           | 65.5        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.027        |
|    crash                | 0.211        |
|    max_step             | 0            |
|    mean_ep_length       | 206          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.973        |
|    raw_action           | 0.43684116   |
|    route_completion     | 0.37         |
|    success_rate         | 0.1          |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 370000       |
| train/                  |              |
|    approx_kl            | 0.0014974007 |
|    arrive_dest          | 0.0432       |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.378        |
|    learning_rate        | 5e-05        |
|    loss                 | 20.2         |
|    max_step             | 0            |
|    n_updates            | 1440         |
|    out_of_road          | 0.957        |
|    policy_gradient_loss | 0.000433     |
|    route_completion     | 0.338        |
|    std                  | 0.724        |
|    total_cost           | 6.51         |
|    value_loss           | 50.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 73       |
|    time_elapsed    | 718      |
|    total_timesteps | 373760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 249          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 74           |
|    time_elapsed         | 725          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0011591174 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.601        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.4         |
|    n_updates            | 1460         |
|    policy_gradient_loss | 0.000754     |
|    std                  | 0.723        |
|    value_loss           | 54.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0421       |
|    crash                | 0.205        |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.958        |
|    raw_action           | 0.43704984   |
|    route_completion     | 0.378        |
|    success_rate         | 0.3          |
|    total_cost           | 11.1         |
| time/                   |              |
|    total_timesteps      | 380000       |
| train/                  |              |
|    approx_kl            | 0.0015170703 |
|    arrive_dest          | 0.0421       |
|    clip_fraction        | 0.066        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.788        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.8         |
|    max_step             | 0            |
|    n_updates            | 1480         |
|    out_of_road          | 0.958        |
|    policy_gradient_loss | -0.00238     |
|    route_completion     | 0.346        |
|    std                  | 0.722        |
|    total_cost           | 6.55         |
|    value_loss           | 45.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 249      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 75       |
|    time_elapsed    | 737      |
|    total_timesteps | 384000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 76           |
|    time_elapsed         | 744          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0026869848 |
|    clip_fraction        | 0.0702       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.593        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.5         |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00242     |
|    std                  | 0.719        |
|    value_loss           | 42.5         |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.041         |
|    crash                | 0.205         |
|    max_step             | 0             |
|    mean_ep_length       | 115           |
|    mean_reward          | 137           |
|    num_episodes         | 5             |
|    out_of_road          | 0.959         |
|    raw_action           | 0.43878233    |
|    route_completion     | 0.38          |
|    success_rate         | 0             |
|    total_cost           | 11            |
| time/                   |               |
|    total_timesteps      | 390000        |
| train/                  |               |
|    approx_kl            | 0.00096621003 |
|    arrive_dest          | 0.041         |
|    clip_fraction        | 0.14          |
|    clip_range           | 0.1           |
|    crash                | 0.19          |
|    entropy_loss         | -2.18         |
|    explained_variance   | 0.56          |
|    learning_rate        | 5e-05         |
|    loss                 | 21.5          |
|    max_step             | 0             |
|    n_updates            | 1520          |
|    out_of_road          | 0.959         |
|    policy_gradient_loss | -0.000716     |
|    route_completion     | 0.347         |
|    std                  | 0.718         |
|    total_cost           | 6.57          |
|    value_loss           | 55.7          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 244      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 77       |
|    time_elapsed    | 757      |
|    total_timesteps | 394240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 351          |
|    ep_rew_mean          | 247          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 78           |
|    time_elapsed         | 763          |
|    total_timesteps      | 399360       |
| train/                  |              |
|    approx_kl            | 0.0015025657 |
|    clip_fraction        | 0.0759       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.542        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.4         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00248     |
|    std                  | 0.718        |
|    value_loss           | 54.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.04         |
|    crash                | 0.21         |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 128          |
|    num_episodes         | 5            |
|    out_of_road          | 0.96         |
|    raw_action           | 0.4404127    |
|    route_completion     | 0.38         |
|    success_rate         | 0            |
|    total_cost           | 10.8         |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0017615675 |
|    arrive_dest          | 0.04         |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.19         |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.586        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.5         |
|    max_step             | 0            |
|    n_updates            | 1560         |
|    out_of_road          | 0.96         |
|    policy_gradient_loss | 2.04e-05     |
|    route_completion     | 0.346        |
|    std                  | 0.714        |
|    total_cost           | 6.49         |
|    value_loss           | 46.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 79       |
|    time_elapsed    | 775      |
|    total_timesteps | 404480   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 353         |
|    ep_rew_mean          | 253         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 80          |
|    time_elapsed         | 781         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.011687623 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.491       |
|    learning_rate        | 5e-05       |
|    loss                 | 27.5        |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.000396   |
|    std                  | 0.715       |
|    value_loss           | 59.5        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.039        |
|    crash                | 0.215        |
|    max_step             | 0            |
|    mean_ep_length       | 126          |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 0.961        |
|    raw_action           | 0.44118273   |
|    route_completion     | 0.381        |
|    success_rate         | 0            |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 410000       |
| train/                  |              |
|    approx_kl            | 0.0048314594 |
|    arrive_dest          | 0.039        |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.484        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.2         |
|    max_step             | 0            |
|    n_updates            | 1600         |
|    out_of_road          | 0.961        |
|    policy_gradient_loss | 0.00139      |
|    route_completion     | 0.346        |
|    std                  | 0.71         |
|    total_cost           | 6.37         |
|    value_loss           | 40.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 81       |
|    time_elapsed    | 795      |
|    total_timesteps | 414720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 371          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 82           |
|    time_elapsed         | 801          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0011511046 |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.456        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.4         |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.000126    |
|    std                  | 0.707        |
|    value_loss           | 59.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0381       |
|    crash                | 0.214        |
|    max_step             | 0            |
|    mean_ep_length       | 89.6         |
|    mean_reward          | 100          |
|    num_episodes         | 5            |
|    out_of_road          | 0.962        |
|    raw_action           | 0.44310614   |
|    route_completion     | 0.379        |
|    success_rate         | 0            |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 420000       |
| train/                  |              |
|    approx_kl            | 0.0013613052 |
|    arrive_dest          | 0.0381       |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    crash                | 0.195        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.617        |
|    learning_rate        | 5e-05        |
|    loss                 | 15.2         |
|    max_step             | 0            |
|    n_updates            | 1640         |
|    out_of_road          | 0.962        |
|    policy_gradient_loss | 0.000175     |
|    route_completion     | 0.348        |
|    std                  | 0.704        |
|    total_cost           | 6.43         |
|    value_loss           | 34.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 83       |
|    time_elapsed    | 811      |
|    total_timesteps | 424960   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0372       |
|    crash                | 0.209        |
|    max_step             | 0            |
|    mean_ep_length       | 170          |
|    mean_reward          | 114          |
|    num_episodes         | 5            |
|    out_of_road          | 0.963        |
|    raw_action           | 0.44411197   |
|    route_completion     | 0.38         |
|    success_rate         | 0            |
|    total_cost           | 11.2         |
| time/                   |              |
|    total_timesteps      | 430000       |
| train/                  |              |
|    approx_kl            | 0.0018796017 |
|    arrive_dest          | 0.0372       |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.191        |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.38         |
|    learning_rate        | 5e-05        |
|    loss                 | 41.7         |
|    max_step             | 0            |
|    n_updates            | 1660         |
|    out_of_road          | 0.963        |
|    policy_gradient_loss | -0.000709    |
|    route_completion     | 0.352        |
|    std                  | 0.704        |
|    total_cost           | 6.33         |
|    value_loss           | 67.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 84       |
|    time_elapsed    | 825      |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 355         |
|    ep_rew_mean          | 274         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 85          |
|    time_elapsed         | 831         |
|    total_timesteps      | 435200      |
| train/                  |             |
|    approx_kl            | 0.001337761 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.465       |
|    learning_rate        | 5e-05       |
|    loss                 | 27.6        |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.000669   |
|    std                  | 0.702       |
|    value_loss           | 63.9        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0364       |
|    crash                | 0.209        |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 0.964        |
|    raw_action           | 0.44325903   |
|    route_completion     | 0.379        |
|    success_rate         | 0            |
|    total_cost           | 11.1         |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0010600034 |
|    arrive_dest          | 0.0364       |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    crash                | 0.191        |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.373        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.8         |
|    max_step             | 0            |
|    n_updates            | 1700         |
|    out_of_road          | 0.964        |
|    policy_gradient_loss | -0.000395    |
|    route_completion     | 0.352        |
|    std                  | 0.698        |
|    total_cost           | 7.33         |
|    value_loss           | 69.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 86       |
|    time_elapsed    | 851      |
|    total_timesteps | 440320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 351          |
|    ep_rew_mean          | 275          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 87           |
|    time_elapsed         | 857          |
|    total_timesteps      | 445440       |
| train/                  |              |
|    approx_kl            | 0.0011344707 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.418        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.3         |
|    n_updates            | 1720         |
|    policy_gradient_loss | 0.00104      |
|    std                  | 0.696        |
|    value_loss           | 78.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.04        |
|    crash                | 0.209       |
|    max_step             | 0           |
|    mean_ep_length       | 165         |
|    mean_reward          | 171         |
|    num_episodes         | 5           |
|    out_of_road          | 0.96        |
|    raw_action           | 0.44279882  |
|    route_completion     | 0.383       |
|    success_rate         | 0.1         |
|    total_cost           | 11.2        |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.004886951 |
|    arrive_dest          | 0.0356      |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.626       |
|    learning_rate        | 5e-05       |
|    loss                 | 25.2        |
|    max_step             | 0           |
|    n_updates            | 1740        |
|    out_of_road          | 0.964       |
|    policy_gradient_loss | -0.000826   |
|    route_completion     | 0.356       |
|    std                  | 0.696       |
|    total_cost           | 7.27        |
|    value_loss           | 48.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 88       |
|    time_elapsed    | 871      |
|    total_timesteps | 450560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 89           |
|    time_elapsed         | 878          |
|    total_timesteps      | 455680       |
| train/                  |              |
|    approx_kl            | 0.0029594062 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.558        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.8         |
|    n_updates            | 1760         |
|    policy_gradient_loss | 0.00358      |
|    std                  | 0.696        |
|    value_loss           | 72.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0435       |
|    crash                | 0.204        |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 223          |
|    num_episodes         | 5            |
|    out_of_road          | 0.957        |
|    raw_action           | 0.4444876    |
|    route_completion     | 0.386        |
|    success_rate         | 0.1          |
|    total_cost           | 11.1         |
| time/                   |              |
|    total_timesteps      | 460000       |
| train/                  |              |
|    approx_kl            | 0.0070769563 |
|    arrive_dest          | 0.0348       |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.636        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.5         |
|    max_step             | 0            |
|    n_updates            | 1780         |
|    out_of_road          | 0.965        |
|    policy_gradient_loss | -0.000289    |
|    route_completion     | 0.359        |
|    std                  | 0.692        |
|    total_cost           | 7.23         |
|    value_loss           | 53.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 90       |
|    time_elapsed    | 892      |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 258         |
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 91          |
|    time_elapsed         | 899         |
|    total_timesteps      | 465920      |
| train/                  |             |
|    approx_kl            | 0.000954948 |
|    clip_fraction        | 0.0827      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.464       |
|    learning_rate        | 5e-05       |
|    loss                 | 55          |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00116    |
|    std                  | 0.691       |
|    value_loss           | 93.3        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0468       |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 0.953        |
|    raw_action           | 0.44583437   |
|    route_completion     | 0.386        |
|    success_rate         | 0.3          |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 470000       |
| train/                  |              |
|    approx_kl            | 0.0020180426 |
|    arrive_dest          | 0.0426       |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.456        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.1         |
|    max_step             | 0            |
|    n_updates            | 1820         |
|    out_of_road          | 0.957        |
|    policy_gradient_loss | -0.00094     |
|    route_completion     | 0.365        |
|    std                  | 0.689        |
|    total_cost           | 7.16         |
|    value_loss           | 73.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 92       |
|    time_elapsed    | 910      |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 261         |
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 93          |
|    time_elapsed         | 917         |
|    total_timesteps      | 476160      |
| train/                  |             |
|    approx_kl            | 0.001523359 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.608       |
|    learning_rate        | 5e-05       |
|    loss                 | 28.4        |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.000648   |
|    std                  | 0.687       |
|    value_loss           | 61.5        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.05         |
|    crash                | 0.196        |
|    max_step             | 0            |
|    mean_ep_length       | 170          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.95         |
|    raw_action           | 0.44679278   |
|    route_completion     | 0.388        |
|    success_rate         | 0.1          |
|    total_cost           | 11.3         |
| time/                   |              |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0014898453 |
|    arrive_dest          | 0.0417       |
|    clip_fraction        | 0.0982       |
|    clip_range           | 0.1          |
|    crash                | 0.204        |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.773        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.6         |
|    max_step             | 0            |
|    n_updates            | 1860         |
|    out_of_road          | 0.958        |
|    policy_gradient_loss | -0.000782    |
|    route_completion     | 0.364        |
|    std                  | 0.686        |
|    total_cost           | 7.04         |
|    value_loss           | 56.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 94       |
|    time_elapsed    | 928      |
|    total_timesteps | 481280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 326          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 95           |
|    time_elapsed         | 935          |
|    total_timesteps      | 486400       |
| train/                  |              |
|    approx_kl            | 0.0015163121 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.758        |
|    learning_rate        | 5e-05        |
|    loss                 | 23.1         |
|    n_updates            | 1880         |
|    policy_gradient_loss | 6.07e-05     |
|    std                  | 0.684        |
|    value_loss           | 55.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.049       |
|    crash                | 0.196       |
|    max_step             | 0           |
|    mean_ep_length       | 118         |
|    mean_reward          | 131         |
|    num_episodes         | 5           |
|    out_of_road          | 0.951       |
|    raw_action           | 0.44709378  |
|    route_completion     | 0.388       |
|    success_rate         | 0.1         |
|    total_cost           | 11.1        |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.001609001 |
|    arrive_dest          | 0.0449      |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.1         |
|    crash                | 0.208       |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.548       |
|    learning_rate        | 5e-05       |
|    loss                 | 32.2        |
|    max_step             | 0           |
|    n_updates            | 1900        |
|    out_of_road          | 0.955       |
|    policy_gradient_loss | -0.00256    |
|    route_completion     | 0.37        |
|    std                  | 0.682       |
|    total_cost           | 6.98        |
|    value_loss           | 62.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 96       |
|    time_elapsed    | 947      |
|    total_timesteps | 491520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 330          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 97           |
|    time_elapsed         | 954          |
|    total_timesteps      | 496640       |
| train/                  |              |
|    approx_kl            | 0.0013905441 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.55         |
|    learning_rate        | 5e-05        |
|    loss                 | 41.5         |
|    n_updates            | 1920         |
|    policy_gradient_loss | -0.00043     |
|    std                  | 0.68         |
|    value_loss           | 75           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.048        |
|    crash                | 0.196        |
|    max_step             | 0            |
|    mean_ep_length       | 171          |
|    mean_reward          | 127          |
|    num_episodes         | 5            |
|    out_of_road          | 0.952        |
|    raw_action           | 0.45063782   |
|    route_completion     | 0.389        |
|    success_rate         | 0.1          |
|    total_cost           | 11.4         |
| time/                   |              |
|    total_timesteps      | 500000       |
| train/                  |              |
|    approx_kl            | 0.0022093183 |
|    arrive_dest          | 0.048        |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    crash                | 0.204        |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.548        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.7         |
|    max_step             | 0            |
|    n_updates            | 1940         |
|    out_of_road          | 0.952        |
|    policy_gradient_loss | -0.00125     |
|    route_completion     | 0.379        |
|    std                  | 0.678        |
|    total_cost           | 7.77         |
|    value_loss           | 66           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 98       |
|    time_elapsed    | 971      |
|    total_timesteps | 501760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 327          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 99           |
|    time_elapsed         | 978          |
|    total_timesteps      | 506880       |
| train/                  |              |
|    approx_kl            | 0.0046978234 |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.434        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.1         |
|    n_updates            | 1960         |
|    policy_gradient_loss | 0.00163      |
|    std                  | 0.679        |
|    value_loss           | 79.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0471       |
|    crash                | 0.2          |
|    max_step             | 0            |
|    mean_ep_length       | 172          |
|    mean_reward          | 115          |
|    num_episodes         | 5            |
|    out_of_road          | 0.953        |
|    raw_action           | 0.4515597    |
|    route_completion     | 0.39         |
|    success_rate         | 0            |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 510000       |
| train/                  |              |
|    approx_kl            | 0.0020183898 |
|    arrive_dest          | 0.0471       |
|    clip_fraction        | 0.0856       |
|    clip_range           | 0.1          |
|    crash                | 0.212        |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.566        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.2         |
|    max_step             | 0            |
|    n_updates            | 1980         |
|    out_of_road          | 0.953        |
|    policy_gradient_loss | -0.0021      |
|    route_completion     | 0.379        |
|    std                  | 0.677        |
|    total_cost           | 7.64         |
|    value_loss           | 74.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 100      |
|    time_elapsed    | 993      |
|    total_timesteps | 512000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 318          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 101          |
|    time_elapsed         | 1000         |
|    total_timesteps      | 517120       |
| train/                  |              |
|    approx_kl            | 0.0020058444 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.496        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.4         |
|    n_updates            | 2000         |
|    policy_gradient_loss | 0.0015       |
|    std                  | 0.673        |
|    value_loss           | 78.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0462       |
|    crash                | 0.208        |
|    max_step             | 0            |
|    mean_ep_length       | 193          |
|    mean_reward          | 152          |
|    num_episodes         | 5            |
|    out_of_road          | 0.954        |
|    raw_action           | 0.4531691    |
|    route_completion     | 0.393        |
|    success_rate         | 0            |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0033146814 |
|    arrive_dest          | 0.0462       |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.208        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.587        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.6         |
|    max_step             | 0            |
|    n_updates            | 2020         |
|    out_of_road          | 0.954        |
|    policy_gradient_loss | -0.000983    |
|    route_completion     | 0.379        |
|    std                  | 0.671        |
|    total_cost           | 7.57         |
|    value_loss           | 57.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 102      |
|    time_elapsed    | 1014     |
|    total_timesteps | 522240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 316          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 103          |
|    time_elapsed         | 1021         |
|    total_timesteps      | 527360       |
| train/                  |              |
|    approx_kl            | 0.0016387764 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.2         |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.000855    |
|    std                  | 0.67         |
|    value_loss           | 65.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0491       |
|    crash                | 0.204        |
|    max_step             | 0            |
|    mean_ep_length       | 147          |
|    mean_reward          | 102          |
|    num_episodes         | 5            |
|    out_of_road          | 0.951        |
|    raw_action           | 0.4538692    |
|    route_completion     | 0.394        |
|    success_rate         | 0.2          |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 530000       |
| train/                  |              |
|    approx_kl            | 0.0013037922 |
|    arrive_dest          | 0.0491       |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.492        |
|    learning_rate        | 5e-05        |
|    loss                 | 38           |
|    max_step             | 0            |
|    n_updates            | 2060         |
|    out_of_road          | 0.951        |
|    policy_gradient_loss | -0.000131    |
|    route_completion     | 0.382        |
|    std                  | 0.669        |
|    total_cost           | 7.73         |
|    value_loss           | 79.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 104      |
|    time_elapsed    | 1035     |
|    total_timesteps | 532480   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 311        |
|    ep_rew_mean          | 247        |
| time/                   |            |
|    fps                  | 515        |
|    iterations           | 105        |
|    time_elapsed         | 1042       |
|    total_timesteps      | 537600     |
| train/                  |            |
|    approx_kl            | 0.00648548 |
|    clip_fraction        | 0.108      |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.02      |
|    explained_variance   | 0.566      |
|    learning_rate        | 5e-05      |
|    loss                 | 43.8       |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.000552  |
|    std                  | 0.667      |
|    value_loss           | 81.9       |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0481      |
|    crash                | 0.207       |
|    max_step             | 0           |
|    mean_ep_length       | 130         |
|    mean_reward          | 166         |
|    num_episodes         | 5           |
|    out_of_road          | 0.952       |
|    raw_action           | 0.45452055  |
|    route_completion     | 0.396       |
|    success_rate         | 0           |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.002304042 |
|    arrive_dest          | 0.0481      |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.1         |
|    crash                | 0.207       |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.68        |
|    learning_rate        | 5e-05       |
|    loss                 | 29          |
|    max_step             | 0           |
|    n_updates            | 2100        |
|    out_of_road          | 0.952       |
|    policy_gradient_loss | 0.00506     |
|    route_completion     | 0.384       |
|    std                  | 0.663       |
|    total_cost           | 7.61        |
|    value_loss           | 58.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | 251      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 106      |
|    time_elapsed    | 1052     |
|    total_timesteps | 542720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 323          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 107          |
|    time_elapsed         | 1059         |
|    total_timesteps      | 547840       |
| train/                  |              |
|    approx_kl            | 0.0052916487 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.6         |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.000798    |
|    std                  | 0.663        |
|    value_loss           | 73.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0473       |
|    crash                | 0.215        |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 134          |
|    num_episodes         | 5            |
|    out_of_road          | 0.953        |
|    raw_action           | 0.45579436   |
|    route_completion     | 0.396        |
|    success_rate         | 0            |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 550000       |
| train/                  |              |
|    approx_kl            | 0.0017890598 |
|    arrive_dest          | 0.0473       |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2           |
|    explained_variance   | 0.544        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.5         |
|    max_step             | 0            |
|    n_updates            | 2140         |
|    out_of_road          | 0.953        |
|    policy_gradient_loss | -0.00173     |
|    route_completion     | 0.384        |
|    std                  | 0.661        |
|    total_cost           | 7.81         |
|    value_loss           | 83.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 249      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 108      |
|    time_elapsed    | 1072     |
|    total_timesteps | 552960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 322          |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 109          |
|    time_elapsed         | 1078         |
|    total_timesteps      | 558080       |
| train/                  |              |
|    approx_kl            | 0.0015331028 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.3         |
|    n_updates            | 2160         |
|    policy_gradient_loss | 5.43e-05     |
|    std                  | 0.662        |
|    value_loss           | 68.2         |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.05       |
|    crash                | 0.218      |
|    max_step             | 0          |
|    mean_ep_length       | 119        |
|    mean_reward          | 127        |
|    num_episodes         | 5          |
|    out_of_road          | 0.95       |
|    raw_action           | 0.45701262 |
|    route_completion     | 0.398      |
|    success_rate         | 0.3        |
|    total_cost           | 12.1       |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.0013057  |
|    arrive_dest          | 0.0536     |
|    clip_fraction        | 0.0942     |
|    clip_range           | 0.1        |
|    crash                | 0.214      |
|    entropy_loss         | -2         |
|    explained_variance   | 0.65       |
|    learning_rate        | 5e-05      |
|    loss                 | 31.8       |
|    max_step             | 0          |
|    n_updates            | 2180       |
|    out_of_road          | 0.946      |
|    policy_gradient_loss | -0.00228   |
|    route_completion     | 0.387      |
|    std                  | 0.661      |
|    total_cost           | 7.81       |
|    value_loss           | 61.8       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 110      |
|    time_elapsed    | 1091     |
|    total_timesteps | 563200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 326          |
|    ep_rew_mean          | 265          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 111          |
|    time_elapsed         | 1099         |
|    total_timesteps      | 568320       |
| train/                  |              |
|    approx_kl            | 0.0019027392 |
|    clip_fraction        | 0.0895       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.673        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.5         |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.00105     |
|    std                  | 0.661        |
|    value_loss           | 67.8         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0526      |
|    crash                | 0.218       |
|    max_step             | 0           |
|    mean_ep_length       | 144         |
|    mean_reward          | 145         |
|    num_episodes         | 5           |
|    out_of_road          | 0.947       |
|    raw_action           | 0.4572267   |
|    route_completion     | 0.4         |
|    success_rate         | 0.2         |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.002815716 |
|    arrive_dest          | 0.0561      |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    crash                | 0.211       |
|    entropy_loss         | -2          |
|    explained_variance   | 0.697       |
|    learning_rate        | 5e-05       |
|    loss                 | 41.9        |
|    max_step             | 0           |
|    n_updates            | 2220        |
|    out_of_road          | 0.944       |
|    policy_gradient_loss | -0.00134    |
|    route_completion     | 0.39        |
|    std                  | 0.658       |
|    total_cost           | 7.95        |
|    value_loss           | 80.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 112      |
|    time_elapsed    | 1113     |
|    total_timesteps | 573440   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 323          |
|    ep_rew_mean          | 259          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 113          |
|    time_elapsed         | 1119         |
|    total_timesteps      | 578560       |
| train/                  |              |
|    approx_kl            | 0.0018346356 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.639        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.1         |
|    n_updates            | 2240         |
|    policy_gradient_loss | -0.00173     |
|    std                  | 0.656        |
|    value_loss           | 85.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0552       |
|    crash                | 0.214        |
|    max_step             | 0            |
|    mean_ep_length       | 179          |
|    mean_reward          | 122          |
|    num_episodes         | 5            |
|    out_of_road          | 0.945        |
|    raw_action           | 0.45735317   |
|    route_completion     | 0.402        |
|    success_rate         | 0.3          |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 580000       |
| train/                  |              |
|    approx_kl            | 0.0017966311 |
|    arrive_dest          | 0.0621       |
|    clip_fraction        | 0.211        |
|    clip_range           | 0.1          |
|    crash                | 0.21         |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.736        |
|    learning_rate        | 5e-05        |
|    loss                 | 29.8         |
|    max_step             | 0            |
|    n_updates            | 2260         |
|    out_of_road          | 0.938        |
|    policy_gradient_loss | 0.00206      |
|    route_completion     | 0.392        |
|    std                  | 0.655        |
|    total_cost           | 8.25         |
|    value_loss           | 53.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 114      |
|    time_elapsed    | 1134     |
|    total_timesteps | 583680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 325          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 115          |
|    time_elapsed         | 1142         |
|    total_timesteps      | 588800       |
| train/                  |              |
|    approx_kl            | 0.0061390894 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.613        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.6         |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.000945    |
|    std                  | 0.656        |
|    value_loss           | 102          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.061       |
|    crash                | 0.21        |
|    max_step             | 0           |
|    mean_ep_length       | 187         |
|    mean_reward          | 170         |
|    num_episodes         | 5           |
|    out_of_road          | 0.939       |
|    raw_action           | 0.45861512  |
|    route_completion     | 0.404       |
|    success_rate         | 0.4         |
|    total_cost           | 12.7        |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.001511395 |
|    arrive_dest          | 0.0678      |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.1         |
|    crash                | 0.214       |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.731       |
|    learning_rate        | 5e-05       |
|    loss                 | 24.3        |
|    max_step             | 0           |
|    n_updates            | 2300        |
|    out_of_road          | 0.932       |
|    policy_gradient_loss | -0.000133   |
|    route_completion     | 0.398       |
|    std                  | 0.656       |
|    total_cost           | 8.98        |
|    value_loss           | 56.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 116      |
|    time_elapsed    | 1157     |
|    total_timesteps | 593920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 325          |
|    ep_rew_mean          | 266          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 117          |
|    time_elapsed         | 1164         |
|    total_timesteps      | 599040       |
| train/                  |              |
|    approx_kl            | 0.0021390137 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.4         |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.0015      |
|    std                  | 0.655        |
|    value_loss           | 86.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.06         |
|    crash                | 0.213        |
|    max_step             | 0            |
|    mean_ep_length       | 82.6         |
|    mean_reward          | 73.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.94         |
|    raw_action           | 0.4609295    |
|    route_completion     | 0.402        |
|    success_rate         | 0            |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 600000       |
| train/                  |              |
|    approx_kl            | 0.0020629796 |
|    arrive_dest          | 0.0667       |
|    clip_fraction        | 0.2          |
|    clip_range           | 0.1          |
|    crash                | 0.217        |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.627        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.3         |
|    max_step             | 0            |
|    n_updates            | 2340         |
|    out_of_road          | 0.933        |
|    policy_gradient_loss | 0.00432      |
|    route_completion     | 0.399        |
|    std                  | 0.656        |
|    total_cost           | 9.43         |
|    value_loss           | 66.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 118      |
|    time_elapsed    | 1176     |
|    total_timesteps | 604160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 322         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 119         |
|    time_elapsed         | 1183        |
|    total_timesteps      | 609280      |
| train/                  |             |
|    approx_kl            | 0.006829439 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.584       |
|    learning_rate        | 5e-05       |
|    loss                 | 49.1        |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.000666   |
|    std                  | 0.654       |
|    value_loss           | 98.1        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.059        |
|    crash                | 0.22         |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 0.941        |
|    raw_action           | 0.4615272    |
|    route_completion     | 0.402        |
|    success_rate         | 0.2          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0023629954 |
|    arrive_dest          | 0.0721       |
|    clip_fraction        | 0.1          |
|    clip_range           | 0.1          |
|    crash                | 0.223        |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.698        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.1         |
|    max_step             | 0            |
|    n_updates            | 2380         |
|    out_of_road          | 0.928        |
|    policy_gradient_loss | -0.00201     |
|    route_completion     | 0.402        |
|    std                  | 0.652        |
|    total_cost           | 9.84         |
|    value_loss           | 64.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 120      |
|    time_elapsed    | 1196     |
|    total_timesteps | 614400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 331        |
|    ep_rew_mean          | 279        |
| time/                   |            |
|    fps                  | 514        |
|    iterations           | 121        |
|    time_elapsed         | 1203       |
|    total_timesteps      | 619520     |
| train/                  |            |
|    approx_kl            | 0.00143806 |
|    clip_fraction        | 0.122      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.97      |
|    explained_variance   | 0.69       |
|    learning_rate        | 5e-05      |
|    loss                 | 37.6       |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.000722  |
|    std                  | 0.651      |
|    value_loss           | 75.8       |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0581      |
|    crash                | 0.219       |
|    max_step             | 0           |
|    mean_ep_length       | 103         |
|    mean_reward          | 124         |
|    num_episodes         | 5           |
|    out_of_road          | 0.942       |
|    raw_action           | 0.46182123  |
|    route_completion     | 0.402       |
|    success_rate         | 0           |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.002848038 |
|    arrive_dest          | 0.071       |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.1         |
|    crash                | 0.226       |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.665       |
|    learning_rate        | 5e-05       |
|    loss                 | 29.5        |
|    max_step             | 0           |
|    n_updates            | 2420        |
|    out_of_road          | 0.929       |
|    policy_gradient_loss | 0.000529    |
|    route_completion     | 0.402       |
|    std                  | 0.649       |
|    total_cost           | 9.72        |
|    value_loss           | 85.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 122      |
|    time_elapsed    | 1214     |
|    total_timesteps | 624640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 339         |
|    ep_rew_mean          | 282         |
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 123         |
|    time_elapsed         | 1220        |
|    total_timesteps      | 629760      |
| train/                  |             |
|    approx_kl            | 0.005025019 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.696       |
|    learning_rate        | 5e-05       |
|    loss                 | 50.2        |
|    n_updates            | 2440        |
|    policy_gradient_loss | 0.00706     |
|    std                  | 0.649       |
|    value_loss           | 81.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0603       |
|    crash                | 0.219        |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 151          |
|    num_episodes         | 5            |
|    out_of_road          | 0.94         |
|    raw_action           | 0.46289015   |
|    route_completion     | 0.404        |
|    success_rate         | 0.3          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 630000       |
| train/                  |              |
|    approx_kl            | 0.0044071754 |
|    arrive_dest          | 0.0762       |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    crash                | 0.229        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.746        |
|    learning_rate        | 5e-05        |
|    loss                 | 37.8         |
|    max_step             | 0            |
|    n_updates            | 2460         |
|    out_of_road          | 0.924        |
|    policy_gradient_loss | -0.000537    |
|    route_completion     | 0.407        |
|    std                  | 0.647        |
|    total_cost           | 10.6         |
|    value_loss           | 77.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 124      |
|    time_elapsed    | 1236     |
|    total_timesteps | 634880   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0656       |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 180          |
|    mean_reward          | 171          |
|    num_episodes         | 5            |
|    out_of_road          | 0.934        |
|    raw_action           | 0.46315604   |
|    route_completion     | 0.406        |
|    success_rate         | 0.3          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0033411894 |
|    arrive_dest          | 0.0781       |
|    clip_fraction        | 0.0815       |
|    clip_range           | 0.1          |
|    crash                | 0.228        |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.664        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.7         |
|    max_step             | 0            |
|    n_updates            | 2480         |
|    out_of_road          | 0.922        |
|    policy_gradient_loss | -0.00231     |
|    route_completion     | 0.408        |
|    std                  | 0.642        |
|    total_cost           | 10.5         |
|    value_loss           | 96.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 125      |
|    time_elapsed    | 1248     |
|    total_timesteps | 640000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 327          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 126          |
|    time_elapsed         | 1255         |
|    total_timesteps      | 645120       |
| train/                  |              |
|    approx_kl            | 0.0015768238 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.779        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.5         |
|    n_updates            | 2500         |
|    policy_gradient_loss | -0.000884    |
|    std                  | 0.641        |
|    value_loss           | 77.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0677       |
|    crash                | 0.222        |
|    max_step             | 0            |
|    mean_ep_length       | 118          |
|    mean_reward          | 144          |
|    num_episodes         | 5            |
|    out_of_road          | 0.932        |
|    raw_action           | 0.46388504   |
|    route_completion     | 0.407        |
|    success_rate         | 0.2          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 650000       |
| train/                  |              |
|    approx_kl            | 0.0026250163 |
|    arrive_dest          | 0.08         |
|    clip_fraction        | 0.138        |
|    clip_range           | 0.1          |
|    crash                | 0.228        |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.755        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.4         |
|    max_step             | 0            |
|    n_updates            | 2520         |
|    out_of_road          | 0.92         |
|    policy_gradient_loss | 0.00118      |
|    route_completion     | 0.409        |
|    std                  | 0.638        |
|    total_cost           | 10.5         |
|    value_loss           | 89.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 127      |
|    time_elapsed    | 1268     |
|    total_timesteps | 650240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 268          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 128          |
|    time_elapsed         | 1274         |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0025795843 |
|    clip_fraction        | 0.0971       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.709        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.3         |
|    n_updates            | 2540         |
|    policy_gradient_loss | -0.00214     |
|    std                  | 0.638        |
|    value_loss           | 80.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0727       |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 221          |
|    num_episodes         | 5            |
|    out_of_road          | 0.927        |
|    raw_action           | 0.4642052    |
|    route_completion     | 0.411        |
|    success_rate         | 0.2          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 660000       |
| train/                  |              |
|    approx_kl            | 0.0012955472 |
|    arrive_dest          | 0.0788       |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    crash                | 0.227        |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.807        |
|    learning_rate        | 5e-05        |
|    loss                 | 25.4         |
|    max_step             | 0            |
|    n_updates            | 2560         |
|    out_of_road          | 0.921        |
|    policy_gradient_loss | -0.000689    |
|    route_completion     | 0.41         |
|    std                  | 0.638        |
|    total_cost           | 10.5         |
|    value_loss           | 68.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 129      |
|    time_elapsed    | 1286     |
|    total_timesteps | 660480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 323          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 130          |
|    time_elapsed         | 1293         |
|    total_timesteps      | 665600       |
| train/                  |              |
|    approx_kl            | 0.0010634621 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.788        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.8         |
|    n_updates            | 2580         |
|    policy_gradient_loss | -0.000946    |
|    std                  | 0.637        |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0716       |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 96           |
|    mean_reward          | 107          |
|    num_episodes         | 5            |
|    out_of_road          | 0.928        |
|    raw_action           | 0.46587536   |
|    route_completion     | 0.41         |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 670000       |
| train/                  |              |
|    approx_kl            | 0.0012368967 |
|    arrive_dest          | 0.0806       |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    crash                | 0.227        |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.578        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.4         |
|    max_step             | 0            |
|    n_updates            | 2600         |
|    out_of_road          | 0.919        |
|    policy_gradient_loss | -0.0013      |
|    route_completion     | 0.412        |
|    std                  | 0.638        |
|    total_cost           | 10.3         |
|    value_loss           | 91           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 327      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 131      |
|    time_elapsed    | 1305     |
|    total_timesteps | 670720   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 331        |
|    ep_rew_mean          | 262        |
| time/                   |            |
|    fps                  | 514        |
|    iterations           | 132        |
|    time_elapsed         | 1312       |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.00995607 |
|    clip_fraction        | 0.195      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.92      |
|    explained_variance   | 0.706      |
|    learning_rate        | 5e-05      |
|    loss                 | 35.4       |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.00371    |
|    std                  | 0.636      |
|    value_loss           | 75.8       |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0735      |
|    crash                | 0.221       |
|    max_step             | 0           |
|    mean_ep_length       | 170         |
|    mean_reward          | 188         |
|    num_episodes         | 5           |
|    out_of_road          | 0.926       |
|    raw_action           | 0.46599534  |
|    route_completion     | 0.412       |
|    success_rate         | 0.3         |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.021400584 |
|    arrive_dest          | 0.0853      |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.1         |
|    crash                | 0.224       |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.744       |
|    learning_rate        | 5e-05       |
|    loss                 | 23.2        |
|    max_step             | 0           |
|    n_updates            | 2640        |
|    out_of_road          | 0.915       |
|    policy_gradient_loss | 0.00176     |
|    route_completion     | 0.413       |
|    std                  | 0.635       |
|    total_cost           | 10.4        |
|    value_loss           | 67.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 133      |
|    time_elapsed    | 1325     |
|    total_timesteps | 680960   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 317       |
|    ep_rew_mean          | 262       |
| time/                   |           |
|    fps                  | 514       |
|    iterations           | 134       |
|    time_elapsed         | 1333      |
|    total_timesteps      | 686080    |
| train/                  |           |
|    approx_kl            | 0.0040464 |
|    clip_fraction        | 0.116     |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.92     |
|    explained_variance   | 0.581     |
|    learning_rate        | 5e-05     |
|    loss                 | 52.7      |
|    n_updates            | 2660      |
|    policy_gradient_loss | -0.00063  |
|    std                  | 0.634     |
|    value_loss           | 104       |
---------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0812       |
|    crash                | 0.217        |
|    max_step             | 0            |
|    mean_ep_length       | 181          |
|    mean_reward          | 253          |
|    num_episodes         | 5            |
|    out_of_road          | 0.919        |
|    raw_action           | 0.46692327   |
|    route_completion     | 0.417        |
|    success_rate         | 0.4          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0019082862 |
|    arrive_dest          | 0.087        |
|    clip_fraction        | 0.097        |
|    clip_range           | 0.1          |
|    crash                | 0.223        |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.61         |
|    learning_rate        | 5e-05        |
|    loss                 | 36           |
|    max_step             | 0            |
|    n_updates            | 2680         |
|    out_of_road          | 0.913        |
|    policy_gradient_loss | -0.00103     |
|    route_completion     | 0.414        |
|    std                  | 0.631        |
|    total_cost           | 10.5         |
|    value_loss           | 91.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 316      |
|    ep_rew_mean     | 262      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 135      |
|    time_elapsed    | 1346     |
|    total_timesteps | 691200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 310          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 136          |
|    time_elapsed         | 1352         |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 0.0017102221 |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.645        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.7         |
|    n_updates            | 2700         |
|    policy_gradient_loss | -0.00101     |
|    std                  | 0.63         |
|    value_loss           | 87.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.08         |
|    crash                | 0.22         |
|    max_step             | 0            |
|    mean_ep_length       | 89.6         |
|    mean_reward          | 88           |
|    num_episodes         | 5            |
|    out_of_road          | 0.92         |
|    raw_action           | 0.46791473   |
|    route_completion     | 0.415        |
|    success_rate         | 0.3          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 700000       |
| train/                  |              |
|    approx_kl            | 0.0021407022 |
|    arrive_dest          | 0.0943       |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.22         |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.1         |
|    max_step             | 0            |
|    n_updates            | 2720         |
|    out_of_road          | 0.906        |
|    policy_gradient_loss | -0.000616    |
|    route_completion     | 0.419        |
|    std                  | 0.629        |
|    total_cost           | 10.8         |
|    value_loss           | 73.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 137      |
|    time_elapsed    | 1365     |
|    total_timesteps | 701440   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 314          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 138          |
|    time_elapsed         | 1372         |
|    total_timesteps      | 706560       |
| train/                  |              |
|    approx_kl            | 0.0007748731 |
|    clip_fraction        | 0.0859       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.488        |
|    learning_rate        | 5e-05        |
|    loss                 | 36.6         |
|    n_updates            | 2740         |
|    policy_gradient_loss | -0.00154     |
|    std                  | 0.625        |
|    value_loss           | 106          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0845       |
|    crash                | 0.22         |
|    max_step             | 0            |
|    mean_ep_length       | 171          |
|    mean_reward          | 168          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.46808732   |
|    route_completion     | 0.417        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 710000       |
| train/                  |              |
|    approx_kl            | 0.0014070314 |
|    arrive_dest          | 0.093        |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    crash                | 0.22         |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.614        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.8         |
|    max_step             | 0            |
|    n_updates            | 2760         |
|    out_of_road          | 0.907        |
|    policy_gradient_loss | 0.00126      |
|    route_completion     | 0.421        |
|    std                  | 0.625        |
|    total_cost           | 10.9         |
|    value_loss           | 75.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 139      |
|    time_elapsed    | 1387     |
|    total_timesteps | 711680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 310          |
|    ep_rew_mean          | 271          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 140          |
|    time_elapsed         | 1394         |
|    total_timesteps      | 716800       |
| train/                  |              |
|    approx_kl            | 0.0016541753 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.4         |
|    n_updates            | 2780         |
|    policy_gradient_loss | -0.00181     |
|    std                  | 0.625        |
|    value_loss           | 78.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0861       |
|    crash                | 0.217        |
|    max_step             | 0            |
|    mean_ep_length       | 131          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.46891636   |
|    route_completion     | 0.418        |
|    success_rate         | 0.1          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0019421175 |
|    arrive_dest          | 0.0917       |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    crash                | 0.222        |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.524        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.8         |
|    max_step             | 0            |
|    n_updates            | 2800         |
|    out_of_road          | 0.908        |
|    policy_gradient_loss | 0.000995     |
|    route_completion     | 0.421        |
|    std                  | 0.623        |
|    total_cost           | 11           |
|    value_loss           | 108          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 141      |
|    time_elapsed    | 1406     |
|    total_timesteps | 721920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 307          |
|    ep_rew_mean          | 262          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 142          |
|    time_elapsed         | 1413         |
|    total_timesteps      | 727040       |
| train/                  |              |
|    approx_kl            | 0.0016516704 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.657        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.8         |
|    n_updates            | 2820         |
|    policy_gradient_loss | 0.000168     |
|    std                  | 0.622        |
|    value_loss           | 99.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0877       |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 176          |
|    mean_reward          | 242          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.4703545    |
|    route_completion     | 0.42         |
|    success_rate         | 0.2          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 730000       |
| train/                  |              |
|    approx_kl            | 0.0021198122 |
|    arrive_dest          | 0.0932       |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    crash                | 0.225        |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.666        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.6         |
|    max_step             | 0            |
|    n_updates            | 2840         |
|    out_of_road          | 0.907        |
|    policy_gradient_loss | -0.00119     |
|    route_completion     | 0.427        |
|    std                  | 0.622        |
|    total_cost           | 11.3         |
|    value_loss           | 101          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 143      |
|    time_elapsed    | 1429     |
|    total_timesteps | 732160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 285         |
|    ep_rew_mean          | 243         |
| time/                   |             |
|    fps                  | 513         |
|    iterations           | 144         |
|    time_elapsed         | 1436        |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.003282193 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.67        |
|    learning_rate        | 5e-05       |
|    loss                 | 40.6        |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.00202    |
|    std                  | 0.622       |
|    value_loss           | 105         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0892       |
|    crash                | 0.216        |
|    max_step             | 0            |
|    mean_ep_length       | 205          |
|    mean_reward          | 219          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.47087905   |
|    route_completion     | 0.424        |
|    success_rate         | 0.4          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 740000       |
| train/                  |              |
|    approx_kl            | 0.0030242663 |
|    arrive_dest          | 0.1          |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    crash                | 0.227        |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.585        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.4         |
|    max_step             | 0            |
|    n_updates            | 2880         |
|    out_of_road          | 0.9          |
|    policy_gradient_loss | -0.000174    |
|    route_completion     | 0.431        |
|    std                  | 0.621        |
|    total_cost           | 12.3         |
|    value_loss           | 115          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 238      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 145      |
|    time_elapsed    | 1452     |
|    total_timesteps | 742400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 285          |
|    ep_rew_mean          | 242          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 146          |
|    time_elapsed         | 1459         |
|    total_timesteps      | 747520       |
| train/                  |              |
|    approx_kl            | 0.0008951573 |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.729        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.7         |
|    n_updates            | 2900         |
|    policy_gradient_loss | 0.000374     |
|    std                  | 0.618        |
|    value_loss           | 85.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0907       |
|    crash                | 0.219        |
|    max_step             | 0            |
|    mean_ep_length       | 212          |
|    mean_reward          | 249          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47050983   |
|    route_completion     | 0.427        |
|    success_rate         | 0.3          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 750000       |
| train/                  |              |
|    approx_kl            | 0.0037228889 |
|    arrive_dest          | 0.104        |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    crash                | 0.229        |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.666        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.6         |
|    max_step             | 0            |
|    n_updates            | 2920         |
|    out_of_road          | 0.896        |
|    policy_gradient_loss | 0.00305      |
|    route_completion     | 0.434        |
|    std                  | 0.617        |
|    total_cost           | 12.4         |
|    value_loss           | 80.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 239      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 147      |
|    time_elapsed    | 1473     |
|    total_timesteps | 752640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 291        |
|    ep_rew_mean          | 252        |
| time/                   |            |
|    fps                  | 511        |
|    iterations           | 148        |
|    time_elapsed         | 1480       |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.00432627 |
|    clip_fraction        | 0.163      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.85      |
|    explained_variance   | 0.647      |
|    learning_rate        | 5e-05      |
|    loss                 | 44.2       |
|    n_updates            | 2940       |
|    policy_gradient_loss | 0.00097    |
|    std                  | 0.616      |
|    value_loss           | 84.5       |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0895       |
|    crash                | 0.224        |
|    max_step             | 0            |
|    mean_ep_length       | 174          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.4709136    |
|    route_completion     | 0.427        |
|    success_rate         | 0            |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 760000       |
| train/                  |              |
|    approx_kl            | 0.0015583948 |
|    arrive_dest          | 0.103        |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.229        |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.725        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.7         |
|    max_step             | 0            |
|    n_updates            | 2960         |
|    out_of_road          | 0.897        |
|    policy_gradient_loss | -0.00166     |
|    route_completion     | 0.433        |
|    std                  | 0.614        |
|    total_cost           | 12.4         |
|    value_loss           | 81.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 149      |
|    time_elapsed    | 1493     |
|    total_timesteps | 762880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 300          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 150          |
|    time_elapsed         | 1499         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 0.0033662734 |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.84        |
|    explained_variance   | 0.619        |
|    learning_rate        | 5e-05        |
|    loss                 | 45           |
|    n_updates            | 2980         |
|    policy_gradient_loss | 0.000703     |
|    std                  | 0.612        |
|    value_loss           | 91.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0883       |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 90.8         |
|    mean_reward          | 101          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.4708456    |
|    route_completion     | 0.426        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 770000       |
| train/                  |              |
|    approx_kl            | 0.0020146386 |
|    arrive_dest          | 0.104        |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    crash                | 0.231        |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.73         |
|    learning_rate        | 5e-05        |
|    loss                 | 26.2         |
|    max_step             | 0            |
|    n_updates            | 3000         |
|    out_of_road          | 0.896        |
|    policy_gradient_loss | -0.00231     |
|    route_completion     | 0.435        |
|    std                  | 0.611        |
|    total_cost           | 12.6         |
|    value_loss           | 67.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 151      |
|    time_elapsed    | 1510     |
|    total_timesteps | 773120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 306         |
|    ep_rew_mean          | 280         |
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 152         |
|    time_elapsed         | 1518        |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.006602575 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.709       |
|    learning_rate        | 5e-05       |
|    loss                 | 31.6        |
|    n_updates            | 3020        |
|    policy_gradient_loss | 0.000692    |
|    std                  | 0.609       |
|    value_loss           | 87.2        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0897       |
|    crash                | 0.221        |
|    max_step             | 0            |
|    mean_ep_length       | 109          |
|    mean_reward          | 110          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47140238   |
|    route_completion     | 0.425        |
|    success_rate         | 0.2          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 780000       |
| train/                  |              |
|    approx_kl            | 0.0026671377 |
|    arrive_dest          | 0.105        |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    crash                | 0.228        |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.728        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.4         |
|    max_step             | 0            |
|    n_updates            | 3040         |
|    out_of_road          | 0.895        |
|    policy_gradient_loss | -0.00108     |
|    route_completion     | 0.437        |
|    std                  | 0.609        |
|    total_cost           | 13           |
|    value_loss           | 120          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 304      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 153      |
|    time_elapsed    | 1532     |
|    total_timesteps | 783360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 315          |
|    ep_rew_mean          | 282          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 154          |
|    time_elapsed         | 1538         |
|    total_timesteps      | 788480       |
| train/                  |              |
|    approx_kl            | 0.0039784587 |
|    clip_fraction        | 0.221        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.817        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.3         |
|    n_updates            | 3060         |
|    policy_gradient_loss | 0.00513      |
|    std                  | 0.609        |
|    value_loss           | 102          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0911       |
|    crash                | 0.223        |
|    max_step             | 0            |
|    mean_ep_length       | 140          |
|    mean_reward          | 164          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47212923   |
|    route_completion     | 0.427        |
|    success_rate         | 0.2          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 790000       |
| train/                  |              |
|    approx_kl            | 0.0019580505 |
|    arrive_dest          | 0.106        |
|    clip_fraction        | 0.17         |
|    clip_range           | 0.1          |
|    crash                | 0.225        |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.913        |
|    learning_rate        | 5e-05        |
|    loss                 | 17.5         |
|    max_step             | 0            |
|    n_updates            | 3080         |
|    out_of_road          | 0.894        |
|    policy_gradient_loss | 0.00247      |
|    route_completion     | 0.438        |
|    std                  | 0.609        |
|    total_cost           | 13.4         |
|    value_loss           | 51.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 155      |
|    time_elapsed    | 1554     |
|    total_timesteps | 793600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 305          |
|    ep_rew_mean          | 261          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 156          |
|    time_elapsed         | 1562         |
|    total_timesteps      | 798720       |
| train/                  |              |
|    approx_kl            | 0.0016475593 |
|    clip_fraction        | 0.0643       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.791        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.4         |
|    n_updates            | 3100         |
|    policy_gradient_loss | -0.00118     |
|    std                  | 0.609        |
|    value_loss           | 114          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.09       |
|    crash                | 0.228      |
|    max_step             | 0          |
|    mean_ep_length       | 81.8       |
|    mean_reward          | 82.7       |
|    num_episodes         | 5          |
|    out_of_road          | 0.91       |
|    raw_action           | 0.47301492 |
|    route_completion     | 0.425      |
|    success_rate         | 0.1        |
|    total_cost           | 11.8       |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.00427406 |
|    arrive_dest          | 0.107      |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.1        |
|    crash                | 0.233      |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.718      |
|    learning_rate        | 5e-05      |
|    loss                 | 37.7       |
|    max_step             | 0          |
|    n_updates            | 3120       |
|    out_of_road          | 0.892      |
|    policy_gradient_loss | -0.00107   |
|    route_completion     | 0.438      |
|    std                  | 0.607      |
|    total_cost           | 13.4       |
|    value_loss           | 102        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 157      |
|    time_elapsed    | 1574     |
|    total_timesteps | 803840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 303          |
|    ep_rew_mean          | 254          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 158          |
|    time_elapsed         | 1581         |
|    total_timesteps      | 808960       |
| train/                  |              |
|    approx_kl            | 0.0018698942 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.646        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.6         |
|    n_updates            | 3140         |
|    policy_gradient_loss | -0.00182     |
|    std                  | 0.607        |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0938       |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 196          |
|    mean_reward          | 221          |
|    num_episodes         | 5            |
|    out_of_road          | 0.906        |
|    raw_action           | 0.47393027   |
|    route_completion     | 0.429        |
|    success_rate         | 0.3          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 810000       |
| train/                  |              |
|    approx_kl            | 0.0054158317 |
|    arrive_dest          | 0.109        |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.761        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.9         |
|    max_step             | 0            |
|    n_updates            | 3160         |
|    out_of_road          | 0.891        |
|    policy_gradient_loss | 0.00148      |
|    route_completion     | 0.439        |
|    std                  | 0.607        |
|    total_cost           | 13.3         |
|    value_loss           | 70.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 159      |
|    time_elapsed    | 1594     |
|    total_timesteps | 814080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 315          |
|    ep_rew_mean          | 268          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 160          |
|    time_elapsed         | 1600         |
|    total_timesteps      | 819200       |
| train/                  |              |
|    approx_kl            | 0.0037903436 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.9         |
|    n_updates            | 3180         |
|    policy_gradient_loss | 0.000139     |
|    std                  | 0.606        |
|    value_loss           | 98           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0927       |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.47343123   |
|    route_completion     | 0.43         |
|    success_rate         | 0            |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 820000       |
| train/                  |              |
|    approx_kl            | 0.0010858297 |
|    arrive_dest          | 0.107        |
|    clip_fraction        | 0.0992       |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.772        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.5         |
|    max_step             | 0            |
|    n_updates            | 3200         |
|    out_of_road          | 0.893        |
|    policy_gradient_loss | -0.00251     |
|    route_completion     | 0.438        |
|    std                  | 0.607        |
|    total_cost           | 13.2         |
|    value_loss           | 88.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 161      |
|    time_elapsed    | 1611     |
|    total_timesteps | 824320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 298          |
|    ep_rew_mean          | 259          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 162          |
|    time_elapsed         | 1620         |
|    total_timesteps      | 829440       |
| train/                  |              |
|    approx_kl            | 0.0044521866 |
|    clip_fraction        | 0.207        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.64         |
|    learning_rate        | 5e-05        |
|    loss                 | 50.1         |
|    n_updates            | 3220         |
|    policy_gradient_loss | 0.00189      |
|    std                  | 0.607        |
|    value_loss           | 99.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0916       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 121          |
|    mean_reward          | 144          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47474954   |
|    route_completion     | 0.43         |
|    success_rate         | 0            |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 830000       |
| train/                  |              |
|    approx_kl            | 0.0046282653 |
|    arrive_dest          | 0.106        |
|    clip_fraction        | 0.0788       |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.763        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.8         |
|    max_step             | 0            |
|    n_updates            | 3240         |
|    out_of_road          | 0.894        |
|    policy_gradient_loss | -0.0024      |
|    route_completion     | 0.439        |
|    std                  | 0.605        |
|    total_cost           | 13.1         |
|    value_loss           | 101          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 163      |
|    time_elapsed    | 1632     |
|    total_timesteps | 834560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 295         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 164         |
|    time_elapsed         | 1638        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.002452214 |
|    clip_fraction        | 0.0973      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.684       |
|    learning_rate        | 5e-05       |
|    loss                 | 51.6        |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.002      |
|    std                  | 0.605       |
|    value_loss           | 95.7        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0905       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 86.6         |
|    mean_reward          | 95.4         |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47548005   |
|    route_completion     | 0.428        |
|    success_rate         | 0.2          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0015561546 |
|    arrive_dest          | 0.11         |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    crash                | 0.233        |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.74         |
|    learning_rate        | 5e-05        |
|    loss                 | 60.6         |
|    max_step             | 0            |
|    n_updates            | 3280         |
|    out_of_road          | 0.89         |
|    policy_gradient_loss | 0.00114      |
|    route_completion     | 0.44         |
|    std                  | 0.604        |
|    total_cost           | 12.9         |
|    value_loss           | 81.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 165      |
|    time_elapsed    | 1650     |
|    total_timesteps | 844800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 286          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 166          |
|    time_elapsed         | 1656         |
|    total_timesteps      | 849920       |
| train/                  |              |
|    approx_kl            | 0.0030782453 |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.679        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.9         |
|    n_updates            | 3300         |
|    policy_gradient_loss | -0.000475    |
|    std                  | 0.605        |
|    value_loss           | 92.7         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0918      |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 240         |
|    mean_reward          | 147         |
|    num_episodes         | 5           |
|    out_of_road          | 0.908       |
|    raw_action           | 0.4762673   |
|    route_completion     | 0.431       |
|    success_rate         | 0.1         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.005367023 |
|    arrive_dest          | 0.108       |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.1         |
|    crash                | 0.233       |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.761       |
|    learning_rate        | 5e-05       |
|    loss                 | 34.5        |
|    max_step             | 0           |
|    n_updates            | 3320        |
|    out_of_road          | 0.892       |
|    policy_gradient_loss | 0.00325     |
|    route_completion     | 0.443       |
|    std                  | 0.602       |
|    total_cost           | 13          |
|    value_loss           | 72.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 295      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 167      |
|    time_elapsed    | 1671     |
|    total_timesteps | 855040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.093        |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 130          |
|    mean_reward          | 171          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.47651795   |
|    route_completion     | 0.431        |
|    success_rate         | 0.1          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0014553048 |
|    arrive_dest          | 0.107        |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.23         |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.752        |
|    learning_rate        | 5e-05        |
|    loss                 | 43           |
|    max_step             | 0            |
|    n_updates            | 3340         |
|    out_of_road          | 0.893        |
|    policy_gradient_loss | -0.00112     |
|    route_completion     | 0.442        |
|    std                  | 0.599        |
|    total_cost           | 12.8         |
|    value_loss           | 92.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 266      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 168      |
|    time_elapsed    | 1683     |
|    total_timesteps | 860160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 292          |
|    ep_rew_mean          | 263          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 169          |
|    time_elapsed         | 1690         |
|    total_timesteps      | 865280       |
| train/                  |              |
|    approx_kl            | 0.0037895367 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.69         |
|    learning_rate        | 5e-05        |
|    loss                 | 54.7         |
|    n_updates            | 3360         |
|    policy_gradient_loss | -0.000895    |
|    std                  | 0.599        |
|    value_loss           | 91.9         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0943      |
|    crash                | 0.23        |
|    max_step             | 0           |
|    mean_ep_length       | 146         |
|    mean_reward          | 148         |
|    num_episodes         | 5           |
|    out_of_road          | 0.906       |
|    raw_action           | 0.47644547  |
|    route_completion     | 0.432       |
|    success_rate         | 0.2         |
|    total_cost           | 12.1        |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.014814687 |
|    arrive_dest          | 0.108       |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    crash                | 0.232       |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.652       |
|    learning_rate        | 5e-05       |
|    loss                 | 55.5        |
|    max_step             | 0           |
|    n_updates            | 3380        |
|    out_of_road          | 0.892       |
|    policy_gradient_loss | -1.7e-05    |
|    route_completion     | 0.444       |
|    std                  | 0.598       |
|    total_cost           | 12.9        |
|    value_loss           | 114         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 170      |
|    time_elapsed    | 1702     |
|    total_timesteps | 870400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 277          |
|    ep_rew_mean          | 243          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 171          |
|    time_elapsed         | 1709         |
|    total_timesteps      | 875520       |
| train/                  |              |
|    approx_kl            | 0.0074221166 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.7         |
|    n_updates            | 3400         |
|    policy_gradient_loss | -0.00042     |
|    std                  | 0.597        |
|    value_loss           | 91.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0955       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 183          |
|    mean_reward          | 216          |
|    num_episodes         | 5            |
|    out_of_road          | 0.905        |
|    raw_action           | 0.47601995   |
|    route_completion     | 0.434        |
|    success_rate         | 0.1          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 880000       |
| train/                  |              |
|    approx_kl            | 0.0023299076 |
|    arrive_dest          | 0.107        |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    crash                | 0.23         |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.711        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.7         |
|    max_step             | 0            |
|    n_updates            | 3420         |
|    out_of_road          | 0.893        |
|    policy_gradient_loss | -0.000374    |
|    route_completion     | 0.442        |
|    std                  | 0.596        |
|    total_cost           | 12.8         |
|    value_loss           | 96           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 274      |
|    ep_rew_mean     | 245      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 172      |
|    time_elapsed    | 1720     |
|    total_timesteps | 880640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 272          |
|    ep_rew_mean          | 243          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 173          |
|    time_elapsed         | 1726         |
|    total_timesteps      | 885760       |
| train/                  |              |
|    approx_kl            | 0.0014694005 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.653        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.1         |
|    n_updates            | 3440         |
|    policy_gradient_loss | -0.000809    |
|    std                  | 0.595        |
|    value_loss           | 118          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0966       |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 127          |
|    mean_reward          | 118          |
|    num_episodes         | 5            |
|    out_of_road          | 0.903        |
|    raw_action           | 0.47606352   |
|    route_completion     | 0.433        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 890000       |
| train/                  |              |
|    approx_kl            | 0.0028683122 |
|    arrive_dest          | 0.106        |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.231        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.674        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.5         |
|    max_step             | 0            |
|    n_updates            | 3460         |
|    out_of_road          | 0.894        |
|    policy_gradient_loss | -0.000247    |
|    route_completion     | 0.44         |
|    std                  | 0.593        |
|    total_cost           | 12.6         |
|    value_loss           | 105          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 248      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 174      |
|    time_elapsed    | 1737     |
|    total_timesteps | 890880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 278          |
|    ep_rew_mean          | 254          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 175          |
|    time_elapsed         | 1743         |
|    total_timesteps      | 896000       |
| train/                  |              |
|    approx_kl            | 0.0030176188 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.711        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.2         |
|    n_updates            | 3480         |
|    policy_gradient_loss | -0.000122    |
|    std                  | 0.593        |
|    value_loss           | 79.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0956       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 92.8         |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 0.904        |
|    raw_action           | 0.4759274    |
|    route_completion     | 0.432        |
|    success_rate         | 0.1          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 900000       |
| train/                  |              |
|    approx_kl            | 0.0015578917 |
|    arrive_dest          | 0.107        |
|    clip_fraction        | 0.178        |
|    clip_range           | 0.1          |
|    crash                | 0.229        |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.677        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.4         |
|    max_step             | 0            |
|    n_updates            | 3500         |
|    out_of_road          | 0.893        |
|    policy_gradient_loss | 0.0029       |
|    route_completion     | 0.441        |
|    std                  | 0.591        |
|    total_cost           | 12.6         |
|    value_loss           | 99.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 276      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 176      |
|    time_elapsed    | 1754     |
|    total_timesteps | 901120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 283          |
|    ep_rew_mean          | 262          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 177          |
|    time_elapsed         | 1760         |
|    total_timesteps      | 906240       |
| train/                  |              |
|    approx_kl            | 0.0010947299 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.631        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.1         |
|    n_updates            | 3520         |
|    policy_gradient_loss | -3.07e-05    |
|    std                  | 0.59         |
|    value_loss           | 133          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0945      |
|    crash                | 0.231       |
|    max_step             | 0           |
|    mean_ep_length       | 91.8        |
|    mean_reward          | 93.8        |
|    num_episodes         | 5           |
|    out_of_road          | 0.905       |
|    raw_action           | 0.47613132  |
|    route_completion     | 0.431       |
|    success_rate         | 0.2         |
|    total_cost           | 11.9        |
| time/                   |             |
|    total_timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.004973299 |
|    arrive_dest          | 0.11        |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.1         |
|    crash                | 0.231       |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.692       |
|    learning_rate        | 5e-05       |
|    loss                 | 63.8        |
|    max_step             | 0           |
|    n_updates            | 3540        |
|    out_of_road          | 0.89        |
|    policy_gradient_loss | -0.000305   |
|    route_completion     | 0.443       |
|    std                  | 0.59        |
|    total_cost           | 12.6        |
|    value_loss           | 101         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 279      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 178      |
|    time_elapsed    | 1773     |
|    total_timesteps | 911360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 287          |
|    ep_rew_mean          | 260          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 179          |
|    time_elapsed         | 1780         |
|    total_timesteps      | 916480       |
| train/                  |              |
|    approx_kl            | 0.0016792992 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.624        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.1         |
|    n_updates            | 3560         |
|    policy_gradient_loss | 0.000233     |
|    std                  | 0.591        |
|    value_loss           | 111          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0935       |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 91.2         |
|    mean_reward          | 103          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.4761121    |
|    route_completion     | 0.429        |
|    success_rate         | 0            |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 920000       |
| train/                  |              |
|    approx_kl            | 0.0050885067 |
|    arrive_dest          | 0.109        |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.675        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.9         |
|    max_step             | 0            |
|    n_updates            | 3580         |
|    out_of_road          | 0.891        |
|    policy_gradient_loss | -0.00062     |
|    route_completion     | 0.441        |
|    std                  | 0.589        |
|    total_cost           | 12.5         |
|    value_loss           | 101          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 244      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 180      |
|    time_elapsed    | 1791     |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 270         |
|    ep_rew_mean          | 240         |
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 181         |
|    time_elapsed         | 1797        |
|    total_timesteps      | 926720      |
| train/                  |             |
|    approx_kl            | 0.004836113 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.669       |
|    learning_rate        | 5e-05       |
|    loss                 | 71          |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.588       |
|    value_loss           | 129         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0989       |
|    crash                | 0.232        |
|    max_step             | 0            |
|    mean_ep_length       | 259          |
|    mean_reward          | 262          |
|    num_episodes         | 5            |
|    out_of_road          | 0.901        |
|    raw_action           | 0.47630537   |
|    route_completion     | 0.434        |
|    success_rate         | 0.3          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 930000       |
| train/                  |              |
|    approx_kl            | 0.0010153585 |
|    arrive_dest          | 0.108        |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0.81         |
|    learning_rate        | 5e-05        |
|    loss                 | 41.5         |
|    max_step             | 0            |
|    n_updates            | 3620         |
|    out_of_road          | 0.892        |
|    policy_gradient_loss | -0.00234     |
|    route_completion     | 0.443        |
|    std                  | 0.586        |
|    total_cost           | 12.5         |
|    value_loss           | 73           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 271      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 182      |
|    time_elapsed    | 1809     |
|    total_timesteps | 931840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 280          |
|    ep_rew_mean          | 254          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 183          |
|    time_elapsed         | 1816         |
|    total_timesteps      | 936960       |
| train/                  |              |
|    approx_kl            | 0.0062669828 |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.762        |
|    learning_rate        | 5e-05        |
|    loss                 | 57           |
|    n_updates            | 3640         |
|    policy_gradient_loss | 0.002        |
|    std                  | 0.587        |
|    value_loss           | 97.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0979       |
|    crash                | 0.23         |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 128          |
|    num_episodes         | 5            |
|    out_of_road          | 0.902        |
|    raw_action           | 0.47700942   |
|    route_completion     | 0.433        |
|    success_rate         | 0            |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 940000       |
| train/                  |              |
|    approx_kl            | 0.0013098046 |
|    arrive_dest          | 0.106        |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    crash                | 0.234        |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.692        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.2         |
|    max_step             | 0            |
|    n_updates            | 3660         |
|    out_of_road          | 0.894        |
|    policy_gradient_loss | -0.00117     |
|    route_completion     | 0.441        |
|    std                  | 0.585        |
|    total_cost           | 12.4         |
|    value_loss           | 89.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 248      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 184      |
|    time_elapsed    | 1826     |
|    total_timesteps | 942080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 270          |
|    ep_rew_mean          | 248          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 185          |
|    time_elapsed         | 1834         |
|    total_timesteps      | 947200       |
| train/                  |              |
|    approx_kl            | 0.0013905421 |
|    clip_fraction        | 0.0911       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.2         |
|    n_updates            | 3680         |
|    policy_gradient_loss | -0.00221     |
|    std                  | 0.584        |
|    value_loss           | 112          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0989      |
|    crash                | 0.232       |
|    max_step             | 0           |
|    mean_ep_length       | 206         |
|    mean_reward          | 273         |
|    num_episodes         | 5           |
|    out_of_road          | 0.901       |
|    raw_action           | 0.4772535   |
|    route_completion     | 0.437       |
|    success_rate         | 0.2         |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.011213586 |
|    arrive_dest          | 0.107       |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.738       |
|    learning_rate        | 5e-05       |
|    loss                 | 50.5        |
|    max_step             | 0           |
|    n_updates            | 3700        |
|    out_of_road          | 0.893       |
|    policy_gradient_loss | 3.46e-05    |
|    route_completion     | 0.442       |
|    std                  | 0.582       |
|    total_cost           | 12.3        |
|    value_loss           | 121         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 186      |
|    time_elapsed    | 1847     |
|    total_timesteps | 952320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 269          |
|    ep_rew_mean          | 248          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 187          |
|    time_elapsed         | 1854         |
|    total_timesteps      | 957440       |
| train/                  |              |
|    approx_kl            | 0.0023371824 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.608        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.5         |
|    n_updates            | 3720         |
|    policy_gradient_loss | -0.000175    |
|    std                  | 0.582        |
|    value_loss           | 150          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0979       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 83.6         |
|    mean_reward          | 90.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.902        |
|    raw_action           | 0.47751823   |
|    route_completion     | 0.435        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 960000       |
| train/                  |              |
|    approx_kl            | 0.0032047569 |
|    arrive_dest          | 0.108        |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    crash                | 0.24         |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.639        |
|    learning_rate        | 5e-05        |
|    loss                 | 55.2         |
|    max_step             | 0            |
|    n_updates            | 3740         |
|    out_of_road          | 0.892        |
|    policy_gradient_loss | 0.000876     |
|    route_completion     | 0.443        |
|    std                  | 0.581        |
|    total_cost           | 12.3         |
|    value_loss           | 104          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 274      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 188      |
|    time_elapsed    | 1866     |
|    total_timesteps | 962560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 278          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 189          |
|    time_elapsed         | 1873         |
|    total_timesteps      | 967680       |
| train/                  |              |
|    approx_kl            | 0.0021798525 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.631        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.1         |
|    n_updates            | 3760         |
|    policy_gradient_loss | -0.000546    |
|    std                  | 0.581        |
|    value_loss           | 120          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.099       |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 166         |
|    mean_reward          | 202         |
|    num_episodes         | 5           |
|    out_of_road          | 0.901       |
|    raw_action           | 0.4781133   |
|    route_completion     | 0.437       |
|    success_rate         | 0.3         |
|    total_cost           | 11.9        |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.005020852 |
|    arrive_dest          | 0.111       |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.1         |
|    crash                | 0.237       |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.785       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.7        |
|    max_step             | 0           |
|    n_updates            | 3780        |
|    out_of_road          | 0.889       |
|    policy_gradient_loss | 0.00325     |
|    route_completion     | 0.444       |
|    std                  | 0.582       |
|    total_cost           | 12.4        |
|    value_loss           | 76.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 276      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 190      |
|    time_elapsed    | 1887     |
|    total_timesteps | 972800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 276         |
|    ep_rew_mean          | 255         |
| time/                   |             |
|    fps                  | 516         |
|    iterations           | 191         |
|    time_elapsed         | 1894        |
|    total_timesteps      | 977920      |
| train/                  |             |
|    approx_kl            | 0.002253164 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.638       |
|    learning_rate        | 5e-05       |
|    loss                 | 46          |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.000532   |
|    std                  | 0.582       |
|    value_loss           | 111         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.1         |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 191         |
|    mean_reward          | 142         |
|    num_episodes         | 5           |
|    out_of_road          | 0.9         |
|    raw_action           | 0.47852972  |
|    route_completion     | 0.438       |
|    success_rate         | 0.1         |
|    total_cost           | 12.1        |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.005012839 |
|    arrive_dest          | 0.11        |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.1         |
|    crash                | 0.239       |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.708       |
|    learning_rate        | 5e-05       |
|    loss                 | 59.1        |
|    max_step             | 0           |
|    n_updates            | 3820        |
|    out_of_road          | 0.89        |
|    policy_gradient_loss | 0.00185     |
|    route_completion     | 0.444       |
|    std                  | 0.581       |
|    total_cost           | 12.3        |
|    value_loss           | 99.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 192      |
|    time_elapsed    | 1907     |
|    total_timesteps | 983040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 285          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 193          |
|    time_elapsed         | 1914         |
|    total_timesteps      | 988160       |
| train/                  |              |
|    approx_kl            | 0.0008445202 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5e-05        |
|    loss                 | 45           |
|    n_updates            | 3840         |
|    policy_gradient_loss | -0.000303    |
|    std                  | 0.579        |
|    value_loss           | 93.2         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.101       |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 153         |
|    mean_reward          | 208         |
|    num_episodes         | 5           |
|    out_of_road          | 0.899       |
|    raw_action           | 0.4791447   |
|    route_completion     | 0.441       |
|    success_rate         | 0.3         |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.008243291 |
|    arrive_dest          | 0.113       |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    crash                | 0.238       |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.702       |
|    learning_rate        | 5e-05       |
|    loss                 | 39.2        |
|    max_step             | 0           |
|    n_updates            | 3860        |
|    out_of_road          | 0.887       |
|    policy_gradient_loss | 0.000818    |
|    route_completion     | 0.447       |
|    std                  | 0.579       |
|    total_cost           | 12.4        |
|    value_loss           | 93.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 280      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 194      |
|    time_elapsed    | 1926     |
|    total_timesteps | 993280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 273          |
|    ep_rew_mean          | 266          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 195          |
|    time_elapsed         | 1932         |
|    total_timesteps      | 998400       |
| train/                  |              |
|    approx_kl            | 0.0073105446 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.1         |
|    n_updates            | 3880         |
|    policy_gradient_loss | 0.00316      |
|    std                  | 0.579        |
|    value_loss           | 93           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.1          |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 146          |
|    mean_reward          | 133          |
|    num_episodes         | 5            |
|    out_of_road          | 0.9          |
|    raw_action           | 0.48065233   |
|    route_completion     | 0.44         |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0016564049 |
|    arrive_dest          | 0.114        |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.712        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.6         |
|    max_step             | 0            |
|    n_updates            | 3900         |
|    out_of_road          | 0.886        |
|    policy_gradient_loss | -0.00067     |
|    route_completion     | 0.448        |
|    std                  | 0.58         |
|    total_cost           | 12.5         |
|    value_loss           | 96           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 196      |
|    time_elapsed    | 1950     |
|    total_timesteps | 1003520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 292          |
|    ep_rew_mean          | 283          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 197          |
|    time_elapsed         | 1957         |
|    total_timesteps      | 1008640      |
| train/                  |              |
|    approx_kl            | 0.0029654445 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.747        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.3         |
|    n_updates            | 3920         |
|    policy_gradient_loss | 0.00178      |
|    std                  | 0.578        |
|    value_loss           | 80.4         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.099       |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 135         |
|    mean_reward          | 165         |
|    num_episodes         | 5           |
|    out_of_road          | 0.901       |
|    raw_action           | 0.48092297  |
|    route_completion     | 0.441       |
|    success_rate         | 0.2         |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 1010000     |
| train/                  |             |
|    approx_kl            | 0.002325238 |
|    arrive_dest          | 0.117       |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.731       |
|    learning_rate        | 5e-05       |
|    loss                 | 40.6        |
|    max_step             | 0           |
|    n_updates            | 3940        |
|    out_of_road          | 0.883       |
|    policy_gradient_loss | 0.00478     |
|    route_completion     | 0.452       |
|    std                  | 0.578       |
|    total_cost           | 12.5        |
|    value_loss           | 94.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 198      |
|    time_elapsed    | 1971     |
|    total_timesteps | 1013760  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 296         |
|    ep_rew_mean          | 280         |
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 199         |
|    time_elapsed         | 1978        |
|    total_timesteps      | 1018880     |
| train/                  |             |
|    approx_kl            | 0.001976572 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.794       |
|    learning_rate        | 5e-05       |
|    loss                 | 32          |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.000829   |
|    std                  | 0.578       |
|    value_loss           | 68.3        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.098        |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 128          |
|    mean_reward          | 114          |
|    num_episodes         | 5            |
|    out_of_road          | 0.902        |
|    raw_action           | 0.48052835   |
|    route_completion     | 0.44         |
|    success_rate         | 0            |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1020000      |
| train/                  |              |
|    approx_kl            | 0.0024740365 |
|    arrive_dest          | 0.116        |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.636        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.5         |
|    max_step             | 0            |
|    n_updates            | 3980         |
|    out_of_road          | 0.884        |
|    policy_gradient_loss | -0.000857    |
|    route_completion     | 0.45         |
|    std                  | 0.577        |
|    total_cost           | 12.4         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 291      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 200      |
|    time_elapsed    | 1989     |
|    total_timesteps | 1024000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 286         |
|    ep_rew_mean          | 268         |
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 201         |
|    time_elapsed         | 1997        |
|    total_timesteps      | 1029120     |
| train/                  |             |
|    approx_kl            | 0.002939632 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.644       |
|    learning_rate        | 5e-05       |
|    loss                 | 40.4        |
|    n_updates            | 4000        |
|    policy_gradient_loss | 0.00225     |
|    std                  | 0.576       |
|    value_loss           | 124         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0971      |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 117         |
|    mean_reward          | 131         |
|    num_episodes         | 5           |
|    out_of_road          | 0.903       |
|    raw_action           | 0.4805474   |
|    route_completion     | 0.44        |
|    success_rate         | 0           |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 1030000     |
| train/                  |             |
|    approx_kl            | 0.001590207 |
|    arrive_dest          | 0.115       |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.1         |
|    crash                | 0.237       |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.615       |
|    learning_rate        | 5e-05       |
|    loss                 | 40.6        |
|    max_step             | 0           |
|    n_updates            | 4020        |
|    out_of_road          | 0.885       |
|    policy_gradient_loss | -0.00259    |
|    route_completion     | 0.449       |
|    std                  | 0.578       |
|    total_cost           | 12.3        |
|    value_loss           | 114         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 202      |
|    time_elapsed    | 2008     |
|    total_timesteps | 1034240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 283          |
|    ep_rew_mean          | 266          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 203          |
|    time_elapsed         | 2014         |
|    total_timesteps      | 1039360      |
| train/                  |              |
|    approx_kl            | 0.0011372168 |
|    clip_fraction        | 0.191        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.624        |
|    learning_rate        | 5e-05        |
|    loss                 | 52           |
|    n_updates            | 4040         |
|    policy_gradient_loss | 0.00194      |
|    std                  | 0.577        |
|    value_loss           | 108          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0962       |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 132          |
|    mean_reward          | 176          |
|    num_episodes         | 5            |
|    out_of_road          | 0.904        |
|    raw_action           | 0.48059875   |
|    route_completion     | 0.44         |
|    success_rate         | 0            |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0022190036 |
|    arrive_dest          | 0.113        |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.873        |
|    learning_rate        | 5e-05        |
|    loss                 | 28.1         |
|    max_step             | 0            |
|    n_updates            | 4060         |
|    out_of_road          | 0.887        |
|    policy_gradient_loss | -0.000785    |
|    route_completion     | 0.45         |
|    std                  | 0.574        |
|    total_cost           | 12.3         |
|    value_loss           | 59.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 204      |
|    time_elapsed    | 2026     |
|    total_timesteps | 1044480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 282          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 205          |
|    time_elapsed         | 2032         |
|    total_timesteps      | 1049600      |
| train/                  |              |
|    approx_kl            | 0.0009611851 |
|    clip_fraction        | 0.0828       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.726        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.1         |
|    n_updates            | 4080         |
|    policy_gradient_loss | -0.00173     |
|    std                  | 0.574        |
|    value_loss           | 109          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0952       |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 157          |
|    num_episodes         | 5            |
|    out_of_road          | 0.905        |
|    raw_action           | 0.4807436    |
|    route_completion     | 0.44         |
|    success_rate         | 0            |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 1050000      |
| train/                  |              |
|    approx_kl            | 0.0023429047 |
|    arrive_dest          | 0.112        |
|    clip_fraction        | 0.17         |
|    clip_range           | 0.1          |
|    crash                | 0.234        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.768        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.3         |
|    max_step             | 0            |
|    n_updates            | 4100         |
|    out_of_road          | 0.888        |
|    policy_gradient_loss | 0.000306     |
|    route_completion     | 0.447        |
|    std                  | 0.576        |
|    total_cost           | 12.2         |
|    value_loss           | 95.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 275      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 206      |
|    time_elapsed    | 2042     |
|    total_timesteps | 1054720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 286          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 207          |
|    time_elapsed         | 2049         |
|    total_timesteps      | 1059840      |
| train/                  |              |
|    approx_kl            | 0.0026289592 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.697        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.4         |
|    n_updates            | 4120         |
|    policy_gradient_loss | 0.000263     |
|    std                  | 0.575        |
|    value_loss           | 111          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0962      |
|    crash                | 0.234       |
|    max_step             | 0           |
|    mean_ep_length       | 141         |
|    mean_reward          | 86.7        |
|    num_episodes         | 5           |
|    out_of_road          | 0.904       |
|    raw_action           | 0.48125118  |
|    route_completion     | 0.439       |
|    success_rate         | 0.1         |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 1060000     |
| train/                  |             |
|    approx_kl            | 0.002225876 |
|    arrive_dest          | 0.111       |
|    clip_fraction        | 0.0814      |
|    clip_range           | 0.1         |
|    crash                | 0.234       |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.738       |
|    learning_rate        | 5e-05       |
|    loss                 | 81.9        |
|    max_step             | 0           |
|    n_updates            | 4140        |
|    out_of_road          | 0.889       |
|    policy_gradient_loss | -0.00193    |
|    route_completion     | 0.447       |
|    std                  | 0.576       |
|    total_cost           | 12.1        |
|    value_loss           | 104         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 275      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 208      |
|    time_elapsed    | 2060     |
|    total_timesteps | 1064960  |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0972       |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 169          |
|    mean_reward          | 215          |
|    num_episodes         | 5            |
|    out_of_road          | 0.903        |
|    raw_action           | 0.48149592   |
|    route_completion     | 0.441        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1070000      |
| train/                  |              |
|    approx_kl            | 0.0018135372 |
|    arrive_dest          | 0.112        |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.722        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.5         |
|    max_step             | 0            |
|    n_updates            | 4160         |
|    out_of_road          | 0.888        |
|    policy_gradient_loss | 0.00114      |
|    route_completion     | 0.447        |
|    std                  | 0.576        |
|    total_cost           | 12           |
|    value_loss           | 126          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 270      |
|    ep_rew_mean     | 260      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 209      |
|    time_elapsed    | 2070     |
|    total_timesteps | 1070080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 259          |
|    ep_rew_mean          | 247          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 210          |
|    time_elapsed         | 2077         |
|    total_timesteps      | 1075200      |
| train/                  |              |
|    approx_kl            | 0.0054541873 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.731        |
|    learning_rate        | 5e-05        |
|    loss                 | 38           |
|    n_updates            | 4180         |
|    policy_gradient_loss | -0.000961    |
|    std                  | 0.574        |
|    value_loss           | 108          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0963       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 125          |
|    mean_reward          | 136          |
|    num_episodes         | 5            |
|    out_of_road          | 0.904        |
|    raw_action           | 0.48171937   |
|    route_completion     | 0.441        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1080000      |
| train/                  |              |
|    approx_kl            | 0.0030964888 |
|    arrive_dest          | 0.113        |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.746        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.3         |
|    max_step             | 0            |
|    n_updates            | 4200         |
|    out_of_road          | 0.887        |
|    policy_gradient_loss | -0.00215     |
|    route_completion     | 0.449        |
|    std                  | 0.572        |
|    total_cost           | 12           |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 211      |
|    time_elapsed    | 2089     |
|    total_timesteps | 1080320  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 268         |
|    ep_rew_mean          | 251         |
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 212         |
|    time_elapsed         | 2096        |
|    total_timesteps      | 1085440     |
| train/                  |             |
|    approx_kl            | 0.002814728 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.709       |
|    learning_rate        | 5e-05       |
|    loss                 | 73.7        |
|    n_updates            | 4220        |
|    policy_gradient_loss | 0.00287     |
|    std                  | 0.572       |
|    value_loss           | 116         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0954       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 167          |
|    mean_reward          | 198          |
|    num_episodes         | 5            |
|    out_of_road          | 0.905        |
|    raw_action           | 0.4819722    |
|    route_completion     | 0.443        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1090000      |
| train/                  |              |
|    approx_kl            | 0.0019314453 |
|    arrive_dest          | 0.114        |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.759        |
|    learning_rate        | 5e-05        |
|    loss                 | 35.6         |
|    max_step             | 0            |
|    n_updates            | 4240         |
|    out_of_road          | 0.886        |
|    policy_gradient_loss | 0.00201      |
|    route_completion     | 0.45         |
|    std                  | 0.571        |
|    total_cost           | 12           |
|    value_loss           | 97.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 267      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 213      |
|    time_elapsed    | 2107     |
|    total_timesteps | 1090560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 267          |
|    ep_rew_mean          | 257          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 214          |
|    time_elapsed         | 2114         |
|    total_timesteps      | 1095680      |
| train/                  |              |
|    approx_kl            | 0.0012355505 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.636        |
|    learning_rate        | 5e-05        |
|    loss                 | 44           |
|    n_updates            | 4260         |
|    policy_gradient_loss | -0.000143    |
|    std                  | 0.569        |
|    value_loss           | 125          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0945      |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 146         |
|    mean_reward          | 178         |
|    num_episodes         | 5           |
|    out_of_road          | 0.905       |
|    raw_action           | 0.4816266   |
|    route_completion     | 0.444       |
|    success_rate         | 0           |
|    total_cost           | 11.8        |
| time/                   |             |
|    total_timesteps      | 1100000     |
| train/                  |             |
|    approx_kl            | 0.002335586 |
|    arrive_dest          | 0.113       |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.1         |
|    crash                | 0.238       |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.649       |
|    learning_rate        | 5e-05       |
|    loss                 | 58.3        |
|    max_step             | 0           |
|    n_updates            | 4280        |
|    out_of_road          | 0.887       |
|    policy_gradient_loss | -0.00148    |
|    route_completion     | 0.453       |
|    std                  | 0.571       |
|    total_cost           | 12          |
|    value_loss           | 115         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 271      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 215      |
|    time_elapsed    | 2127     |
|    total_timesteps | 1100800  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 261          |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 216          |
|    time_elapsed         | 2134         |
|    total_timesteps      | 1105920      |
| train/                  |              |
|    approx_kl            | 0.0021618893 |
|    clip_fraction        | 0.0978       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.605        |
|    learning_rate        | 5e-05        |
|    loss                 | 85.7         |
|    n_updates            | 4300         |
|    policy_gradient_loss | -0.00194     |
|    std                  | 0.572        |
|    value_loss           | 124          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0937      |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 124         |
|    mean_reward          | 145         |
|    num_episodes         | 5           |
|    out_of_road          | 0.906       |
|    raw_action           | 0.48192137  |
|    route_completion     | 0.444       |
|    success_rate         | 0.1         |
|    total_cost           | 11.8        |
| time/                   |             |
|    total_timesteps      | 1110000     |
| train/                  |             |
|    approx_kl            | 0.004470733 |
|    arrive_dest          | 0.114       |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.1         |
|    crash                | 0.241       |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.716       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.2        |
|    max_step             | 0           |
|    n_updates            | 4320        |
|    out_of_road          | 0.886       |
|    policy_gradient_loss | -0.00158    |
|    route_completion     | 0.454       |
|    std                  | 0.573       |
|    total_cost           | 11.9        |
|    value_loss           | 111         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 217      |
|    time_elapsed    | 2145     |
|    total_timesteps | 1111040  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 263         |
|    ep_rew_mean          | 260         |
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 218         |
|    time_elapsed         | 2152        |
|    total_timesteps      | 1116160     |
| train/                  |             |
|    approx_kl            | 0.003627582 |
|    clip_fraction        | 0.0918      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.654       |
|    learning_rate        | 5e-05       |
|    loss                 | 55.7        |
|    n_updates            | 4340        |
|    policy_gradient_loss | -0.0032     |
|    std                  | 0.571       |
|    value_loss           | 119         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0929      |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 94.8        |
|    mean_reward          | 112         |
|    num_episodes         | 5           |
|    out_of_road          | 0.907       |
|    raw_action           | 0.48218298  |
|    route_completion     | 0.443       |
|    success_rate         | 0.2         |
|    total_cost           | 11.7        |
| time/                   |             |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.001843385 |
|    arrive_dest          | 0.116       |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    crash                | 0.241       |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.786       |
|    learning_rate        | 5e-05       |
|    loss                 | 39.6        |
|    max_step             | 0           |
|    n_updates            | 4360        |
|    out_of_road          | 0.884       |
|    policy_gradient_loss | -0.000665   |
|    route_completion     | 0.455       |
|    std                  | 0.569       |
|    total_cost           | 11.9        |
|    value_loss           | 98.2        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 219      |
|    time_elapsed    | 2165     |
|    total_timesteps | 1121280  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 270        |
|    ep_rew_mean          | 271        |
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 220        |
|    time_elapsed         | 2172       |
|    total_timesteps      | 1126400    |
| train/                  |            |
|    approx_kl            | 0.01804828 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.66      |
|    explained_variance   | 0.618      |
|    learning_rate        | 5e-05      |
|    loss                 | 58.7       |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.000432   |
|    std                  | 0.569      |
|    value_loss           | 156        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.092        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 148          |
|    mean_reward          | 201          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.48180693   |
|    route_completion     | 0.444        |
|    success_rate         | 0.1          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 1130000      |
| train/                  |              |
|    approx_kl            | 0.0024442903 |
|    arrive_dest          | 0.117        |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.241        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.747        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.7         |
|    max_step             | 0            |
|    n_updates            | 4400         |
|    out_of_road          | 0.883        |
|    policy_gradient_loss | -0.00088     |
|    route_completion     | 0.455        |
|    std                  | 0.568        |
|    total_cost           | 11.8         |
|    value_loss           | 85.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 270      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 221      |
|    time_elapsed    | 2182     |
|    total_timesteps | 1131520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 262          |
|    ep_rew_mean          | 262          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 222          |
|    time_elapsed         | 2190         |
|    total_timesteps      | 1136640      |
| train/                  |              |
|    approx_kl            | 0.0016615009 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.8         |
|    n_updates            | 4420         |
|    policy_gradient_loss | -0.00072     |
|    std                  | 0.567        |
|    value_loss           | 111          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0912       |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 150          |
|    mean_reward          | 202          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4818928    |
|    route_completion     | 0.445        |
|    success_rate         | 0.1          |
|    total_cost           | 11.6         |
| time/                   |              |
|    total_timesteps      | 1140000      |
| train/                  |              |
|    approx_kl            | 0.0016940057 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.677        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.5         |
|    max_step             | 0            |
|    n_updates            | 4440         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.00105      |
|    route_completion     | 0.457        |
|    std                  | 0.567        |
|    total_cost           | 11.8         |
|    value_loss           | 127          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 223      |
|    time_elapsed    | 2201     |
|    total_timesteps | 1141760  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 256         |
|    ep_rew_mean          | 256         |
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 224         |
|    time_elapsed         | 2208        |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.018580128 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.714       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.6        |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.000608   |
|    std                  | 0.566       |
|    value_loss           | 103         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0904       |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 123          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.4814475    |
|    route_completion     | 0.445        |
|    success_rate         | 0.1          |
|    total_cost           | 11.5         |
| time/                   |              |
|    total_timesteps      | 1150000      |
| train/                  |              |
|    approx_kl            | 0.0014370668 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.186        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.6         |
|    max_step             | 0            |
|    n_updates            | 4480         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.00063      |
|    route_completion     | 0.456        |
|    std                  | 0.568        |
|    total_cost           | 11.7         |
|    value_loss           | 125          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 256      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 225      |
|    time_elapsed    | 2219     |
|    total_timesteps | 1152000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 252          |
|    ep_rew_mean          | 250          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 226          |
|    time_elapsed         | 2226         |
|    total_timesteps      | 1157120      |
| train/                  |              |
|    approx_kl            | 0.0015647507 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0.615        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.3         |
|    n_updates            | 4500         |
|    policy_gradient_loss | -0.00087     |
|    std                  | 0.565        |
|    value_loss           | 126          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0897     |
|    crash                | 0.255      |
|    max_step             | 0          |
|    mean_ep_length       | 110        |
|    mean_reward          | 142        |
|    num_episodes         | 5          |
|    out_of_road          | 0.91       |
|    raw_action           | 0.48076853 |
|    route_completion     | 0.445      |
|    success_rate         | 0.1        |
|    total_cost           | 11.4       |
| time/                   |            |
|    total_timesteps      | 1160000    |
| train/                  |            |
|    approx_kl            | 0.01039693 |
|    arrive_dest          | 0.119      |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.1        |
|    crash                | 0.243      |
|    entropy_loss         | -1.65      |
|    explained_variance   | 0.79       |
|    learning_rate        | 5e-05      |
|    loss                 | 50.9       |
|    max_step             | 0          |
|    n_updates            | 4520       |
|    out_of_road          | 0.881      |
|    policy_gradient_loss | -0.000484  |
|    route_completion     | 0.458      |
|    std                  | 0.568      |
|    total_cost           | 11.8       |
|    value_loss           | 116        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 227      |
|    time_elapsed    | 2242     |
|    total_timesteps | 1162240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 258         |
|    ep_rew_mean          | 254         |
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 228         |
|    time_elapsed         | 2248        |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.001852083 |
|    clip_fraction        | 0.093       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.621       |
|    learning_rate        | 5e-05       |
|    loss                 | 41.3        |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.00201    |
|    std                  | 0.567       |
|    value_loss           | 135         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0889       |
|    crash                | 0.256        |
|    max_step             | 0            |
|    mean_ep_length       | 151          |
|    mean_reward          | 224          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.48123783   |
|    route_completion     | 0.446        |
|    success_rate         | 0.3          |
|    total_cost           | 11.3         |
| time/                   |              |
|    total_timesteps      | 1170000      |
| train/                  |              |
|    approx_kl            | 0.0024944046 |
|    arrive_dest          | 0.123        |
|    clip_fraction        | 0.204        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.747        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.5         |
|    max_step             | 0            |
|    n_updates            | 4560         |
|    out_of_road          | 0.877        |
|    policy_gradient_loss | 0.000853     |
|    route_completion     | 0.461        |
|    std                  | 0.565        |
|    total_cost           | 11.8         |
|    value_loss           | 106          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 256      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 229      |
|    time_elapsed    | 2261     |
|    total_timesteps | 1172480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 260          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 230          |
|    time_elapsed         | 2269         |
|    total_timesteps      | 1177600      |
| train/                  |              |
|    approx_kl            | 0.0024121075 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.64        |
|    explained_variance   | 0.671        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.5         |
|    n_updates            | 4580         |
|    policy_gradient_loss | 0.000252     |
|    std                  | 0.564        |
|    value_loss           | 125          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0881       |
|    crash                | 0.259        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.48168305   |
|    route_completion     | 0.447        |
|    success_rate         | 0.1          |
|    total_cost           | 11.3         |
| time/                   |              |
|    total_timesteps      | 1180000      |
| train/                  |              |
|    approx_kl            | 0.0018738766 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.814        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.6         |
|    max_step             | 0            |
|    n_updates            | 4600         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | -0.000632    |
|    route_completion     | 0.461        |
|    std                  | 0.563        |
|    total_cost           | 11.7         |
|    value_loss           | 105          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 267      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 231      |
|    time_elapsed    | 2280     |
|    total_timesteps | 1182720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 269          |
|    ep_rew_mean          | 261          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 232          |
|    time_elapsed         | 2287         |
|    total_timesteps      | 1187840      |
| train/                  |              |
|    approx_kl            | 0.0029281792 |
|    clip_fraction        | 0.0921       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.805        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.1         |
|    n_updates            | 4620         |
|    policy_gradient_loss | -0.0015      |
|    std                  | 0.562        |
|    value_loss           | 111          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0891       |
|    crash                | 0.257        |
|    max_step             | 0            |
|    mean_ep_length       | 186          |
|    mean_reward          | 246          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.48139825   |
|    route_completion     | 0.448        |
|    success_rate         | 0.2          |
|    total_cost           | 11.2         |
| time/                   |              |
|    total_timesteps      | 1190000      |
| train/                  |              |
|    approx_kl            | 0.0023359156 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    crash                | 0.245        |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.795        |
|    learning_rate        | 5e-05        |
|    loss                 | 39           |
|    max_step             | 0            |
|    n_updates            | 4640         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | -0.000561    |
|    route_completion     | 0.461        |
|    std                  | 0.562        |
|    total_cost           | 11.7         |
|    value_loss           | 101          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 280      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 233      |
|    time_elapsed    | 2299     |
|    total_timesteps | 1192960  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 276         |
|    ep_rew_mean          | 275         |
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 234         |
|    time_elapsed         | 2306        |
|    total_timesteps      | 1198080     |
| train/                  |             |
|    approx_kl            | 0.001683395 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.687       |
|    learning_rate        | 5e-05       |
|    loss                 | 57.9        |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.0025     |
|    std                  | 0.562       |
|    value_loss           | 138         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0883       |
|    crash                | 0.257        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 189          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.4813672    |
|    route_completion     | 0.449        |
|    success_rate         | 0.3          |
|    total_cost           | 11.1         |
| time/                   |              |
|    total_timesteps      | 1200000      |
| train/                  |              |
|    approx_kl            | 0.0016886439 |
|    arrive_dest          | 0.128        |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.247        |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.77         |
|    learning_rate        | 5e-05        |
|    loss                 | 45.2         |
|    max_step             | 0            |
|    n_updates            | 4680         |
|    out_of_road          | 0.872        |
|    policy_gradient_loss | -0.00105     |
|    route_completion     | 0.463        |
|    std                  | 0.563        |
|    total_cost           | 11.7         |
|    value_loss           | 95           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 235      |
|    time_elapsed    | 2321     |
|    total_timesteps | 1203200  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 271          |
|    ep_rew_mean          | 273          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 236          |
|    time_elapsed         | 2328         |
|    total_timesteps      | 1208320      |
| train/                  |              |
|    approx_kl            | 0.0022770448 |
|    clip_fraction        | 0.0928       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.63        |
|    explained_variance   | 0.674        |
|    learning_rate        | 5e-05        |
|    loss                 | 44.3         |
|    n_updates            | 4700         |
|    policy_gradient_loss | -0.00122     |
|    std                  | 0.562        |
|    value_loss           | 138          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0876      |
|    crash                | 0.258       |
|    max_step             | 0           |
|    mean_ep_length       | 158         |
|    mean_reward          | 246         |
|    num_episodes         | 5           |
|    out_of_road          | 0.912       |
|    raw_action           | 0.48202053  |
|    route_completion     | 0.451       |
|    success_rate         | 0           |
|    total_cost           | 11.1        |
| time/                   |             |
|    total_timesteps      | 1210000     |
| train/                  |             |
|    approx_kl            | 0.001585499 |
|    arrive_dest          | 0.127       |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.1         |
|    crash                | 0.245       |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.594       |
|    learning_rate        | 5e-05       |
|    loss                 | 83.1        |
|    max_step             | 0           |
|    n_updates            | 4720        |
|    out_of_road          | 0.873       |
|    policy_gradient_loss | -0.000541   |
|    route_completion     | 0.463       |
|    std                  | 0.562       |
|    total_cost           | 11.6        |
|    value_loss           | 169         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 237      |
|    time_elapsed    | 2342     |
|    total_timesteps | 1213440  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 256          |
|    ep_rew_mean          | 270          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 238          |
|    time_elapsed         | 2348         |
|    total_timesteps      | 1218560      |
| train/                  |              |
|    approx_kl            | 0.0059589376 |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.552        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.4         |
|    n_updates            | 4740         |
|    policy_gradient_loss | -0.000973    |
|    std                  | 0.561        |
|    value_loss           | 132          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0885       |
|    crash                | 0.257        |
|    max_step             | 0            |
|    mean_ep_length       | 161          |
|    mean_reward          | 217          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.4824313    |
|    route_completion     | 0.452        |
|    success_rate         | 0.1          |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 1220000      |
| train/                  |              |
|    approx_kl            | 0.0031749383 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.737        |
|    learning_rate        | 5e-05        |
|    loss                 | 54           |
|    max_step             | 0            |
|    n_updates            | 4760         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | 0.00184      |
|    route_completion     | 0.463        |
|    std                  | 0.56         |
|    total_cost           | 11.6         |
|    value_loss           | 101          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 239      |
|    time_elapsed    | 2359     |
|    total_timesteps | 1223680  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 245         |
|    ep_rew_mean          | 253         |
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 240         |
|    time_elapsed         | 2366        |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.003911977 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.657       |
|    learning_rate        | 5e-05       |
|    loss                 | 89.6        |
|    n_updates            | 4780        |
|    policy_gradient_loss | 0.00111     |
|    std                  | 0.559       |
|    value_loss           | 165         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0894       |
|    crash                | 0.257        |
|    max_step             | 0            |
|    mean_ep_length       | 117          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.48225018   |
|    route_completion     | 0.453        |
|    success_rate         | 0.1          |
|    total_cost           | 10.9         |
| time/                   |              |
|    total_timesteps      | 1230000      |
| train/                  |              |
|    approx_kl            | 0.0015782209 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.614        |
|    learning_rate        | 5e-05        |
|    loss                 | 58           |
|    max_step             | 0            |
|    n_updates            | 4800         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | -0.0012      |
|    route_completion     | 0.462        |
|    std                  | 0.559        |
|    total_cost           | 11.5         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 241      |
|    time_elapsed    | 2376     |
|    total_timesteps | 1233920  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 241          |
|    ep_rew_mean          | 245          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 242          |
|    time_elapsed         | 2385         |
|    total_timesteps      | 1239040      |
| train/                  |              |
|    approx_kl            | 0.0024514706 |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.61        |
|    explained_variance   | 0.727        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.6         |
|    n_updates            | 4820         |
|    policy_gradient_loss | -0.00117     |
|    std                  | 0.558        |
|    value_loss           | 121          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0903      |
|    crash                | 0.261       |
|    max_step             | 0           |
|    mean_ep_length       | 147         |
|    mean_reward          | 198         |
|    num_episodes         | 5           |
|    out_of_road          | 0.91        |
|    raw_action           | 0.48256108  |
|    route_completion     | 0.454       |
|    success_rate         | 0.1         |
|    total_cost           | 10.9        |
| time/                   |             |
|    total_timesteps      | 1240000     |
| train/                  |             |
|    approx_kl            | 0.018009339 |
|    arrive_dest          | 0.124       |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.1         |
|    crash                | 0.244       |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.78        |
|    learning_rate        | 5e-05       |
|    loss                 | 43.9        |
|    max_step             | 0           |
|    n_updates            | 4840        |
|    out_of_road          | 0.876       |
|    policy_gradient_loss | 0.00197     |
|    route_completion     | 0.463       |
|    std                  | 0.558       |
|    total_cost           | 11.4        |
|    value_loss           | 115         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 228      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 243      |
|    time_elapsed    | 2400     |
|    total_timesteps | 1244160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 236          |
|    ep_rew_mean          | 244          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 244          |
|    time_elapsed         | 2406         |
|    total_timesteps      | 1249280      |
| train/                  |              |
|    approx_kl            | 0.0025637515 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.6         |
|    explained_variance   | 0.648        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.1         |
|    n_updates            | 4860         |
|    policy_gradient_loss | -0.000486    |
|    std                  | 0.557        |
|    value_loss           | 163          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0896       |
|    crash                | 0.262        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 185          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.48295993   |
|    route_completion     | 0.454        |
|    success_rate         | 0.2          |
|    total_cost           | 10.8         |
| time/                   |              |
|    total_timesteps      | 1250000      |
| train/                  |              |
|    approx_kl            | 0.0037772711 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.169        |
|    clip_range           | 0.1          |
|    crash                | 0.245        |
|    entropy_loss         | -1.6         |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.2         |
|    max_step             | 0            |
|    n_updates            | 4880         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | -0.000353    |
|    route_completion     | 0.464        |
|    std                  | 0.557        |
|    total_cost           | 11.4         |
|    value_loss           | 115          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 232      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 245      |
|    time_elapsed    | 2418     |
|    total_timesteps | 1254400  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 227          |
|    ep_rew_mean          | 232          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 246          |
|    time_elapsed         | 2426         |
|    total_timesteps      | 1259520      |
| train/                  |              |
|    approx_kl            | 0.0013218649 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.6         |
|    explained_variance   | 0.65         |
|    learning_rate        | 5e-05        |
|    loss                 | 74.2         |
|    n_updates            | 4900         |
|    policy_gradient_loss | -0.000433    |
|    std                  | 0.558        |
|    value_loss           | 155          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0889       |
|    crash                | 0.26         |
|    max_step             | 0            |
|    mean_ep_length       | 86.4         |
|    mean_reward          | 91.7         |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.48320878   |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 1260000      |
| train/                  |              |
|    approx_kl            | 0.0036532898 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    crash                | 0.248        |
|    entropy_loss         | -1.6         |
|    explained_variance   | 0.719        |
|    learning_rate        | 5e-05        |
|    loss                 | 55.9         |
|    max_step             | 0            |
|    n_updates            | 4920         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | 0.00216      |
|    route_completion     | 0.465        |
|    std                  | 0.557        |
|    total_cost           | 11.4         |
|    value_loss           | 140          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 234      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 247      |
|    time_elapsed    | 2437     |
|    total_timesteps | 1264640  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 233          |
|    ep_rew_mean          | 239          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 248          |
|    time_elapsed         | 2444         |
|    total_timesteps      | 1269760      |
| train/                  |              |
|    approx_kl            | 0.0015283555 |
|    clip_fraction        | 0.195        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.59        |
|    explained_variance   | 0.711        |
|    learning_rate        | 5e-05        |
|    loss                 | 62.3         |
|    n_updates            | 4940         |
|    policy_gradient_loss | 0.00294      |
|    std                  | 0.554        |
|    value_loss           | 123          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0882       |
|    crash                | 0.261        |
|    max_step             | 0            |
|    mean_ep_length       | 78.6         |
|    mean_reward          | 78.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.48344657   |
|    route_completion     | 0.451        |
|    success_rate         | 0            |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 1270000      |
| train/                  |              |
|    approx_kl            | 0.0021487523 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    crash                | 0.246        |
|    entropy_loss         | -1.59        |
|    explained_variance   | 0.722        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.2         |
|    max_step             | 0            |
|    n_updates            | 4960         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | -0.00181     |
|    route_completion     | 0.464        |
|    std                  | 0.554        |
|    total_cost           | 11.3         |
|    value_loss           | 135          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 228      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 249      |
|    time_elapsed    | 2453     |
|    total_timesteps | 1274880  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0891      |
|    crash                | 0.259       |
|    max_step             | 0           |
|    mean_ep_length       | 177         |
|    mean_reward          | 230         |
|    num_episodes         | 5           |
|    out_of_road          | 0.911       |
|    raw_action           | 0.48317552  |
|    route_completion     | 0.452       |
|    success_rate         | 0.2         |
|    total_cost           | 10.6        |
| time/                   |             |
|    total_timesteps      | 1280000     |
| train/                  |             |
|    approx_kl            | 0.012069547 |
|    arrive_dest          | 0.125       |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.1         |
|    crash                | 0.244       |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.675       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.1        |
|    max_step             | 0           |
|    n_updates            | 4980        |
|    out_of_road          | 0.875       |
|    policy_gradient_loss | 0.00069     |
|    route_completion     | 0.464       |
|    std                  | 0.551       |
|    total_cost           | 11.3        |
|    value_loss           | 141         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 238      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 250      |
|    time_elapsed    | 2468     |
|    total_timesteps | 1280000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 231          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 251          |
|    time_elapsed         | 2474         |
|    total_timesteps      | 1285120      |
| train/                  |              |
|    approx_kl            | 0.0016804829 |
|    clip_fraction        | 0.0896       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.672        |
|    learning_rate        | 5e-05        |
|    loss                 | 88.6         |
|    n_updates            | 5000         |
|    policy_gradient_loss | -0.00171     |
|    std                  | 0.549        |
|    value_loss           | 158          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0899       |
|    crash                | 0.259        |
|    max_step             | 0            |
|    mean_ep_length       | 160          |
|    mean_reward          | 213          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.48343706   |
|    route_completion     | 0.452        |
|    success_rate         | 0.2          |
|    total_cost           | 10.6         |
| time/                   |              |
|    total_timesteps      | 1290000      |
| train/                  |              |
|    approx_kl            | 0.0048906407 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.185        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.602        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.4         |
|    max_step             | 0            |
|    n_updates            | 5020         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | 0.00358      |
|    route_completion     | 0.463        |
|    std                  | 0.548        |
|    total_cost           | 11.2         |
|    value_loss           | 135          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 236      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 252      |
|    time_elapsed    | 2486     |
|    total_timesteps | 1290240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 232          |
|    ep_rew_mean          | 245          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 253          |
|    time_elapsed         | 2492         |
|    total_timesteps      | 1295360      |
| train/                  |              |
|    approx_kl            | 0.0017125417 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.682        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.8         |
|    n_updates            | 5040         |
|    policy_gradient_loss | 0.000891     |
|    std                  | 0.547        |
|    value_loss           | 132          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0892       |
|    crash                | 0.26         |
|    max_step             | 0            |
|    mean_ep_length       | 136          |
|    mean_reward          | 185          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.48356432   |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 10.5         |
| time/                   |              |
|    total_timesteps      | 1300000      |
| train/                  |              |
|    approx_kl            | 0.0014361289 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.56        |
|    explained_variance   | 0.658        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.9         |
|    max_step             | 0            |
|    n_updates            | 5060         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | 0.000511     |
|    route_completion     | 0.462        |
|    std                  | 0.546        |
|    total_cost           | 11.1         |
|    value_loss           | 139          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 239      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 254      |
|    time_elapsed    | 2503     |
|    total_timesteps | 1300480  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 226         |
|    ep_rew_mean          | 235         |
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 255         |
|    time_elapsed         | 2510        |
|    total_timesteps      | 1305600     |
| train/                  |             |
|    approx_kl            | 0.001464226 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.624       |
|    learning_rate        | 5e-05       |
|    loss                 | 72.4        |
|    n_updates            | 5080        |
|    policy_gradient_loss | -0.00128    |
|    std                  | 0.546       |
|    value_loss           | 149         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0885       |
|    crash                | 0.261        |
|    max_step             | 0            |
|    mean_ep_length       | 125          |
|    mean_reward          | 172          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.483362     |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 10.5         |
| time/                   |              |
|    total_timesteps      | 1310000      |
| train/                  |              |
|    approx_kl            | 0.0052362992 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.24         |
|    entropy_loss         | -1.55        |
|    explained_variance   | 0.667        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.4         |
|    max_step             | 0            |
|    n_updates            | 5100         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | -0.00027     |
|    route_completion     | 0.461        |
|    std                  | 0.545        |
|    total_cost           | 11           |
|    value_loss           | 143          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 236      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 256      |
|    time_elapsed    | 2520     |
|    total_timesteps | 1310720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 234          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 257          |
|    time_elapsed         | 2527         |
|    total_timesteps      | 1315840      |
| train/                  |              |
|    approx_kl            | 0.0021493328 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.55        |
|    explained_variance   | 0.584        |
|    learning_rate        | 5e-05        |
|    loss                 | 65.5         |
|    n_updates            | 5120         |
|    policy_gradient_loss | -0.00225     |
|    std                  | 0.546        |
|    value_loss           | 158          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0879      |
|    crash                | 0.261       |
|    max_step             | 0           |
|    mean_ep_length       | 99.8        |
|    mean_reward          | 115         |
|    num_episodes         | 5           |
|    out_of_road          | 0.912       |
|    raw_action           | 0.48350784  |
|    route_completion     | 0.452       |
|    success_rate         | 0.1         |
|    total_cost           | 10.4        |
| time/                   |             |
|    total_timesteps      | 1320000     |
| train/                  |             |
|    approx_kl            | 0.009630051 |
|    arrive_dest          | 0.124       |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.1         |
|    crash                | 0.239       |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.722       |
|    learning_rate        | 5e-05       |
|    loss                 | 62          |
|    max_step             | 0           |
|    n_updates            | 5140        |
|    out_of_road          | 0.876       |
|    policy_gradient_loss | 0.00288     |
|    route_completion     | 0.461       |
|    std                  | 0.545       |
|    total_cost           | 11          |
|    value_loss           | 125         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 228      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 258      |
|    time_elapsed    | 2537     |
|    total_timesteps | 1320960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 231          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 259          |
|    time_elapsed         | 2544         |
|    total_timesteps      | 1326080      |
| train/                  |              |
|    approx_kl            | 0.0022994955 |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.662        |
|    learning_rate        | 5e-05        |
|    loss                 | 77.9         |
|    n_updates            | 5160         |
|    policy_gradient_loss | -0.00178     |
|    std                  | 0.542        |
|    value_loss           | 134          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0872       |
|    crash                | 0.26         |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 187          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.4835336    |
|    route_completion     | 0.452        |
|    success_rate         | 0            |
|    total_cost           | 10.4         |
| time/                   |              |
|    total_timesteps      | 1330000      |
| train/                  |              |
|    approx_kl            | 0.0017695191 |
|    arrive_dest          | 0.123        |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    crash                | 0.238        |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.709        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.7         |
|    max_step             | 0            |
|    n_updates            | 5180         |
|    out_of_road          | 0.877        |
|    policy_gradient_loss | -0.000874    |
|    route_completion     | 0.461        |
|    std                  | 0.543        |
|    total_cost           | 10.9         |
|    value_loss           | 133          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 236      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 260      |
|    time_elapsed    | 2554     |
|    total_timesteps | 1331200  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 232          |
|    ep_rew_mean          | 240          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 261          |
|    time_elapsed         | 2561         |
|    total_timesteps      | 1336320      |
| train/                  |              |
|    approx_kl            | 0.0021654668 |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.657        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.1         |
|    n_updates            | 5200         |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.541        |
|    value_loss           | 139          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0866       |
|    crash                | 0.261        |
|    max_step             | 0            |
|    mean_ep_length       | 123          |
|    mean_reward          | 132          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.48361424   |
|    route_completion     | 0.452        |
|    success_rate         | 0.2          |
|    total_cost           | 10.3         |
| time/                   |              |
|    total_timesteps      | 1340000      |
| train/                  |              |
|    approx_kl            | 0.0020833553 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.6         |
|    max_step             | 0            |
|    n_updates            | 5220         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | 0.0011       |
|    route_completion     | 0.463        |
|    std                  | 0.544        |
|    total_cost           | 11           |
|    value_loss           | 128          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 245      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 262      |
|    time_elapsed    | 2573     |
|    total_timesteps | 1341440  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 232          |
|    ep_rew_mean          | 241          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 263          |
|    time_elapsed         | 2580         |
|    total_timesteps      | 1346560      |
| train/                  |              |
|    approx_kl            | 0.0020140274 |
|    clip_fraction        | 0.207        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.593        |
|    learning_rate        | 5e-05        |
|    loss                 | 77.5         |
|    n_updates            | 5240         |
|    policy_gradient_loss | 0.00825      |
|    std                  | 0.543        |
|    value_loss           | 174          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0859       |
|    crash                | 0.262        |
|    max_step             | 0            |
|    mean_ep_length       | 89.2         |
|    mean_reward          | 96.2         |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.4838212    |
|    route_completion     | 0.451        |
|    success_rate         | 0            |
|    total_cost           | 10.3         |
| time/                   |              |
|    total_timesteps      | 1350000      |
| train/                  |              |
|    approx_kl            | 0.0038861386 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.24         |
|    entropy_loss         | -1.54        |
|    explained_variance   | 0.756        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.8         |
|    max_step             | 0            |
|    n_updates            | 5260         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | 0.000291     |
|    route_completion     | 0.462        |
|    std                  | 0.542        |
|    total_cost           | 10.9         |
|    value_loss           | 118          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 236      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 264      |
|    time_elapsed    | 2590     |
|    total_timesteps | 1351680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 208          |
|    ep_rew_mean          | 219          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 265          |
|    time_elapsed         | 2596         |
|    total_timesteps      | 1356800      |
| train/                  |              |
|    approx_kl            | 0.0027703948 |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.579        |
|    learning_rate        | 5e-05        |
|    loss                 | 115          |
|    n_updates            | 5280         |
|    policy_gradient_loss | -0.00117     |
|    std                  | 0.542        |
|    value_loss           | 172          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0853      |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 89.4        |
|    mean_reward          | 92          |
|    num_episodes         | 5           |
|    out_of_road          | 0.915       |
|    raw_action           | 0.48356637  |
|    route_completion     | 0.45        |
|    success_rate         | 0.1         |
|    total_cost           | 10.2        |
| time/                   |             |
|    total_timesteps      | 1360000     |
| train/                  |             |
|    approx_kl            | 0.002389912 |
|    arrive_dest          | 0.125       |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.1         |
|    crash                | 0.241       |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5e-05       |
|    loss                 | 77.4        |
|    max_step             | 0           |
|    n_updates            | 5300        |
|    out_of_road          | 0.875       |
|    policy_gradient_loss | 4.27e-05    |
|    route_completion     | 0.463       |
|    std                  | 0.542       |
|    total_cost           | 11          |
|    value_loss           | 144         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 206      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 266      |
|    time_elapsed    | 2608     |
|    total_timesteps | 1361920  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 267         |
|    time_elapsed         | 2615        |
|    total_timesteps      | 1367040     |
| train/                  |             |
|    approx_kl            | 0.001717135 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.7         |
|    learning_rate        | 5e-05       |
|    loss                 | 72.8        |
|    n_updates            | 5320        |
|    policy_gradient_loss | -0.000669   |
|    std                  | 0.541       |
|    value_loss           | 138         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0847       |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 146          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.48306486   |
|    route_completion     | 0.45         |
|    success_rate         | 0.1          |
|    total_cost           | 10.1         |
| time/                   |              |
|    total_timesteps      | 1370000      |
| train/                  |              |
|    approx_kl            | 0.0022326803 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.651        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.4         |
|    max_step             | 0            |
|    n_updates            | 5340         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | 0.00146      |
|    route_completion     | 0.463        |
|    std                  | 0.541        |
|    total_cost           | 11           |
|    value_loss           | 138          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 268      |
|    time_elapsed    | 2626     |
|    total_timesteps | 1372160  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 208         |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 269         |
|    time_elapsed         | 2632        |
|    total_timesteps      | 1377280     |
| train/                  |             |
|    approx_kl            | 0.003194214 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.63        |
|    learning_rate        | 5e-05       |
|    loss                 | 79.3        |
|    n_updates            | 5360        |
|    policy_gradient_loss | -0.00194    |
|    std                  | 0.541       |
|    value_loss           | 160         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0841      |
|    crash                | 0.265       |
|    max_step             | 0           |
|    mean_ep_length       | 112         |
|    mean_reward          | 125         |
|    num_episodes         | 5           |
|    out_of_road          | 0.916       |
|    raw_action           | 0.48317194  |
|    route_completion     | 0.45        |
|    success_rate         | 0.1         |
|    total_cost           | 10.1        |
| time/                   |             |
|    total_timesteps      | 1380000     |
| train/                  |             |
|    approx_kl            | 0.006325809 |
|    arrive_dest          | 0.126       |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    crash                | 0.238       |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.701       |
|    learning_rate        | 5e-05       |
|    loss                 | 46.1        |
|    max_step             | 0           |
|    n_updates            | 5380        |
|    out_of_road          | 0.874       |
|    policy_gradient_loss | -0.000971   |
|    route_completion     | 0.463       |
|    std                  | 0.541       |
|    total_cost           | 10.9        |
|    value_loss           | 112         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 221      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 270      |
|    time_elapsed    | 2645     |
|    total_timesteps | 1382400  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 209          |
|    ep_rew_mean          | 213          |
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 271          |
|    time_elapsed         | 2652         |
|    total_timesteps      | 1387520      |
| train/                  |              |
|    approx_kl            | 0.0029348996 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.52        |
|    explained_variance   | 0.659        |
|    learning_rate        | 5e-05        |
|    loss                 | 73           |
|    n_updates            | 5400         |
|    policy_gradient_loss | 0.000492     |
|    std                  | 0.542        |
|    value_loss           | 156          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0849      |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 104         |
|    mean_reward          | 111         |
|    num_episodes         | 5           |
|    out_of_road          | 0.915       |
|    raw_action           | 0.48312113  |
|    route_completion     | 0.45        |
|    success_rate         | 0.1         |
|    total_cost           | 10          |
| time/                   |             |
|    total_timesteps      | 1390000     |
| train/                  |             |
|    approx_kl            | 0.002185535 |
|    arrive_dest          | 0.125       |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.1         |
|    crash                | 0.237       |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.634       |
|    learning_rate        | 5e-05       |
|    loss                 | 51.4        |
|    max_step             | 0           |
|    n_updates            | 5420        |
|    out_of_road          | 0.875       |
|    policy_gradient_loss | -0.000794   |
|    route_completion     | 0.462       |
|    std                  | 0.541       |
|    total_cost           | 10.9        |
|    value_loss           | 139         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 272      |
|    time_elapsed    | 2663     |
|    total_timesteps | 1392640  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 212          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 273          |
|    time_elapsed         | 2669         |
|    total_timesteps      | 1397760      |
| train/                  |              |
|    approx_kl            | 0.0073825913 |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.51        |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.2         |
|    n_updates            | 5440         |
|    policy_gradient_loss | 0.00187      |
|    std                  | 0.539        |
|    value_loss           | 130          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0843       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 182          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.48321587   |
|    route_completion     | 0.451        |
|    success_rate         | 0            |
|    total_cost           | 9.96         |
| time/                   |              |
|    total_timesteps      | 1400000      |
| train/                  |              |
|    approx_kl            | 0.0021885722 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.51        |
|    explained_variance   | 0.735        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.3         |
|    max_step             | 0            |
|    n_updates            | 5460         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | -0.00292     |
|    route_completion     | 0.462        |
|    std                  | 0.537        |
|    total_cost           | 10.8         |
|    value_loss           | 125          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 274      |
|    time_elapsed    | 2679     |
|    total_timesteps | 1402880  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 206          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 275          |
|    time_elapsed         | 2686         |
|    total_timesteps      | 1408000      |
| train/                  |              |
|    approx_kl            | 0.0031972274 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.5         |
|    explained_variance   | 0.611        |
|    learning_rate        | 5e-05        |
|    loss                 | 74           |
|    n_updates            | 5480         |
|    policy_gradient_loss | -0.000384    |
|    std                  | 0.536        |
|    value_loss           | 165          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0851       |
|    crash                | 0.27         |
|    max_step             | 0            |
|    mean_ep_length       | 159          |
|    mean_reward          | 231          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.483048     |
|    route_completion     | 0.452        |
|    success_rate         | 0.1          |
|    total_cost           | 9.91         |
| time/                   |              |
|    total_timesteps      | 1410000      |
| train/                  |              |
|    approx_kl            | 0.0031694346 |
|    arrive_dest          | 0.123        |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.238        |
|    entropy_loss         | -1.49        |
|    explained_variance   | 0.603        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.9         |
|    max_step             | 0            |
|    n_updates            | 5500         |
|    out_of_road          | 0.877        |
|    policy_gradient_loss | -0.00111     |
|    route_completion     | 0.462        |
|    std                  | 0.533        |
|    total_cost           | 10.8         |
|    value_loss           | 151          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 276      |
|    time_elapsed    | 2700     |
|    total_timesteps | 1413120  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 205          |
|    ep_rew_mean          | 214          |
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 277          |
|    time_elapsed         | 2706         |
|    total_timesteps      | 1418240      |
| train/                  |              |
|    approx_kl            | 0.0042615314 |
|    clip_fraction        | 0.19         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.49        |
|    explained_variance   | 0.633        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.1         |
|    n_updates            | 5520         |
|    policy_gradient_loss | 0.00246      |
|    std                  | 0.532        |
|    value_loss           | 150          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0845       |
|    crash                | 0.27         |
|    max_step             | 0            |
|    mean_ep_length       | 121          |
|    mean_reward          | 154          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.4828973    |
|    route_completion     | 0.452        |
|    success_rate         | 0            |
|    total_cost           | 9.85         |
| time/                   |              |
|    total_timesteps      | 1420000      |
| train/                  |              |
|    approx_kl            | 0.0026508525 |
|    arrive_dest          | 0.123        |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.1          |
|    crash                | 0.238        |
|    entropy_loss         | -1.48        |
|    explained_variance   | 0.716        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.9         |
|    max_step             | 0            |
|    n_updates            | 5540         |
|    out_of_road          | 0.877        |
|    policy_gradient_loss | 0.00179      |
|    route_completion     | 0.46         |
|    std                  | 0.532        |
|    total_cost           | 10.7         |
|    value_loss           | 106          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 219      |
| time/              |          |
|    fps             | 524      |
|    iterations      | 278      |
|    time_elapsed    | 2716     |
|    total_timesteps | 1423360  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 219         |
|    ep_rew_mean          | 221         |
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 279         |
|    time_elapsed         | 2722        |
|    total_timesteps      | 1428480     |
| train/                  |             |
|    approx_kl            | 0.002742626 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.662       |
|    learning_rate        | 5e-05       |
|    loss                 | 73          |
|    n_updates            | 5560        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.529       |
|    value_loss           | 144         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0839       |
|    crash                | 0.271        |
|    max_step             | 0            |
|    mean_ep_length       | 80           |
|    mean_reward          | 86.7         |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.48279202   |
|    route_completion     | 0.451        |
|    success_rate         | 0            |
|    total_cost           | 9.79         |
| time/                   |              |
|    total_timesteps      | 1430000      |
| train/                  |              |
|    approx_kl            | 0.0044857934 |
|    arrive_dest          | 0.122        |
|    clip_fraction        | 0.161        |
|    clip_range           | 0.1          |
|    crash                | 0.241        |
|    entropy_loss         | -1.47        |
|    explained_variance   | 0.684        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.6         |
|    max_step             | 0            |
|    n_updates            | 5580         |
|    out_of_road          | 0.878        |
|    policy_gradient_loss | 0.000449     |
|    route_completion     | 0.459        |
|    std                  | 0.53         |
|    total_cost           | 10.6         |
|    value_loss           | 136          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | 215      |
| time/              |          |
|    fps             | 524      |
|    iterations      | 280      |
|    time_elapsed    | 2731     |
|    total_timesteps | 1433600  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 218          |
|    ep_rew_mean          | 221          |
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 281          |
|    time_elapsed         | 2737         |
|    total_timesteps      | 1438720      |
| train/                  |              |
|    approx_kl            | 0.0053282715 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.47        |
|    explained_variance   | 0.637        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.3         |
|    n_updates            | 5600         |
|    policy_gradient_loss | 0.000532     |
|    std                  | 0.528        |
|    value_loss           | 155          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0833      |
|    crash                | 0.269       |
|    max_step             | 0           |
|    mean_ep_length       | 126         |
|    mean_reward          | 155         |
|    num_episodes         | 5           |
|    out_of_road          | 0.917       |
|    raw_action           | 0.4828969   |
|    route_completion     | 0.451       |
|    success_rate         | 0           |
|    total_cost           | 9.75        |
| time/                   |             |
|    total_timesteps      | 1440000     |
| train/                  |             |
|    approx_kl            | 0.002497136 |
|    arrive_dest          | 0.121       |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.1         |
|    crash                | 0.243       |
|    entropy_loss         | -1.47       |
|    explained_variance   | 0.715       |
|    learning_rate        | 5e-05       |
|    loss                 | 64          |
|    max_step             | 0           |
|    n_updates            | 5620        |
|    out_of_road          | 0.879       |
|    policy_gradient_loss | -0.000309   |
|    route_completion     | 0.459       |
|    std                  | 0.528       |
|    total_cost           | 10.6        |
|    value_loss           | 129         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 525      |
|    iterations      | 282      |
|    time_elapsed    | 2748     |
|    total_timesteps | 1443840  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 236          |
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 283          |
|    time_elapsed         | 2755         |
|    total_timesteps      | 1448960      |
| train/                  |              |
|    approx_kl            | 0.0019556717 |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.47        |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 65.5         |
|    n_updates            | 5640         |
|    policy_gradient_loss | 0.00441      |
|    std                  | 0.527        |
|    value_loss           | 108          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0828       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 110          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.917        |
|    raw_action           | 0.48277718   |
|    route_completion     | 0.45         |
|    success_rate         | 0.1          |
|    total_cost           | 9.69         |
| time/                   |              |
|    total_timesteps      | 1450000      |
| train/                  |              |
|    approx_kl            | 0.0048610824 |
|    arrive_dest          | 0.121        |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    crash                | 0.243        |
|    entropy_loss         | -1.46        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 62.6         |
|    max_step             | 0            |
|    n_updates            | 5660         |
|    out_of_road          | 0.879        |
|    policy_gradient_loss | -0.00113     |
|    route_completion     | 0.46         |
|    std                  | 0.527        |
|    total_cost           | 10.5         |
|    value_loss           | 126          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 244      |
| time/              |          |
|    fps             | 525      |
|    iterations      | 284      |
|    time_elapsed    | 2764     |
|    total_timesteps | 1454080  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 227         |
|    ep_rew_mean          | 243         |
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 285         |
|    time_elapsed         | 2771        |
|    total_timesteps      | 1459200     |
| train/                  |             |
|    approx_kl            | 0.004874603 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.46       |
|    explained_variance   | 0.875       |
|    learning_rate        | 5e-05       |
|    loss                 | 75.8        |
|    n_updates            | 5680        |
|    policy_gradient_loss | -0.000425   |
|    std                  | 0.525       |
|    value_loss           | 132         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0836       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 136          |
|    mean_reward          | 184          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.48262554   |
|    route_completion     | 0.451        |
|    success_rate         | 0.1          |
|    total_cost           | 9.65         |
| time/                   |              |
|    total_timesteps      | 1460000      |
| train/                  |              |
|    approx_kl            | 0.0061994414 |
|    arrive_dest          | 0.121        |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.45        |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.3         |
|    max_step             | 0            |
|    n_updates            | 5700         |
|    out_of_road          | 0.879        |
|    policy_gradient_loss | -0.0016      |
|    route_completion     | 0.459        |
|    std                  | 0.522        |
|    total_cost           | 10.5         |
|    value_loss           | 116          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 286      |
|    time_elapsed    | 2781     |
|    total_timesteps | 1464320  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 233         |
|    ep_rew_mean          | 244         |
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 287         |
|    time_elapsed         | 2787        |
|    total_timesteps      | 1469440     |
| train/                  |             |
|    approx_kl            | 0.001233788 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.44       |
|    explained_variance   | 0.683       |
|    learning_rate        | 5e-05       |
|    loss                 | 43.9        |
|    n_updates            | 5720        |
|    policy_gradient_loss | 0.00219     |
|    std                  | 0.523       |
|    value_loss           | 108         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.083      |
|    crash                | 0.267      |
|    max_step             | 0          |
|    mean_ep_length       | 148        |
|    mean_reward          | 199        |
|    num_episodes         | 5          |
|    out_of_road          | 0.917      |
|    raw_action           | 0.4827748  |
|    route_completion     | 0.451      |
|    success_rate         | 0.1        |
|    total_cost           | 9.61       |
| time/                   |            |
|    total_timesteps      | 1470000    |
| train/                  |            |
|    approx_kl            | 0.04014825 |
|    arrive_dest          | 0.121      |
|    clip_fraction        | 0.146      |
|    clip_range           | 0.1        |
|    crash                | 0.242      |
|    entropy_loss         | -1.44      |
|    explained_variance   | 0.728      |
|    learning_rate        | 5e-05      |
|    loss                 | 49.3       |
|    max_step             | 0          |
|    n_updates            | 5740       |
|    out_of_road          | 0.879      |
|    policy_gradient_loss | -7.55e-05  |
|    route_completion     | 0.459      |
|    std                  | 0.521      |
|    total_cost           | 10.4       |
|    value_loss           | 116        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 232      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 288      |
|    time_elapsed    | 2798     |
|    total_timesteps | 1474560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 225          |
|    ep_rew_mean          | 238          |
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 289          |
|    time_elapsed         | 2804         |
|    total_timesteps      | 1479680      |
| train/                  |              |
|    approx_kl            | 0.0053112763 |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.44        |
|    explained_variance   | 0.538        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.1         |
|    n_updates            | 5760         |
|    policy_gradient_loss | 0.00131      |
|    std                  | 0.522        |
|    value_loss           | 189          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0824     |
|    crash                | 0.268      |
|    max_step             | 0          |
|    mean_ep_length       | 129        |
|    mean_reward          | 180        |
|    num_episodes         | 5          |
|    out_of_road          | 0.918      |
|    raw_action           | 0.48286068 |
|    route_completion     | 0.452      |
|    success_rate         | 0          |
|    total_cost           | 9.56       |
| time/                   |            |
|    total_timesteps      | 1480000    |
| train/                  |            |
|    approx_kl            | 0.00232565 |
|    arrive_dest          | 0.12       |
|    clip_fraction        | 0.109      |
|    clip_range           | 0.1        |
|    crash                | 0.241      |
|    entropy_loss         | -1.44      |
|    explained_variance   | 0.668      |
|    learning_rate        | 5e-05      |
|    loss                 | 51.8       |
|    max_step             | 0          |
|    n_updates            | 5780       |
|    out_of_road          | 0.88       |
|    policy_gradient_loss | -0.00221   |
|    route_completion     | 0.46       |
|    std                  | 0.521      |
|    total_cost           | 10.4       |
|    value_loss           | 126        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 239      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 290      |
|    time_elapsed    | 2815     |
|    total_timesteps | 1484800  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 218         |
|    ep_rew_mean          | 236         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 291         |
|    time_elapsed         | 2821        |
|    total_timesteps      | 1489920     |
| train/                  |             |
|    approx_kl            | 0.002493518 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.615       |
|    learning_rate        | 5e-05       |
|    loss                 | 67.7        |
|    n_updates            | 5800        |
|    policy_gradient_loss | -0.00025    |
|    std                  | 0.519       |
|    value_loss           | 134         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0832      |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 196         |
|    mean_reward          | 291         |
|    num_episodes         | 5           |
|    out_of_road          | 0.917       |
|    raw_action           | 0.48325956  |
|    route_completion     | 0.454       |
|    success_rate         | 0.1         |
|    total_cost           | 9.54        |
| time/                   |             |
|    total_timesteps      | 1490000     |
| train/                  |             |
|    approx_kl            | 0.023592513 |
|    arrive_dest          | 0.119       |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.1         |
|    crash                | 0.239       |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.719       |
|    learning_rate        | 5e-05       |
|    loss                 | 60.4        |
|    max_step             | 0           |
|    n_updates            | 5820        |
|    out_of_road          | 0.881       |
|    policy_gradient_loss | 0.00246     |
|    route_completion     | 0.459       |
|    std                  | 0.519       |
|    total_cost           | 10.3        |
|    value_loss           | 126         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 241      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 292      |
|    time_elapsed    | 2831     |
|    total_timesteps | 1495040  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0827      |
|    crash                | 0.267       |
|    max_step             | 0           |
|    mean_ep_length       | 134         |
|    mean_reward          | 178         |
|    num_episodes         | 5           |
|    out_of_road          | 0.917       |
|    raw_action           | 0.48315164  |
|    route_completion     | 0.454       |
|    success_rate         | 0           |
|    total_cost           | 9.49        |
| time/                   |             |
|    total_timesteps      | 1500000     |
| train/                  |             |
|    approx_kl            | 0.003264134 |
|    arrive_dest          | 0.119       |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.1         |
|    crash                | 0.239       |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.605       |
|    learning_rate        | 5e-05       |
|    loss                 | 79          |
|    max_step             | 0           |
|    n_updates            | 5840        |
|    out_of_road          | 0.881       |
|    policy_gradient_loss | 0.000305    |
|    route_completion     | 0.459       |
|    std                  | 0.52        |
|    total_cost           | 10.3        |
|    value_loss           | 174         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | 237      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 293      |
|    time_elapsed    | 2842     |
|    total_timesteps | 1500160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 208          |
|    ep_rew_mean          | 229          |
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 294          |
|    time_elapsed         | 2849         |
|    total_timesteps      | 1505280      |
| train/                  |              |
|    approx_kl            | 0.0028876746 |
|    clip_fraction        | 0.172        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.43        |
|    explained_variance   | 0.719        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.1         |
|    n_updates            | 5860         |
|    policy_gradient_loss | 0.000597     |
|    std                  | 0.521        |
|    value_loss           | 123          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0821       |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 153          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.48322585   |
|    route_completion     | 0.454        |
|    success_rate         | 0.1          |
|    total_cost           | 9.46         |
| time/                   |              |
|    total_timesteps      | 1510000      |
| train/                  |              |
|    approx_kl            | 0.0019967312 |
|    arrive_dest          | 0.119        |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.241        |
|    entropy_loss         | -1.43        |
|    explained_variance   | 0.657        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.9         |
|    max_step             | 0            |
|    n_updates            | 5880         |
|    out_of_road          | 0.881        |
|    policy_gradient_loss | -0.000502    |
|    route_completion     | 0.459        |
|    std                  | 0.52         |
|    total_cost           | 10.2         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 213      |
|    ep_rew_mean     | 230      |
| time/              |          |
|    fps             | 528      |
|    iterations      | 295      |
|    time_elapsed    | 2859     |
|    total_timesteps | 1510400  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 217         |
|    ep_rew_mean          | 233         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 296         |
|    time_elapsed         | 2865        |
|    total_timesteps      | 1515520     |
| train/                  |             |
|    approx_kl            | 0.002169465 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.644       |
|    learning_rate        | 5e-05       |
|    loss                 | 105         |
|    n_updates            | 5900        |
|    policy_gradient_loss | -0.00186    |
|    std                  | 0.52        |
|    value_loss           | 178         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0842       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 180          |
|    mean_reward          | 175          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.48292917   |
|    route_completion     | 0.455        |
|    success_rate         | 0.2          |
|    total_cost           | 9.52         |
| time/                   |              |
|    total_timesteps      | 1520000      |
| train/                  |              |
|    approx_kl            | 0.0033584586 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    crash                | 0.241        |
|    entropy_loss         | -1.42        |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.5         |
|    max_step             | 0            |
|    n_updates            | 5920         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 8.16e-05     |
|    route_completion     | 0.458        |
|    std                  | 0.518        |
|    total_cost           | 10.2         |
|    value_loss           | 142          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 218      |
|    ep_rew_mean     | 232      |
| time/              |          |
|    fps             | 528      |
|    iterations      | 297      |
|    time_elapsed    | 2876     |
|    total_timesteps | 1520640  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 224         |
|    ep_rew_mean          | 239         |
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 298         |
|    time_elapsed         | 2883        |
|    total_timesteps      | 1525760     |
| train/                  |             |
|    approx_kl            | 0.001376998 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.42       |
|    explained_variance   | 0.529       |
|    learning_rate        | 5e-05       |
|    loss                 | 72.7        |
|    n_updates            | 5940        |
|    policy_gradient_loss | -0.000234   |
|    std                  | 0.518       |
|    value_loss           | 173         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0837       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 133          |
|    mean_reward          | 188          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.48268947   |
|    route_completion     | 0.455        |
|    success_rate         | 0.1          |
|    total_cost           | 9.46         |
| time/                   |              |
|    total_timesteps      | 1530000      |
| train/                  |              |
|    approx_kl            | 0.0027230936 |
|    arrive_dest          | 0.119        |
|    clip_fraction        | 0.161        |
|    clip_range           | 0.1          |
|    crash                | 0.243        |
|    entropy_loss         | -1.42        |
|    explained_variance   | 0.62         |
|    learning_rate        | 5e-05        |
|    loss                 | 56.5         |
|    max_step             | 0            |
|    n_updates            | 5960         |
|    out_of_road          | 0.881        |
|    policy_gradient_loss | 0.00181      |
|    route_completion     | 0.459        |
|    std                  | 0.519        |
|    total_cost           | 10.2         |
|    value_loss           | 159          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 218      |
| time/              |          |
|    fps             | 528      |
|    iterations      | 299      |
|    time_elapsed    | 2896     |
|    total_timesteps | 1530880  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 206          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 529          |
|    iterations           | 300          |
|    time_elapsed         | 2902         |
|    total_timesteps      | 1536000      |
| train/                  |              |
|    approx_kl            | 0.0039349683 |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.42        |
|    explained_variance   | 0.686        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.4         |
|    n_updates            | 5980         |
|    policy_gradient_loss | -0.000719    |
|    std                  | 0.519        |
|    value_loss           | 163          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0831     |
|    crash                | 0.266      |
|    max_step             | 0          |
|    mean_ep_length       | 91.8       |
|    mean_reward          | 104        |
|    num_episodes         | 5          |
|    out_of_road          | 0.917      |
|    raw_action           | 0.48302338 |
|    route_completion     | 0.455      |
|    success_rate         | 0.2        |
|    total_cost           | 9.41       |
| time/                   |            |
|    total_timesteps      | 1540000    |
| train/                  |            |
|    approx_kl            | 0.05908093 |
|    arrive_dest          | 0.121      |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.1        |
|    crash                | 0.243      |
|    entropy_loss         | -1.42      |
|    explained_variance   | 0.686      |
|    learning_rate        | 5e-05      |
|    loss                 | 55.6       |
|    max_step             | 0          |
|    n_updates            | 6000       |
|    out_of_road          | 0.879      |
|    policy_gradient_loss | 0.00668    |
|    route_completion     | 0.46       |
|    std                  | 0.518      |
|    total_cost           | 10.1       |
|    value_loss           | 133        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 211      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 301      |
|    time_elapsed    | 2911     |
|    total_timesteps | 1541120  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 200         |
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 302         |
|    time_elapsed         | 2918        |
|    total_timesteps      | 1546240     |
| train/                  |             |
|    approx_kl            | 0.001786655 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.42       |
|    explained_variance   | 0.595       |
|    learning_rate        | 5e-05       |
|    loss                 | 102         |
|    n_updates            | 6020        |
|    policy_gradient_loss | 0.000734    |
|    std                  | 0.517       |
|    value_loss           | 169         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0826      |
|    crash                | 0.267       |
|    max_step             | 0           |
|    mean_ep_length       | 109         |
|    mean_reward          | 141         |
|    num_episodes         | 5           |
|    out_of_road          | 0.917       |
|    raw_action           | 0.48298156  |
|    route_completion     | 0.455       |
|    success_rate         | 0           |
|    total_cost           | 9.35        |
| time/                   |             |
|    total_timesteps      | 1550000     |
| train/                  |             |
|    approx_kl            | 0.004509305 |
|    arrive_dest          | 0.12        |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.1         |
|    crash                | 0.244       |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.592       |
|    learning_rate        | 5e-05       |
|    loss                 | 80          |
|    max_step             | 0           |
|    n_updates            | 6040        |
|    out_of_road          | 0.88        |
|    policy_gradient_loss | -0.000517   |
|    route_completion     | 0.459       |
|    std                  | 0.515       |
|    total_cost           | 10.1        |
|    value_loss           | 162         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 197      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 303      |
|    time_elapsed    | 2928     |
|    total_timesteps | 1551360  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 191          |
| time/                   |              |
|    fps                  | 530          |
|    iterations           | 304          |
|    time_elapsed         | 2934         |
|    total_timesteps      | 1556480      |
| train/                  |              |
|    approx_kl            | 0.0022762876 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.4         |
|    explained_variance   | 0.578        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.9         |
|    n_updates            | 6060         |
|    policy_gradient_loss | -0.000149    |
|    std                  | 0.514        |
|    value_loss           | 158          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0821       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 95.4         |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.4827801    |
|    route_completion     | 0.454        |
|    success_rate         | 0            |
|    total_cost           | 9.3          |
| time/                   |              |
|    total_timesteps      | 1560000      |
| train/                  |              |
|    approx_kl            | 0.0028496557 |
|    arrive_dest          | 0.119        |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.625        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.9         |
|    max_step             | 0            |
|    n_updates            | 6080         |
|    out_of_road          | 0.881        |
|    policy_gradient_loss | -0.00115     |
|    route_completion     | 0.458        |
|    std                  | 0.512        |
|    total_cost           | 10           |
|    value_loss           | 163          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 179      |
| time/              |          |
|    fps             | 530      |
|    iterations      | 305      |
|    time_elapsed    | 2943     |
|    total_timesteps | 1561600  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 188         |
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 306         |
|    time_elapsed         | 2949        |
|    total_timesteps      | 1566720     |
| train/                  |             |
|    approx_kl            | 0.001544603 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.618       |
|    learning_rate        | 5e-05       |
|    loss                 | 84.4        |
|    n_updates            | 6100        |
|    policy_gradient_loss | -0.00043    |
|    std                  | 0.512       |
|    value_loss           | 170         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0815       |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 98.6         |
|    mean_reward          | 101          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.48279038   |
|    route_completion     | 0.454        |
|    success_rate         | 0            |
|    total_cost           | 9.25         |
| time/                   |              |
|    total_timesteps      | 1570000      |
| train/                  |              |
|    approx_kl            | 0.0072028255 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.19         |
|    clip_range           | 0.1          |
|    crash                | 0.243        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.682        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.9         |
|    max_step             | 0            |
|    n_updates            | 6120         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.00236      |
|    route_completion     | 0.457        |
|    std                  | 0.512        |
|    total_cost           | 9.97         |
|    value_loss           | 107          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 195      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 307      |
|    time_elapsed    | 2959     |
|    total_timesteps | 1571840  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 195          |
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 308          |
|    time_elapsed         | 2967         |
|    total_timesteps      | 1576960      |
| train/                  |              |
|    approx_kl            | 0.0013233431 |
|    clip_fraction        | 0.21         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.612        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.7         |
|    n_updates            | 6140         |
|    policy_gradient_loss | 0.00265      |
|    std                  | 0.514        |
|    value_loss           | 136          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0823       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 151          |
|    mean_reward          | 177          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.48253173   |
|    route_completion     | 0.454        |
|    success_rate         | 0.1          |
|    total_cost           | 9.24         |
| time/                   |              |
|    total_timesteps      | 1580000      |
| train/                  |              |
|    approx_kl            | 0.0013339038 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.772        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.5         |
|    max_step             | 0            |
|    n_updates            | 6160         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | -4.54e-05    |
|    route_completion     | 0.457        |
|    std                  | 0.513        |
|    total_cost           | 9.93         |
|    value_loss           | 121          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 309      |
|    time_elapsed    | 2978     |
|    total_timesteps | 1582080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 196          |
|    ep_rew_mean          | 205          |
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 310          |
|    time_elapsed         | 2984         |
|    total_timesteps      | 1587200      |
| train/                  |              |
|    approx_kl            | 0.0020052663 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.666        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.8         |
|    n_updates            | 6180         |
|    policy_gradient_loss | -0.000546    |
|    std                  | 0.515        |
|    value_loss           | 138          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0818      |
|    crash                | 0.268       |
|    max_step             | 0           |
|    mean_ep_length       | 120         |
|    mean_reward          | 161         |
|    num_episodes         | 5           |
|    out_of_road          | 0.918       |
|    raw_action           | 0.48274282  |
|    route_completion     | 0.454       |
|    success_rate         | 0           |
|    total_cost           | 9.19        |
| time/                   |             |
|    total_timesteps      | 1590000     |
| train/                  |             |
|    approx_kl            | 0.004157115 |
|    arrive_dest          | 0.117       |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    crash                | 0.243       |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5e-05       |
|    loss                 | 66.1        |
|    max_step             | 0           |
|    n_updates            | 6200        |
|    out_of_road          | 0.883       |
|    policy_gradient_loss | -0.000921   |
|    route_completion     | 0.457       |
|    std                  | 0.514       |
|    total_cost           | 9.89        |
|    value_loss           | 140         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 206      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 311      |
|    time_elapsed    | 2994     |
|    total_timesteps | 1592320  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 202         |
|    ep_rew_mean          | 211         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 312         |
|    time_elapsed         | 3000        |
|    total_timesteps      | 1597440     |
| train/                  |             |
|    approx_kl            | 0.008284806 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.653       |
|    learning_rate        | 5e-05       |
|    loss                 | 68.9        |
|    n_updates            | 6220        |
|    policy_gradient_loss | -0.00102    |
|    std                  | 0.514       |
|    value_loss           | 154         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0813       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 130          |
|    mean_reward          | 166          |
|    num_episodes         | 5            |
|    out_of_road          | 0.919        |
|    raw_action           | 0.48284817   |
|    route_completion     | 0.454        |
|    success_rate         | 0.1          |
|    total_cost           | 9.15         |
| time/                   |              |
|    total_timesteps      | 1600000      |
| train/                  |              |
|    approx_kl            | 0.0020905375 |
|    arrive_dest          | 0.117        |
|    clip_fraction        | 0.202        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.676        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.6         |
|    max_step             | 0            |
|    n_updates            | 6240         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.00176      |
|    route_completion     | 0.457        |
|    std                  | 0.515        |
|    total_cost           | 9.85         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 224      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 313      |
|    time_elapsed    | 3011     |
|    total_timesteps | 1602560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 211          |
|    ep_rew_mean          | 223          |
| time/                   |              |
|    fps                  | 532          |
|    iterations           | 314          |
|    time_elapsed         | 3018         |
|    total_timesteps      | 1607680      |
| train/                  |              |
|    approx_kl            | 0.0033300421 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 52           |
|    n_updates            | 6260         |
|    policy_gradient_loss | -0.001       |
|    std                  | 0.515        |
|    value_loss           | 129          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0807       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 88           |
|    mean_reward          | 92.3         |
|    num_episodes         | 5            |
|    out_of_road          | 0.919        |
|    raw_action           | 0.4830622    |
|    route_completion     | 0.453        |
|    success_rate         | 0.1          |
|    total_cost           | 9.1          |
| time/                   |              |
|    total_timesteps      | 1610000      |
| train/                  |              |
|    approx_kl            | 0.0023642674 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    crash                | 0.242        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.669        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.5         |
|    max_step             | 0            |
|    n_updates            | 6280         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | -0.00192     |
|    route_completion     | 0.459        |
|    std                  | 0.516        |
|    total_cost           | 9.82         |
|    value_loss           | 144          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 315      |
|    time_elapsed    | 3028     |
|    total_timesteps | 1612800  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 210         |
|    ep_rew_mean          | 219         |
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 316         |
|    time_elapsed         | 3034        |
|    total_timesteps      | 1617920     |
| train/                  |             |
|    approx_kl            | 0.002725327 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.654       |
|    learning_rate        | 5e-05       |
|    loss                 | 70.1        |
|    n_updates            | 6300        |
|    policy_gradient_loss | -0.00112    |
|    std                  | 0.514       |
|    value_loss           | 162         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0802       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 219          |
|    num_episodes         | 5            |
|    out_of_road          | 0.92         |
|    raw_action           | 0.48287115   |
|    route_completion     | 0.455        |
|    success_rate         | 0            |
|    total_cost           | 9.07         |
| time/                   |              |
|    total_timesteps      | 1620000      |
| train/                  |              |
|    approx_kl            | 0.0077992594 |
|    arrive_dest          | 0.117        |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.241        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.632        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.9         |
|    max_step             | 0            |
|    n_updates            | 6320         |
|    out_of_road          | 0.883        |
|    policy_gradient_loss | -7.29e-05    |
|    route_completion     | 0.46         |
|    std                  | 0.515        |
|    total_cost           | 9.8          |
|    value_loss           | 159          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 317      |
|    time_elapsed    | 3045     |
|    total_timesteps | 1623040  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 200          |
|    ep_rew_mean          | 206          |
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 318          |
|    time_elapsed         | 3051         |
|    total_timesteps      | 1628160      |
| train/                  |              |
|    approx_kl            | 0.0029701241 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.659        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.2         |
|    n_updates            | 6340         |
|    policy_gradient_loss | -0.00173     |
|    std                  | 0.515        |
|    value_loss           | 143          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0798       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 81.6         |
|    mean_reward          | 86.4         |
|    num_episodes         | 5            |
|    out_of_road          | 0.92         |
|    raw_action           | 0.48248133   |
|    route_completion     | 0.454        |
|    success_rate         | 0.1          |
|    total_cost           | 9.02         |
| time/                   |              |
|    total_timesteps      | 1630000      |
| train/                  |              |
|    approx_kl            | 0.0016805393 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.173        |
|    clip_range           | 0.1          |
|    crash                | 0.24         |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.639        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.1         |
|    max_step             | 0            |
|    n_updates            | 6360         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.00129      |
|    route_completion     | 0.46         |
|    std                  | 0.513        |
|    total_cost           | 9.78         |
|    value_loss           | 164          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 319      |
|    time_elapsed    | 3064     |
|    total_timesteps | 1633280  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 204          |
|    ep_rew_mean          | 218          |
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 320          |
|    time_elapsed         | 3070         |
|    total_timesteps      | 1638400      |
| train/                  |              |
|    approx_kl            | 0.0062554018 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.593        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.8         |
|    n_updates            | 6380         |
|    policy_gradient_loss | -0.000847    |
|    std                  | 0.512        |
|    value_loss           | 165          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0793       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 91.8         |
|    mean_reward          | 107          |
|    num_episodes         | 5            |
|    out_of_road          | 0.921        |
|    raw_action           | 0.48223978   |
|    route_completion     | 0.453        |
|    success_rate         | 0.1          |
|    total_cost           | 8.97         |
| time/                   |              |
|    total_timesteps      | 1640000      |
| train/                  |              |
|    approx_kl            | 0.0024423976 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.2          |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.704        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.4         |
|    max_step             | 0            |
|    n_updates            | 6400         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.00262      |
|    route_completion     | 0.46         |
|    std                  | 0.514        |
|    total_cost           | 9.77         |
|    value_loss           | 117          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 321      |
|    time_elapsed    | 3082     |
|    total_timesteps | 1643520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 196          |
|    ep_rew_mean          | 213          |
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 322          |
|    time_elapsed         | 3089         |
|    total_timesteps      | 1648640      |
| train/                  |              |
|    approx_kl            | 0.0021443167 |
|    clip_fraction        | 0.221        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.674        |
|    learning_rate        | 5e-05        |
|    loss                 | 97.2         |
|    n_updates            | 6420         |
|    policy_gradient_loss | 0.00496      |
|    std                  | 0.513        |
|    value_loss           | 162          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0788       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 0.921        |
|    raw_action           | 0.48210078   |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 8.93         |
| time/                   |              |
|    total_timesteps      | 1650000      |
| train/                  |              |
|    approx_kl            | 0.0036618032 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    crash                | 0.24         |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.678        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.6         |
|    max_step             | 0            |
|    n_updates            | 6440         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | 0.000881     |
|    route_completion     | 0.461        |
|    std                  | 0.513        |
|    total_cost           | 9.73         |
|    value_loss           | 160          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 323      |
|    time_elapsed    | 3099     |
|    total_timesteps | 1653760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 192          |
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 324          |
|    time_elapsed         | 3105         |
|    total_timesteps      | 1658880      |
| train/                  |              |
|    approx_kl            | 0.0016442674 |
|    clip_fraction        | 0.226        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.53         |
|    learning_rate        | 5e-05        |
|    loss                 | 85.8         |
|    n_updates            | 6460         |
|    policy_gradient_loss | 0.00441      |
|    std                  | 0.513        |
|    value_loss           | 172          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0783      |
|    crash                | 0.27        |
|    max_step             | 0           |
|    mean_ep_length       | 114         |
|    mean_reward          | 140         |
|    num_episodes         | 5           |
|    out_of_road          | 0.922       |
|    raw_action           | 0.48203722  |
|    route_completion     | 0.453       |
|    success_rate         | 0.2         |
|    total_cost           | 8.89        |
| time/                   |             |
|    total_timesteps      | 1660000     |
| train/                  |             |
|    approx_kl            | 0.001695207 |
|    arrive_dest          | 0.119       |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.1         |
|    crash                | 0.239       |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.682       |
|    learning_rate        | 5e-05       |
|    loss                 | 50.3        |
|    max_step             | 0           |
|    n_updates            | 6480        |
|    out_of_road          | 0.881       |
|    policy_gradient_loss | 0.00101     |
|    route_completion     | 0.461       |
|    std                  | 0.511       |
|    total_cost           | 9.7         |
|    value_loss           | 128         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 198      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 325      |
|    time_elapsed    | 3118     |
|    total_timesteps | 1664000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 198         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 326         |
|    time_elapsed         | 3124        |
|    total_timesteps      | 1669120     |
| train/                  |             |
|    approx_kl            | 0.013301738 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.765       |
|    learning_rate        | 5e-05       |
|    loss                 | 57          |
|    n_updates            | 6500        |
|    policy_gradient_loss | 0.000813    |
|    std                  | 0.513       |
|    value_loss           | 99.7        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0778      |
|    crash                | 0.269       |
|    max_step             | 0           |
|    mean_ep_length       | 137         |
|    mean_reward          | 196         |
|    num_episodes         | 5           |
|    out_of_road          | 0.922       |
|    raw_action           | 0.4819294   |
|    route_completion     | 0.453       |
|    success_rate         | 0.1         |
|    total_cost           | 8.85        |
| time/                   |             |
|    total_timesteps      | 1670000     |
| train/                  |             |
|    approx_kl            | 0.005812022 |
|    arrive_dest          | 0.12        |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.1         |
|    crash                | 0.238       |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.663       |
|    learning_rate        | 5e-05       |
|    loss                 | 69.8        |
|    max_step             | 0           |
|    n_updates            | 6520        |
|    out_of_road          | 0.88        |
|    policy_gradient_loss | 0.00375     |
|    route_completion     | 0.461       |
|    std                  | 0.513       |
|    total_cost           | 9.65        |
|    value_loss           | 155         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 327      |
|    time_elapsed    | 3134     |
|    total_timesteps | 1674240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 198          |
|    ep_rew_mean          | 203          |
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 328          |
|    time_elapsed         | 3140         |
|    total_timesteps      | 1679360      |
| train/                  |              |
|    approx_kl            | 0.0021636272 |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.448        |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    n_updates            | 6540         |
|    policy_gradient_loss | -0.000378    |
|    std                  | 0.514        |
|    value_loss           | 233          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0774      |
|    crash                | 0.27        |
|    max_step             | 0           |
|    mean_ep_length       | 142         |
|    mean_reward          | 213         |
|    num_episodes         | 5           |
|    out_of_road          | 0.923       |
|    raw_action           | 0.48181352  |
|    route_completion     | 0.454       |
|    success_rate         | 0           |
|    total_cost           | 8.81        |
| time/                   |             |
|    total_timesteps      | 1680000     |
| train/                  |             |
|    approx_kl            | 0.028474445 |
|    arrive_dest          | 0.119       |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.1         |
|    crash                | 0.238       |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.66        |
|    learning_rate        | 5e-05       |
|    loss                 | 91          |
|    max_step             | 0           |
|    n_updates            | 6560        |
|    out_of_road          | 0.881       |
|    policy_gradient_loss | 0.00203     |
|    route_completion     | 0.461       |
|    std                  | 0.514       |
|    total_cost           | 9.61        |
|    value_loss           | 142         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 329      |
|    time_elapsed    | 3150     |
|    total_timesteps | 1684480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 198          |
|    ep_rew_mean          | 192          |
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 330          |
|    time_elapsed         | 3156         |
|    total_timesteps      | 1689600      |
| train/                  |              |
|    approx_kl            | 0.0015556052 |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.822        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.6         |
|    n_updates            | 6580         |
|    policy_gradient_loss | -0.000192    |
|    std                  | 0.517        |
|    value_loss           | 125          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0769       |
|    crash                | 0.27         |
|    max_step             | 0            |
|    mean_ep_length       | 99           |
|    mean_reward          | 123          |
|    num_episodes         | 5            |
|    out_of_road          | 0.923        |
|    raw_action           | 0.48201847   |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 8.76         |
| time/                   |              |
|    total_timesteps      | 1690000      |
| train/                  |              |
|    approx_kl            | 0.0033001113 |
|    arrive_dest          | 0.118        |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    crash                | 0.239        |
|    entropy_loss         | -1.39        |
|    explained_variance   | 0.737        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.1         |
|    max_step             | 0            |
|    n_updates            | 6600         |
|    out_of_road          | 0.882        |
|    policy_gradient_loss | -0.00247     |
|    route_completion     | 0.461        |
|    std                  | 0.517        |
|    total_cost           | 9.58         |
|    value_loss           | 148          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 331      |
|    time_elapsed    | 3166     |
|    total_timesteps | 1694720  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 210        |
|    ep_rew_mean          | 215        |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 332        |
|    time_elapsed         | 3172       |
|    total_timesteps      | 1699840    |
| train/                  |            |
|    approx_kl            | 0.00908936 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.39      |
|    explained_variance   | 0.686      |
|    learning_rate        | 5e-05      |
|    loss                 | 50.6       |
|    n_updates            | 6620       |
|    policy_gradient_loss | 0.000316   |
|    std                  | 0.516      |
|    value_loss           | 128        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0776       |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 187          |
|    num_episodes         | 5            |
|    out_of_road          | 0.922        |
|    raw_action           | 0.48207307   |
|    route_completion     | 0.453        |
|    success_rate         | 0.2          |
|    total_cost           | 8.73         |
| time/                   |              |
|    total_timesteps      | 1700000      |
| train/                  |              |
|    approx_kl            | 0.0018000302 |
|    arrive_dest          | 0.119        |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    crash                | 0.238        |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.677        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.3         |
|    max_step             | 0            |
|    n_updates            | 6640         |
|    out_of_road          | 0.881        |
|    policy_gradient_loss | -0.0012      |
|    route_completion     | 0.462        |
|    std                  | 0.517        |
|    total_cost           | 9.54         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 333      |
|    time_elapsed    | 3184     |
|    total_timesteps | 1704960  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0772      |
|    crash                | 0.269       |
|    max_step             | 0           |
|    mean_ep_length       | 96.6        |
|    mean_reward          | 111         |
|    num_episodes         | 5           |
|    out_of_road          | 0.923       |
|    raw_action           | 0.4815858   |
|    route_completion     | 0.453       |
|    success_rate         | 0           |
|    total_cost           | 8.69        |
| time/                   |             |
|    total_timesteps      | 1710000     |
| train/                  |             |
|    approx_kl            | 0.004965361 |
|    arrive_dest          | 0.118       |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.597       |
|    learning_rate        | 5e-05       |
|    loss                 | 69.5        |
|    max_step             | 0           |
|    n_updates            | 6660        |
|    out_of_road          | 0.882       |
|    policy_gradient_loss | 0.000239    |
|    route_completion     | 0.462       |
|    std                  | 0.516       |
|    total_cost           | 9.5         |
|    value_loss           | 172         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 222      |
| time/              |          |
|    fps             | 535      |
|    iterations      | 334      |
|    time_elapsed    | 3194     |
|    total_timesteps | 1710080  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 208         |
|    ep_rew_mean          | 225         |
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 335         |
|    time_elapsed         | 3200        |
|    total_timesteps      | 1715200     |
| train/                  |             |
|    approx_kl            | 0.012195779 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.684       |
|    learning_rate        | 5e-05       |
|    loss                 | 61.2        |
|    n_updates            | 6680        |
|    policy_gradient_loss | 0.00102     |
|    std                  | 0.514       |
|    value_loss           | 145         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0767       |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 95           |
|    mean_reward          | 97.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.923        |
|    raw_action           | 0.4815785    |
|    route_completion     | 0.452        |
|    success_rate         | 0.3          |
|    total_cost           | 8.65         |
| time/                   |              |
|    total_timesteps      | 1720000      |
| train/                  |              |
|    approx_kl            | 0.0014256898 |
|    arrive_dest          | 0.121        |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.38        |
|    explained_variance   | 0.61         |
|    learning_rate        | 5e-05        |
|    loss                 | 78.6         |
|    max_step             | 0            |
|    n_updates            | 6700         |
|    out_of_road          | 0.879        |
|    policy_gradient_loss | 0.00183      |
|    route_completion     | 0.464        |
|    std                  | 0.514        |
|    total_cost           | 9.46         |
|    value_loss           | 160          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 336      |
|    time_elapsed    | 3209     |
|    total_timesteps | 1720320  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 214         |
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 337         |
|    time_elapsed         | 3215        |
|    total_timesteps      | 1725440     |
| train/                  |             |
|    approx_kl            | 0.002237292 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.744       |
|    learning_rate        | 5e-05       |
|    loss                 | 72.8        |
|    n_updates            | 6720        |
|    policy_gradient_loss | 0.00195     |
|    std                  | 0.511       |
|    value_loss           | 149         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0763      |
|    crash                | 0.271       |
|    max_step             | 0           |
|    mean_ep_length       | 173         |
|    mean_reward          | 241         |
|    num_episodes         | 5           |
|    out_of_road          | 0.924       |
|    raw_action           | 0.48142502  |
|    route_completion     | 0.454       |
|    success_rate         | 0.1         |
|    total_cost           | 8.64        |
| time/                   |             |
|    total_timesteps      | 1730000     |
| train/                  |             |
|    approx_kl            | 0.004312073 |
|    arrive_dest          | 0.121       |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.693       |
|    learning_rate        | 5e-05       |
|    loss                 | 83.3        |
|    max_step             | 0           |
|    n_updates            | 6740        |
|    out_of_road          | 0.879       |
|    policy_gradient_loss | -0.000437   |
|    route_completion     | 0.463       |
|    std                  | 0.511       |
|    total_cost           | 9.41        |
|    value_loss           | 144         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 211      |
| time/              |          |
|    fps             | 536      |
|    iterations      | 338      |
|    time_elapsed    | 3224     |
|    total_timesteps | 1730560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 209          |
|    ep_rew_mean          | 221          |
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 339          |
|    time_elapsed         | 3230         |
|    total_timesteps      | 1735680      |
| train/                  |              |
|    approx_kl            | 0.0025908225 |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.37        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.9         |
|    n_updates            | 6760         |
|    policy_gradient_loss | -0.000689    |
|    std                  | 0.511        |
|    value_loss           | 131          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0759       |
|    crash                | 0.27         |
|    max_step             | 0            |
|    mean_ep_length       | 153          |
|    mean_reward          | 197          |
|    num_episodes         | 5            |
|    out_of_road          | 0.924        |
|    raw_action           | 0.48134297   |
|    route_completion     | 0.455        |
|    success_rate         | 0.1          |
|    total_cost           | 8.62         |
| time/                   |              |
|    total_timesteps      | 1740000      |
| train/                  |              |
|    approx_kl            | 0.0032126214 |
|    arrive_dest          | 0.122        |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.37        |
|    explained_variance   | 0.681        |
|    learning_rate        | 5e-05        |
|    loss                 | 62.9         |
|    max_step             | 0            |
|    n_updates            | 6780         |
|    out_of_road          | 0.878        |
|    policy_gradient_loss | -6.8e-05     |
|    route_completion     | 0.463        |
|    std                  | 0.512        |
|    total_cost           | 9.36         |
|    value_loss           | 129          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 230      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 340      |
|    time_elapsed    | 3240     |
|    total_timesteps | 1740800  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 212         |
|    ep_rew_mean          | 229         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 341         |
|    time_elapsed         | 3248        |
|    total_timesteps      | 1745920     |
| train/                  |             |
|    approx_kl            | 0.005685852 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.728       |
|    learning_rate        | 5e-05       |
|    loss                 | 52.2        |
|    n_updates            | 6800        |
|    policy_gradient_loss | -0.00078    |
|    std                  | 0.512       |
|    value_loss           | 113         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0754      |
|    crash                | 0.269       |
|    max_step             | 0           |
|    mean_ep_length       | 122         |
|    mean_reward          | 168         |
|    num_episodes         | 5           |
|    out_of_road          | 0.925       |
|    raw_action           | 0.48153344  |
|    route_completion     | 0.455       |
|    success_rate         | 0.1         |
|    total_cost           | 8.58        |
| time/                   |             |
|    total_timesteps      | 1750000     |
| train/                  |             |
|    approx_kl            | 0.001987153 |
|    arrive_dest          | 0.122       |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.1         |
|    crash                | 0.235       |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.773       |
|    learning_rate        | 5e-05       |
|    loss                 | 51.6        |
|    max_step             | 0           |
|    n_updates            | 6820        |
|    out_of_road          | 0.878       |
|    policy_gradient_loss | -0.0009     |
|    route_completion     | 0.464       |
|    std                  | 0.511       |
|    total_cost           | 9.32        |
|    value_loss           | 120         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 219      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 342      |
|    time_elapsed    | 3259     |
|    total_timesteps | 1751040  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 210          |
|    ep_rew_mean          | 230          |
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 343          |
|    time_elapsed         | 3265         |
|    total_timesteps      | 1756160      |
| train/                  |              |
|    approx_kl            | 0.0013891999 |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.36        |
|    explained_variance   | 0.723        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.6         |
|    n_updates            | 6840         |
|    policy_gradient_loss | -0.00046     |
|    std                  | 0.509        |
|    value_loss           | 160          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.075       |
|    crash                | 0.268       |
|    max_step             | 0           |
|    mean_ep_length       | 147         |
|    mean_reward          | 200         |
|    num_episodes         | 5           |
|    out_of_road          | 0.925       |
|    raw_action           | 0.4813652   |
|    route_completion     | 0.455       |
|    success_rate         | 0           |
|    total_cost           | 8.56        |
| time/                   |             |
|    total_timesteps      | 1760000     |
| train/                  |             |
|    approx_kl            | 0.011854044 |
|    arrive_dest          | 0.122       |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.1         |
|    crash                | 0.235       |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.713       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.6        |
|    max_step             | 0           |
|    n_updates            | 6860        |
|    out_of_road          | 0.878       |
|    policy_gradient_loss | -0.000766   |
|    route_completion     | 0.464       |
|    std                  | 0.51        |
|    total_cost           | 9.28        |
|    value_loss           | 139         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 242      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 344      |
|    time_elapsed    | 3277     |
|    total_timesteps | 1761280  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 213         |
|    ep_rew_mean          | 233         |
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 345         |
|    time_elapsed         | 3284        |
|    total_timesteps      | 1766400     |
| train/                  |             |
|    approx_kl            | 0.003740631 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.739       |
|    learning_rate        | 5e-05       |
|    loss                 | 64.7        |
|    n_updates            | 6880        |
|    policy_gradient_loss | 0.00127     |
|    std                  | 0.508       |
|    value_loss           | 125         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0746       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 103          |
|    mean_reward          | 132          |
|    num_episodes         | 5            |
|    out_of_road          | 0.925        |
|    raw_action           | 0.4813903    |
|    route_completion     | 0.455        |
|    success_rate         | 0.1          |
|    total_cost           | 8.51         |
| time/                   |              |
|    total_timesteps      | 1770000      |
| train/                  |              |
|    approx_kl            | 0.0033385083 |
|    arrive_dest          | 0.122        |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.35        |
|    explained_variance   | 0.73         |
|    learning_rate        | 5e-05        |
|    loss                 | 48.2         |
|    max_step             | 0            |
|    n_updates            | 6900         |
|    out_of_road          | 0.878        |
|    policy_gradient_loss | 0.00143      |
|    route_completion     | 0.464        |
|    std                  | 0.508        |
|    total_cost           | 9.23         |
|    value_loss           | 133          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 216      |
|    ep_rew_mean     | 242      |
| time/              |          |
|    fps             | 537      |
|    iterations      | 346      |
|    time_elapsed    | 3293     |
|    total_timesteps | 1771520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 213          |
|    ep_rew_mean          | 232          |
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 347          |
|    time_elapsed         | 3299         |
|    total_timesteps      | 1776640      |
| train/                  |              |
|    approx_kl            | 0.0032889328 |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.36        |
|    explained_variance   | 0.711        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.7         |
|    n_updates            | 6920         |
|    policy_gradient_loss | -0.000186    |
|    std                  | 0.509        |
|    value_loss           | 155          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0742      |
|    crash                | 0.265       |
|    max_step             | 0           |
|    mean_ep_length       | 92.8        |
|    mean_reward          | 109         |
|    num_episodes         | 5           |
|    out_of_road          | 0.926       |
|    raw_action           | 0.48133513  |
|    route_completion     | 0.454       |
|    success_rate         | 0.1         |
|    total_cost           | 8.47        |
| time/                   |             |
|    total_timesteps      | 1780000     |
| train/                  |             |
|    approx_kl            | 0.005682016 |
|    arrive_dest          | 0.122       |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.723       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.7        |
|    max_step             | 0           |
|    n_updates            | 6940        |
|    out_of_road          | 0.878       |
|    policy_gradient_loss | -5.65e-05   |
|    route_completion     | 0.465       |
|    std                  | 0.51        |
|    total_cost           | 9.19        |
|    value_loss           | 131         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 213      |
| time/              |          |
|    fps             | 538      |
|    iterations      | 348      |
|    time_elapsed    | 3309     |
|    total_timesteps | 1781760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 213          |
|    ep_rew_mean          | 222          |
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 349          |
|    time_elapsed         | 3315         |
|    total_timesteps      | 1786880      |
| train/                  |              |
|    approx_kl            | 0.0040527666 |
|    clip_fraction        | 0.206        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.36        |
|    explained_variance   | 0.8          |
|    learning_rate        | 5e-05        |
|    loss                 | 74.8         |
|    n_updates            | 6960         |
|    policy_gradient_loss | 0.00293      |
|    std                  | 0.509        |
|    value_loss           | 132          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0749      |
|    crash                | 0.264       |
|    max_step             | 0           |
|    mean_ep_length       | 121         |
|    mean_reward          | 133         |
|    num_episodes         | 5           |
|    out_of_road          | 0.925       |
|    raw_action           | 0.48157668  |
|    route_completion     | 0.454       |
|    success_rate         | 0.3         |
|    total_cost           | 8.47        |
| time/                   |             |
|    total_timesteps      | 1790000     |
| train/                  |             |
|    approx_kl            | 0.013658802 |
|    arrive_dest          | 0.124       |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.1         |
|    crash                | 0.237       |
|    entropy_loss         | -1.35       |
|    explained_variance   | 0.746       |
|    learning_rate        | 5e-05       |
|    loss                 | 44.2        |
|    max_step             | 0           |
|    n_updates            | 6980        |
|    out_of_road          | 0.876       |
|    policy_gradient_loss | 0.00727     |
|    route_completion     | 0.466       |
|    std                  | 0.507       |
|    total_cost           | 9.2         |
|    value_loss           | 108         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 219      |
| time/              |          |
|    fps             | 538      |
|    iterations      | 350      |
|    time_elapsed    | 3326     |
|    total_timesteps | 1792000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 210          |
|    ep_rew_mean          | 221          |
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 351          |
|    time_elapsed         | 3332         |
|    total_timesteps      | 1797120      |
| train/                  |              |
|    approx_kl            | 0.0018953212 |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.35        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.3         |
|    n_updates            | 7000         |
|    policy_gradient_loss | -0.000693    |
|    std                  | 0.507        |
|    value_loss           | 167          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0744     |
|    crash                | 0.264      |
|    max_step             | 0          |
|    mean_ep_length       | 128        |
|    mean_reward          | 173        |
|    num_episodes         | 5          |
|    out_of_road          | 0.926      |
|    raw_action           | 0.48161188 |
|    route_completion     | 0.454      |
|    success_rate         | 0.1        |
|    total_cost           | 8.44       |
| time/                   |            |
|    total_timesteps      | 1800000    |
| train/                  |            |
|    approx_kl            | 0.00216464 |
|    arrive_dest          | 0.124      |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.1        |
|    crash                | 0.237      |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.675      |
|    learning_rate        | 5e-05      |
|    loss                 | 65.4       |
|    max_step             | 0          |
|    n_updates            | 7020       |
|    out_of_road          | 0.876      |
|    policy_gradient_loss | 0.00142    |
|    route_completion     | 0.466      |
|    std                  | 0.508      |
|    total_cost           | 9.33       |
|    value_loss           | 137        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 222      |
| time/              |          |
|    fps             | 538      |
|    iterations      | 352      |
|    time_elapsed    | 3344     |
|    total_timesteps | 1802240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 214         |
|    ep_rew_mean          | 234         |
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 353         |
|    time_elapsed         | 3351        |
|    total_timesteps      | 1807360     |
| train/                  |             |
|    approx_kl            | 0.002345133 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.34       |
|    explained_variance   | 0.672       |
|    learning_rate        | 5e-05       |
|    loss                 | 91.5        |
|    n_updates            | 7040        |
|    policy_gradient_loss | -0.00137    |
|    std                  | 0.507       |
|    value_loss           | 161         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.074        |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 139          |
|    mean_reward          | 174          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.48173046   |
|    route_completion     | 0.455        |
|    success_rate         | 0.1          |
|    total_cost           | 8.42         |
| time/                   |              |
|    total_timesteps      | 1810000      |
| train/                  |              |
|    approx_kl            | 0.0024973894 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -1.34        |
|    explained_variance   | 0.706        |
|    learning_rate        | 5e-05        |
|    loss                 | 44           |
|    max_step             | 0            |
|    n_updates            | 7060         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | -0.00221     |
|    route_completion     | 0.466        |
|    std                  | 0.507        |
|    total_cost           | 9.29         |
|    value_loss           | 128          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 228      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 354      |
|    time_elapsed    | 3361     |
|    total_timesteps | 1812480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 216          |
|    ep_rew_mean          | 226          |
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 355          |
|    time_elapsed         | 3368         |
|    total_timesteps      | 1817600      |
| train/                  |              |
|    approx_kl            | 0.0032399497 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.35        |
|    explained_variance   | 0.743        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.6         |
|    n_updates            | 7080         |
|    policy_gradient_loss | 0.000667     |
|    std                  | 0.509        |
|    value_loss           | 132          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0747       |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 190          |
|    mean_reward          | 239          |
|    num_episodes         | 5            |
|    out_of_road          | 0.925        |
|    raw_action           | 0.48152822   |
|    route_completion     | 0.456        |
|    success_rate         | 0.2          |
|    total_cost           | 8.41         |
| time/                   |              |
|    total_timesteps      | 1820000      |
| train/                  |              |
|    approx_kl            | 0.0025322258 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.217        |
|    clip_range           | 0.1          |
|    crash                | 0.234        |
|    entropy_loss         | -1.34        |
|    explained_variance   | 0.785        |
|    learning_rate        | 5e-05        |
|    loss                 | 58           |
|    max_step             | 0            |
|    n_updates            | 7100         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | 0.0032       |
|    route_completion     | 0.466        |
|    std                  | 0.507        |
|    total_cost           | 9.3          |
|    value_loss           | 99           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 230      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 356      |
|    time_elapsed    | 3380     |
|    total_timesteps | 1822720  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 220         |
|    ep_rew_mean          | 230         |
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 357         |
|    time_elapsed         | 3387        |
|    total_timesteps      | 1827840     |
| train/                  |             |
|    approx_kl            | 0.002779469 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.34       |
|    explained_variance   | 0.688       |
|    learning_rate        | 5e-05       |
|    loss                 | 42          |
|    n_updates            | 7120        |
|    policy_gradient_loss | -0.000593   |
|    std                  | 0.506       |
|    value_loss           | 135         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0743      |
|    crash                | 0.268       |
|    max_step             | 0           |
|    mean_ep_length       | 120         |
|    mean_reward          | 159         |
|    num_episodes         | 5           |
|    out_of_road          | 0.926       |
|    raw_action           | 0.4814027   |
|    route_completion     | 0.456       |
|    success_rate         | 0           |
|    total_cost           | 8.39        |
| time/                   |             |
|    total_timesteps      | 1830000     |
| train/                  |             |
|    approx_kl            | 0.006762301 |
|    arrive_dest          | 0.125       |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.1         |
|    crash                | 0.234       |
|    entropy_loss         | -1.34       |
|    explained_variance   | 0.753       |
|    learning_rate        | 5e-05       |
|    loss                 | 62          |
|    max_step             | 0           |
|    n_updates            | 7140        |
|    out_of_road          | 0.875       |
|    policy_gradient_loss | 0.000529    |
|    route_completion     | 0.465       |
|    std                  | 0.506       |
|    total_cost           | 9.26        |
|    value_loss           | 110         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 358      |
|    time_elapsed    | 3397     |
|    total_timesteps | 1832960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 216          |
|    ep_rew_mean          | 233          |
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 359          |
|    time_elapsed         | 3403         |
|    total_timesteps      | 1838080      |
| train/                  |              |
|    approx_kl            | 0.0021978684 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.732        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.6         |
|    n_updates            | 7160         |
|    policy_gradient_loss | -0.00206     |
|    std                  | 0.507        |
|    value_loss           | 135          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.075        |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 119          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.925        |
|    raw_action           | 0.48132318   |
|    route_completion     | 0.456        |
|    success_rate         | 0.1          |
|    total_cost           | 8.35         |
| time/                   |              |
|    total_timesteps      | 1840000      |
| train/                  |              |
|    approx_kl            | 0.0040622554 |
|    arrive_dest          | 0.124        |
|    clip_fraction        | 0.235        |
|    clip_range           | 0.1          |
|    crash                | 0.233        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.768        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.7         |
|    max_step             | 0            |
|    n_updates            | 7180         |
|    out_of_road          | 0.876        |
|    policy_gradient_loss | 0.00732      |
|    route_completion     | 0.465        |
|    std                  | 0.506        |
|    total_cost           | 9.22         |
|    value_loss           | 113          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 360      |
|    time_elapsed    | 3415     |
|    total_timesteps | 1843200  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 209          |
|    ep_rew_mean          | 229          |
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 361          |
|    time_elapsed         | 3421         |
|    total_timesteps      | 1848320      |
| train/                  |              |
|    approx_kl            | 0.0024713376 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.9         |
|    n_updates            | 7200         |
|    policy_gradient_loss | 0.000911     |
|    std                  | 0.505        |
|    value_loss           | 154          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0746       |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 222          |
|    mean_reward          | 283          |
|    num_episodes         | 5            |
|    out_of_road          | 0.925        |
|    raw_action           | 0.4808076    |
|    route_completion     | 0.457        |
|    success_rate         | 0.2          |
|    total_cost           | 8.37         |
| time/                   |              |
|    total_timesteps      | 1850000      |
| train/                  |              |
|    approx_kl            | 0.0033497862 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    crash                | 0.232        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.836        |
|    learning_rate        | 5e-05        |
|    loss                 | 40.8         |
|    max_step             | 0            |
|    n_updates            | 7220         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | -0.00114     |
|    route_completion     | 0.466        |
|    std                  | 0.506        |
|    total_cost           | 9.23         |
|    value_loss           | 103          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 362      |
|    time_elapsed    | 3435     |
|    total_timesteps | 1853440  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 207         |
|    ep_rew_mean          | 226         |
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 363         |
|    time_elapsed         | 3442        |
|    total_timesteps      | 1858560     |
| train/                  |             |
|    approx_kl            | 0.010229127 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.751       |
|    learning_rate        | 5e-05       |
|    loss                 | 83.4        |
|    n_updates            | 7240        |
|    policy_gradient_loss | 0.00126     |
|    std                  | 0.504       |
|    value_loss           | 148         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0742       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 89.2         |
|    mean_reward          | 105          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.48096216   |
|    route_completion     | 0.457        |
|    success_rate         | 0            |
|    total_cost           | 8.33         |
| time/                   |              |
|    total_timesteps      | 1860000      |
| train/                  |              |
|    approx_kl            | 0.0020341277 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.32        |
|    explained_variance   | 0.702        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.9         |
|    max_step             | 0            |
|    n_updates            | 7260         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | -0.00152     |
|    route_completion     | 0.465        |
|    std                  | 0.503        |
|    total_cost           | 9.19         |
|    value_loss           | 135          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 233      |
| time/              |          |
|    fps             | 540      |
|    iterations      | 364      |
|    time_elapsed    | 3450     |
|    total_timesteps | 1863680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 224          |
|    ep_rew_mean          | 240          |
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 365          |
|    time_elapsed         | 3456         |
|    total_timesteps      | 1868800      |
| train/                  |              |
|    approx_kl            | 0.0035424829 |
|    clip_fraction        | 0.216        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.31        |
|    explained_variance   | 0.731        |
|    learning_rate        | 5e-05        |
|    loss                 | 45.9         |
|    n_updates            | 7280         |
|    policy_gradient_loss | 0.00287      |
|    std                  | 0.503        |
|    value_loss           | 132          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0749       |
|    crash                | 0.264        |
|    max_step             | 0            |
|    mean_ep_length       | 127          |
|    mean_reward          | 145          |
|    num_episodes         | 5            |
|    out_of_road          | 0.925        |
|    raw_action           | 0.480544     |
|    route_completion     | 0.457        |
|    success_rate         | 0.4          |
|    total_cost           | 8.34         |
| time/                   |              |
|    total_timesteps      | 1870000      |
| train/                  |              |
|    approx_kl            | 0.0018723648 |
|    arrive_dest          | 0.127        |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.31        |
|    explained_variance   | 0.756        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.7         |
|    max_step             | 0            |
|    n_updates            | 7300         |
|    out_of_road          | 0.873        |
|    policy_gradient_loss | -0.000969    |
|    route_completion     | 0.466        |
|    std                  | 0.503        |
|    total_cost           | 9.23         |
|    value_loss           | 140          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 234      |
| time/              |          |
|    fps             | 539      |
|    iterations      | 366      |
|    time_elapsed    | 3471     |
|    total_timesteps | 1873920  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 223         |
|    ep_rew_mean          | 242         |
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 367         |
|    time_elapsed         | 3476        |
|    total_timesteps      | 1879040     |
| train/                  |             |
|    approx_kl            | 0.008796344 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.752       |
|    learning_rate        | 5e-05       |
|    loss                 | 44.8        |
|    n_updates            | 7320        |
|    policy_gradient_loss | -0.00129    |
|    std                  | 0.502       |
|    value_loss           | 153         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0745       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 161          |
|    mean_reward          | 222          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.48073247   |
|    route_completion     | 0.457        |
|    success_rate         | 0            |
|    total_cost           | 8.32         |
| time/                   |              |
|    total_timesteps      | 1880000      |
| train/                  |              |
|    approx_kl            | 0.0028129444 |
|    arrive_dest          | 0.127        |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.31        |
|    explained_variance   | 0.754        |
|    learning_rate        | 5e-05        |
|    loss                 | 42           |
|    max_step             | 0            |
|    n_updates            | 7340         |
|    out_of_road          | 0.873        |
|    policy_gradient_loss | 0.000832     |
|    route_completion     | 0.467        |
|    std                  | 0.5          |
|    total_cost           | 9.25         |
|    value_loss           | 115          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 216      |
|    ep_rew_mean     | 241      |
| time/              |          |
|    fps             | 540      |
|    iterations      | 368      |
|    time_elapsed    | 3488     |
|    total_timesteps | 1884160  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 224        |
|    ep_rew_mean          | 253        |
| time/                   |            |
|    fps                  | 540        |
|    iterations           | 369        |
|    time_elapsed         | 3494       |
|    total_timesteps      | 1889280    |
| train/                  |            |
|    approx_kl            | 0.04896214 |
|    clip_fraction        | 0.169      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.3       |
|    explained_variance   | 0.717      |
|    learning_rate        | 5e-05      |
|    loss                 | 66.3       |
|    n_updates            | 7360       |
|    policy_gradient_loss | 0.00105    |
|    std                  | 0.5        |
|    value_loss           | 136        |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0741      |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 138         |
|    mean_reward          | 165         |
|    num_episodes         | 5           |
|    out_of_road          | 0.926       |
|    raw_action           | 0.4805878   |
|    route_completion     | 0.458       |
|    success_rate         | 0           |
|    total_cost           | 8.3         |
| time/                   |             |
|    total_timesteps      | 1890000     |
| train/                  |             |
|    approx_kl            | 0.008948602 |
|    arrive_dest          | 0.126       |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.809       |
|    learning_rate        | 5e-05       |
|    loss                 | 39.8        |
|    max_step             | 0           |
|    n_updates            | 7380        |
|    out_of_road          | 0.874       |
|    policy_gradient_loss | -1.57e-05   |
|    route_completion     | 0.467       |
|    std                  | 0.502       |
|    total_cost           | 9.21        |
|    value_loss           | 87.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 540      |
|    iterations      | 370      |
|    time_elapsed    | 3504     |
|    total_timesteps | 1894400  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 232         |
|    ep_rew_mean          | 260         |
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 371         |
|    time_elapsed         | 3510        |
|    total_timesteps      | 1899520     |
| train/                  |             |
|    approx_kl            | 0.004216603 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.766       |
|    learning_rate        | 5e-05       |
|    loss                 | 67.6        |
|    n_updates            | 7400        |
|    policy_gradient_loss | -0.00143    |
|    std                  | 0.503       |
|    value_loss           | 126         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0737       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 155          |
|    mean_reward          | 226          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.48056647   |
|    route_completion     | 0.458        |
|    success_rate         | 0.1          |
|    total_cost           | 8.26         |
| time/                   |              |
|    total_timesteps      | 1900000      |
| train/                  |              |
|    approx_kl            | 0.0016663496 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.31        |
|    explained_variance   | 0.838        |
|    learning_rate        | 5e-05        |
|    loss                 | 42           |
|    max_step             | 0            |
|    n_updates            | 7420         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | 0.00138      |
|    route_completion     | 0.467        |
|    std                  | 0.502        |
|    total_cost           | 9.17         |
|    value_loss           | 111          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 227      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 541      |
|    iterations      | 372      |
|    time_elapsed    | 3520     |
|    total_timesteps | 1904640  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 229         |
|    ep_rew_mean          | 246         |
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 373         |
|    time_elapsed         | 3527        |
|    total_timesteps      | 1909760     |
| train/                  |             |
|    approx_kl            | 0.004800809 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.738       |
|    learning_rate        | 5e-05       |
|    loss                 | 64.7        |
|    n_updates            | 7440        |
|    policy_gradient_loss | 0.00367     |
|    std                  | 0.503       |
|    value_loss           | 125         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0743       |
|    crash                | 0.266        |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 212          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.48063096   |
|    route_completion     | 0.458        |
|    success_rate         | 0.2          |
|    total_cost           | 8.24         |
| time/                   |              |
|    total_timesteps      | 1910000      |
| train/                  |              |
|    approx_kl            | 0.0018842078 |
|    arrive_dest          | 0.127        |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.32        |
|    explained_variance   | 0.609        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.7         |
|    max_step             | 0            |
|    n_updates            | 7460         |
|    out_of_road          | 0.873        |
|    policy_gradient_loss | -0.000845    |
|    route_completion     | 0.467        |
|    std                  | 0.504        |
|    total_cost           | 9.15         |
|    value_loss           | 151          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 237      |
| time/              |          |
|    fps             | 541      |
|    iterations      | 374      |
|    time_elapsed    | 3538     |
|    total_timesteps | 1914880  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.074       |
|    crash                | 0.266       |
|    max_step             | 0           |
|    mean_ep_length       | 126         |
|    mean_reward          | 170         |
|    num_episodes         | 5           |
|    out_of_road          | 0.926       |
|    raw_action           | 0.4806207   |
|    route_completion     | 0.459       |
|    success_rate         | 0.2         |
|    total_cost           | 8.21        |
| time/                   |             |
|    total_timesteps      | 1920000     |
| train/                  |             |
|    approx_kl            | 0.005004611 |
|    arrive_dest          | 0.128       |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.1         |
|    crash                | 0.236       |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.754       |
|    learning_rate        | 5e-05       |
|    loss                 | 66.9        |
|    max_step             | 0           |
|    n_updates            | 7480        |
|    out_of_road          | 0.872       |
|    policy_gradient_loss | 0.000373    |
|    route_completion     | 0.469       |
|    std                  | 0.505       |
|    total_cost           | 9.15        |
|    value_loss           | 146         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    fps             | 540      |
|    iterations      | 375      |
|    time_elapsed    | 3549     |
|    total_timesteps | 1920000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 214         |
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 376         |
|    time_elapsed         | 3556        |
|    total_timesteps      | 1925120     |
| train/                  |             |
|    approx_kl            | 0.008624935 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.755       |
|    learning_rate        | 5e-05       |
|    loss                 | 36.1        |
|    n_updates            | 7500        |
|    policy_gradient_loss | 0.00814     |
|    std                  | 0.507       |
|    value_loss           | 98          |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0736       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 94.6         |
|    mean_reward          | 104          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.48034963   |
|    route_completion     | 0.458        |
|    success_rate         | 0            |
|    total_cost           | 8.18         |
| time/                   |              |
|    total_timesteps      | 1930000      |
| train/                  |              |
|    approx_kl            | 0.0017367447 |
|    arrive_dest          | 0.127        |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.747        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.8         |
|    max_step             | 0            |
|    n_updates            | 7520         |
|    out_of_road          | 0.873        |
|    policy_gradient_loss | 0.000651     |
|    route_completion     | 0.468        |
|    std                  | 0.509        |
|    total_cost           | 9.11         |
|    value_loss           | 129          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 541      |
|    iterations      | 377      |
|    time_elapsed    | 3564     |
|    total_timesteps | 1930240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 199         |
|    ep_rew_mean          | 206         |
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 378         |
|    time_elapsed         | 3571        |
|    total_timesteps      | 1935360     |
| train/                  |             |
|    approx_kl            | 0.002791664 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.752       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.3        |
|    n_updates            | 7540        |
|    policy_gradient_loss | -0.000253   |
|    std                  | 0.509       |
|    value_loss           | 137         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0732       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 156          |
|    mean_reward          | 210          |
|    num_episodes         | 5            |
|    out_of_road          | 0.927        |
|    raw_action           | 0.48017836   |
|    route_completion     | 0.459        |
|    success_rate         | 0.1          |
|    total_cost           | 8.15         |
| time/                   |              |
|    total_timesteps      | 1940000      |
| train/                  |              |
|    approx_kl            | 0.0027420032 |
|    arrive_dest          | 0.128        |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.754        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.3         |
|    max_step             | 0            |
|    n_updates            | 7560         |
|    out_of_road          | 0.872        |
|    policy_gradient_loss | -0.00164     |
|    route_completion     | 0.469        |
|    std                  | 0.509        |
|    total_cost           | 9.09         |
|    value_loss           | 149          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 219      |
| time/              |          |
|    fps             | 541      |
|    iterations      | 379      |
|    time_elapsed    | 3581     |
|    total_timesteps | 1940480  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 206         |
|    ep_rew_mean          | 214         |
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 380         |
|    time_elapsed         | 3588        |
|    total_timesteps      | 1945600     |
| train/                  |             |
|    approx_kl            | 0.015230069 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.702       |
|    learning_rate        | 5e-05       |
|    loss                 | 107         |
|    n_updates            | 7580        |
|    policy_gradient_loss | 0.000204    |
|    std                  | 0.508       |
|    value_loss           | 159         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0728      |
|    crash                | 0.269       |
|    max_step             | 0           |
|    mean_ep_length       | 137         |
|    mean_reward          | 177         |
|    num_episodes         | 5           |
|    out_of_road          | 0.927       |
|    raw_action           | 0.48004442  |
|    route_completion     | 0.459       |
|    success_rate         | 0           |
|    total_cost           | 8.14        |
| time/                   |             |
|    total_timesteps      | 1950000     |
| train/                  |             |
|    approx_kl            | 0.005746928 |
|    arrive_dest          | 0.127       |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.1         |
|    crash                | 0.237       |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.693       |
|    learning_rate        | 5e-05       |
|    loss                 | 77.2        |
|    max_step             | 0           |
|    n_updates            | 7600        |
|    out_of_road          | 0.873       |
|    policy_gradient_loss | 0.00476     |
|    route_completion     | 0.469       |
|    std                  | 0.507       |
|    total_cost           | 9.05        |
|    value_loss           | 151         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 542      |
|    iterations      | 381      |
|    time_elapsed    | 3598     |
|    total_timesteps | 1950720  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 204         |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 382         |
|    time_elapsed         | 3605        |
|    total_timesteps      | 1955840     |
| train/                  |             |
|    approx_kl            | 0.009830813 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.624       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.2        |
|    n_updates            | 7620        |
|    policy_gradient_loss | 0.00419     |
|    std                  | 0.509       |
|    value_loss           | 160         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0724       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 119          |
|    mean_reward          | 141          |
|    num_episodes         | 5            |
|    out_of_road          | 0.928        |
|    raw_action           | 0.48003992   |
|    route_completion     | 0.459        |
|    success_rate         | 0.1          |
|    total_cost           | 8.11         |
| time/                   |              |
|    total_timesteps      | 1960000      |
| train/                  |              |
|    approx_kl            | 0.0021970388 |
|    arrive_dest          | 0.128        |
|    clip_fraction        | 0.173        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.754        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.6         |
|    max_step             | 0            |
|    n_updates            | 7640         |
|    out_of_road          | 0.872        |
|    policy_gradient_loss | 0.00223      |
|    route_completion     | 0.469        |
|    std                  | 0.51         |
|    total_cost           | 9.13         |
|    value_loss           | 97.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 542      |
|    iterations      | 383      |
|    time_elapsed    | 3617     |
|    total_timesteps | 1960960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 196          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 384          |
|    time_elapsed         | 3624         |
|    total_timesteps      | 1966080      |
| train/                  |              |
|    approx_kl            | 0.0015007758 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.711        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.6         |
|    n_updates            | 7660         |
|    policy_gradient_loss | -0.000299    |
|    std                  | 0.509        |
|    value_loss           | 163          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0721      |
|    crash                | 0.267       |
|    max_step             | 0           |
|    mean_ep_length       | 77.6        |
|    mean_reward          | 74          |
|    num_episodes         | 5           |
|    out_of_road          | 0.928       |
|    raw_action           | 0.4800214   |
|    route_completion     | 0.458       |
|    success_rate         | 0           |
|    total_cost           | 8.07        |
| time/                   |             |
|    total_timesteps      | 1970000     |
| train/                  |             |
|    approx_kl            | 0.005181866 |
|    arrive_dest          | 0.127       |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.1         |
|    crash                | 0.237       |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.656       |
|    learning_rate        | 5e-05       |
|    loss                 | 81.9        |
|    max_step             | 0           |
|    n_updates            | 7680        |
|    out_of_road          | 0.873       |
|    policy_gradient_loss | -0.000487   |
|    route_completion     | 0.469       |
|    std                  | 0.51        |
|    total_cost           | 9.1         |
|    value_loss           | 151         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 542      |
|    iterations      | 385      |
|    time_elapsed    | 3634     |
|    total_timesteps | 1971200  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 386         |
|    time_elapsed         | 3641        |
|    total_timesteps      | 1976320     |
| train/                  |             |
|    approx_kl            | 0.005651324 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.73        |
|    learning_rate        | 5e-05       |
|    loss                 | 57.1        |
|    n_updates            | 7700        |
|    policy_gradient_loss | 0.00431     |
|    std                  | 0.512       |
|    value_loss           | 126         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0717       |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 139          |
|    mean_reward          | 195          |
|    num_episodes         | 5            |
|    out_of_road          | 0.928        |
|    raw_action           | 0.48025456   |
|    route_completion     | 0.458        |
|    success_rate         | 0            |
|    total_cost           | 8.04         |
| time/                   |              |
|    total_timesteps      | 1980000      |
| train/                  |              |
|    approx_kl            | 0.0024977217 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    crash                | 0.237        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.4         |
|    max_step             | 0            |
|    n_updates            | 7720         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | -0.0015      |
|    route_completion     | 0.469        |
|    std                  | 0.513        |
|    total_cost           | 9.07         |
|    value_loss           | 153          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 218      |
| time/              |          |
|    fps             | 542      |
|    iterations      | 387      |
|    time_elapsed    | 3651     |
|    total_timesteps | 1981440  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 210         |
|    ep_rew_mean          | 225         |
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 388         |
|    time_elapsed         | 3658        |
|    total_timesteps      | 1986560     |
| train/                  |             |
|    approx_kl            | 0.005415656 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.744       |
|    learning_rate        | 5e-05       |
|    loss                 | 46.1        |
|    n_updates            | 7740        |
|    policy_gradient_loss | -0.000199   |
|    std                  | 0.513       |
|    value_loss           | 126         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0714       |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 91.6         |
|    mean_reward          | 105          |
|    num_episodes         | 5            |
|    out_of_road          | 0.929        |
|    raw_action           | 0.4802642    |
|    route_completion     | 0.458        |
|    success_rate         | 0            |
|    total_cost           | 8.01         |
| time/                   |              |
|    total_timesteps      | 1990000      |
| train/                  |              |
|    approx_kl            | 0.0016330054 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.185        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.795        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.5         |
|    max_step             | 0            |
|    n_updates            | 7760         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | 0.000666     |
|    route_completion     | 0.468        |
|    std                  | 0.512        |
|    total_cost           | 9.03         |
|    value_loss           | 104          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 543      |
|    iterations      | 389      |
|    time_elapsed    | 3667     |
|    total_timesteps | 1991680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 204          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 390          |
|    time_elapsed         | 3674         |
|    total_timesteps      | 1996800      |
| train/                  |              |
|    approx_kl            | 0.0030722835 |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.8         |
|    n_updates            | 7780         |
|    policy_gradient_loss | -0.000197    |
|    std                  | 0.513        |
|    value_loss           | 124          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.072        |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 182          |
|    mean_reward          | 265          |
|    num_episodes         | 5            |
|    out_of_road          | 0.928        |
|    raw_action           | 0.47983918   |
|    route_completion     | 0.458        |
|    success_rate         | 0.1          |
|    total_cost           | 8            |
| time/                   |              |
|    total_timesteps      | 2000000      |
| train/                  |              |
|    approx_kl            | 0.0036826083 |
|    arrive_dest          | 0.125        |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    crash                | 0.236        |
|    entropy_loss         | -1.33        |
|    explained_variance   | 0.724        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.3         |
|    max_step             | 0            |
|    n_updates            | 7800         |
|    out_of_road          | 0.875        |
|    policy_gradient_loss | 0.000733     |
|    route_completion     | 0.469        |
|    std                  | 0.514        |
|    total_cost           | 9.01         |
|    value_loss           | 147          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 543      |
|    iterations      | 391      |
|    time_elapsed    | 3685     |
|    total_timesteps | 2001920  |
---------------------------------
