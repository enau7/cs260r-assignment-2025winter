Using cpu device
Logging to runs\ppo_metadrive_new_reward\ppo_metadrive_new_reward_2025-03-19_23-21-13_96be01e6\ppo_metadrive_new_reward_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 100      |
|    ep_rew_mean     | 0.452    |
| time/              |          |
|    fps             | 1637     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 193          |
|    mean_reward          | 46.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.041735474  |
|    route_completion     | 0.135        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0030141869 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.00748     |
|    learning_rate        | 5e-05        |
|    loss                 | -0.000881    |
|    max_step             | 0            |
|    n_updates            | 20           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00924     |
|    route_completion     | 0.163        |
|    std                  | 0.997        |
|    total_cost           | 1            |
|    value_loss           | 0.0326       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 1.76     |
| time/              |          |
|    fps             | 736      |
|    iterations      | 2        |
|    time_elapsed    | 13       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 306         |
|    ep_rew_mean          | 1.76        |
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 3           |
|    time_elapsed         | 17          |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.003289932 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.00388     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00255    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00605    |
|    std                  | 0.993       |
|    value_loss           | 0.133       |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0            |
|    max_step             | 0            |
|    mean_ep_length       | 98           |
|    mean_reward          | 36.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.06633829   |
|    route_completion     | 0.128        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0037840202 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.26         |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.183        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.00956     |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0135      |
|    route_completion     | 0.152        |
|    std                  | 0.987        |
|    total_cost           | 1            |
|    value_loss           | 0.0266       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 36.9     |
| time/              |          |
|    fps             | 749      |
|    iterations      | 4        |
|    time_elapsed    | 27       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 414          |
|    ep_rew_mean          | 26.7         |
| time/                   |              |
|    fps                  | 793          |
|    iterations           | 5            |
|    time_elapsed         | 32           |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0028472934 |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.088        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00494     |
|    std                  | 0.985        |
|    value_loss           | 0.235        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 92.4         |
|    mean_reward          | 50.3         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.09233886   |
|    route_completion     | 0.138        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0026075444 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.029        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.261        |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00479     |
|    route_completion     | 0.15         |
|    std                  | 0.979        |
|    total_cost           | 1            |
|    value_loss           | 0.244        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 398      |
|    ep_rew_mean     | 21.1     |
| time/              |          |
|    fps             | 732      |
|    iterations      | 6        |
|    time_elapsed    | 41       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 381          |
|    ep_rew_mean          | 18.4         |
| time/                   |              |
|    fps                  | 760          |
|    iterations           | 7            |
|    time_elapsed         | 47           |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 0.0021083355 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0143       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0959       |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00385     |
|    std                  | 0.975        |
|    value_loss           | 0.338        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.15         |
|    max_step             | 0            |
|    mean_ep_length       | 91.6         |
|    mean_reward          | 63.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.119704954  |
|    route_completion     | 0.158        |
|    success_rate         | 0            |
|    total_cost           | 1.05         |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0031541057 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.0396       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0855       |
|    max_step             | 0            |
|    n_updates            | 140          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00558     |
|    route_completion     | 0.15         |
|    std                  | 0.963        |
|    total_cost           | 1            |
|    value_loss           | 0.298        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 21.3     |
| time/              |          |
|    fps             | 715      |
|    iterations      | 8        |
|    time_elapsed    | 57       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 371          |
|    ep_rew_mean          | 18.4         |
| time/                   |              |
|    fps                  | 725          |
|    iterations           | 9            |
|    time_elapsed         | 63           |
|    total_timesteps      | 46080        |
| train/                  |              |
|    approx_kl            | 0.0023205515 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.0354       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.423        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00457     |
|    std                  | 0.961        |
|    value_loss           | 0.717        |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.16        |
|    max_step             | 0           |
|    mean_ep_length       | 63.4        |
|    mean_reward          | 35.6        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.1419212   |
|    route_completion     | 0.149       |
|    success_rate         | 0           |
|    total_cost           | 1.04        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.002027429 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.1         |
|    crash                | 0.12        |
|    entropy_loss         | -2.75       |
|    explained_variance   | -0.00287    |
|    learning_rate        | 5e-05       |
|    loss                 | 0.487       |
|    max_step             | 0           |
|    n_updates            | 180         |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00383    |
|    route_completion     | 0.141       |
|    std                  | 0.954       |
|    total_cost           | 1           |
|    value_loss           | 0.721       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 17.9     |
| time/              |          |
|    fps             | 696      |
|    iterations      | 10       |
|    time_elapsed    | 73       |
|    total_timesteps | 51200    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 361        |
|    ep_rew_mean          | 18.9       |
| time/                   |            |
|    fps                  | 711        |
|    iterations           | 11         |
|    time_elapsed         | 79         |
|    total_timesteps      | 56320      |
| train/                  |            |
|    approx_kl            | 0.00158683 |
|    clip_fraction        | 0.0471     |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.73      |
|    explained_variance   | 0.0239     |
|    learning_rate        | 5e-05      |
|    loss                 | 0.893      |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.00159   |
|    std                  | 0.944      |
|    value_loss           | 2.07       |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.167        |
|    max_step             | 0            |
|    mean_ep_length       | 67           |
|    mean_reward          | 48.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.17189571   |
|    route_completion     | 0.151        |
|    success_rate         | 0            |
|    total_cost           | 1.03         |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0020103166 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0931       |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.0355       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.358        |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00349     |
|    route_completion     | 0.155        |
|    std                  | 0.935        |
|    total_cost           | 1            |
|    value_loss           | 0.747        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 19.8     |
| time/              |          |
|    fps             | 669      |
|    iterations      | 12       |
|    time_elapsed    | 91       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 317          |
|    ep_rew_mean          | 18.7         |
| time/                   |              |
|    fps                  | 674          |
|    iterations           | 13           |
|    time_elapsed         | 98           |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0010741847 |
|    clip_fraction        | 0.0418       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.0276       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.47         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00136     |
|    std                  | 0.934        |
|    value_loss           | 2.93         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.143        |
|    max_step             | 0            |
|    mean_ep_length       | 41.8         |
|    mean_reward          | 21.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.19059798   |
|    route_completion     | 0.142        |
|    success_rate         | 0            |
|    total_cost           | 1.03         |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0019158358 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0869       |
|    clip_range           | 0.1          |
|    crash                | 0.143        |
|    entropy_loss         | -2.69        |
|    explained_variance   | -0.0221      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.872        |
|    max_step             | 0            |
|    n_updates            | 260          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00315     |
|    route_completion     | 0.149        |
|    std                  | 0.927        |
|    total_cost           | 1            |
|    value_loss           | 1.85         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 19.5     |
| time/              |          |
|    fps             | 653      |
|    iterations      | 14       |
|    time_elapsed    | 109      |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 244         |
|    ep_rew_mean          | 18.7        |
| time/                   |             |
|    fps                  | 652         |
|    iterations           | 15          |
|    time_elapsed         | 117         |
|    total_timesteps      | 76800       |
| train/                  |             |
|    approx_kl            | 0.001978234 |
|    clip_fraction        | 0.0928      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.68       |
|    explained_variance   | -0.00925    |
|    learning_rate        | 5e-05       |
|    loss                 | 1.34        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00262    |
|    std                  | 0.922       |
|    value_loss           | 2.69        |
-----------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0             |
|    crash                | 0.125         |
|    max_step             | 0             |
|    mean_ep_length       | 55.2          |
|    mean_reward          | 40.1          |
|    num_episodes         | 5             |
|    out_of_road          | 1             |
|    raw_action           | 0.21806967    |
|    route_completion     | 0.143         |
|    success_rate         | 0             |
|    total_cost           | 1.02          |
| time/                   |               |
|    total_timesteps      | 80000         |
| train/                  |               |
|    approx_kl            | 0.00077112904 |
|    arrive_dest          | 0             |
|    clip_fraction        | 0.0245        |
|    clip_range           | 0.1           |
|    crash                | 0.15          |
|    entropy_loss         | -2.67         |
|    explained_variance   | 0.00197       |
|    learning_rate        | 5e-05         |
|    loss                 | 1.16          |
|    max_step             | 0             |
|    n_updates            | 300           |
|    out_of_road          | 1             |
|    policy_gradient_loss | -0.000748     |
|    route_completion     | 0.162         |
|    std                  | 0.918         |
|    total_cost           | 1.9           |
|    value_loss           | 2.8           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 19.2     |
| time/              |          |
|    fps             | 619      |
|    iterations      | 16       |
|    time_elapsed    | 132      |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 201          |
|    ep_rew_mean          | 20.6         |
| time/                   |              |
|    fps                  | 616          |
|    iterations           | 17           |
|    time_elapsed         | 141          |
|    total_timesteps      | 87040        |
| train/                  |              |
|    approx_kl            | 0.0015219437 |
|    clip_fraction        | 0.0564       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.0156       |
|    learning_rate        | 5e-05        |
|    loss                 | 7.04         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.914        |
|    value_loss           | 9.33         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 53.2         |
|    mean_reward          | 38.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.23399334   |
|    route_completion     | 0.141        |
|    success_rate         | 0            |
|    total_cost           | 1.02         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0012917684 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0278       |
|    clip_range           | 0.1          |
|    crash                | 0.156        |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0529       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.96         |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.000999    |
|    route_completion     | 0.155        |
|    std                  | 0.908        |
|    total_cost           | 1.8          |
|    value_loss           | 4.27         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | 20       |
| time/              |          |
|    fps             | 593      |
|    iterations      | 18       |
|    time_elapsed    | 155      |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 138          |
|    ep_rew_mean          | 18.6         |
| time/                   |              |
|    fps                  | 587          |
|    iterations           | 19           |
|    time_elapsed         | 165          |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0013647586 |
|    clip_fraction        | 0.0455       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.64        |
|    explained_variance   | -0.000749    |
|    learning_rate        | 5e-05        |
|    loss                 | 4.82         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.905        |
|    value_loss           | 7.75         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.14         |
|    max_step             | 0            |
|    mean_ep_length       | 72.8         |
|    mean_reward          | 67           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.26169106   |
|    route_completion     | 0.148        |
|    success_rate         | 0            |
|    total_cost           | 1.2          |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0012874946 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.1          |
|    crash                | 0.16         |
|    entropy_loss         | -2.63        |
|    explained_variance   | -0.00803     |
|    learning_rate        | 5e-05        |
|    loss                 | 3.91         |
|    max_step             | 0            |
|    n_updates            | 380          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00116     |
|    route_completion     | 0.173        |
|    std                  | 0.898        |
|    total_cost           | 2.08         |
|    value_loss           | 6.94         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | 21.7     |
| time/              |          |
|    fps             | 568      |
|    iterations      | 20       |
|    time_elapsed    | 180      |
|    total_timesteps | 102400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 149          |
|    ep_rew_mean          | 24           |
| time/                   |              |
|    fps                  | 564          |
|    iterations           | 21           |
|    time_elapsed         | 190          |
|    total_timesteps      | 107520       |
| train/                  |              |
|    approx_kl            | 0.0014456308 |
|    clip_fraction        | 0.0547       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.00879      |
|    learning_rate        | 5e-05        |
|    loss                 | 7.05         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00216     |
|    std                  | 0.891        |
|    value_loss           | 15.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.164        |
|    max_step             | 0            |
|    mean_ep_length       | 72.2         |
|    mean_reward          | 75.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.2855534    |
|    route_completion     | 0.156        |
|    success_rate         | 0            |
|    total_cost           | 1.18         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0009064216 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.1          |
|    crash                | 0.164        |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.0557       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.54         |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0012      |
|    route_completion     | 0.183        |
|    std                  | 0.89         |
|    total_cost           | 3.51         |
|    value_loss           | 7.48         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 27       |
| time/              |          |
|    fps             | 535      |
|    iterations      | 22       |
|    time_elapsed    | 210      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 139          |
|    ep_rew_mean          | 23.2         |
| time/                   |              |
|    fps                  | 532          |
|    iterations           | 23           |
|    time_elapsed         | 221          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0007797958 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.0573       |
|    learning_rate        | 5e-05        |
|    loss                 | 7.58         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.884        |
|    value_loss           | 13.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.167        |
|    max_step             | 0            |
|    mean_ep_length       | 132          |
|    mean_reward          | 113          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.30612123   |
|    route_completion     | 0.177        |
|    success_rate         | 0            |
|    total_cost           | 2.9          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0012725426 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0457       |
|    clip_range           | 0.1          |
|    crash                | 0.15         |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.108        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.71         |
|    max_step             | 0            |
|    n_updates            | 460          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00306     |
|    route_completion     | 0.195        |
|    std                  | 0.881        |
|    total_cost           | 4.7          |
|    value_loss           | 12.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 123      |
|    ep_rew_mean     | 30.5     |
| time/              |          |
|    fps             | 507      |
|    iterations      | 24       |
|    time_elapsed    | 242      |
|    total_timesteps | 122880   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 136           |
|    ep_rew_mean          | 30.9          |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 25            |
|    time_elapsed         | 252           |
|    total_timesteps      | 128000        |
| train/                  |               |
|    approx_kl            | 0.00058553054 |
|    clip_fraction        | 0.0106        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.104         |
|    learning_rate        | 5e-05         |
|    loss                 | 11.4          |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.00149      |
|    std                  | 0.877         |
|    value_loss           | 21.8          |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.154        |
|    max_step             | 0            |
|    mean_ep_length       | 72.8         |
|    mean_reward          | 74.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.32319912   |
|    route_completion     | 0.183        |
|    success_rate         | 0            |
|    total_cost           | 2.78         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0016320792 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0524       |
|    clip_range           | 0.1          |
|    crash                | 0.154        |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.0115       |
|    learning_rate        | 5e-05        |
|    loss                 | 6.64         |
|    max_step             | 0            |
|    n_updates            | 500          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00316     |
|    route_completion     | 0.203        |
|    std                  | 0.875        |
|    total_cost           | 4.97         |
|    value_loss           | 13.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | 35.4     |
| time/              |          |
|    fps             | 491      |
|    iterations      | 26       |
|    time_elapsed    | 270      |
|    total_timesteps | 133120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | 34.2         |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 27           |
|    time_elapsed         | 279          |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0010305137 |
|    clip_fraction        | 0.0349       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.0651       |
|    learning_rate        | 5e-05        |
|    loss                 | 13.7         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00196     |
|    std                  | 0.868        |
|    value_loss           | 25.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.157        |
|    max_step             | 0            |
|    mean_ep_length       | 84.8         |
|    mean_reward          | 85.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.33684343   |
|    route_completion     | 0.189        |
|    success_rate         | 0.1          |
|    total_cost           | 2.91         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0010802683 |
|    arrive_dest          | 0.0143       |
|    clip_fraction        | 0.0502       |
|    clip_range           | 0.1          |
|    crash                | 0.157        |
|    entropy_loss         | -2.55        |
|    explained_variance   | -0.0194      |
|    learning_rate        | 5e-05        |
|    loss                 | 7.22         |
|    max_step             | 0            |
|    n_updates            | 540          |
|    out_of_road          | 0.986        |
|    policy_gradient_loss | -0.0029      |
|    route_completion     | 0.213        |
|    std                  | 0.868        |
|    total_cost           | 5.09         |
|    value_loss           | 15           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 39.1     |
| time/              |          |
|    fps             | 483      |
|    iterations      | 28       |
|    time_elapsed    | 296      |
|    total_timesteps | 143360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 162          |
|    ep_rew_mean          | 38.1         |
| time/                   |              |
|    fps                  | 484          |
|    iterations           | 29           |
|    time_elapsed         | 306          |
|    total_timesteps      | 148480       |
| train/                  |              |
|    approx_kl            | 0.0013961138 |
|    clip_fraction        | 0.0756       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.55        |
|    explained_variance   | -0.0184      |
|    learning_rate        | 5e-05        |
|    loss                 | 12.3         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.0021      |
|    std                  | 0.864        |
|    value_loss           | 23.7         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.147        |
|    max_step             | 0            |
|    mean_ep_length       | 82           |
|    mean_reward          | 78.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3598497    |
|    route_completion     | 0.195        |
|    success_rate         | 0            |
|    total_cost           | 3.12         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0017773351 |
|    arrive_dest          | 0.0133       |
|    clip_fraction        | 0.0866       |
|    clip_range           | 0.1          |
|    crash                | 0.187        |
|    entropy_loss         | -2.54        |
|    explained_variance   | -0.000128    |
|    learning_rate        | 5e-05        |
|    loss                 | 8.22         |
|    max_step             | 0            |
|    n_updates            | 580          |
|    out_of_road          | 0.987        |
|    policy_gradient_loss | -0.00416     |
|    route_completion     | 0.232        |
|    std                  | 0.863        |
|    total_cost           | 9.16         |
|    value_loss           | 20           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 158      |
|    ep_rew_mean     | 42.1     |
| time/              |          |
|    fps             | 467      |
|    iterations      | 30       |
|    time_elapsed    | 328      |
|    total_timesteps | 153600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 40.8         |
| time/                   |              |
|    fps                  | 473          |
|    iterations           | 31           |
|    time_elapsed         | 335          |
|    total_timesteps      | 158720       |
| train/                  |              |
|    approx_kl            | 0.0015694819 |
|    clip_fraction        | 0.0765       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.000168     |
|    learning_rate        | 5e-05        |
|    loss                 | 11.4         |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.856        |
|    value_loss           | 21.6         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.163       |
|    max_step             | 0           |
|    mean_ep_length       | 109         |
|    mean_reward          | 122         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.36954993  |
|    route_completion     | 0.205       |
|    success_rate         | 0           |
|    total_cost           | 3.4         |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.001540541 |
|    arrive_dest          | 0.0125      |
|    clip_fraction        | 0.0679      |
|    clip_range           | 0.1         |
|    crash                | 0.225       |
|    entropy_loss         | -2.52       |
|    explained_variance   | 0.00218     |
|    learning_rate        | 5e-05       |
|    loss                 | 9.16        |
|    max_step             | 0           |
|    n_updates            | 620         |
|    out_of_road          | 0.988       |
|    policy_gradient_loss | -0.00261    |
|    route_completion     | 0.242       |
|    std                  | 0.853       |
|    total_cost           | 9.38        |
|    value_loss           | 18.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 47.7     |
| time/              |          |
|    fps             | 466      |
|    iterations      | 32       |
|    time_elapsed    | 351      |
|    total_timesteps | 163840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 54.3         |
| time/                   |              |
|    fps                  | 472          |
|    iterations           | 33           |
|    time_elapsed         | 357          |
|    total_timesteps      | 168960       |
| train/                  |              |
|    approx_kl            | 0.0011319651 |
|    clip_fraction        | 0.0566       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.00333      |
|    learning_rate        | 5e-05        |
|    loss                 | 12.1         |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00351     |
|    std                  | 0.847        |
|    value_loss           | 30.3         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.188       |
|    max_step             | 0           |
|    mean_ep_length       | 92.8        |
|    mean_reward          | 98.7        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.3754989   |
|    route_completion     | 0.213       |
|    success_rate         | 0           |
|    total_cost           | 3.49        |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.002124046 |
|    arrive_dest          | 0.0118      |
|    clip_fraction        | 0.0543      |
|    clip_range           | 0.1         |
|    crash                | 0.212       |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0.0036      |
|    learning_rate        | 5e-05       |
|    loss                 | 12          |
|    max_step             | 0           |
|    n_updates            | 660         |
|    out_of_road          | 0.988       |
|    policy_gradient_loss | -0.00244    |
|    route_completion     | 0.246       |
|    std                  | 0.842       |
|    total_cost           | 8.99        |
|    value_loss           | 22.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 64.5     |
| time/              |          |
|    fps             | 473      |
|    iterations      | 34       |
|    time_elapsed    | 367      |
|    total_timesteps | 174080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 227          |
|    ep_rew_mean          | 74.2         |
| time/                   |              |
|    fps                  | 476          |
|    iterations           | 35           |
|    time_elapsed         | 375          |
|    total_timesteps      | 179200       |
| train/                  |              |
|    approx_kl            | 0.0010834007 |
|    clip_fraction        | 0.0459       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.00047      |
|    learning_rate        | 5e-05        |
|    loss                 | 16.9         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.000833    |
|    std                  | 0.84         |
|    value_loss           | 32.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.211        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3827973    |
|    route_completion     | 0.221        |
|    success_rate         | 0            |
|    total_cost           | 3.77         |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0011556374 |
|    arrive_dest          | 0.0111       |
|    clip_fraction        | 0.0618       |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.000375     |
|    learning_rate        | 5e-05        |
|    loss                 | 9.28         |
|    max_step             | 0            |
|    n_updates            | 700          |
|    out_of_road          | 0.989        |
|    policy_gradient_loss | -0.000957    |
|    route_completion     | 0.251        |
|    std                  | 0.834        |
|    total_cost           | 8.76         |
|    value_loss           | 27.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 81.6     |
| time/              |          |
|    fps             | 474      |
|    iterations      | 36       |
|    time_elapsed    | 388      |
|    total_timesteps | 184320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 240          |
|    ep_rew_mean          | 88.2         |
| time/                   |              |
|    fps                  | 479          |
|    iterations           | 37           |
|    time_elapsed         | 395          |
|    total_timesteps      | 189440       |
| train/                  |              |
|    approx_kl            | 0.0027291118 |
|    clip_fraction        | 0.0824       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.000865     |
|    learning_rate        | 5e-05        |
|    loss                 | 22.4         |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00266     |
|    std                  | 0.828        |
|    value_loss           | 42.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.211        |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 110          |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.39146462   |
|    route_completion     | 0.227        |
|    success_rate         | 0.1          |
|    total_cost           | 3.99         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0012652903 |
|    arrive_dest          | 0.0211       |
|    clip_fraction        | 0.0735       |
|    clip_range           | 0.1          |
|    crash                | 0.211        |
|    entropy_loss         | -2.46        |
|    explained_variance   | -0.000301    |
|    learning_rate        | 5e-05        |
|    loss                 | 12.9         |
|    max_step             | 0            |
|    n_updates            | 740          |
|    out_of_road          | 0.979        |
|    policy_gradient_loss | -0.00124     |
|    route_completion     | 0.267        |
|    std                  | 0.825        |
|    total_cost           | 9.39         |
|    value_loss           | 33.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 97.4     |
| time/              |          |
|    fps             | 473      |
|    iterations      | 38       |
|    time_elapsed    | 410      |
|    total_timesteps | 194560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 268         |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 478         |
|    iterations           | 39          |
|    time_elapsed         | 417         |
|    total_timesteps      | 199680      |
| train/                  |             |
|    approx_kl            | 0.001329681 |
|    clip_fraction        | 0.0488      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.00045     |
|    learning_rate        | 5e-05       |
|    loss                 | 18.4        |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00252    |
|    std                  | 0.823       |
|    value_loss           | 42.2        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.22         |
|    max_step             | 0            |
|    mean_ep_length       | 76.6         |
|    mean_reward          | 78.7         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.398416     |
|    route_completion     | 0.229        |
|    success_rate         | 0            |
|    total_cost           | 3.84         |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0015983544 |
|    arrive_dest          | 0.02         |
|    clip_fraction        | 0.0596       |
|    clip_range           | 0.1          |
|    crash                | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.000763     |
|    learning_rate        | 5e-05        |
|    loss                 | 12           |
|    max_step             | 0            |
|    n_updates            | 780          |
|    out_of_road          | 0.98         |
|    policy_gradient_loss | -0.00156     |
|    route_completion     | 0.275        |
|    std                  | 0.818        |
|    total_cost           | 9.29         |
|    value_loss           | 28.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 255      |
|    ep_rew_mean     | 111      |
| time/              |          |
|    fps             | 479      |
|    iterations      | 40       |
|    time_elapsed    | 427      |
|    total_timesteps | 204800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 280         |
|    ep_rew_mean          | 117         |
| time/                   |             |
|    fps                  | 482         |
|    iterations           | 41          |
|    time_elapsed         | 434         |
|    total_timesteps      | 209920      |
| train/                  |             |
|    approx_kl            | 0.000782188 |
|    clip_fraction        | 0.0364      |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.000567    |
|    learning_rate        | 5e-05       |
|    loss                 | 15.9        |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00155    |
|    std                  | 0.814       |
|    value_loss           | 40.5        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.229       |
|    max_step             | 0           |
|    mean_ep_length       | 180         |
|    mean_reward          | 141         |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.4046909   |
|    route_completion     | 0.244       |
|    success_rate         | 0           |
|    total_cost           | 5.7         |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.001346091 |
|    arrive_dest          | 0.019       |
|    clip_fraction        | 0.0907      |
|    clip_range           | 0.1         |
|    crash                | 0.219       |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 5e-05       |
|    loss                 | 29.5        |
|    max_step             | 0           |
|    n_updates            | 820         |
|    out_of_road          | 0.981       |
|    policy_gradient_loss | -0.00262    |
|    route_completion     | 0.288       |
|    std                  | 0.809       |
|    total_cost           | 9.5         |
|    value_loss           | 44.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 115      |
| time/              |          |
|    fps             | 478      |
|    iterations      | 42       |
|    time_elapsed    | 449      |
|    total_timesteps | 215040   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00909      |
|    crash                | 0.227        |
|    max_step             | 0            |
|    mean_ep_length       | 179          |
|    mean_reward          | 188          |
|    num_episodes         | 5            |
|    out_of_road          | 0.991        |
|    raw_action           | 0.40549996   |
|    route_completion     | 0.262        |
|    success_rate         | 0.1          |
|    total_cost           | 6.91         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0016502116 |
|    arrive_dest          | 0.0182       |
|    clip_fraction        | 0.0878       |
|    clip_range           | 0.1          |
|    crash                | 0.227        |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.0125       |
|    learning_rate        | 5e-05        |
|    loss                 | 20           |
|    max_step             | 0            |
|    n_updates            | 840          |
|    out_of_road          | 0.982        |
|    policy_gradient_loss | -0.00324     |
|    route_completion     | 0.29         |
|    std                  | 0.808        |
|    total_cost           | 9.2          |
|    value_loss           | 56.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 237      |
|    ep_rew_mean     | 110      |
| time/              |          |
|    fps             | 475      |
|    iterations      | 43       |
|    time_elapsed    | 463      |
|    total_timesteps | 220160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 245          |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 478          |
|    iterations           | 44           |
|    time_elapsed         | 470          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0011687981 |
|    clip_fraction        | 0.0643       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.012        |
|    learning_rate        | 5e-05        |
|    loss                 | 33.1         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00301     |
|    std                  | 0.81         |
|    value_loss           | 57.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0087       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 182          |
|    mean_reward          | 202          |
|    num_episodes         | 5            |
|    out_of_road          | 0.991        |
|    raw_action           | 0.40994123   |
|    route_completion     | 0.276        |
|    success_rate         | 0            |
|    total_cost           | 7.64         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0013426248 |
|    arrive_dest          | 0.0174       |
|    clip_fraction        | 0.0952       |
|    clip_range           | 0.1          |
|    crash                | 0.217        |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.0575       |
|    learning_rate        | 5e-05        |
|    loss                 | 17.7         |
|    max_step             | 0            |
|    n_updates            | 880          |
|    out_of_road          | 0.983        |
|    policy_gradient_loss | -0.00353     |
|    route_completion     | 0.296        |
|    std                  | 0.808        |
|    total_cost           | 9.25         |
|    value_loss           | 48.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 475      |
|    iterations      | 45       |
|    time_elapsed    | 484      |
|    total_timesteps | 230400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 247          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 480          |
|    iterations           | 46           |
|    time_elapsed         | 490          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0018089854 |
|    clip_fraction        | 0.0834       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.0917       |
|    learning_rate        | 5e-05        |
|    loss                 | 20.8         |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00229     |
|    std                  | 0.802        |
|    value_loss           | 36.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00833      |
|    crash                | 0.233        |
|    max_step             | 0            |
|    mean_ep_length       | 93.2         |
|    mean_reward          | 76.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.992        |
|    raw_action           | 0.41645822   |
|    route_completion     | 0.279        |
|    success_rate         | 0            |
|    total_cost           | 7.88         |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0011592986 |
|    arrive_dest          | 0.0167       |
|    clip_fraction        | 0.0567       |
|    clip_range           | 0.1          |
|    crash                | 0.217        |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.0409       |
|    learning_rate        | 5e-05        |
|    loss                 | 10.9         |
|    max_step             | 0            |
|    n_updates            | 920          |
|    out_of_road          | 0.983        |
|    policy_gradient_loss | -0.00144     |
|    route_completion     | 0.301        |
|    std                  | 0.8          |
|    total_cost           | 11.1         |
|    value_loss           | 32.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 267      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 475      |
|    iterations      | 47       |
|    time_elapsed    | 506      |
|    total_timesteps | 240640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 260          |
|    ep_rew_mean          | 127          |
| time/                   |              |
|    fps                  | 478          |
|    iterations           | 48           |
|    time_elapsed         | 513          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0012225526 |
|    clip_fraction        | 0.0612       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.39        |
|    explained_variance   | -0.00447     |
|    learning_rate        | 5e-05        |
|    loss                 | 19.5         |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.00177     |
|    std                  | 0.797        |
|    value_loss           | 58.1         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.008        |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 84.6         |
|    mean_reward          | 90.9         |
|    num_episodes         | 5            |
|    out_of_road          | 0.992        |
|    raw_action           | 0.4201647    |
|    route_completion     | 0.279        |
|    success_rate         | 0.2          |
|    total_cost           | 7.62         |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0022496749 |
|    arrive_dest          | 0.032        |
|    clip_fraction        | 0.0783       |
|    clip_range           | 0.1          |
|    crash                | 0.216        |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.00756      |
|    learning_rate        | 5e-05        |
|    loss                 | 20.7         |
|    max_step             | 0            |
|    n_updates            | 960          |
|    out_of_road          | 0.968        |
|    policy_gradient_loss | -0.00325     |
|    route_completion     | 0.314        |
|    std                  | 0.794        |
|    total_cost           | 10.9         |
|    value_loss           | 55.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 139      |
| time/              |          |
|    fps             | 479      |
|    iterations      | 49       |
|    time_elapsed    | 523      |
|    total_timesteps | 250880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 299          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 483          |
|    iterations           | 50           |
|    time_elapsed         | 529          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0017938117 |
|    clip_fraction        | 0.0946       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.0277       |
|    learning_rate        | 5e-05        |
|    loss                 | 12.3         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00174     |
|    std                  | 0.79         |
|    value_loss           | 37.5         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.00769     |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 125         |
|    mean_reward          | 103         |
|    num_episodes         | 5           |
|    out_of_road          | 0.992       |
|    raw_action           | 0.42385903  |
|    route_completion     | 0.282       |
|    success_rate         | 0.1         |
|    total_cost           | 8.02        |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.001229092 |
|    arrive_dest          | 0.0385      |
|    clip_fraction        | 0.0664      |
|    clip_range           | 0.1         |
|    crash                | 0.215       |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.119       |
|    learning_rate        | 5e-05       |
|    loss                 | 12.1        |
|    max_step             | 0           |
|    n_updates            | 1000        |
|    out_of_road          | 0.962       |
|    policy_gradient_loss | -0.0021     |
|    route_completion     | 0.324       |
|    std                  | 0.786       |
|    total_cost           | 11.2        |
|    value_loss           | 42          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 156      |
| time/              |          |
|    fps             | 480      |
|    iterations      | 51       |
|    time_elapsed    | 543      |
|    total_timesteps | 261120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 325          |
|    ep_rew_mean          | 162          |
| time/                   |              |
|    fps                  | 484          |
|    iterations           | 52           |
|    time_elapsed         | 550          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0021815079 |
|    clip_fraction        | 0.0964       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.0471       |
|    learning_rate        | 5e-05        |
|    loss                 | 38.8         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00206     |
|    std                  | 0.784        |
|    value_loss           | 66.3         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.00741      |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 142          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.993        |
|    raw_action           | 0.42780548   |
|    route_completion     | 0.289        |
|    success_rate         | 0            |
|    total_cost           | 8.5          |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0017352799 |
|    arrive_dest          | 0.037        |
|    clip_fraction        | 0.0885       |
|    clip_range           | 0.1          |
|    crash                | 0.222        |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.114        |
|    learning_rate        | 5e-05        |
|    loss                 | 27.5         |
|    max_step             | 0            |
|    n_updates            | 1040         |
|    out_of_road          | 0.963        |
|    policy_gradient_loss | -0.00362     |
|    route_completion     | 0.327        |
|    std                  | 0.782        |
|    total_cost           | 11.6         |
|    value_loss           | 50.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 181      |
| time/              |          |
|    fps             | 480      |
|    iterations      | 53       |
|    time_elapsed    | 565      |
|    total_timesteps | 271360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 352          |
|    ep_rew_mean          | 182          |
| time/                   |              |
|    fps                  | 484          |
|    iterations           | 54           |
|    time_elapsed         | 570          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0027948485 |
|    clip_fraction        | 0.0733       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.0558       |
|    learning_rate        | 5e-05        |
|    loss                 | 43.9         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.78         |
|    value_loss           | 74.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0143       |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 167          |
|    mean_reward          | 152          |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.43001828   |
|    route_completion     | 0.297        |
|    success_rate         | 0.1          |
|    total_cost           | 9.29         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0016082019 |
|    arrive_dest          | 0.0357       |
|    clip_fraction        | 0.074        |
|    clip_range           | 0.1          |
|    crash                | 0.221        |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.142        |
|    learning_rate        | 5e-05        |
|    loss                 | 22           |
|    max_step             | 0            |
|    n_updates            | 1080         |
|    out_of_road          | 0.964        |
|    policy_gradient_loss | -0.00178     |
|    route_completion     | 0.329        |
|    std                  | 0.778        |
|    total_cost           | 12           |
|    value_loss           | 50           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 192      |
| time/              |          |
|    fps             | 481      |
|    iterations      | 55       |
|    time_elapsed    | 585      |
|    total_timesteps | 281600   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 186          |
| time/                   |              |
|    fps                  | 484          |
|    iterations           | 56           |
|    time_elapsed         | 591          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0019272275 |
|    clip_fraction        | 0.0589       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.0277       |
|    learning_rate        | 5e-05        |
|    loss                 | 37.8         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00209     |
|    std                  | 0.78         |
|    value_loss           | 88           |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0138       |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 103          |
|    mean_reward          | 130          |
|    num_episodes         | 5            |
|    out_of_road          | 0.986        |
|    raw_action           | 0.4321608    |
|    route_completion     | 0.3          |
|    success_rate         | 0            |
|    total_cost           | 9.03         |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0015217708 |
|    arrive_dest          | 0.0345       |
|    clip_fraction        | 0.057        |
|    clip_range           | 0.1          |
|    crash                | 0.221        |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.132        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.9         |
|    max_step             | 0            |
|    n_updates            | 1120         |
|    out_of_road          | 0.966        |
|    policy_gradient_loss | -0.00169     |
|    route_completion     | 0.332        |
|    std                  | 0.778        |
|    total_cost           | 15.7         |
|    value_loss           | 72           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 189      |
| time/              |          |
|    fps             | 474      |
|    iterations      | 57       |
|    time_elapsed    | 615      |
|    total_timesteps | 291840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 196          |
| time/                   |              |
|    fps                  | 477          |
|    iterations           | 58           |
|    time_elapsed         | 621          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0024681627 |
|    clip_fraction        | 0.0941       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.0846       |
|    learning_rate        | 5e-05        |
|    loss                 | 42.9         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.0004      |
|    std                  | 0.779        |
|    value_loss           | 74.7         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0133      |
|    crash                | 0.247       |
|    max_step             | 0           |
|    mean_ep_length       | 113         |
|    mean_reward          | 142         |
|    num_episodes         | 5           |
|    out_of_road          | 0.987       |
|    raw_action           | 0.43452412  |
|    route_completion     | 0.303       |
|    success_rate         | 0.1         |
|    total_cost           | 8.87        |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.001639468 |
|    arrive_dest          | 0.04        |
|    clip_fraction        | 0.0738      |
|    clip_range           | 0.1         |
|    crash                | 0.22        |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.163       |
|    learning_rate        | 5e-05       |
|    loss                 | 26.2        |
|    max_step             | 0           |
|    n_updates            | 1160        |
|    out_of_road          | 0.96        |
|    policy_gradient_loss | -0.00162    |
|    route_completion     | 0.336       |
|    std                  | 0.777       |
|    total_cost           | 15.9        |
|    value_loss           | 58.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 196      |
| time/              |          |
|    fps             | 475      |
|    iterations      | 59       |
|    time_elapsed    | 635      |
|    total_timesteps | 302080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 211          |
| time/                   |              |
|    fps                  | 478          |
|    iterations           | 60           |
|    time_elapsed         | 641          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0023291758 |
|    clip_fraction        | 0.0698       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.212        |
|    learning_rate        | 5e-05        |
|    loss                 | 37.4         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.777        |
|    value_loss           | 90.8         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0129       |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 125          |
|    mean_reward          | 132          |
|    num_episodes         | 5            |
|    out_of_road          | 0.987        |
|    raw_action           | 0.43385798   |
|    route_completion     | 0.309        |
|    success_rate         | 0            |
|    total_cost           | 8.98         |
| time/                   |              |
|    total_timesteps      | 310000       |
| train/                  |              |
|    approx_kl            | 0.0014696575 |
|    arrive_dest          | 0.0387       |
|    clip_fraction        | 0.0686       |
|    clip_range           | 0.1          |
|    crash                | 0.226        |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.092        |
|    learning_rate        | 5e-05        |
|    loss                 | 24.5         |
|    max_step             | 0            |
|    n_updates            | 1200         |
|    out_of_road          | 0.961        |
|    policy_gradient_loss | -0.00121     |
|    route_completion     | 0.34         |
|    std                  | 0.775        |
|    total_cost           | 15.9         |
|    value_loss           | 67.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    fps             | 478      |
|    iterations      | 61       |
|    time_elapsed    | 653      |
|    total_timesteps | 312320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 345          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 481          |
|    iterations           | 62           |
|    time_elapsed         | 659          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0016063051 |
|    clip_fraction        | 0.0883       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.0228       |
|    learning_rate        | 5e-05        |
|    loss                 | 33.9         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.769        |
|    value_loss           | 75.4         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0125       |
|    crash                | 0.269        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 95.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.4330269    |
|    route_completion     | 0.31         |
|    success_rate         | 0            |
|    total_cost           | 9.68         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0017575258 |
|    arrive_dest          | 0.0375       |
|    clip_fraction        | 0.0815       |
|    clip_range           | 0.1          |
|    crash                | 0.231        |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.116        |
|    learning_rate        | 5e-05        |
|    loss                 | 21.3         |
|    max_step             | 0            |
|    n_updates            | 1240         |
|    out_of_road          | 0.963        |
|    policy_gradient_loss | -0.000556    |
|    route_completion     | 0.344        |
|    std                  | 0.766        |
|    total_cost           | 16.1         |
|    value_loss           | 81.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 331      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 478      |
|    iterations      | 63       |
|    time_elapsed    | 674      |
|    total_timesteps | 322560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 213          |
| time/                   |              |
|    fps                  | 481          |
|    iterations           | 64           |
|    time_elapsed         | 680          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0008427079 |
|    clip_fraction        | 0.0498       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.431        |
|    learning_rate        | 5e-05        |
|    loss                 | 22.9         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00156     |
|    std                  | 0.765        |
|    value_loss           | 72.9         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0121       |
|    crash                | 0.267        |
|    max_step             | 0            |
|    mean_ep_length       | 187          |
|    mean_reward          | 152          |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.43652445   |
|    route_completion     | 0.317        |
|    success_rate         | 0.1          |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 330000       |
| train/                  |              |
|    approx_kl            | 0.0026578598 |
|    arrive_dest          | 0.0424       |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    crash                | 0.23         |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0185      |
|    learning_rate        | 5e-05        |
|    loss                 | 38.6         |
|    max_step             | 0            |
|    n_updates            | 1280         |
|    out_of_road          | 0.958        |
|    policy_gradient_loss | 0.000346     |
|    route_completion     | 0.355        |
|    std                  | 0.759        |
|    total_cost           | 16.7         |
|    value_loss           | 80.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 477      |
|    iterations      | 65       |
|    time_elapsed    | 697      |
|    total_timesteps | 332800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 480          |
|    iterations           | 66           |
|    time_elapsed         | 703          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0013987725 |
|    clip_fraction        | 0.0484       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.00787      |
|    learning_rate        | 5e-05        |
|    loss                 | 37.8         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00217     |
|    std                  | 0.76         |
|    value_loss           | 106          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0118       |
|    crash                | 0.276        |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 0.988        |
|    raw_action           | 0.43830362   |
|    route_completion     | 0.32         |
|    success_rate         | 0            |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0010616358 |
|    arrive_dest          | 0.0412       |
|    clip_fraction        | 0.0377       |
|    clip_range           | 0.1          |
|    crash                | 0.235        |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.0959       |
|    learning_rate        | 5e-05        |
|    loss                 | 60.3         |
|    max_step             | 0            |
|    n_updates            | 1320         |
|    out_of_road          | 0.959        |
|    policy_gradient_loss | -0.00256     |
|    route_completion     | 0.359        |
|    std                  | 0.759        |
|    total_cost           | 16.8         |
|    value_loss           | 90.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 478      |
|    iterations      | 67       |
|    time_elapsed    | 716      |
|    total_timesteps | 343040   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 482          |
|    iterations           | 68           |
|    time_elapsed         | 722          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0017304482 |
|    clip_fraction        | 0.0628       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.0595       |
|    learning_rate        | 5e-05        |
|    loss                 | 59.5         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00188     |
|    std                  | 0.758        |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0114       |
|    crash                | 0.28         |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 91.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.989        |
|    raw_action           | 0.4391048    |
|    route_completion     | 0.321        |
|    success_rate         | 0            |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0008809286 |
|    arrive_dest          | 0.04         |
|    clip_fraction        | 0.0428       |
|    clip_range           | 0.1          |
|    crash                | 0.24         |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.248        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.9         |
|    max_step             | 0            |
|    n_updates            | 1360         |
|    out_of_road          | 0.96         |
|    policy_gradient_loss | -0.000981    |
|    route_completion     | 0.362        |
|    std                  | 0.756        |
|    total_cost           | 16.5         |
|    value_loss           | 76.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 211      |
| time/              |          |
|    fps             | 480      |
|    iterations      | 69       |
|    time_elapsed    | 735      |
|    total_timesteps | 353280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 324          |
|    ep_rew_mean          | 214          |
| time/                   |              |
|    fps                  | 483          |
|    iterations           | 70           |
|    time_elapsed         | 741          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0026414716 |
|    clip_fraction        | 0.062        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.237        |
|    learning_rate        | 5e-05        |
|    loss                 | 44.2         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00294     |
|    std                  | 0.754        |
|    value_loss           | 117          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0222      |
|    crash                | 0.272       |
|    max_step             | 0           |
|    mean_ep_length       | 143         |
|    mean_reward          | 181         |
|    num_episodes         | 5           |
|    out_of_road          | 0.978       |
|    raw_action           | 0.44149807  |
|    route_completion     | 0.327       |
|    success_rate         | 0.3         |
|    total_cost           | 10.9        |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.002853269 |
|    arrive_dest          | 0.0444      |
|    clip_fraction        | 0.0615      |
|    clip_range           | 0.1         |
|    crash                | 0.239       |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.0846      |
|    learning_rate        | 5e-05       |
|    loss                 | 85.2        |
|    max_step             | 0           |
|    n_updates            | 1400        |
|    out_of_road          | 0.956       |
|    policy_gradient_loss | -0.00208    |
|    route_completion     | 0.372       |
|    std                  | 0.751       |
|    total_cost           | 17.2        |
|    value_loss           | 112         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 482      |
|    iterations      | 71       |
|    time_elapsed    | 753      |
|    total_timesteps | 363520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 311          |
|    ep_rew_mean          | 206          |
| time/                   |              |
|    fps                  | 484          |
|    iterations           | 72           |
|    time_elapsed         | 760          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0013101245 |
|    clip_fraction        | 0.0919       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.109        |
|    learning_rate        | 5e-05        |
|    loss                 | 52           |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00152     |
|    std                  | 0.75         |
|    value_loss           | 106          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0216       |
|    crash                | 0.281        |
|    max_step             | 0            |
|    mean_ep_length       | 99.2         |
|    mean_reward          | 112          |
|    num_episodes         | 5            |
|    out_of_road          | 0.978        |
|    raw_action           | 0.44239658   |
|    route_completion     | 0.329        |
|    success_rate         | 0            |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 370000       |
| train/                  |              |
|    approx_kl            | 0.0028394398 |
|    arrive_dest          | 0.0432       |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.254        |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.058        |
|    learning_rate        | 5e-05        |
|    loss                 | 44.2         |
|    max_step             | 0            |
|    n_updates            | 1440         |
|    out_of_road          | 0.957        |
|    policy_gradient_loss | 0.000557     |
|    route_completion     | 0.373        |
|    std                  | 0.749        |
|    total_cost           | 17           |
|    value_loss           | 98.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    fps             | 484      |
|    iterations      | 73       |
|    time_elapsed    | 771      |
|    total_timesteps | 373760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 313          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 487          |
|    iterations           | 74           |
|    time_elapsed         | 777          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0018204565 |
|    clip_fraction        | 0.0927       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.414        |
|    learning_rate        | 5e-05        |
|    loss                 | 38.3         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00157     |
|    std                  | 0.745        |
|    value_loss           | 85.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0211       |
|    crash                | 0.274        |
|    max_step             | 0            |
|    mean_ep_length       | 99.6         |
|    mean_reward          | 100          |
|    num_episodes         | 5            |
|    out_of_road          | 0.979        |
|    raw_action           | 0.4451454    |
|    route_completion     | 0.33         |
|    success_rate         | 0.2          |
|    total_cost           | 10.6         |
| time/                   |              |
|    total_timesteps      | 380000       |
| train/                  |              |
|    approx_kl            | 0.0015800595 |
|    arrive_dest          | 0.0526       |
|    clip_fraction        | 0.0495       |
|    clip_range           | 0.1          |
|    crash                | 0.253        |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.518        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.6         |
|    max_step             | 0            |
|    n_updates            | 1480         |
|    out_of_road          | 0.947        |
|    policy_gradient_loss | -0.0016      |
|    route_completion     | 0.381        |
|    std                  | 0.744        |
|    total_cost           | 18.4         |
|    value_loss           | 102          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 304      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 483      |
|    iterations      | 75       |
|    time_elapsed    | 793      |
|    total_timesteps | 384000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 331          |
|    ep_rew_mean          | 221          |
| time/                   |              |
|    fps                  | 486          |
|    iterations           | 76           |
|    time_elapsed         | 800          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0014648093 |
|    clip_fraction        | 0.0725       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.141        |
|    learning_rate        | 5e-05        |
|    loss                 | 26.9         |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00215     |
|    std                  | 0.744        |
|    value_loss           | 98           |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0205      |
|    crash                | 0.272       |
|    max_step             | 0           |
|    mean_ep_length       | 84.6        |
|    mean_reward          | 93.6        |
|    num_episodes         | 5           |
|    out_of_road          | 0.979       |
|    raw_action           | 0.44848722  |
|    route_completion     | 0.329       |
|    success_rate         | 0.1         |
|    total_cost           | 10.3        |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.005065006 |
|    arrive_dest          | 0.0564      |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.1         |
|    crash                | 0.251       |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.0579      |
|    learning_rate        | 5e-05       |
|    loss                 | 53.4        |
|    max_step             | 0           |
|    n_updates            | 1520        |
|    out_of_road          | 0.944       |
|    policy_gradient_loss | 0.000669    |
|    route_completion     | 0.388       |
|    std                  | 0.742       |
|    total_cost           | 18.6        |
|    value_loss           | 113         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 484      |
|    iterations      | 77       |
|    time_elapsed    | 813      |
|    total_timesteps | 394240   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 326           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 487           |
|    iterations           | 78            |
|    time_elapsed         | 819           |
|    total_timesteps      | 399360        |
| train/                  |               |
|    approx_kl            | 0.00089011656 |
|    clip_fraction        | 0.111         |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.23         |
|    explained_variance   | 0.0369        |
|    learning_rate        | 5e-05         |
|    loss                 | 89.6          |
|    n_updates            | 1540          |
|    policy_gradient_loss | -0.000788     |
|    std                  | 0.739         |
|    value_loss           | 145           |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.025        |
|    crash                | 0.275        |
|    max_step             | 0            |
|    mean_ep_length       | 206          |
|    mean_reward          | 198          |
|    num_episodes         | 5            |
|    out_of_road          | 0.975        |
|    raw_action           | 0.44990423   |
|    route_completion     | 0.338        |
|    success_rate         | 0.1          |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0014703608 |
|    arrive_dest          | 0.055        |
|    clip_fraction        | 0.0775       |
|    clip_range           | 0.1          |
|    crash                | 0.255        |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.199        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.4         |
|    max_step             | 0            |
|    n_updates            | 1560         |
|    out_of_road          | 0.945        |
|    policy_gradient_loss | -0.00169     |
|    route_completion     | 0.383        |
|    std                  | 0.74         |
|    total_cost           | 18.2         |
|    value_loss           | 111          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 320      |
|    ep_rew_mean     | 218      |
| time/              |          |
|    fps             | 487      |
|    iterations      | 79       |
|    time_elapsed    | 830      |
|    total_timesteps | 404480   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 349        |
|    ep_rew_mean          | 238        |
| time/                   |            |
|    fps                  | 489        |
|    iterations           | 80         |
|    time_elapsed         | 836        |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.00270645 |
|    clip_fraction        | 0.1        |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.23      |
|    explained_variance   | 0.14       |
|    learning_rate        | 5e-05      |
|    loss                 | 50.5       |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.0025    |
|    std                  | 0.736      |
|    value_loss           | 106        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0244       |
|    crash                | 0.268        |
|    max_step             | 0            |
|    mean_ep_length       | 68.6         |
|    mean_reward          | 61.3         |
|    num_episodes         | 5            |
|    out_of_road          | 0.976        |
|    raw_action           | 0.4509006    |
|    route_completion     | 0.334        |
|    success_rate         | 0            |
|    total_cost           | 10.8         |
| time/                   |              |
|    total_timesteps      | 410000       |
| train/                  |              |
|    approx_kl            | 0.0013409315 |
|    arrive_dest          | 0.0537       |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.254        |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.00482      |
|    learning_rate        | 5e-05        |
|    loss                 | 67.9         |
|    max_step             | 0            |
|    n_updates            | 1600         |
|    out_of_road          | 0.946        |
|    policy_gradient_loss | -0.00054     |
|    route_completion     | 0.385        |
|    std                  | 0.735        |
|    total_cost           | 17.8         |
|    value_loss           | 124          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 235      |
| time/              |          |
|    fps             | 489      |
|    iterations      | 81       |
|    time_elapsed    | 846      |
|    total_timesteps | 414720   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 354          |
|    ep_rew_mean          | 246          |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 82           |
|    time_elapsed         | 852          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0013116172 |
|    clip_fraction        | 0.0672       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.0211       |
|    learning_rate        | 5e-05        |
|    loss                 | 68.4         |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.00118     |
|    std                  | 0.734        |
|    value_loss           | 137          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0286       |
|    crash                | 0.271        |
|    max_step             | 0            |
|    mean_ep_length       | 164          |
|    mean_reward          | 245          |
|    num_episodes         | 5            |
|    out_of_road          | 0.971        |
|    raw_action           | 0.4536891    |
|    route_completion     | 0.342        |
|    success_rate         | 0.4          |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 420000       |
| train/                  |              |
|    approx_kl            | 0.0037209927 |
|    arrive_dest          | 0.0667       |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    crash                | 0.252        |
|    entropy_loss         | -2.21        |
|    explained_variance   | -0.0153      |
|    learning_rate        | 5e-05        |
|    loss                 | 43.5         |
|    max_step             | 0            |
|    n_updates            | 1640         |
|    out_of_road          | 0.933        |
|    policy_gradient_loss | -0.00125     |
|    route_completion     | 0.395        |
|    std                  | 0.73         |
|    total_cost           | 18.5         |
|    value_loss           | 91.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 241      |
| time/              |          |
|    fps             | 488      |
|    iterations      | 83       |
|    time_elapsed    | 869      |
|    total_timesteps | 424960   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0279       |
|    crash                | 0.265        |
|    max_step             | 0            |
|    mean_ep_length       | 85           |
|    mean_reward          | 92.4         |
|    num_episodes         | 5            |
|    out_of_road          | 0.972        |
|    raw_action           | 0.4545839    |
|    route_completion     | 0.341        |
|    success_rate         | 0            |
|    total_cost           | 10.4         |
| time/                   |              |
|    total_timesteps      | 430000       |
| train/                  |              |
|    approx_kl            | 0.0027207728 |
|    arrive_dest          | 0.0651       |
|    clip_fraction        | 0.0765       |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.217        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.1         |
|    max_step             | 0            |
|    n_updates            | 1660         |
|    out_of_road          | 0.935        |
|    policy_gradient_loss | -0.00137     |
|    route_completion     | 0.396        |
|    std                  | 0.73         |
|    total_cost           | 18.8         |
|    value_loss           | 128          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 367      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 488      |
|    iterations      | 84       |
|    time_elapsed    | 880      |
|    total_timesteps | 430080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 356          |
|    ep_rew_mean          | 251          |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 85           |
|    time_elapsed         | 887          |
|    total_timesteps      | 435200       |
| train/                  |              |
|    approx_kl            | 0.0008331477 |
|    clip_fraction        | 0.0518       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.183        |
|    learning_rate        | 5e-05        |
|    loss                 | 73.8         |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.00139     |
|    std                  | 0.728        |
|    value_loss           | 137          |
------------------------------------------
-------------------------------------------
| eval/                   |               |
|    arrive_dest          | 0.0273        |
|    crash                | 0.264         |
|    max_step             | 0             |
|    mean_ep_length       | 99.2          |
|    mean_reward          | 108           |
|    num_episodes         | 5             |
|    out_of_road          | 0.973         |
|    raw_action           | 0.4553844     |
|    route_completion     | 0.341         |
|    success_rate         | 0.1           |
|    total_cost           | 10.3          |
| time/                   |               |
|    total_timesteps      | 440000        |
| train/                  |               |
|    approx_kl            | 0.00062579603 |
|    arrive_dest          | 0.0682        |
|    clip_fraction        | 0.0605        |
|    clip_range           | 0.1           |
|    crash                | 0.259         |
|    entropy_loss         | -2.2          |
|    explained_variance   | 0.165         |
|    learning_rate        | 5e-05         |
|    loss                 | 60            |
|    max_step             | 0             |
|    n_updates            | 1700          |
|    out_of_road          | 0.932         |
|    policy_gradient_loss | -0.000634     |
|    route_completion     | 0.399         |
|    std                  | 0.727         |
|    total_cost           | 18.7          |
|    value_loss           | 143           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    fps             | 488      |
|    iterations      | 86       |
|    time_elapsed    | 901      |
|    total_timesteps | 440320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 359          |
|    ep_rew_mean          | 257          |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 87           |
|    time_elapsed         | 908          |
|    total_timesteps      | 445440       |
| train/                  |              |
|    approx_kl            | 0.0019800195 |
|    clip_fraction        | 0.0423       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.0667       |
|    learning_rate        | 5e-05        |
|    loss                 | 86.8         |
|    n_updates            | 1720         |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.726        |
|    value_loss           | 161          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0311       |
|    crash                | 0.258        |
|    max_step             | 0            |
|    mean_ep_length       | 178          |
|    mean_reward          | 181          |
|    num_episodes         | 5            |
|    out_of_road          | 0.969        |
|    raw_action           | 0.45556185   |
|    route_completion     | 0.347        |
|    success_rate         | 0.2          |
|    total_cost           | 10.7         |
| time/                   |              |
|    total_timesteps      | 450000       |
| train/                  |              |
|    approx_kl            | 0.0007880454 |
|    arrive_dest          | 0.0711       |
|    clip_fraction        | 0.0653       |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.291        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.7         |
|    max_step             | 0            |
|    n_updates            | 1740         |
|    out_of_road          | 0.929        |
|    policy_gradient_loss | -0.00203     |
|    route_completion     | 0.402        |
|    std                  | 0.726        |
|    total_cost           | 18.4         |
|    value_loss           | 130          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 249      |
| time/              |          |
|    fps             | 489      |
|    iterations      | 88       |
|    time_elapsed    | 919      |
|    total_timesteps | 450560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 256          |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 89           |
|    time_elapsed         | 925          |
|    total_timesteps      | 455680       |
| train/                  |              |
|    approx_kl            | 0.0010511301 |
|    clip_fraction        | 0.0712       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.387        |
|    learning_rate        | 5e-05        |
|    loss                 | 39.6         |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00151     |
|    std                  | 0.725        |
|    value_loss           | 136          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0304       |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 139          |
|    mean_reward          | 111          |
|    num_episodes         | 5            |
|    out_of_road          | 0.97         |
|    raw_action           | 0.4560924    |
|    route_completion     | 0.348        |
|    success_rate         | 0            |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 460000       |
| train/                  |              |
|    approx_kl            | 0.0014513785 |
|    arrive_dest          | 0.0696       |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    crash                | 0.261        |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.153        |
|    learning_rate        | 5e-05        |
|    loss                 | 47           |
|    max_step             | 0            |
|    n_updates            | 1780         |
|    out_of_road          | 0.93         |
|    policy_gradient_loss | 0.000306     |
|    route_completion     | 0.403        |
|    std                  | 0.723        |
|    total_cost           | 18.1         |
|    value_loss           | 92.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    fps             | 490      |
|    iterations      | 90       |
|    time_elapsed    | 939      |
|    total_timesteps | 460800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 367          |
|    ep_rew_mean          | 273          |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 91           |
|    time_elapsed         | 945          |
|    total_timesteps      | 465920       |
| train/                  |              |
|    approx_kl            | 0.0025785388 |
|    clip_fraction        | 0.0517       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.0828       |
|    learning_rate        | 5e-05        |
|    loss                 | 89.5         |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.00152     |
|    std                  | 0.723        |
|    value_loss           | 170          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0298       |
|    crash                | 0.251        |
|    max_step             | 0            |
|    mean_ep_length       | 96.2         |
|    mean_reward          | 115          |
|    num_episodes         | 5            |
|    out_of_road          | 0.97         |
|    raw_action           | 0.45602396   |
|    route_completion     | 0.348        |
|    success_rate         | 0.1          |
|    total_cost           | 10.8         |
| time/                   |              |
|    total_timesteps      | 470000       |
| train/                  |              |
|    approx_kl            | 0.0029273843 |
|    arrive_dest          | 0.0723       |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.251        |
|    learning_rate        | 5e-05        |
|    loss                 | 32.2         |
|    max_step             | 0            |
|    n_updates            | 1820         |
|    out_of_road          | 0.928        |
|    policy_gradient_loss | -0.000733    |
|    route_completion     | 0.408        |
|    std                  | 0.722        |
|    total_cost           | 18.1         |
|    value_loss           | 117          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 492      |
|    iterations      | 92       |
|    time_elapsed    | 957      |
|    total_timesteps | 471040   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 363           |
|    ep_rew_mean          | 278           |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 93            |
|    time_elapsed         | 964           |
|    total_timesteps      | 476160        |
| train/                  |               |
|    approx_kl            | 0.00065542536 |
|    clip_fraction        | 0.08          |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.18         |
|    explained_variance   | 0.191         |
|    learning_rate        | 5e-05         |
|    loss                 | 50.3          |
|    n_updates            | 1840          |
|    policy_gradient_loss | -0.000776     |
|    std                  | 0.721         |
|    value_loss           | 133           |
-------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0333      |
|    crash                | 0.25        |
|    max_step             | 0           |
|    mean_ep_length       | 167         |
|    mean_reward          | 147         |
|    num_episodes         | 5           |
|    out_of_road          | 0.967       |
|    raw_action           | 0.4563325   |
|    route_completion     | 0.353       |
|    success_rate         | 0.2         |
|    total_cost           | 11.3        |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.003560417 |
|    arrive_dest          | 0.075       |
|    clip_fraction        | 0.0705      |
|    clip_range           | 0.1         |
|    crash                | 0.263       |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.234       |
|    learning_rate        | 5e-05       |
|    loss                 | 41.9        |
|    max_step             | 0           |
|    n_updates            | 1860        |
|    out_of_road          | 0.925       |
|    policy_gradient_loss | -0.000813   |
|    route_completion     | 0.413       |
|    std                  | 0.721       |
|    total_cost           | 17.9        |
|    value_loss           | 132         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 492      |
|    iterations      | 94       |
|    time_elapsed    | 978      |
|    total_timesteps | 481280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 373          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 95           |
|    time_elapsed         | 985          |
|    total_timesteps      | 486400       |
| train/                  |              |
|    approx_kl            | 0.0044732685 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.358        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.1         |
|    n_updates            | 1880         |
|    policy_gradient_loss | -0.00115     |
|    std                  | 0.721        |
|    value_loss           | 148          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0408       |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 199          |
|    mean_reward          | 179          |
|    num_episodes         | 5            |
|    out_of_road          | 0.959        |
|    raw_action           | 0.45661294   |
|    route_completion     | 0.36         |
|    success_rate         | 0.3          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 490000       |
| train/                  |              |
|    approx_kl            | 0.0011850777 |
|    arrive_dest          | 0.0776       |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    crash                | 0.257        |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.357        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.7         |
|    max_step             | 0            |
|    n_updates            | 1900         |
|    out_of_road          | 0.922        |
|    policy_gradient_loss | -0.000818    |
|    route_completion     | 0.413        |
|    std                  | 0.719        |
|    total_cost           | 17.6         |
|    value_loss           | 130          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 493      |
|    iterations      | 96       |
|    time_elapsed    | 996      |
|    total_timesteps | 491520   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 97           |
|    time_elapsed         | 1002         |
|    total_timesteps      | 496640       |
| train/                  |              |
|    approx_kl            | 0.0010982832 |
|    clip_fraction        | 0.0809       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.229        |
|    learning_rate        | 5e-05        |
|    loss                 | 71.3         |
|    n_updates            | 1920         |
|    policy_gradient_loss | -0.00146     |
|    std                  | 0.719        |
|    value_loss           | 174          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.044        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 130          |
|    num_episodes         | 5            |
|    out_of_road          | 0.956        |
|    raw_action           | 0.4575455    |
|    route_completion     | 0.361        |
|    success_rate         | 0.3          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 500000       |
| train/                  |              |
|    approx_kl            | 0.0035373576 |
|    arrive_dest          | 0.084        |
|    clip_fraction        | 0.0912       |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.361        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.1         |
|    max_step             | 0            |
|    n_updates            | 1940         |
|    out_of_road          | 0.916        |
|    policy_gradient_loss | -0.00183     |
|    route_completion     | 0.42         |
|    std                  | 0.717        |
|    total_cost           | 17.8         |
|    value_loss           | 170          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 493      |
|    iterations      | 98       |
|    time_elapsed    | 1016     |
|    total_timesteps | 501760   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 347          |
|    ep_rew_mean          | 267          |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 99           |
|    time_elapsed         | 1024         |
|    total_timesteps      | 506880       |
| train/                  |              |
|    approx_kl            | 0.0031584874 |
|    clip_fraction        | 0.164        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.258        |
|    learning_rate        | 5e-05        |
|    loss                 | 104          |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.000117    |
|    std                  | 0.715        |
|    value_loss           | 168          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0431       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 130          |
|    mean_reward          | 175          |
|    num_episodes         | 5            |
|    out_of_road          | 0.957        |
|    raw_action           | 0.45897618   |
|    route_completion     | 0.365        |
|    success_rate         | 0.2          |
|    total_cost           | 11.5         |
| time/                   |              |
|    total_timesteps      | 510000       |
| train/                  |              |
|    approx_kl            | 0.0052654236 |
|    arrive_dest          | 0.0902       |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.181        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.3         |
|    max_step             | 0            |
|    n_updates            | 1980         |
|    out_of_road          | 0.91         |
|    policy_gradient_loss | 0.00188      |
|    route_completion     | 0.427        |
|    std                  | 0.714        |
|    total_cost           | 18.2         |
|    value_loss           | 145          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 268      |
| time/              |          |
|    fps             | 493      |
|    iterations      | 100      |
|    time_elapsed    | 1037     |
|    total_timesteps | 512000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 351          |
|    ep_rew_mean          | 271          |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 101          |
|    time_elapsed         | 1044         |
|    total_timesteps      | 517120       |
| train/                  |              |
|    approx_kl            | 0.0026633302 |
|    clip_fraction        | 0.0984       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.315        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.3         |
|    n_updates            | 2000         |
|    policy_gradient_loss | -0.00238     |
|    std                  | 0.712        |
|    value_loss           | 146          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0423       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 110          |
|    mean_reward          | 109          |
|    num_episodes         | 5            |
|    out_of_road          | 0.958        |
|    raw_action           | 0.4602681    |
|    route_completion     | 0.364        |
|    success_rate         | 0.1          |
|    total_cost           | 11.5         |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0021819384 |
|    arrive_dest          | 0.0923       |
|    clip_fraction        | 0.0773       |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.451        |
|    learning_rate        | 5e-05        |
|    loss                 | 46           |
|    max_step             | 0            |
|    n_updates            | 2020         |
|    out_of_road          | 0.908        |
|    policy_gradient_loss | -0.00194     |
|    route_completion     | 0.427        |
|    std                  | 0.711        |
|    total_cost           | 18.8         |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 492      |
|    iterations      | 102      |
|    time_elapsed    | 1059     |
|    total_timesteps | 522240   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 274          |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 103          |
|    time_elapsed         | 1065         |
|    total_timesteps      | 527360       |
| train/                  |              |
|    approx_kl            | 0.0041908175 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.261        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.1         |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.00186     |
|    std                  | 0.709        |
|    value_loss           | 154          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0453       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 177          |
|    mean_reward          | 169          |
|    num_episodes         | 5            |
|    out_of_road          | 0.955        |
|    raw_action           | 0.46139997   |
|    route_completion     | 0.368        |
|    success_rate         | 0.2          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 530000       |
| train/                  |              |
|    approx_kl            | 0.0014326427 |
|    arrive_dest          | 0.0943       |
|    clip_fraction        | 0.0985       |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.576        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.3         |
|    max_step             | 0            |
|    n_updates            | 2060         |
|    out_of_road          | 0.906        |
|    policy_gradient_loss | -0.00123     |
|    route_completion     | 0.426        |
|    std                  | 0.708        |
|    total_cost           | 18.8         |
|    value_loss           | 121          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 493      |
|    iterations      | 104      |
|    time_elapsed    | 1079     |
|    total_timesteps | 532480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 360          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 105          |
|    time_elapsed         | 1085         |
|    total_timesteps      | 537600       |
| train/                  |              |
|    approx_kl            | 0.0016043686 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.37         |
|    learning_rate        | 5e-05        |
|    loss                 | 55.3         |
|    n_updates            | 2080         |
|    policy_gradient_loss | -0.000226    |
|    std                  | 0.707        |
|    value_loss           | 129          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0444       |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 87.2         |
|    mean_reward          | 88.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.956        |
|    raw_action           | 0.46188405   |
|    route_completion     | 0.367        |
|    success_rate         | 0            |
|    total_cost           | 11.5         |
| time/                   |              |
|    total_timesteps      | 540000       |
| train/                  |              |
|    approx_kl            | 0.0017237116 |
|    arrive_dest          | 0.0926       |
|    clip_fraction        | 0.0628       |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.621        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.2         |
|    max_step             | 0            |
|    n_updates            | 2100         |
|    out_of_road          | 0.907        |
|    policy_gradient_loss | -0.00135     |
|    route_completion     | 0.425        |
|    std                  | 0.706        |
|    total_cost           | 18.6         |
|    value_loss           | 91.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 277      |
| time/              |          |
|    fps             | 494      |
|    iterations      | 106      |
|    time_elapsed    | 1097     |
|    total_timesteps | 542720   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 360         |
|    ep_rew_mean          | 284         |
| time/                   |             |
|    fps                  | 496         |
|    iterations           | 107         |
|    time_elapsed         | 1104        |
|    total_timesteps      | 547840      |
| train/                  |             |
|    approx_kl            | 0.002190903 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.386       |
|    learning_rate        | 5e-05       |
|    loss                 | 122         |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.00166    |
|    std                  | 0.705       |
|    value_loss           | 193         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0436      |
|    crash                | 0.244       |
|    max_step             | 0           |
|    mean_ep_length       | 83.4        |
|    mean_reward          | 90.5        |
|    num_episodes         | 5           |
|    out_of_road          | 0.956       |
|    raw_action           | 0.4630348   |
|    route_completion     | 0.366       |
|    success_rate         | 0.2         |
|    total_cost           | 11.3        |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.002979215 |
|    arrive_dest          | 0.0982      |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    crash                | 0.269       |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.578       |
|    learning_rate        | 5e-05       |
|    loss                 | 58.7        |
|    max_step             | 0           |
|    n_updates            | 2140        |
|    out_of_road          | 0.902       |
|    policy_gradient_loss | -0.000142   |
|    route_completion     | 0.43        |
|    std                  | 0.703       |
|    total_cost           | 18.7        |
|    value_loss           | 113         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 495      |
|    iterations      | 108      |
|    time_elapsed    | 1116     |
|    total_timesteps | 552960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 354          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 109          |
|    time_elapsed         | 1122         |
|    total_timesteps      | 558080       |
| train/                  |              |
|    approx_kl            | 0.0016551319 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.388        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.3         |
|    n_updates            | 2160         |
|    policy_gradient_loss | 0.000194     |
|    std                  | 0.7          |
|    value_loss           | 173          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0464       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 132          |
|    num_episodes         | 5            |
|    out_of_road          | 0.954        |
|    raw_action           | 0.46296233   |
|    route_completion     | 0.367        |
|    success_rate         | 0.2          |
|    total_cost           | 11.4         |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0013947285 |
|    arrive_dest          | 0.1          |
|    clip_fraction        | 0.095        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.59         |
|    learning_rate        | 5e-05        |
|    loss                 | 72.5         |
|    max_step             | 0            |
|    n_updates            | 2180         |
|    out_of_road          | 0.9          |
|    policy_gradient_loss | -0.000912    |
|    route_completion     | 0.429        |
|    std                  | 0.702        |
|    total_cost           | 18.4         |
|    value_loss           | 117          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 496      |
|    iterations      | 110      |
|    time_elapsed    | 1134     |
|    total_timesteps | 563200   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 367          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 498          |
|    iterations           | 111          |
|    time_elapsed         | 1140         |
|    total_timesteps      | 568320       |
| train/                  |              |
|    approx_kl            | 0.0017718922 |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.504        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.1         |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.000185    |
|    std                  | 0.701        |
|    value_loss           | 159          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0491      |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 128         |
|    mean_reward          | 183         |
|    num_episodes         | 5           |
|    out_of_road          | 0.951       |
|    raw_action           | 0.46307507  |
|    route_completion     | 0.369       |
|    success_rate         | 0.2         |
|    total_cost           | 11.2        |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.011413468 |
|    arrive_dest          | 0.102       |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.657       |
|    learning_rate        | 5e-05       |
|    loss                 | 51.5        |
|    max_step             | 0           |
|    n_updates            | 2220        |
|    out_of_road          | 0.898       |
|    policy_gradient_loss | 0.00441     |
|    route_completion     | 0.431       |
|    std                  | 0.699       |
|    total_cost           | 18.1        |
|    value_loss           | 85.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 498      |
|    iterations      | 112      |
|    time_elapsed    | 1150     |
|    total_timesteps | 573440   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 362          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 113          |
|    time_elapsed         | 1157         |
|    total_timesteps      | 578560       |
| train/                  |              |
|    approx_kl            | 0.0016551049 |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.419        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.8         |
|    n_updates            | 2240         |
|    policy_gradient_loss | 0.00148      |
|    std                  | 0.699        |
|    value_loss           | 124          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0517      |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 171         |
|    mean_reward          | 204         |
|    num_episodes         | 5           |
|    out_of_road          | 0.948       |
|    raw_action           | 0.46363378  |
|    route_completion     | 0.374       |
|    success_rate         | 0.1         |
|    total_cost           | 11.2        |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.002630458 |
|    arrive_dest          | 0.1         |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.1         |
|    crash                | 0.269       |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.634       |
|    learning_rate        | 5e-05       |
|    loss                 | 53.8        |
|    max_step             | 0           |
|    n_updates            | 2260        |
|    out_of_road          | 0.9         |
|    policy_gradient_loss | 0.00171     |
|    route_completion     | 0.429       |
|    std                  | 0.7         |
|    total_cost           | 17.8        |
|    value_loss           | 122         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 499      |
|    iterations      | 114      |
|    time_elapsed    | 1168     |
|    total_timesteps | 583680   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 354          |
|    ep_rew_mean          | 271          |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 115          |
|    time_elapsed         | 1175         |
|    total_timesteps      | 588800       |
| train/                  |              |
|    approx_kl            | 0.0017809678 |
|    clip_fraction        | 0.0662       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.318        |
|    learning_rate        | 5e-05        |
|    loss                 | 108          |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.00367     |
|    std                  | 0.699        |
|    value_loss           | 208          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0508      |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 173         |
|    mean_reward          | 204         |
|    num_episodes         | 5           |
|    out_of_road          | 0.949       |
|    raw_action           | 0.46309835  |
|    route_completion     | 0.376       |
|    success_rate         | 0.2         |
|    total_cost           | 11.3        |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.001339695 |
|    arrive_dest          | 0.105       |
|    clip_fraction        | 0.0852      |
|    clip_range           | 0.1         |
|    crash                | 0.271       |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.523       |
|    learning_rate        | 5e-05       |
|    loss                 | 68.1        |
|    max_step             | 0           |
|    n_updates            | 2300        |
|    out_of_road          | 0.895       |
|    policy_gradient_loss | -0.00145    |
|    route_completion     | 0.432       |
|    std                  | 0.694       |
|    total_cost           | 17.9        |
|    value_loss           | 160         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 498      |
|    iterations      | 116      |
|    time_elapsed    | 1190     |
|    total_timesteps | 593920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 282          |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 117          |
|    time_elapsed         | 1196         |
|    total_timesteps      | 599040       |
| train/                  |              |
|    approx_kl            | 0.0017574081 |
|    clip_fraction        | 0.0855       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.509        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.3         |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.000756    |
|    std                  | 0.695        |
|    value_loss           | 149          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0533       |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 162          |
|    mean_reward          | 206          |
|    num_episodes         | 5            |
|    out_of_road          | 0.947        |
|    raw_action           | 0.46381852   |
|    route_completion     | 0.379        |
|    success_rate         | 0.2          |
|    total_cost           | 11.2         |
| time/                   |              |
|    total_timesteps      | 600000       |
| train/                  |              |
|    approx_kl            | 0.0019724115 |
|    arrive_dest          | 0.107        |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.1          |
|    crash                | 0.277        |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.67         |
|    learning_rate        | 5e-05        |
|    loss                 | 30.8         |
|    max_step             | 0            |
|    n_updates            | 2340         |
|    out_of_road          | 0.893        |
|    policy_gradient_loss | 0.00165      |
|    route_completion     | 0.436        |
|    std                  | 0.697        |
|    total_cost           | 17.9         |
|    value_loss           | 94.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 499      |
|    iterations      | 118      |
|    time_elapsed    | 1208     |
|    total_timesteps | 604160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 279          |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 119          |
|    time_elapsed         | 1215         |
|    total_timesteps      | 609280       |
| train/                  |              |
|    approx_kl            | 0.0011143107 |
|    clip_fraction        | 0.0856       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.55         |
|    learning_rate        | 5e-05        |
|    loss                 | 66.3         |
|    n_updates            | 2360         |
|    policy_gradient_loss | -0.00056     |
|    std                  | 0.696        |
|    value_loss           | 163          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0525       |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 91.4         |
|    mean_reward          | 106          |
|    num_episodes         | 5            |
|    out_of_road          | 0.948        |
|    raw_action           | 0.4641994    |
|    route_completion     | 0.379        |
|    success_rate         | 0.1          |
|    total_cost           | 11           |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0015804028 |
|    arrive_dest          | 0.108        |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.1          |
|    crash                | 0.275        |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.678        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.6         |
|    max_step             | 0            |
|    n_updates            | 2380         |
|    out_of_road          | 0.892        |
|    policy_gradient_loss | 0.000977     |
|    route_completion     | 0.437        |
|    std                  | 0.695        |
|    total_cost           | 17.9         |
|    value_loss           | 116          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 500      |
|    iterations      | 120      |
|    time_elapsed    | 1228     |
|    total_timesteps | 614400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 121          |
|    time_elapsed         | 1234         |
|    total_timesteps      | 619520       |
| train/                  |              |
|    approx_kl            | 0.0013692181 |
|    clip_fraction        | 0.0603       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.614        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.1         |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.00164     |
|    std                  | 0.695        |
|    value_loss           | 141          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0581      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 237         |
|    mean_reward          | 210         |
|    num_episodes         | 5           |
|    out_of_road          | 0.942       |
|    raw_action           | 0.46336612  |
|    route_completion     | 0.385       |
|    success_rate         | 0.3         |
|    total_cost           | 11.6        |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.004111055 |
|    arrive_dest          | 0.11        |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.1         |
|    crash                | 0.274       |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.705       |
|    learning_rate        | 5e-05       |
|    loss                 | 68.4        |
|    max_step             | 0           |
|    n_updates            | 2420        |
|    out_of_road          | 0.89        |
|    policy_gradient_loss | -0.000823   |
|    route_completion     | 0.439       |
|    std                  | 0.695       |
|    total_cost           | 18.1        |
|    value_loss           | 125         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 499      |
|    iterations      | 122      |
|    time_elapsed    | 1249     |
|    total_timesteps | 624640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 289          |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 123          |
|    time_elapsed         | 1255         |
|    total_timesteps      | 629760       |
| train/                  |              |
|    approx_kl            | 0.0023821145 |
|    clip_fraction        | 0.1          |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.458        |
|    learning_rate        | 5e-05        |
|    loss                 | 94.2         |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.000371    |
|    std                  | 0.693        |
|    value_loss           | 192          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0603       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 171          |
|    num_episodes         | 5            |
|    out_of_road          | 0.94         |
|    raw_action           | 0.4639089    |
|    route_completion     | 0.386        |
|    success_rate         | 0.2          |
|    total_cost           | 11.5         |
| time/                   |              |
|    total_timesteps      | 630000       |
| train/                  |              |
|    approx_kl            | 0.0016203687 |
|    arrive_dest          | 0.111        |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    crash                | 0.276        |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.626        |
|    learning_rate        | 5e-05        |
|    loss                 | 41.2         |
|    max_step             | 0            |
|    n_updates            | 2460         |
|    out_of_road          | 0.889        |
|    policy_gradient_loss | 0.00115      |
|    route_completion     | 0.442        |
|    std                  | 0.69         |
|    total_cost           | 18.3         |
|    value_loss           | 148          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 352      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 500      |
|    iterations      | 124      |
|    time_elapsed    | 1267     |
|    total_timesteps | 634880   |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0594       |
|    crash                | 0.231        |
|    max_step             | 0            |
|    mean_ep_length       | 119          |
|    mean_reward          | 136          |
|    num_episodes         | 5            |
|    out_of_road          | 0.941        |
|    raw_action           | 0.4647251    |
|    route_completion     | 0.386        |
|    success_rate         | 0.1          |
|    total_cost           | 11.4         |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0033540172 |
|    arrive_dest          | 0.113        |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    crash                | 0.272        |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.698        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.3         |
|    max_step             | 0            |
|    n_updates            | 2480         |
|    out_of_road          | 0.887        |
|    policy_gradient_loss | -0.00051     |
|    route_completion     | 0.441        |
|    std                  | 0.689        |
|    total_cost           | 18.1         |
|    value_loss           | 158          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 500      |
|    iterations      | 125      |
|    time_elapsed    | 1278     |
|    total_timesteps | 640000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 360         |
|    ep_rew_mean          | 289         |
| time/                   |             |
|    fps                  | 502         |
|    iterations           | 126         |
|    time_elapsed         | 1284        |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.014978237 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.691       |
|    learning_rate        | 5e-05       |
|    loss                 | 57.5        |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.00632     |
|    std                  | 0.689       |
|    value_loss           | 139         |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0615     |
|    crash                | 0.231      |
|    max_step             | 0          |
|    mean_ep_length       | 139        |
|    mean_reward          | 186        |
|    num_episodes         | 5          |
|    out_of_road          | 0.938      |
|    raw_action           | 0.46540415 |
|    route_completion     | 0.388      |
|    success_rate         | 0.4        |
|    total_cost           | 11.3       |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.04063458 |
|    arrive_dest          | 0.12       |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.1        |
|    crash                | 0.268      |
|    entropy_loss         | -2.08      |
|    explained_variance   | 0.606      |
|    learning_rate        | 5e-05      |
|    loss                 | 65         |
|    max_step             | 0          |
|    n_updates            | 2520       |
|    out_of_road          | 0.88       |
|    policy_gradient_loss | 0.00221    |
|    route_completion     | 0.446      |
|    std                  | 0.689      |
|    total_cost           | 18.2       |
|    value_loss           | 157        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 352      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 501      |
|    iterations      | 127      |
|    time_elapsed    | 1296     |
|    total_timesteps | 650240   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 345         |
|    ep_rew_mean          | 275         |
| time/                   |             |
|    fps                  | 502         |
|    iterations           | 128         |
|    time_elapsed         | 1303        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.004379253 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.585       |
|    learning_rate        | 5e-05       |
|    loss                 | 74.3        |
|    n_updates            | 2540        |
|    policy_gradient_loss | 0.00168     |
|    std                  | 0.687       |
|    value_loss           | 176         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0606      |
|    crash                | 0.233       |
|    max_step             | 0           |
|    mean_ep_length       | 140         |
|    mean_reward          | 169         |
|    num_episodes         | 5           |
|    out_of_road          | 0.939       |
|    raw_action           | 0.46539515  |
|    route_completion     | 0.389       |
|    success_rate         | 0           |
|    total_cost           | 11.3        |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.001764458 |
|    arrive_dest          | 0.118       |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.553       |
|    learning_rate        | 5e-05       |
|    loss                 | 76.2        |
|    max_step             | 0           |
|    n_updates            | 2560        |
|    out_of_road          | 0.882       |
|    policy_gradient_loss | -0.000224   |
|    route_completion     | 0.444       |
|    std                  | 0.687       |
|    total_cost           | 18          |
|    value_loss           | 176         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 502      |
|    iterations      | 129      |
|    time_elapsed    | 1313     |
|    total_timesteps | 660480   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 342          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 504          |
|    iterations           | 130          |
|    time_elapsed         | 1319         |
|    total_timesteps      | 665600       |
| train/                  |              |
|    approx_kl            | 0.0019224936 |
|    clip_fraction        | 0.0973       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.628        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.9         |
|    n_updates            | 2580         |
|    policy_gradient_loss | -0.00142     |
|    std                  | 0.686        |
|    value_loss           | 167          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0597      |
|    crash                | 0.236       |
|    max_step             | 0           |
|    mean_ep_length       | 133         |
|    mean_reward          | 158         |
|    num_episodes         | 5           |
|    out_of_road          | 0.94        |
|    raw_action           | 0.46615416  |
|    route_completion     | 0.39        |
|    success_rate         | 0           |
|    total_cost           | 11.2        |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.035330955 |
|    arrive_dest          | 0.116       |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.1         |
|    crash                | 0.275       |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.502       |
|    learning_rate        | 5e-05       |
|    loss                 | 95.1        |
|    max_step             | 0           |
|    n_updates            | 2600        |
|    out_of_road          | 0.884       |
|    policy_gradient_loss | 0.00125     |
|    route_completion     | 0.444       |
|    std                  | 0.685       |
|    total_cost           | 17.7        |
|    value_loss           | 216         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 131      |
|    time_elapsed    | 1329     |
|    total_timesteps | 670720   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 341         |
|    ep_rew_mean          | 275         |
| time/                   |             |
|    fps                  | 506         |
|    iterations           | 132         |
|    time_elapsed         | 1335        |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.013670224 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.698       |
|    learning_rate        | 5e-05       |
|    loss                 | 79.5        |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.00143     |
|    std                  | 0.685       |
|    value_loss           | 139         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0588      |
|    crash                | 0.235       |
|    max_step             | 0           |
|    mean_ep_length       | 131         |
|    mean_reward          | 125         |
|    num_episodes         | 5           |
|    out_of_road          | 0.941       |
|    raw_action           | 0.4660041   |
|    route_completion     | 0.39        |
|    success_rate         | 0.2         |
|    total_cost           | 11.3        |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.002731188 |
|    arrive_dest          | 0.121       |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.1         |
|    crash                | 0.271       |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.663       |
|    learning_rate        | 5e-05       |
|    loss                 | 50.8        |
|    max_step             | 0           |
|    n_updates            | 2640        |
|    out_of_road          | 0.879       |
|    policy_gradient_loss | -0.000565   |
|    route_completion     | 0.445       |
|    std                  | 0.688       |
|    total_cost           | 18.3        |
|    value_loss           | 158         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 503      |
|    iterations      | 133      |
|    time_elapsed    | 1351     |
|    total_timesteps | 680960   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 324          |
|    ep_rew_mean          | 261          |
| time/                   |              |
|    fps                  | 505          |
|    iterations           | 134          |
|    time_elapsed         | 1357         |
|    total_timesteps      | 686080       |
| train/                  |              |
|    approx_kl            | 0.0013577437 |
|    clip_fraction        | 0.0742       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.613        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.8         |
|    n_updates            | 2660         |
|    policy_gradient_loss | -0.000865    |
|    std                  | 0.688        |
|    value_loss           | 180          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0609       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 114          |
|    num_episodes         | 5            |
|    out_of_road          | 0.939        |
|    raw_action           | 0.46661267   |
|    route_completion     | 0.391        |
|    success_rate         | 0.2          |
|    total_cost           | 11.3         |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0058592167 |
|    arrive_dest          | 0.122        |
|    clip_fraction        | 0.161        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.57         |
|    learning_rate        | 5e-05        |
|    loss                 | 61.8         |
|    max_step             | 0            |
|    n_updates            | 2680         |
|    out_of_road          | 0.878        |
|    policy_gradient_loss | -0.00022     |
|    route_completion     | 0.447        |
|    std                  | 0.685        |
|    total_cost           | 18.1         |
|    value_loss           | 175          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 135      |
|    time_elapsed    | 1368     |
|    total_timesteps | 691200   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 339           |
|    ep_rew_mean          | 280           |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 136           |
|    time_elapsed         | 1374          |
|    total_timesteps      | 696320        |
| train/                  |               |
|    approx_kl            | 0.00096475054 |
|    clip_fraction        | 0.151         |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.07         |
|    explained_variance   | 0.596         |
|    learning_rate        | 5e-05         |
|    loss                 | 105           |
|    n_updates            | 2700          |
|    policy_gradient_loss | 0.00254       |
|    std                  | 0.684         |
|    value_loss           | 169           |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0629       |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 167          |
|    mean_reward          | 143          |
|    num_episodes         | 5            |
|    out_of_road          | 0.937        |
|    raw_action           | 0.46657383   |
|    route_completion     | 0.392        |
|    success_rate         | 0.3          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 700000       |
| train/                  |              |
|    approx_kl            | 0.0020632243 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.217        |
|    clip_range           | 0.1          |
|    crash                | 0.269        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.2         |
|    max_step             | 0            |
|    n_updates            | 2720         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | 0.00518      |
|    route_completion     | 0.45         |
|    std                  | 0.685        |
|    total_cost           | 18.7         |
|    value_loss           | 109          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 503      |
|    iterations      | 137      |
|    time_elapsed    | 1391     |
|    total_timesteps | 701440   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 297          |
| time/                   |              |
|    fps                  | 505          |
|    iterations           | 138          |
|    time_elapsed         | 1398         |
|    total_timesteps      | 706560       |
| train/                  |              |
|    approx_kl            | 0.0026502132 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.583        |
|    learning_rate        | 5e-05        |
|    loss                 | 131          |
|    n_updates            | 2740         |
|    policy_gradient_loss | 0.00014      |
|    std                  | 0.685        |
|    value_loss           | 189          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0648       |
|    crash                | 0.234        |
|    max_step             | 0            |
|    mean_ep_length       | 166          |
|    mean_reward          | 196          |
|    num_episodes         | 5            |
|    out_of_road          | 0.935        |
|    raw_action           | 0.46740833   |
|    route_completion     | 0.395        |
|    success_rate         | 0.2          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 710000       |
| train/                  |              |
|    approx_kl            | 0.0035007484 |
|    arrive_dest          | 0.127        |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.1          |
|    crash                | 0.273        |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.713        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.9         |
|    max_step             | 0            |
|    n_updates            | 2760         |
|    out_of_road          | 0.873        |
|    policy_gradient_loss | -0.000355    |
|    route_completion     | 0.452        |
|    std                  | 0.683        |
|    total_cost           | 18.6         |
|    value_loss           | 126          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 139      |
|    time_elapsed    | 1411     |
|    total_timesteps | 711680   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 352        |
|    ep_rew_mean          | 294        |
| time/                   |            |
|    fps                  | 505        |
|    iterations           | 140        |
|    time_elapsed         | 1418       |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.00214646 |
|    clip_fraction        | 0.13       |
|    clip_range           | 0.1        |
|    entropy_loss         | -2.06      |
|    explained_variance   | 0.554      |
|    learning_rate        | 5e-05      |
|    loss                 | 97.8       |
|    n_updates            | 2780       |
|    policy_gradient_loss | -0.000431  |
|    std                  | 0.681      |
|    value_loss           | 191        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0639       |
|    crash                | 0.236        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 133          |
|    num_episodes         | 5            |
|    out_of_road          | 0.936        |
|    raw_action           | 0.4675726    |
|    route_completion     | 0.395        |
|    success_rate         | 0.1          |
|    total_cost           | 11.6         |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0015849499 |
|    arrive_dest          | 0.128        |
|    clip_fraction        | 0.09         |
|    clip_range           | 0.1          |
|    crash                | 0.272        |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.651        |
|    learning_rate        | 5e-05        |
|    loss                 | 85.5         |
|    max_step             | 0            |
|    n_updates            | 2800         |
|    out_of_road          | 0.872        |
|    policy_gradient_loss | -0.00154     |
|    route_completion     | 0.455        |
|    std                  | 0.682        |
|    total_cost           | 18.7         |
|    value_loss           | 165          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 141      |
|    time_elapsed    | 1432     |
|    total_timesteps | 721920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 298          |
| time/                   |              |
|    fps                  | 505          |
|    iterations           | 142          |
|    time_elapsed         | 1438         |
|    total_timesteps      | 727040       |
| train/                  |              |
|    approx_kl            | 0.0014104452 |
|    clip_fraction        | 0.0904       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.634        |
|    learning_rate        | 5e-05        |
|    loss                 | 92.1         |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.00187     |
|    std                  | 0.682        |
|    value_loss           | 179          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.063        |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 146          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.937        |
|    raw_action           | 0.4676356    |
|    route_completion     | 0.396        |
|    success_rate         | 0            |
|    total_cost           | 11.6         |
| time/                   |              |
|    total_timesteps      | 730000       |
| train/                  |              |
|    approx_kl            | 0.0055567524 |
|    arrive_dest          | 0.126        |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    crash                | 0.274        |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.666        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.1         |
|    max_step             | 0            |
|    n_updates            | 2840         |
|    out_of_road          | 0.874        |
|    policy_gradient_loss | -0.000865    |
|    route_completion     | 0.454        |
|    std                  | 0.681        |
|    total_cost           | 18.4         |
|    value_loss           | 158          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 505      |
|    iterations      | 143      |
|    time_elapsed    | 1449     |
|    total_timesteps | 732160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 506          |
|    iterations           | 144          |
|    time_elapsed         | 1455         |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 0.0008794841 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.62         |
|    learning_rate        | 5e-05        |
|    loss                 | 78.5         |
|    n_updates            | 2860         |
|    policy_gradient_loss | 0.000973     |
|    std                  | 0.682        |
|    value_loss           | 152          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0649       |
|    crash                | 0.235        |
|    max_step             | 0            |
|    mean_ep_length       | 137          |
|    mean_reward          | 148          |
|    num_episodes         | 5            |
|    out_of_road          | 0.935        |
|    raw_action           | 0.46844357   |
|    route_completion     | 0.397        |
|    success_rate         | 0.3          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 740000       |
| train/                  |              |
|    approx_kl            | 0.0030130502 |
|    arrive_dest          | 0.13         |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.613        |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    max_step             | 0            |
|    n_updates            | 2880         |
|    out_of_road          | 0.87         |
|    policy_gradient_loss | -0.000529    |
|    route_completion     | 0.459        |
|    std                  | 0.679        |
|    total_cost           | 18.6         |
|    value_loss           | 210          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 145      |
|    time_elapsed    | 1470     |
|    total_timesteps | 742400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 339         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 505         |
|    iterations           | 146         |
|    time_elapsed         | 1477        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.021616796 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.682       |
|    learning_rate        | 5e-05       |
|    loss                 | 68.8        |
|    n_updates            | 2900        |
|    policy_gradient_loss | 0.00184     |
|    std                  | 0.68        |
|    value_loss           | 142         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.064       |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 106         |
|    mean_reward          | 124         |
|    num_episodes         | 5           |
|    out_of_road          | 0.936       |
|    raw_action           | 0.46871084  |
|    route_completion     | 0.396       |
|    success_rate         | 0.1         |
|    total_cost           | 11.6        |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.002694991 |
|    arrive_dest          | 0.131       |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.1         |
|    crash                | 0.269       |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.499       |
|    learning_rate        | 5e-05       |
|    loss                 | 122         |
|    max_step             | 0           |
|    n_updates            | 2920        |
|    out_of_road          | 0.869       |
|    policy_gradient_loss | -0.00155    |
|    route_completion     | 0.46        |
|    std                  | 0.678       |
|    total_cost           | 18.6        |
|    value_loss           | 249         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 147      |
|    time_elapsed    | 1491     |
|    total_timesteps | 752640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 334         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 505         |
|    iterations           | 148         |
|    time_elapsed         | 1497        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.004174008 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.572       |
|    learning_rate        | 5e-05       |
|    loss                 | 105         |
|    n_updates            | 2940        |
|    policy_gradient_loss | 0.00126     |
|    std                  | 0.677       |
|    value_loss           | 218         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0684       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 201          |
|    mean_reward          | 222          |
|    num_episodes         | 5            |
|    out_of_road          | 0.932        |
|    raw_action           | 0.4689914    |
|    route_completion     | 0.399        |
|    success_rate         | 0.4          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 760000       |
| train/                  |              |
|    approx_kl            | 0.0029894784 |
|    arrive_dest          | 0.134        |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    crash                | 0.268        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.47         |
|    learning_rate        | 5e-05        |
|    loss                 | 54.1         |
|    max_step             | 0            |
|    n_updates            | 2960         |
|    out_of_road          | 0.866        |
|    policy_gradient_loss | -0.0017      |
|    route_completion     | 0.462        |
|    std                  | 0.675        |
|    total_cost           | 18.6         |
|    value_loss           | 201          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 149      |
|    time_elapsed    | 1512     |
|    total_timesteps | 762880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 270          |
| time/                   |              |
|    fps                  | 505          |
|    iterations           | 150          |
|    time_elapsed         | 1520         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 0.0039594295 |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.575        |
|    learning_rate        | 5e-05        |
|    loss                 | 78.9         |
|    n_updates            | 2980         |
|    policy_gradient_loss | -0.0016      |
|    std                  | 0.676        |
|    value_loss           | 151          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0701       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 218          |
|    mean_reward          | 219          |
|    num_episodes         | 5            |
|    out_of_road          | 0.93         |
|    raw_action           | 0.4691815    |
|    route_completion     | 0.404        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 770000       |
| train/                  |              |
|    approx_kl            | 0.0022276272 |
|    arrive_dest          | 0.132        |
|    clip_fraction        | 0.196        |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.737        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.2         |
|    max_step             | 0            |
|    n_updates            | 3000         |
|    out_of_road          | 0.868        |
|    policy_gradient_loss | 0.000538     |
|    route_completion     | 0.46         |
|    std                  | 0.677        |
|    total_cost           | 18.4         |
|    value_loss           | 175          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 504      |
|    iterations      | 151      |
|    time_elapsed    | 1531     |
|    total_timesteps | 773120   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 333           |
|    ep_rew_mean          | 264           |
| time/                   |               |
|    fps                  | 505           |
|    iterations           | 152           |
|    time_elapsed         | 1538          |
|    total_timesteps      | 778240        |
| train/                  |               |
|    approx_kl            | 0.00088167225 |
|    clip_fraction        | 0.0977        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.04         |
|    explained_variance   | 0.644         |
|    learning_rate        | 5e-05         |
|    loss                 | 86.4          |
|    n_updates            | 3020          |
|    policy_gradient_loss | -0.000785     |
|    std                  | 0.678         |
|    value_loss           | 153           |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0744       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 196          |
|    mean_reward          | 177          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.46972722   |
|    route_completion     | 0.406        |
|    success_rate         | 0.2          |
|    total_cost           | 12.4         |
| time/                   |              |
|    total_timesteps      | 780000       |
| train/                  |              |
|    approx_kl            | 0.0013916753 |
|    arrive_dest          | 0.131        |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.681        |
|    learning_rate        | 5e-05        |
|    loss                 | 110          |
|    max_step             | 0            |
|    n_updates            | 3040         |
|    out_of_road          | 0.869        |
|    policy_gradient_loss | -0.000901    |
|    route_completion     | 0.458        |
|    std                  | 0.677        |
|    total_cost           | 18.2         |
|    value_loss           | 158          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 320      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    fps             | 505      |
|    iterations      | 153      |
|    time_elapsed    | 1550     |
|    total_timesteps | 783360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 331          |
|    ep_rew_mean          | 259          |
| time/                   |              |
|    fps                  | 506          |
|    iterations           | 154          |
|    time_elapsed         | 1555         |
|    total_timesteps      | 788480       |
| train/                  |              |
|    approx_kl            | 0.0019402948 |
|    clip_fraction        | 0.189        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.476        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.3         |
|    n_updates            | 3060         |
|    policy_gradient_loss | 0.00109      |
|    std                  | 0.678        |
|    value_loss           | 184          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0734       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 120          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.927        |
|    raw_action           | 0.4694502    |
|    route_completion     | 0.407        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 790000       |
| train/                  |              |
|    approx_kl            | 0.0020013805 |
|    arrive_dest          | 0.132        |
|    clip_fraction        | 0.257        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.655        |
|    learning_rate        | 5e-05        |
|    loss                 | 97.2         |
|    max_step             | 0            |
|    n_updates            | 3080         |
|    out_of_road          | 0.868        |
|    policy_gradient_loss | 0.00497      |
|    route_completion     | 0.461        |
|    std                  | 0.678        |
|    total_cost           | 18.1         |
|    value_loss           | 184          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 506      |
|    iterations      | 155      |
|    time_elapsed    | 1568     |
|    total_timesteps | 793600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 331         |
|    ep_rew_mean          | 258         |
| time/                   |             |
|    fps                  | 507         |
|    iterations           | 156         |
|    time_elapsed         | 1574        |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.008048252 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.548       |
|    learning_rate        | 5e-05       |
|    loss                 | 107         |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.000297    |
|    std                  | 0.679       |
|    value_loss           | 177         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0725       |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 142          |
|    num_episodes         | 5            |
|    out_of_road          | 0.927        |
|    raw_action           | 0.46984828   |
|    route_completion     | 0.407        |
|    success_rate         | 0            |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0014786865 |
|    arrive_dest          | 0.13         |
|    clip_fraction        | 0.195        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.669        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.4         |
|    max_step             | 0            |
|    n_updates            | 3120         |
|    out_of_road          | 0.87         |
|    policy_gradient_loss | 0.00116      |
|    route_completion     | 0.463        |
|    std                  | 0.679        |
|    total_cost           | 18           |
|    value_loss           | 142          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 507      |
|    iterations      | 157      |
|    time_elapsed    | 1584     |
|    total_timesteps | 803840   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 338          |
|    ep_rew_mean          | 272          |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 158          |
|    time_elapsed         | 1592         |
|    total_timesteps      | 808960       |
| train/                  |              |
|    approx_kl            | 0.0016549453 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.673        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.9         |
|    n_updates            | 3140         |
|    policy_gradient_loss | 0.000317     |
|    std                  | 0.678        |
|    value_loss           | 121          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0765      |
|    crash                | 0.247       |
|    max_step             | 0           |
|    mean_ep_length       | 156         |
|    mean_reward          | 164         |
|    num_episodes         | 5           |
|    out_of_road          | 0.923       |
|    raw_action           | 0.47007054  |
|    route_completion     | 0.41        |
|    success_rate         | 0.3         |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.003054744 |
|    arrive_dest          | 0.131       |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.669       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.9        |
|    max_step             | 0           |
|    n_updates            | 3160        |
|    out_of_road          | 0.869       |
|    policy_gradient_loss | 0.00242     |
|    route_completion     | 0.465       |
|    std                  | 0.676       |
|    total_cost           | 17.9        |
|    value_loss           | 185         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    fps             | 507      |
|    iterations      | 159      |
|    time_elapsed    | 1604     |
|    total_timesteps | 814080   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 344          |
|    ep_rew_mean          | 270          |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 160          |
|    time_elapsed         | 1610         |
|    total_timesteps      | 819200       |
| train/                  |              |
|    approx_kl            | 0.0017595959 |
|    clip_fraction        | 0.207        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.634        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.8         |
|    n_updates            | 3180         |
|    policy_gradient_loss | 0.00264      |
|    std                  | 0.675        |
|    value_loss           | 172          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0756      |
|    crash                | 0.246       |
|    max_step             | 0           |
|    mean_ep_length       | 162         |
|    mean_reward          | 118         |
|    num_episodes         | 5           |
|    out_of_road          | 0.924       |
|    raw_action           | 0.47443157  |
|    route_completion     | 0.411       |
|    success_rate         | 0.1         |
|    total_cost           | 12.5        |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.006433389 |
|    arrive_dest          | 0.132       |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.1         |
|    crash                | 0.268       |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.758       |
|    learning_rate        | 5e-05       |
|    loss                 | 44.9        |
|    max_step             | 0           |
|    n_updates            | 3200        |
|    out_of_road          | 0.868       |
|    policy_gradient_loss | -0.000238   |
|    route_completion     | 0.464       |
|    std                  | 0.673       |
|    total_cost           | 18.6        |
|    value_loss           | 124         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    fps             | 503      |
|    iterations      | 161      |
|    time_elapsed    | 1637     |
|    total_timesteps | 824320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 344         |
|    ep_rew_mean          | 271         |
| time/                   |             |
|    fps                  | 504         |
|    iterations           | 162         |
|    time_elapsed         | 1644        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.002435427 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.571       |
|    learning_rate        | 5e-05       |
|    loss                 | 84.7        |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.674       |
|    value_loss           | 172         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0747      |
|    crash                | 0.243       |
|    max_step             | 0           |
|    mean_ep_length       | 122         |
|    mean_reward          | 160         |
|    num_episodes         | 5           |
|    out_of_road          | 0.925       |
|    raw_action           | 0.47429562  |
|    route_completion     | 0.411       |
|    success_rate         | 0.1         |
|    total_cost           | 12.4        |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.004393788 |
|    arrive_dest          | 0.133       |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.537       |
|    learning_rate        | 5e-05       |
|    loss                 | 121         |
|    max_step             | 0           |
|    n_updates            | 3240        |
|    out_of_road          | 0.867       |
|    policy_gradient_loss | 0.0016      |
|    route_completion     | 0.465       |
|    std                  | 0.674       |
|    total_cost           | 18.5        |
|    value_loss           | 221         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 503      |
|    iterations      | 163      |
|    time_elapsed    | 1656     |
|    total_timesteps | 834560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 344          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 505          |
|    iterations           | 164          |
|    time_elapsed         | 1662         |
|    total_timesteps      | 839680       |
| train/                  |              |
|    approx_kl            | 0.0017273163 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.578        |
|    learning_rate        | 5e-05        |
|    loss                 | 70.9         |
|    n_updates            | 3260         |
|    policy_gradient_loss | -0.000577    |
|    std                  | 0.67         |
|    value_loss           | 198          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0738       |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 140          |
|    mean_reward          | 183          |
|    num_episodes         | 5            |
|    out_of_road          | 0.926        |
|    raw_action           | 0.4740003    |
|    route_completion     | 0.413        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0044408096 |
|    arrive_dest          | 0.133        |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.682        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.7         |
|    max_step             | 0            |
|    n_updates            | 3280         |
|    out_of_road          | 0.867        |
|    policy_gradient_loss | 0.000908     |
|    route_completion     | 0.464        |
|    std                  | 0.667        |
|    total_cost           | 18.3         |
|    value_loss           | 152          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 505      |
|    iterations      | 165      |
|    time_elapsed    | 1671     |
|    total_timesteps | 844800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 352          |
|    ep_rew_mean          | 273          |
| time/                   |              |
|    fps                  | 506          |
|    iterations           | 166          |
|    time_elapsed         | 1677         |
|    total_timesteps      | 849920       |
| train/                  |              |
|    approx_kl            | 0.0014824264 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.649        |
|    learning_rate        | 5e-05        |
|    loss                 | 118          |
|    n_updates            | 3300         |
|    policy_gradient_loss | 0.000399     |
|    std                  | 0.666        |
|    value_loss           | 182          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0729       |
|    crash                | 0.247        |
|    max_step             | 0            |
|    mean_ep_length       | 89.4         |
|    mean_reward          | 93.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.927        |
|    raw_action           | 0.47423106   |
|    route_completion     | 0.412        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 850000       |
| train/                  |              |
|    approx_kl            | 0.0038408511 |
|    arrive_dest          | 0.134        |
|    clip_fraction        | 0.278        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.775        |
|    learning_rate        | 5e-05        |
|    loss                 | 47.7         |
|    max_step             | 0            |
|    n_updates            | 3320         |
|    out_of_road          | 0.866        |
|    policy_gradient_loss | 0.0158       |
|    route_completion     | 0.464        |
|    std                  | 0.666        |
|    total_cost           | 18.1         |
|    value_loss           | 127          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 277      |
| time/              |          |
|    fps             | 505      |
|    iterations      | 167      |
|    time_elapsed    | 1690     |
|    total_timesteps | 855040   |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0721      |
|    crash                | 0.253       |
|    max_step             | 0           |
|    mean_ep_length       | 125         |
|    mean_reward          | 123         |
|    num_episodes         | 5           |
|    out_of_road          | 0.928       |
|    raw_action           | 0.47432584  |
|    route_completion     | 0.412       |
|    success_rate         | 0.1         |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.003555288 |
|    arrive_dest          | 0.135       |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.1         |
|    crash                | 0.263       |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.735       |
|    learning_rate        | 5e-05       |
|    loss                 | 81.6        |
|    max_step             | 0           |
|    n_updates            | 3340        |
|    out_of_road          | 0.865       |
|    policy_gradient_loss | 0.00254     |
|    route_completion     | 0.464       |
|    std                  | 0.665       |
|    total_cost           | 18          |
|    value_loss           | 118         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 505      |
|    iterations      | 168      |
|    time_elapsed    | 1701     |
|    total_timesteps | 860160   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 348          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 506          |
|    iterations           | 169          |
|    time_elapsed         | 1707         |
|    total_timesteps      | 865280       |
| train/                  |              |
|    approx_kl            | 0.0017218668 |
|    clip_fraction        | 0.17         |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.571        |
|    learning_rate        | 5e-05        |
|    loss                 | 73.3         |
|    n_updates            | 3360         |
|    policy_gradient_loss | 0.00122      |
|    std                  | 0.665        |
|    value_loss           | 202          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0713       |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 114          |
|    mean_reward          | 127          |
|    num_episodes         | 5            |
|    out_of_road          | 0.929        |
|    raw_action           | 0.4739158    |
|    route_completion     | 0.411        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 870000       |
| train/                  |              |
|    approx_kl            | 0.0013386405 |
|    arrive_dest          | 0.136        |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.695        |
|    learning_rate        | 5e-05        |
|    loss                 | 90           |
|    max_step             | 0            |
|    n_updates            | 3380         |
|    out_of_road          | 0.864        |
|    policy_gradient_loss | -0.000169    |
|    route_completion     | 0.466        |
|    std                  | 0.667        |
|    total_cost           | 18.2         |
|    value_loss           | 166          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 506      |
|    iterations      | 170      |
|    time_elapsed    | 1720     |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 359         |
|    ep_rew_mean          | 279         |
| time/                   |             |
|    fps                  | 507         |
|    iterations           | 171         |
|    time_elapsed         | 1726        |
|    total_timesteps      | 875520      |
| train/                  |             |
|    approx_kl            | 0.011775502 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.704       |
|    learning_rate        | 5e-05       |
|    loss                 | 69.8        |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.00299     |
|    std                  | 0.667       |
|    value_loss           | 134         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0727      |
|    crash                | 0.252       |
|    max_step             | 0           |
|    mean_ep_length       | 142         |
|    mean_reward          | 116         |
|    num_episodes         | 5           |
|    out_of_road          | 0.927       |
|    raw_action           | 0.47364086  |
|    route_completion     | 0.412       |
|    success_rate         | 0.2         |
|    total_cost           | 12.1        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.015534954 |
|    arrive_dest          | 0.136       |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    crash                | 0.261       |
|    entropy_loss         | -2          |
|    explained_variance   | 0.714       |
|    learning_rate        | 5e-05       |
|    loss                 | 77.2        |
|    max_step             | 0           |
|    n_updates            | 3420        |
|    out_of_road          | 0.864       |
|    policy_gradient_loss | 0.00161     |
|    route_completion     | 0.467       |
|    std                  | 0.665       |
|    total_cost           | 18.1        |
|    value_loss           | 150         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 352      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    fps             | 506      |
|    iterations      | 172      |
|    time_elapsed    | 1740     |
|    total_timesteps | 880640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 275          |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 173          |
|    time_elapsed         | 1746         |
|    total_timesteps      | 885760       |
| train/                  |              |
|    approx_kl            | 0.0017619876 |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.645        |
|    learning_rate        | 5e-05        |
|    loss                 | 92.6         |
|    n_updates            | 3440         |
|    policy_gradient_loss | 0.000336     |
|    std                  | 0.665        |
|    value_loss           | 204          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0719       |
|    crash                | 0.256        |
|    max_step             | 0            |
|    mean_ep_length       | 103          |
|    mean_reward          | 121          |
|    num_episodes         | 5            |
|    out_of_road          | 0.928        |
|    raw_action           | 0.47394225   |
|    route_completion     | 0.412        |
|    success_rate         | 0.1          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 890000       |
| train/                  |              |
|    approx_kl            | 0.0007359048 |
|    arrive_dest          | 0.137        |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.1          |
|    crash                | 0.263        |
|    entropy_loss         | -2           |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 83.6         |
|    max_step             | 0            |
|    n_updates            | 3460         |
|    out_of_road          | 0.863        |
|    policy_gradient_loss | -0.000739    |
|    route_completion     | 0.467        |
|    std                  | 0.666        |
|    total_cost           | 17.9         |
|    value_loss           | 154          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 506      |
|    iterations      | 174      |
|    time_elapsed    | 1757     |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 352         |
|    ep_rew_mean          | 278         |
| time/                   |             |
|    fps                  | 508         |
|    iterations           | 175         |
|    time_elapsed         | 1762        |
|    total_timesteps      | 896000      |
| train/                  |             |
|    approx_kl            | 0.002555289 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.1         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.693       |
|    learning_rate        | 5e-05       |
|    loss                 | 60          |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.000455   |
|    std                  | 0.664       |
|    value_loss           | 170         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0778      |
|    crash                | 0.256       |
|    max_step             | 0           |
|    mean_ep_length       | 205         |
|    mean_reward          | 227         |
|    num_episodes         | 5           |
|    out_of_road          | 0.922       |
|    raw_action           | 0.47359595  |
|    route_completion     | 0.415       |
|    success_rate         | 0.5         |
|    total_cost           | 12.1        |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.003130808 |
|    arrive_dest          | 0.14        |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.1         |
|    crash                | 0.26        |
|    entropy_loss         | -2          |
|    explained_variance   | 0.754       |
|    learning_rate        | 5e-05       |
|    loss                 | 59.8        |
|    max_step             | 0           |
|    n_updates            | 3500        |
|    out_of_road          | 0.86        |
|    policy_gradient_loss | 0.000484    |
|    route_completion     | 0.469       |
|    std                  | 0.664       |
|    total_cost           | 17.8        |
|    value_loss           | 130         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 506      |
|    iterations      | 176      |
|    time_elapsed    | 1777     |
|    total_timesteps | 901120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 355          |
|    ep_rew_mean          | 284          |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 177          |
|    time_elapsed         | 1783         |
|    total_timesteps      | 906240       |
| train/                  |              |
|    approx_kl            | 0.0012513744 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.665        |
|    learning_rate        | 5e-05        |
|    loss                 | 51           |
|    n_updates            | 3520         |
|    policy_gradient_loss | 0.00107      |
|    std                  | 0.661        |
|    value_loss           | 162          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0769       |
|    crash                | 0.255        |
|    max_step             | 0            |
|    mean_ep_length       | 119          |
|    mean_reward          | 144          |
|    num_episodes         | 5            |
|    out_of_road          | 0.923        |
|    raw_action           | 0.47357678   |
|    route_completion     | 0.415        |
|    success_rate         | 0.1          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0056858147 |
|    arrive_dest          | 0.141        |
|    clip_fraction        | 0.332        |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.805        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.8         |
|    max_step             | 0            |
|    n_updates            | 3540         |
|    out_of_road          | 0.859        |
|    policy_gradient_loss | 0.0126       |
|    route_completion     | 0.473        |
|    std                  | 0.66         |
|    total_cost           | 17.8         |
|    value_loss           | 109          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 507      |
|    iterations      | 178      |
|    time_elapsed    | 1795     |
|    total_timesteps | 911360   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 340          |
|    ep_rew_mean          | 279          |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 179          |
|    time_elapsed         | 1803         |
|    total_timesteps      | 916480       |
| train/                  |              |
|    approx_kl            | 0.0019784817 |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.549        |
|    learning_rate        | 5e-05        |
|    loss                 | 103          |
|    n_updates            | 3560         |
|    policy_gradient_loss | -0.000986    |
|    std                  | 0.659        |
|    value_loss           | 190          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0783       |
|    crash                | 0.254        |
|    max_step             | 0            |
|    mean_ep_length       | 172          |
|    mean_reward          | 197          |
|    num_episodes         | 5            |
|    out_of_road          | 0.922        |
|    raw_action           | 0.47386318   |
|    route_completion     | 0.416        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 920000       |
| train/                  |              |
|    approx_kl            | 0.0019139104 |
|    arrive_dest          | 0.139        |
|    clip_fraction        | 0.181        |
|    clip_range           | 0.1          |
|    crash                | 0.261        |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.657        |
|    learning_rate        | 5e-05        |
|    loss                 | 44.5         |
|    max_step             | 0            |
|    n_updates            | 3580         |
|    out_of_road          | 0.861        |
|    policy_gradient_loss | 0.000513     |
|    route_completion     | 0.473        |
|    std                  | 0.659        |
|    total_cost           | 17.6         |
|    value_loss           | 128          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 507      |
|    iterations      | 180      |
|    time_elapsed    | 1816     |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 357         |
|    ep_rew_mean          | 294         |
| time/                   |             |
|    fps                  | 508         |
|    iterations           | 181         |
|    time_elapsed         | 1822        |
|    total_timesteps      | 926720      |
| train/                  |             |
|    approx_kl            | 0.004474898 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.741       |
|    learning_rate        | 5e-05       |
|    loss                 | 55.8        |
|    n_updates            | 3600        |
|    policy_gradient_loss | 8.22e-05    |
|    std                  | 0.658       |
|    value_loss           | 152         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0796      |
|    crash                | 0.254       |
|    max_step             | 0           |
|    mean_ep_length       | 136         |
|    mean_reward          | 144         |
|    num_episodes         | 5           |
|    out_of_road          | 0.92        |
|    raw_action           | 0.47395238  |
|    route_completion     | 0.416       |
|    success_rate         | 0.1         |
|    total_cost           | 11.9        |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.009247368 |
|    arrive_dest          | 0.138       |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    crash                | 0.265       |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.61        |
|    learning_rate        | 5e-05       |
|    loss                 | 92.5        |
|    max_step             | 0           |
|    n_updates            | 3620        |
|    out_of_road          | 0.862       |
|    policy_gradient_loss | 0.00137     |
|    route_completion     | 0.471       |
|    std                  | 0.658       |
|    total_cost           | 17.5        |
|    value_loss           | 183         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 292      |
| time/              |          |
|    fps             | 508      |
|    iterations      | 182      |
|    time_elapsed    | 1833     |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 352        |
|    ep_rew_mean          | 291        |
| time/                   |            |
|    fps                  | 509        |
|    iterations           | 183        |
|    time_elapsed         | 1839       |
|    total_timesteps      | 936960     |
| train/                  |            |
|    approx_kl            | 0.00453375 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.97      |
|    explained_variance   | 0.607      |
|    learning_rate        | 5e-05      |
|    loss                 | 73.7       |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.000266   |
|    std                  | 0.655      |
|    value_loss           | 150        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0809       |
|    crash                | 0.255        |
|    max_step             | 0            |
|    mean_ep_length       | 149          |
|    mean_reward          | 154          |
|    num_episodes         | 5            |
|    out_of_road          | 0.919        |
|    raw_action           | 0.47400048   |
|    route_completion     | 0.416        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 940000       |
| train/                  |              |
|    approx_kl            | 0.0019239072 |
|    arrive_dest          | 0.136        |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    crash                | 0.268        |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.731        |
|    learning_rate        | 5e-05        |
|    loss                 | 107          |
|    max_step             | 0            |
|    n_updates            | 3660         |
|    out_of_road          | 0.864        |
|    policy_gradient_loss | -0.000252    |
|    route_completion     | 0.469        |
|    std                  | 0.657        |
|    total_cost           | 17.3         |
|    value_loss           | 151          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 508      |
|    iterations      | 184      |
|    time_elapsed    | 1851     |
|    total_timesteps | 942080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 346        |
|    ep_rew_mean          | 292        |
| time/                   |            |
|    fps                  | 509        |
|    iterations           | 185        |
|    time_elapsed         | 1857       |
|    total_timesteps      | 947200     |
| train/                  |            |
|    approx_kl            | 0.00262712 |
|    clip_fraction        | 0.223      |
|    clip_range           | 0.1        |
|    entropy_loss         | -1.97      |
|    explained_variance   | 0.721      |
|    learning_rate        | 5e-05      |
|    loss                 | 96.4       |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.00349    |
|    std                  | 0.655      |
|    value_loss           | 172        |
----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.08         |
|    crash                | 0.255        |
|    max_step             | 0            |
|    mean_ep_length       | 83.2         |
|    mean_reward          | 86.9         |
|    num_episodes         | 5            |
|    out_of_road          | 0.92         |
|    raw_action           | 0.47425073   |
|    route_completion     | 0.414        |
|    success_rate         | 0            |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 950000       |
| train/                  |              |
|    approx_kl            | 0.0015725031 |
|    arrive_dest          | 0.135        |
|    clip_fraction        | 0.18         |
|    clip_range           | 0.1          |
|    crash                | 0.272        |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.776        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.7         |
|    max_step             | 0            |
|    n_updates            | 3700         |
|    out_of_road          | 0.865        |
|    policy_gradient_loss | 0.00254      |
|    route_completion     | 0.468        |
|    std                  | 0.656        |
|    total_cost           | 17.2         |
|    value_loss           | 130          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 510      |
|    iterations      | 186      |
|    time_elapsed    | 1866     |
|    total_timesteps | 952320   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 347          |
|    ep_rew_mean          | 292          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 187          |
|    time_elapsed         | 1872         |
|    total_timesteps      | 957440       |
| train/                  |              |
|    approx_kl            | 0.0013632828 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.567        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.4         |
|    n_updates            | 3720         |
|    policy_gradient_loss | 8.68e-05     |
|    std                  | 0.656        |
|    value_loss           | 178          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0813      |
|    crash                | 0.252       |
|    max_step             | 0           |
|    mean_ep_length       | 188         |
|    mean_reward          | 215         |
|    num_episodes         | 5           |
|    out_of_road          | 0.919       |
|    raw_action           | 0.4744099   |
|    route_completion     | 0.416       |
|    success_rate         | 0.2         |
|    total_cost           | 11.8        |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.011733089 |
|    arrive_dest          | 0.135       |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.1         |
|    crash                | 0.269       |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.66        |
|    learning_rate        | 5e-05       |
|    loss                 | 80.9        |
|    max_step             | 0           |
|    n_updates            | 3740        |
|    out_of_road          | 0.865       |
|    policy_gradient_loss | -0.00116    |
|    route_completion     | 0.467       |
|    std                  | 0.656       |
|    total_cost           | 17          |
|    value_loss           | 164         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 188      |
|    time_elapsed    | 1883     |
|    total_timesteps | 962560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 336          |
|    ep_rew_mean          | 283          |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 189          |
|    time_elapsed         | 1890         |
|    total_timesteps      | 967680       |
| train/                  |              |
|    approx_kl            | 0.0013903892 |
|    clip_fraction        | 0.0878       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.583        |
|    learning_rate        | 5e-05        |
|    loss                 | 96.4         |
|    n_updates            | 3760         |
|    policy_gradient_loss | -0.000839    |
|    std                  | 0.655        |
|    value_loss           | 215          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0825       |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 190          |
|    mean_reward          | 179          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.47410235   |
|    route_completion     | 0.418        |
|    success_rate         | 0.2          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 970000       |
| train/                  |              |
|    approx_kl            | 0.0062335585 |
|    arrive_dest          | 0.136        |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.701        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.1         |
|    max_step             | 0            |
|    n_updates            | 3780         |
|    out_of_road          | 0.864        |
|    policy_gradient_loss | -0.000274    |
|    route_completion     | 0.469        |
|    std                  | 0.654        |
|    total_cost           | 16.9         |
|    value_loss           | 137          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 190      |
|    time_elapsed    | 1903     |
|    total_timesteps | 972800   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 293          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 191          |
|    time_elapsed         | 1909         |
|    total_timesteps      | 977920       |
| train/                  |              |
|    approx_kl            | 0.0024441269 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.65         |
|    learning_rate        | 5e-05        |
|    loss                 | 99.1         |
|    n_updates            | 3800         |
|    policy_gradient_loss | 0.000688     |
|    std                  | 0.655        |
|    value_loss           | 149          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0816      |
|    crash                | 0.251       |
|    max_step             | 0           |
|    mean_ep_length       | 98.6        |
|    mean_reward          | 108         |
|    num_episodes         | 5           |
|    out_of_road          | 0.918       |
|    raw_action           | 0.47392255  |
|    route_completion     | 0.417       |
|    success_rate         | 0.2         |
|    total_cost           | 11.9        |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.004603532 |
|    arrive_dest          | 0.139       |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.1         |
|    crash                | 0.269       |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.748       |
|    learning_rate        | 5e-05       |
|    loss                 | 59          |
|    max_step             | 0           |
|    n_updates            | 3820        |
|    out_of_road          | 0.861       |
|    policy_gradient_loss | 0.000672    |
|    route_completion     | 0.471       |
|    std                  | 0.654       |
|    total_cost           | 16.9        |
|    value_loss           | 155         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 192      |
|    time_elapsed    | 1921     |
|    total_timesteps | 983040   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 358           |
|    ep_rew_mean          | 286           |
| time/                   |               |
|    fps                  | 512           |
|    iterations           | 193           |
|    time_elapsed         | 1928          |
|    total_timesteps      | 988160        |
| train/                  |               |
|    approx_kl            | 0.00081542943 |
|    clip_fraction        | 0.214         |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.96         |
|    explained_variance   | 0.654         |
|    learning_rate        | 5e-05         |
|    loss                 | 68            |
|    n_updates            | 3840          |
|    policy_gradient_loss | 0.00481       |
|    std                  | 0.652         |
|    value_loss           | 144           |
-------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0828     |
|    crash                | 0.248      |
|    max_step             | 0          |
|    mean_ep_length       | 132        |
|    mean_reward          | 177        |
|    num_episodes         | 5          |
|    out_of_road          | 0.917      |
|    raw_action           | 0.47389877 |
|    route_completion     | 0.418      |
|    success_rate         | 0.1        |
|    total_cost           | 11.8       |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.00375915 |
|    arrive_dest          | 0.137      |
|    clip_fraction        | 0.146      |
|    clip_range           | 0.1        |
|    crash                | 0.269      |
|    entropy_loss         | -1.96      |
|    explained_variance   | 0.738      |
|    learning_rate        | 5e-05      |
|    loss                 | 80.9       |
|    max_step             | 0          |
|    n_updates            | 3860       |
|    out_of_road          | 0.863      |
|    policy_gradient_loss | 0.00111    |
|    route_completion     | 0.47       |
|    std                  | 0.652      |
|    total_cost           | 16.8       |
|    value_loss           | 172        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 194      |
|    time_elapsed    | 1938     |
|    total_timesteps | 993280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 195          |
|    time_elapsed         | 1944         |
|    total_timesteps      | 998400       |
| train/                  |              |
|    approx_kl            | 0.0010470593 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.663        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.9         |
|    n_updates            | 3880         |
|    policy_gradient_loss | -0.000507    |
|    std                  | 0.653        |
|    value_loss           | 168          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.084        |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 167          |
|    mean_reward          | 235          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.47307456   |
|    route_completion     | 0.421        |
|    success_rate         | 0.4          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0054051676 |
|    arrive_dest          | 0.142        |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 98.4         |
|    max_step             | 0            |
|    n_updates            | 3900         |
|    out_of_road          | 0.858        |
|    policy_gradient_loss | 0.00125      |
|    route_completion     | 0.472        |
|    std                  | 0.654        |
|    total_cost           | 17.1         |
|    value_loss           | 189          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 196      |
|    time_elapsed    | 1958     |
|    total_timesteps | 1003520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 356          |
|    ep_rew_mean          | 290          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 197          |
|    time_elapsed         | 1964         |
|    total_timesteps      | 1008640      |
| train/                  |              |
|    approx_kl            | 0.0018329484 |
|    clip_fraction        | 0.138        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.676        |
|    learning_rate        | 5e-05        |
|    loss                 | 83.3         |
|    n_updates            | 3920         |
|    policy_gradient_loss | -0.000184    |
|    std                  | 0.654        |
|    value_loss           | 209          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0832       |
|    crash                | 0.248        |
|    max_step             | 0            |
|    mean_ep_length       | 172          |
|    mean_reward          | 153          |
|    num_episodes         | 5            |
|    out_of_road          | 0.917        |
|    raw_action           | 0.47341448   |
|    route_completion     | 0.421        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1010000      |
| train/                  |              |
|    approx_kl            | 0.0021645024 |
|    arrive_dest          | 0.145        |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    crash                | 0.269        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.729        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.5         |
|    max_step             | 0            |
|    n_updates            | 3940         |
|    out_of_road          | 0.855        |
|    policy_gradient_loss | -7.23e-05    |
|    route_completion     | 0.473        |
|    std                  | 0.654        |
|    total_cost           | 17.1         |
|    value_loss           | 142          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 198      |
|    time_elapsed    | 1977     |
|    total_timesteps | 1013760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 347          |
|    ep_rew_mean          | 289          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 199          |
|    time_elapsed         | 1984         |
|    total_timesteps      | 1018880      |
| train/                  |              |
|    approx_kl            | 0.0032237465 |
|    clip_fraction        | 0.206        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.644        |
|    learning_rate        | 5e-05        |
|    loss                 | 86.3         |
|    n_updates            | 3960         |
|    policy_gradient_loss | 0.000356     |
|    std                  | 0.655        |
|    value_loss           | 200          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0824       |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 166          |
|    mean_reward          | 224          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.4737945    |
|    route_completion     | 0.423        |
|    success_rate         | 0.1          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 1020000      |
| train/                  |              |
|    approx_kl            | 0.0020913458 |
|    arrive_dest          | 0.145        |
|    clip_fraction        | 0.279        |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.789        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.4         |
|    max_step             | 0            |
|    n_updates            | 3980         |
|    out_of_road          | 0.855        |
|    policy_gradient_loss | 0.00736      |
|    route_completion     | 0.473        |
|    std                  | 0.653        |
|    total_cost           | 17           |
|    value_loss           | 117          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 297      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 200      |
|    time_elapsed    | 1994     |
|    total_timesteps | 1024000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 350          |
|    ep_rew_mean          | 291          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 201          |
|    time_elapsed         | 2000         |
|    total_timesteps      | 1029120      |
| train/                  |              |
|    approx_kl            | 0.0023906603 |
|    clip_fraction        | 0.189        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.771        |
|    learning_rate        | 5e-05        |
|    loss                 | 70.1         |
|    n_updates            | 4000         |
|    policy_gradient_loss | 0.00539      |
|    std                  | 0.65         |
|    value_loss           | 151          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0816       |
|    crash                | 0.249        |
|    max_step             | 0            |
|    mean_ep_length       | 96.4         |
|    mean_reward          | 118          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.47350422   |
|    route_completion     | 0.423        |
|    success_rate         | 0.1          |
|    total_cost           | 11.7         |
| time/                   |              |
|    total_timesteps      | 1030000      |
| train/                  |              |
|    approx_kl            | 0.0022310382 |
|    arrive_dest          | 0.146        |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.76         |
|    learning_rate        | 5e-05        |
|    loss                 | 60.6         |
|    max_step             | 0            |
|    n_updates            | 4020         |
|    out_of_road          | 0.854        |
|    policy_gradient_loss | -0.00154     |
|    route_completion     | 0.474        |
|    std                  | 0.65         |
|    total_cost           | 17.1         |
|    value_loss           | 157          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 202      |
|    time_elapsed    | 2012     |
|    total_timesteps | 1034240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 296          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 203          |
|    time_elapsed         | 2018         |
|    total_timesteps      | 1039360      |
| train/                  |              |
|    approx_kl            | 0.0036326863 |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.783        |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    n_updates            | 4040         |
|    policy_gradient_loss | 0.000996     |
|    std                  | 0.649        |
|    value_loss           | 158          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0827       |
|    crash                | 0.254        |
|    max_step             | 0            |
|    mean_ep_length       | 192          |
|    mean_reward          | 151          |
|    num_episodes         | 5            |
|    out_of_road          | 0.917        |
|    raw_action           | 0.47368592   |
|    route_completion     | 0.424        |
|    success_rate         | 0.3          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0021627273 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.769        |
|    learning_rate        | 5e-05        |
|    loss                 | 73.6         |
|    max_step             | 0            |
|    n_updates            | 4060         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | 9.26e-05     |
|    route_completion     | 0.475        |
|    std                  | 0.648        |
|    total_cost           | 17.1         |
|    value_loss           | 166          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 204      |
|    time_elapsed    | 2032     |
|    total_timesteps | 1044480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 356          |
|    ep_rew_mean          | 287          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 205          |
|    time_elapsed         | 2039         |
|    total_timesteps      | 1049600      |
| train/                  |              |
|    approx_kl            | 0.0012562599 |
|    clip_fraction        | 0.196        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.682        |
|    learning_rate        | 5e-05        |
|    loss                 | 123          |
|    n_updates            | 4080         |
|    policy_gradient_loss | 0.00293      |
|    std                  | 0.647        |
|    value_loss           | 199          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0819       |
|    crash                | 0.255        |
|    max_step             | 0            |
|    mean_ep_length       | 115          |
|    mean_reward          | 139          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.47223538   |
|    route_completion     | 0.424        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1050000      |
| train/                  |              |
|    approx_kl            | 0.0016889016 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.725        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.9         |
|    max_step             | 0            |
|    n_updates            | 4100         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | 0.000868     |
|    route_completion     | 0.475        |
|    std                  | 0.647        |
|    total_cost           | 17.2         |
|    value_loss           | 154          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 206      |
|    time_elapsed    | 2056     |
|    total_timesteps | 1054720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 292          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 207          |
|    time_elapsed         | 2063         |
|    total_timesteps      | 1059840      |
| train/                  |              |
|    approx_kl            | 0.0027094954 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.3         |
|    n_updates            | 4120         |
|    policy_gradient_loss | 0.000833     |
|    std                  | 0.645        |
|    value_loss           | 150          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0811       |
|    crash                | 0.253        |
|    max_step             | 0            |
|    mean_ep_length       | 190          |
|    mean_reward          | 223          |
|    num_episodes         | 5            |
|    out_of_road          | 0.919        |
|    raw_action           | 0.4723507    |
|    route_completion     | 0.426        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1060000      |
| train/                  |              |
|    approx_kl            | 0.0017343763 |
|    arrive_dest          | 0.151        |
|    clip_fraction        | 0.257        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.832        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.1         |
|    max_step             | 0            |
|    n_updates            | 4140         |
|    out_of_road          | 0.849        |
|    policy_gradient_loss | 0.00785      |
|    route_completion     | 0.476        |
|    std                  | 0.645        |
|    total_cost           | 17.1         |
|    value_loss           | 118          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 208      |
|    time_elapsed    | 2075     |
|    total_timesteps | 1064960  |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0804       |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 211          |
|    num_episodes         | 5            |
|    out_of_road          | 0.92         |
|    raw_action           | 0.4722239    |
|    route_completion     | 0.427        |
|    success_rate         | 0            |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1070000      |
| train/                  |              |
|    approx_kl            | 0.0059273993 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.552        |
|    learning_rate        | 5e-05        |
|    loss                 | 135          |
|    max_step             | 0            |
|    n_updates            | 4160         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | -0.00152     |
|    route_completion     | 0.474        |
|    std                  | 0.645        |
|    total_cost           | 17           |
|    value_loss           | 231          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 209      |
|    time_elapsed    | 2085     |
|    total_timesteps | 1070080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 361          |
|    ep_rew_mean          | 295          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 210          |
|    time_elapsed         | 2091         |
|    total_timesteps      | 1075200      |
| train/                  |              |
|    approx_kl            | 0.0026118287 |
|    clip_fraction        | 0.186        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.7          |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    n_updates            | 4180         |
|    policy_gradient_loss | 0.00108      |
|    std                  | 0.647        |
|    value_loss           | 178          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0815       |
|    crash                | 0.252        |
|    max_step             | 0            |
|    mean_ep_length       | 187          |
|    mean_reward          | 156          |
|    num_episodes         | 5            |
|    out_of_road          | 0.919        |
|    raw_action           | 0.47168076   |
|    route_completion     | 0.428        |
|    success_rate         | 0.2          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1080000      |
| train/                  |              |
|    approx_kl            | 0.0025866772 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.1          |
|    crash                | 0.27         |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.609        |
|    learning_rate        | 5e-05        |
|    loss                 | 50.2         |
|    max_step             | 0            |
|    n_updates            | 4200         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | -0.000392    |
|    route_completion     | 0.474        |
|    std                  | 0.646        |
|    total_cost           | 17           |
|    value_loss           | 170          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 211      |
|    time_elapsed    | 2106     |
|    total_timesteps | 1080320  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 367          |
|    ep_rew_mean          | 305          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 212          |
|    time_elapsed         | 2111         |
|    total_timesteps      | 1085440      |
| train/                  |              |
|    approx_kl            | 0.0015479472 |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.767        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.6         |
|    n_updates            | 4220         |
|    policy_gradient_loss | 0.0012       |
|    std                  | 0.646        |
|    value_loss           | 144          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0826       |
|    crash                | 0.25         |
|    max_step             | 0            |
|    mean_ep_length       | 137          |
|    mean_reward          | 170          |
|    num_episodes         | 5            |
|    out_of_road          | 0.917        |
|    raw_action           | 0.47055545   |
|    route_completion     | 0.428        |
|    success_rate         | 0.3          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1090000      |
| train/                  |              |
|    approx_kl            | 0.0070176832 |
|    arrive_dest          | 0.152        |
|    clip_fraction        | 0.148        |
|    clip_range           | 0.1          |
|    crash                | 0.273        |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.9         |
|    max_step             | 0            |
|    n_updates            | 4240         |
|    out_of_road          | 0.848        |
|    policy_gradient_loss | -0.000977    |
|    route_completion     | 0.475        |
|    std                  | 0.644        |
|    total_cost           | 17.2         |
|    value_loss           | 118          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 213      |
|    time_elapsed    | 2124     |
|    total_timesteps | 1090560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 366          |
|    ep_rew_mean          | 304          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 214          |
|    time_elapsed         | 2130         |
|    total_timesteps      | 1095680      |
| train/                  |              |
|    approx_kl            | 0.0020817013 |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.807        |
|    learning_rate        | 5e-05        |
|    loss                 | 56           |
|    n_updates            | 4260         |
|    policy_gradient_loss | 0.00134      |
|    std                  | 0.642        |
|    value_loss           | 109          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0818       |
|    crash                | 0.247        |
|    max_step             | 0            |
|    mean_ep_length       | 108          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 0.918        |
|    raw_action           | 0.47072628   |
|    route_completion     | 0.428        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1100000      |
| train/                  |              |
|    approx_kl            | 0.0072414773 |
|    arrive_dest          | 0.153        |
|    clip_fraction        | 0.262        |
|    clip_range           | 0.1          |
|    crash                | 0.273        |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.735        |
|    learning_rate        | 5e-05        |
|    loss                 | 54.4         |
|    max_step             | 0            |
|    n_updates            | 4280         |
|    out_of_road          | 0.847        |
|    policy_gradient_loss | 0.00889      |
|    route_completion     | 0.475        |
|    std                  | 0.642        |
|    total_cost           | 17.1         |
|    value_loss           | 142          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 215      |
|    time_elapsed    | 2140     |
|    total_timesteps | 1100800  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 322         |
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 216         |
|    time_elapsed         | 2146        |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.002279418 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.797       |
|    learning_rate        | 5e-05       |
|    loss                 | 38.4        |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.0023      |
|    std                  | 0.641       |
|    value_loss           | 109         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0811      |
|    crash                | 0.249       |
|    max_step             | 0           |
|    mean_ep_length       | 124         |
|    mean_reward          | 152         |
|    num_episodes         | 5           |
|    out_of_road          | 0.919       |
|    raw_action           | 0.47086617  |
|    route_completion     | 0.429       |
|    success_rate         | 0           |
|    total_cost           | 11.8        |
| time/                   |             |
|    total_timesteps      | 1110000     |
| train/                  |             |
|    approx_kl            | 0.002879295 |
|    arrive_dest          | 0.151       |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.1         |
|    crash                | 0.27        |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.852       |
|    learning_rate        | 5e-05       |
|    loss                 | 47.8        |
|    max_step             | 0           |
|    n_updates            | 4320        |
|    out_of_road          | 0.849       |
|    policy_gradient_loss | 0.000655    |
|    route_completion     | 0.476       |
|    std                  | 0.639       |
|    total_cost           | 17          |
|    value_loss           | 85.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 322      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 217      |
|    time_elapsed    | 2157     |
|    total_timesteps | 1111040  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 381          |
|    ep_rew_mean          | 318          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 218          |
|    time_elapsed         | 2163         |
|    total_timesteps      | 1116160      |
| train/                  |              |
|    approx_kl            | 0.0015290101 |
|    clip_fraction        | 0.172        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.71         |
|    learning_rate        | 5e-05        |
|    loss                 | 44.9         |
|    n_updates            | 4340         |
|    policy_gradient_loss | 0.00365      |
|    std                  | 0.637        |
|    value_loss           | 148          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0839       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 212          |
|    mean_reward          | 257          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.47081488   |
|    route_completion     | 0.432        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1120000      |
| train/                  |              |
|    approx_kl            | 0.0016546203 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    crash                | 0.273        |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.816        |
|    learning_rate        | 5e-05        |
|    loss                 | 31.4         |
|    max_step             | 0            |
|    n_updates            | 4360         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | 0.000833     |
|    route_completion     | 0.474        |
|    std                  | 0.637        |
|    total_cost           | 16.9         |
|    value_loss           | 107          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | 314      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 219      |
|    time_elapsed    | 2173     |
|    total_timesteps | 1121280  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 380          |
|    ep_rew_mean          | 311          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 220          |
|    time_elapsed         | 2179         |
|    total_timesteps      | 1126400      |
| train/                  |              |
|    approx_kl            | 0.0057018567 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.616        |
|    learning_rate        | 5e-05        |
|    loss                 | 93.2         |
|    n_updates            | 4380         |
|    policy_gradient_loss | -0.000185    |
|    std                  | 0.635        |
|    value_loss           | 178          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.085        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 279          |
|    mean_reward          | 225          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.4712964    |
|    route_completion     | 0.434        |
|    success_rate         | 0.2          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1130000      |
| train/                  |              |
|    approx_kl            | 0.0057191188 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.17         |
|    clip_range           | 0.1          |
|    crash                | 0.271        |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.791        |
|    learning_rate        | 5e-05        |
|    loss                 | 43.5         |
|    max_step             | 0            |
|    n_updates            | 4400         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | 0.0032       |
|    route_completion     | 0.476        |
|    std                  | 0.634        |
|    total_cost           | 16.8         |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | 304      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 221      |
|    time_elapsed    | 2190     |
|    total_timesteps | 1131520  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 394         |
|    ep_rew_mean          | 309         |
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 222         |
|    time_elapsed         | 2196        |
|    total_timesteps      | 1136640     |
| train/                  |             |
|    approx_kl            | 0.008024741 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.775       |
|    learning_rate        | 5e-05       |
|    loss                 | 45.9        |
|    n_updates            | 4420        |
|    policy_gradient_loss | 0.00172     |
|    std                  | 0.633       |
|    value_loss           | 115         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.086       |
|    crash                | 0.242       |
|    max_step             | 0           |
|    mean_ep_length       | 164         |
|    mean_reward          | 168         |
|    num_episodes         | 5           |
|    out_of_road          | 0.914       |
|    raw_action           | 0.46781424  |
|    route_completion     | 0.436       |
|    success_rate         | 0.1         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1140000     |
| train/                  |             |
|    approx_kl            | 0.004291607 |
|    arrive_dest          | 0.149       |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.1         |
|    crash                | 0.268       |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.817       |
|    learning_rate        | 5e-05       |
|    loss                 | 33.8        |
|    max_step             | 0           |
|    n_updates            | 4440        |
|    out_of_road          | 0.851       |
|    policy_gradient_loss | -0.000116   |
|    route_completion     | 0.475       |
|    std                  | 0.634       |
|    total_cost           | 17          |
|    value_loss           | 113         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 394      |
|    ep_rew_mean     | 310      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 223      |
|    time_elapsed    | 2213     |
|    total_timesteps | 1141760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 398          |
|    ep_rew_mean          | 315          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 224          |
|    time_elapsed         | 2220         |
|    total_timesteps      | 1146880      |
| train/                  |              |
|    approx_kl            | 0.0047270916 |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.824        |
|    learning_rate        | 5e-05        |
|    loss                 | 46.8         |
|    n_updates            | 4460         |
|    policy_gradient_loss | -0.00105     |
|    std                  | 0.637        |
|    value_loss           | 97.4         |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0852      |
|    crash                | 0.245       |
|    max_step             | 0           |
|    mean_ep_length       | 115         |
|    mean_reward          | 142         |
|    num_episodes         | 5           |
|    out_of_road          | 0.915       |
|    raw_action           | 0.46774048  |
|    route_completion     | 0.435       |
|    success_rate         | 0.1         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1150000     |
| train/                  |             |
|    approx_kl            | 0.004331438 |
|    arrive_dest          | 0.15        |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.1         |
|    crash                | 0.266       |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.839       |
|    learning_rate        | 5e-05       |
|    loss                 | 21.2        |
|    max_step             | 0           |
|    n_updates            | 4480        |
|    out_of_road          | 0.85        |
|    policy_gradient_loss | 0.000603    |
|    route_completion     | 0.476       |
|    std                  | 0.636       |
|    total_cost           | 17          |
|    value_loss           | 76.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 406      |
|    ep_rew_mean     | 320      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 225      |
|    time_elapsed    | 2231     |
|    total_timesteps | 1152000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 411          |
|    ep_rew_mean          | 325          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 226          |
|    time_elapsed         | 2237         |
|    total_timesteps      | 1157120      |
| train/                  |              |
|    approx_kl            | 0.0024536247 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.89        |
|    explained_variance   | 0.851        |
|    learning_rate        | 5e-05        |
|    loss                 | 34.7         |
|    n_updates            | 4500         |
|    policy_gradient_loss | -0.000325    |
|    std                  | 0.635        |
|    value_loss           | 104          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0862      |
|    crash                | 0.245       |
|    max_step             | 0           |
|    mean_ep_length       | 146         |
|    mean_reward          | 143         |
|    num_episodes         | 5           |
|    out_of_road          | 0.914       |
|    raw_action           | 0.468148    |
|    route_completion     | 0.435       |
|    success_rate         | 0.1         |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 1160000     |
| train/                  |             |
|    approx_kl            | 0.007508911 |
|    arrive_dest          | 0.148       |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.867       |
|    learning_rate        | 5e-05       |
|    loss                 | 38.2        |
|    max_step             | 0           |
|    n_updates            | 4520        |
|    out_of_road          | 0.852       |
|    policy_gradient_loss | 0.00741     |
|    route_completion     | 0.475       |
|    std                  | 0.637       |
|    total_cost           | 16.9        |
|    value_loss           | 86.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 320      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 227      |
|    time_elapsed    | 2247     |
|    total_timesteps | 1162240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 412          |
|    ep_rew_mean          | 323          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 228          |
|    time_elapsed         | 2253         |
|    total_timesteps      | 1167360      |
| train/                  |              |
|    approx_kl            | 0.0027677657 |
|    clip_fraction        | 0.152        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.676        |
|    learning_rate        | 5e-05        |
|    loss                 | 59.3         |
|    n_updates            | 4540         |
|    policy_gradient_loss | 0.00108      |
|    std                  | 0.636        |
|    value_loss           | 146          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0855      |
|    crash                | 0.244       |
|    max_step             | 0           |
|    mean_ep_length       | 92.4        |
|    mean_reward          | 99.7        |
|    num_episodes         | 5           |
|    out_of_road          | 0.915       |
|    raw_action           | 0.46738097  |
|    route_completion     | 0.435       |
|    success_rate         | 0           |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 1170000     |
| train/                  |             |
|    approx_kl            | 0.003424222 |
|    arrive_dest          | 0.147       |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.1         |
|    crash                | 0.27        |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.805       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.7        |
|    max_step             | 0           |
|    n_updates            | 4560        |
|    out_of_road          | 0.853       |
|    policy_gradient_loss | 0.00464     |
|    route_completion     | 0.474       |
|    std                  | 0.634       |
|    total_cost           | 17          |
|    value_loss           | 95.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 321      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 229      |
|    time_elapsed    | 2269     |
|    total_timesteps | 1172480  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 420         |
|    ep_rew_mean          | 326         |
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 230         |
|    time_elapsed         | 2275        |
|    total_timesteps      | 1177600     |
| train/                  |             |
|    approx_kl            | 0.002857168 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.76        |
|    learning_rate        | 5e-05       |
|    loss                 | 60.9        |
|    n_updates            | 4580        |
|    policy_gradient_loss | 0.00211     |
|    std                  | 0.633       |
|    value_loss           | 132         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0847      |
|    crash                | 0.242       |
|    max_step             | 0           |
|    mean_ep_length       | 144         |
|    mean_reward          | 120         |
|    num_episodes         | 5           |
|    out_of_road          | 0.915       |
|    raw_action           | 0.46627066  |
|    route_completion     | 0.435       |
|    success_rate         | 0.2         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1180000     |
| train/                  |             |
|    approx_kl            | 0.012396571 |
|    arrive_dest          | 0.149       |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    crash                | 0.269       |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.816       |
|    learning_rate        | 5e-05       |
|    loss                 | 35.1        |
|    max_step             | 0           |
|    n_updates            | 4600        |
|    out_of_road          | 0.851       |
|    policy_gradient_loss | 0.00229     |
|    route_completion     | 0.476       |
|    std                  | 0.635       |
|    total_cost           | 18.1        |
|    value_loss           | 78.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 326      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 231      |
|    time_elapsed    | 2300     |
|    total_timesteps | 1182720  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 422         |
|    ep_rew_mean          | 339         |
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 232         |
|    time_elapsed         | 2306        |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.010251084 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.616       |
|    learning_rate        | 5e-05       |
|    loss                 | 84.2        |
|    n_updates            | 4620        |
|    policy_gradient_loss | 0.00355     |
|    std                  | 0.634       |
|    value_loss           | 158         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.084       |
|    crash                | 0.242       |
|    max_step             | 0           |
|    mean_ep_length       | 107         |
|    mean_reward          | 134         |
|    num_episodes         | 5           |
|    out_of_road          | 0.916       |
|    raw_action           | 0.46661112  |
|    route_completion     | 0.434       |
|    success_rate         | 0           |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 1190000     |
| train/                  |             |
|    approx_kl            | 0.004682316 |
|    arrive_dest          | 0.148       |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.818       |
|    learning_rate        | 5e-05       |
|    loss                 | 51.7        |
|    max_step             | 0           |
|    n_updates            | 4640        |
|    out_of_road          | 0.852       |
|    policy_gradient_loss | 0.000483    |
|    route_completion     | 0.477       |
|    std                  | 0.632       |
|    total_cost           | 18          |
|    value_loss           | 85.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 327      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 233      |
|    time_elapsed    | 2316     |
|    total_timesteps | 1192960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 415          |
|    ep_rew_mean          | 323          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 234          |
|    time_elapsed         | 2322         |
|    total_timesteps      | 1198080      |
| train/                  |              |
|    approx_kl            | 0.0010513962 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.714        |
|    learning_rate        | 5e-05        |
|    loss                 | 65           |
|    n_updates            | 4660         |
|    policy_gradient_loss | -0.000298    |
|    std                  | 0.632        |
|    value_loss           | 139          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.085        |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 193          |
|    mean_reward          | 171          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.4670495    |
|    route_completion     | 0.436        |
|    success_rate         | 0.2          |
|    total_cost           | 12.4         |
| time/                   |              |
|    total_timesteps      | 1200000      |
| train/                  |              |
|    approx_kl            | 0.0024583817 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.797        |
|    learning_rate        | 5e-05        |
|    loss                 | 94.2         |
|    max_step             | 0            |
|    n_updates            | 4680         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | -0.000422    |
|    route_completion     | 0.479        |
|    std                  | 0.629        |
|    total_cost           | 18           |
|    value_loss           | 130          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 235      |
|    time_elapsed    | 2336     |
|    total_timesteps | 1203200  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 393          |
|    ep_rew_mean          | 303          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 236          |
|    time_elapsed         | 2342         |
|    total_timesteps      | 1208320      |
| train/                  |              |
|    approx_kl            | 0.0013235069 |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.752        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.9         |
|    n_updates            | 4700         |
|    policy_gradient_loss | 0.00121      |
|    std                  | 0.63         |
|    value_loss           | 113          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.086        |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 144          |
|    mean_reward          | 180          |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.46721706   |
|    route_completion     | 0.437        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1210000      |
| train/                  |              |
|    approx_kl            | 0.0016639602 |
|    arrive_dest          | 0.147        |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.825        |
|    learning_rate        | 5e-05        |
|    loss                 | 56.5         |
|    max_step             | 0            |
|    n_updates            | 4720         |
|    out_of_road          | 0.853        |
|    policy_gradient_loss | 0.00332      |
|    route_completion     | 0.478        |
|    std                  | 0.628        |
|    total_cost           | 17.8         |
|    value_loss           | 107          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 405      |
|    ep_rew_mean     | 310      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 237      |
|    time_elapsed    | 2351     |
|    total_timesteps | 1213440  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 403          |
|    ep_rew_mean          | 314          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 238          |
|    time_elapsed         | 2357         |
|    total_timesteps      | 1218560      |
| train/                  |              |
|    approx_kl            | 0.0057371957 |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.723        |
|    learning_rate        | 5e-05        |
|    loss                 | 119          |
|    n_updates            | 4740         |
|    policy_gradient_loss | 0.00193      |
|    std                  | 0.627        |
|    value_loss           | 160          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0852      |
|    crash                | 0.241       |
|    max_step             | 0           |
|    mean_ep_length       | 90.4        |
|    mean_reward          | 104         |
|    num_episodes         | 5           |
|    out_of_road          | 0.915       |
|    raw_action           | 0.4669698   |
|    route_completion     | 0.436       |
|    success_rate         | 0           |
|    total_cost           | 12.2        |
| time/                   |             |
|    total_timesteps      | 1220000     |
| train/                  |             |
|    approx_kl            | 0.015796604 |
|    arrive_dest          | 0.146       |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.77        |
|    learning_rate        | 5e-05       |
|    loss                 | 60.7        |
|    max_step             | 0           |
|    n_updates            | 4760        |
|    out_of_road          | 0.854       |
|    policy_gradient_loss | -0.000344   |
|    route_completion     | 0.478       |
|    std                  | 0.627       |
|    total_cost           | 17.9        |
|    value_loss           | 132         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 322      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 239      |
|    time_elapsed    | 2368     |
|    total_timesteps | 1223680  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 401         |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 240         |
|    time_elapsed         | 2373        |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.007953095 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.767       |
|    learning_rate        | 5e-05       |
|    loss                 | 43.3        |
|    n_updates            | 4780        |
|    policy_gradient_loss | 0.0034      |
|    std                  | 0.629       |
|    value_loss           | 90.3        |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0862       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 110          |
|    mean_reward          | 106          |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.4673882    |
|    route_completion     | 0.435        |
|    success_rate         | 0.3          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 1230000      |
| train/                  |              |
|    approx_kl            | 0.0013591446 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.268        |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.835        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.4         |
|    max_step             | 0            |
|    n_updates            | 4800         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | 0.000654     |
|    route_completion     | 0.478        |
|    std                  | 0.629        |
|    total_cost           | 17.8         |
|    value_loss           | 73.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 317      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 241      |
|    time_elapsed    | 2386     |
|    total_timesteps | 1233920  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 402          |
|    ep_rew_mean          | 323          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 242          |
|    time_elapsed         | 2392         |
|    total_timesteps      | 1239040      |
| train/                  |              |
|    approx_kl            | 0.0017956335 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.701        |
|    learning_rate        | 5e-05        |
|    loss                 | 57.8         |
|    n_updates            | 4820         |
|    policy_gradient_loss | -0.000475    |
|    std                  | 0.628        |
|    value_loss           | 174          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0871       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 159          |
|    mean_reward          | 199          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.46826074   |
|    route_completion     | 0.436        |
|    success_rate         | 0.2          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1240000      |
| train/                  |              |
|    approx_kl            | 0.0023481953 |
|    arrive_dest          | 0.148        |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    crash                | 0.268        |
|    entropy_loss         | -1.87        |
|    explained_variance   | 0.797        |
|    learning_rate        | 5e-05        |
|    loss                 | 49.6         |
|    max_step             | 0            |
|    n_updates            | 4840         |
|    out_of_road          | 0.852        |
|    policy_gradient_loss | 0.000759     |
|    route_completion     | 0.479        |
|    std                  | 0.627        |
|    total_cost           | 17.9         |
|    value_loss           | 121          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 243      |
|    time_elapsed    | 2407     |
|    total_timesteps | 1244160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 390          |
|    ep_rew_mean          | 318          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 244          |
|    time_elapsed         | 2413         |
|    total_timesteps      | 1249280      |
| train/                  |              |
|    approx_kl            | 0.0017252238 |
|    clip_fraction        | 0.189        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.732        |
|    learning_rate        | 5e-05        |
|    loss                 | 103          |
|    n_updates            | 4860         |
|    policy_gradient_loss | 0.00214      |
|    std                  | 0.627        |
|    value_loss           | 168          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0896       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 171          |
|    mean_reward          | 161          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.46709257   |
|    route_completion     | 0.438        |
|    success_rate         | 0.4          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1250000      |
| train/                  |              |
|    approx_kl            | 0.0032298167 |
|    arrive_dest          | 0.15         |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.82         |
|    learning_rate        | 5e-05        |
|    loss                 | 78.3         |
|    max_step             | 0            |
|    n_updates            | 4880         |
|    out_of_road          | 0.85         |
|    policy_gradient_loss | 0.00155      |
|    route_completion     | 0.48         |
|    std                  | 0.626        |
|    total_cost           | 18.2         |
|    value_loss           | 107          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 245      |
|    time_elapsed    | 2436     |
|    total_timesteps | 1254400  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 381          |
|    ep_rew_mean          | 315          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 246          |
|    time_elapsed         | 2442         |
|    total_timesteps      | 1259520      |
| train/                  |              |
|    approx_kl            | 0.0015661804 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.731        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.1         |
|    n_updates            | 4900         |
|    policy_gradient_loss | 0.000695     |
|    std                  | 0.628        |
|    value_loss           | 175          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0889       |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 110          |
|    mean_reward          | 114          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.4670163    |
|    route_completion     | 0.437        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1260000      |
| train/                  |              |
|    approx_kl            | 0.0066270307 |
|    arrive_dest          | 0.151        |
|    clip_fraction        | 0.228        |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.824        |
|    learning_rate        | 5e-05        |
|    loss                 | 42.2         |
|    max_step             | 0            |
|    n_updates            | 4920         |
|    out_of_road          | 0.849        |
|    policy_gradient_loss | 0.00522      |
|    route_completion     | 0.482        |
|    std                  | 0.628        |
|    total_cost           | 18.1         |
|    value_loss           | 112          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 247      |
|    time_elapsed    | 2456     |
|    total_timesteps | 1264640  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 351         |
|    ep_rew_mean          | 292         |
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 248         |
|    time_elapsed         | 2463        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.005982948 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.568       |
|    learning_rate        | 5e-05       |
|    loss                 | 117         |
|    n_updates            | 4940        |
|    policy_gradient_loss | 0.000371    |
|    std                  | 0.628       |
|    value_loss           | 282         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0882       |
|    crash                | 0.238        |
|    max_step             | 0            |
|    mean_ep_length       | 93.4         |
|    mean_reward          | 108          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.4671715    |
|    route_completion     | 0.436        |
|    success_rate         | 0.3          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 1270000      |
| train/                  |              |
|    approx_kl            | 0.0018948267 |
|    arrive_dest          | 0.154        |
|    clip_fraction        | 0.0894       |
|    clip_range           | 0.1          |
|    crash                | 0.263        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.77         |
|    learning_rate        | 5e-05        |
|    loss                 | 64           |
|    max_step             | 0            |
|    n_updates            | 4960         |
|    out_of_road          | 0.846        |
|    policy_gradient_loss | -0.00168     |
|    route_completion     | 0.484        |
|    std                  | 0.628        |
|    total_cost           | 18           |
|    value_loss           | 136          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 249      |
|    time_elapsed    | 2478     |
|    total_timesteps | 1274880  |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0875       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 171          |
|    mean_reward          | 138          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.46727347   |
|    route_completion     | 0.437        |
|    success_rate         | 0.2          |
|    total_cost           | 12.4         |
| time/                   |              |
|    total_timesteps      | 1280000      |
| train/                  |              |
|    approx_kl            | 0.0052188886 |
|    arrive_dest          | 0.156        |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.1          |
|    crash                | 0.263        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.738        |
|    learning_rate        | 5e-05        |
|    loss                 | 67.5         |
|    max_step             | 0            |
|    n_updates            | 4980         |
|    out_of_road          | 0.844        |
|    policy_gradient_loss | 0.000605     |
|    route_completion     | 0.486        |
|    std                  | 0.628        |
|    total_cost           | 18           |
|    value_loss           | 191          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 250      |
|    time_elapsed    | 2492     |
|    total_timesteps | 1280000  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 296          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 251          |
|    time_elapsed         | 2498         |
|    total_timesteps      | 1285120      |
| train/                  |              |
|    approx_kl            | 0.0060542654 |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.693        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.8         |
|    n_updates            | 5000         |
|    policy_gradient_loss | 0.00145      |
|    std                  | 0.628        |
|    value_loss           | 160          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0884      |
|    crash                | 0.239       |
|    max_step             | 0           |
|    mean_ep_length       | 164         |
|    mean_reward          | 216         |
|    num_episodes         | 5           |
|    out_of_road          | 0.912       |
|    raw_action           | 0.467065    |
|    route_completion     | 0.438       |
|    success_rate         | 0.3         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1290000     |
| train/                  |             |
|    approx_kl            | 0.006271909 |
|    arrive_dest          | 0.158       |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.1         |
|    crash                | 0.264       |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.727       |
|    learning_rate        | 5e-05       |
|    loss                 | 78.6        |
|    max_step             | 0           |
|    n_updates            | 5020        |
|    out_of_road          | 0.842       |
|    policy_gradient_loss | -1.88e-05   |
|    route_completion     | 0.488       |
|    std                  | 0.627       |
|    total_cost           | 17.9        |
|    value_loss           | 122         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 252      |
|    time_elapsed    | 2509     |
|    total_timesteps | 1290240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 359         |
|    ep_rew_mean          | 302         |
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 253         |
|    time_elapsed         | 2515        |
|    total_timesteps      | 1295360     |
| train/                  |             |
|    approx_kl            | 0.004561286 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.622       |
|    learning_rate        | 5e-05       |
|    loss                 | 81.9        |
|    n_updates            | 5040        |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.628       |
|    value_loss           | 179         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0892       |
|    crash                | 0.24         |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.4673045    |
|    route_completion     | 0.439        |
|    success_rate         | 0.2          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1300000      |
| train/                  |              |
|    approx_kl            | 0.0024508692 |
|    arrive_dest          | 0.158        |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.71         |
|    learning_rate        | 5e-05        |
|    loss                 | 50.8         |
|    max_step             | 0            |
|    n_updates            | 5060         |
|    out_of_road          | 0.842        |
|    policy_gradient_loss | -0.00125     |
|    route_completion     | 0.49         |
|    std                  | 0.629        |
|    total_cost           | 17.8         |
|    value_loss           | 155          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 254      |
|    time_elapsed    | 2526     |
|    total_timesteps | 1300480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 294          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 255          |
|    time_elapsed         | 2533         |
|    total_timesteps      | 1305600      |
| train/                  |              |
|    approx_kl            | 0.0024875437 |
|    clip_fraction        | 0.243        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.698        |
|    learning_rate        | 5e-05        |
|    loss                 | 62.4         |
|    n_updates            | 5080         |
|    policy_gradient_loss | 0.00638      |
|    std                  | 0.628        |
|    value_loss           | 172          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0901      |
|    crash                | 0.241       |
|    max_step             | 0           |
|    mean_ep_length       | 162         |
|    mean_reward          | 214         |
|    num_episodes         | 5           |
|    out_of_road          | 0.91        |
|    raw_action           | 0.46742     |
|    route_completion     | 0.44        |
|    success_rate         | 0.3         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1310000     |
| train/                  |             |
|    approx_kl            | 0.002004776 |
|    arrive_dest          | 0.16        |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.811       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.1        |
|    max_step             | 0           |
|    n_updates            | 5100        |
|    out_of_road          | 0.84        |
|    policy_gradient_loss | -0.000806   |
|    route_completion     | 0.49        |
|    std                  | 0.627       |
|    total_cost           | 17.8        |
|    value_loss           | 108         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 256      |
|    time_elapsed    | 2544     |
|    total_timesteps | 1310720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 339          |
|    ep_rew_mean          | 289          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 257          |
|    time_elapsed         | 2550         |
|    total_timesteps      | 1315840      |
| train/                  |              |
|    approx_kl            | 0.0028631398 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.751        |
|    learning_rate        | 5e-05        |
|    loss                 | 119          |
|    n_updates            | 5120         |
|    policy_gradient_loss | 0.000179     |
|    std                  | 0.626        |
|    value_loss           | 187          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0909       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 175          |
|    mean_reward          | 197          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4675059    |
|    route_completion     | 0.441        |
|    success_rate         | 0.2          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1320000      |
| train/                  |              |
|    approx_kl            | 0.0029763936 |
|    arrive_dest          | 0.161        |
|    clip_fraction        | 0.0774       |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.782        |
|    learning_rate        | 5e-05        |
|    loss                 | 77.8         |
|    max_step             | 0            |
|    n_updates            | 5140         |
|    out_of_road          | 0.839        |
|    policy_gradient_loss | -0.00181     |
|    route_completion     | 0.491        |
|    std                  | 0.627        |
|    total_cost           | 17.9         |
|    value_loss           | 166          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 258      |
|    time_elapsed    | 2562     |
|    total_timesteps | 1320960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 290          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 259          |
|    time_elapsed         | 2568         |
|    total_timesteps      | 1326080      |
| train/                  |              |
|    approx_kl            | 0.0012251697 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.664        |
|    learning_rate        | 5e-05        |
|    loss                 | 101          |
|    n_updates            | 5160         |
|    policy_gradient_loss | -0.001       |
|    std                  | 0.627        |
|    value_loss           | 173          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0917      |
|    crash                | 0.242       |
|    max_step             | 0           |
|    mean_ep_length       | 154         |
|    mean_reward          | 202         |
|    num_episodes         | 5           |
|    out_of_road          | 0.908       |
|    raw_action           | 0.47081244  |
|    route_completion     | 0.442       |
|    success_rate         | 0.2         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1330000     |
| train/                  |             |
|    approx_kl            | 0.004698272 |
|    arrive_dest          | 0.161       |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.1         |
|    crash                | 0.268       |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.735       |
|    learning_rate        | 5e-05       |
|    loss                 | 56.3        |
|    max_step             | 0           |
|    n_updates            | 5180        |
|    out_of_road          | 0.839       |
|    policy_gradient_loss | 0.00109     |
|    route_completion     | 0.491       |
|    std                  | 0.628       |
|    total_cost           | 19.3        |
|    value_loss           | 119         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 260      |
|    time_elapsed    | 2599     |
|    total_timesteps | 1331200  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 291          |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 261          |
|    time_elapsed         | 2605         |
|    total_timesteps      | 1336320      |
| train/                  |              |
|    approx_kl            | 0.0011979131 |
|    clip_fraction        | 0.0775       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.74         |
|    learning_rate        | 5e-05        |
|    loss                 | 75.5         |
|    n_updates            | 5200         |
|    policy_gradient_loss | -0.000835    |
|    std                  | 0.63         |
|    value_loss           | 153          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.091       |
|    crash                | 0.245       |
|    max_step             | 0           |
|    mean_ep_length       | 169         |
|    mean_reward          | 182         |
|    num_episodes         | 5           |
|    out_of_road          | 0.909       |
|    raw_action           | 0.47074     |
|    route_completion     | 0.442       |
|    success_rate         | 0.4         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1340000     |
| train/                  |             |
|    approx_kl            | 0.004688829 |
|    arrive_dest          | 0.166       |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.1         |
|    crash                | 0.267       |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.791       |
|    learning_rate        | 5e-05       |
|    loss                 | 64.2        |
|    max_step             | 0           |
|    n_updates            | 5220        |
|    out_of_road          | 0.834       |
|    policy_gradient_loss | -0.00125    |
|    route_completion     | 0.494       |
|    std                  | 0.629       |
|    total_cost           | 19.7        |
|    value_loss           | 141         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    fps             | 511      |
|    iterations      | 262      |
|    time_elapsed    | 2620     |
|    total_timesteps | 1341440  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 343         |
|    ep_rew_mean          | 291         |
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 263         |
|    time_elapsed         | 2626        |
|    total_timesteps      | 1346560     |
| train/                  |             |
|    approx_kl            | 0.005612294 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.657       |
|    learning_rate        | 5e-05       |
|    loss                 | 131         |
|    n_updates            | 5240        |
|    policy_gradient_loss | -0.000547   |
|    std                  | 0.629       |
|    value_loss           | 220         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0904       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 116          |
|    mean_reward          | 136          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47093835   |
|    route_completion     | 0.442        |
|    success_rate         | 0.3          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1350000      |
| train/                  |              |
|    approx_kl            | 0.0022914158 |
|    arrive_dest          | 0.169        |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    crash                | 0.267        |
|    entropy_loss         | -1.86        |
|    explained_variance   | 0.799        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.5         |
|    max_step             | 0            |
|    n_updates            | 5260         |
|    out_of_road          | 0.831        |
|    policy_gradient_loss | 0.0029       |
|    route_completion     | 0.496        |
|    std                  | 0.628        |
|    total_cost           | 19.8         |
|    value_loss           | 135          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 264      |
|    time_elapsed    | 2637     |
|    total_timesteps | 1351680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 297          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 265          |
|    time_elapsed         | 2644         |
|    total_timesteps      | 1356800      |
| train/                  |              |
|    approx_kl            | 0.0025590863 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.482        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.9         |
|    n_updates            | 5280         |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.624        |
|    value_loss           | 160          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0912       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 146          |
|    mean_reward          | 196          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47079405   |
|    route_completion     | 0.443        |
|    success_rate         | 0.2          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 1360000      |
| train/                  |              |
|    approx_kl            | 0.0013458821 |
|    arrive_dest          | 0.169        |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.734        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.2         |
|    max_step             | 0            |
|    n_updates            | 5300         |
|    out_of_road          | 0.831        |
|    policy_gradient_loss | 6.41e-05     |
|    route_completion     | 0.497        |
|    std                  | 0.626        |
|    total_cost           | 19.8         |
|    value_loss           | 131          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 512      |
|    iterations      | 266      |
|    time_elapsed    | 2656     |
|    total_timesteps | 1361920  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 346          |
|    ep_rew_mean          | 302          |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 267          |
|    time_elapsed         | 2662         |
|    total_timesteps      | 1367040      |
| train/                  |              |
|    approx_kl            | 0.0021172955 |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.85        |
|    explained_variance   | 0.746        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.3         |
|    n_updates            | 5320         |
|    policy_gradient_loss | 0.000571     |
|    std                  | 0.625        |
|    value_loss           | 121          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.092        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 169          |
|    mean_reward          | 213          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.4711613    |
|    route_completion     | 0.444        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1370000      |
| train/                  |              |
|    approx_kl            | 0.0023473375 |
|    arrive_dest          | 0.168        |
|    clip_fraction        | 0.0905       |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.84        |
|    explained_variance   | 0.715        |
|    learning_rate        | 5e-05        |
|    loss                 | 48.7         |
|    max_step             | 0            |
|    n_updates            | 5340         |
|    out_of_road          | 0.832        |
|    policy_gradient_loss | -0.00146     |
|    route_completion     | 0.495        |
|    std                  | 0.621        |
|    total_cost           | 19.7         |
|    value_loss           | 184          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 300      |
| time/              |          |
|    fps             | 513      |
|    iterations      | 268      |
|    time_elapsed    | 2672     |
|    total_timesteps | 1372160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 331          |
|    ep_rew_mean          | 291          |
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 269          |
|    time_elapsed         | 2677         |
|    total_timesteps      | 1377280      |
| train/                  |              |
|    approx_kl            | 0.0020655827 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.84        |
|    explained_variance   | 0.636        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.7         |
|    n_updates            | 5360         |
|    policy_gradient_loss | 0.00026      |
|    std                  | 0.621        |
|    value_loss           | 153          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0928       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 197          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.4710146    |
|    route_completion     | 0.446        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1380000      |
| train/                  |              |
|    approx_kl            | 0.0020183418 |
|    arrive_dest          | 0.167        |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.657        |
|    learning_rate        | 5e-05        |
|    loss                 | 127          |
|    max_step             | 0            |
|    n_updates            | 5380         |
|    out_of_road          | 0.833        |
|    policy_gradient_loss | -0.000924    |
|    route_completion     | 0.495        |
|    std                  | 0.621        |
|    total_cost           | 19.6         |
|    value_loss           | 252          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 270      |
|    time_elapsed    | 2688     |
|    total_timesteps | 1382400  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 331         |
|    ep_rew_mean          | 304         |
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 271         |
|    time_elapsed         | 2695        |
|    total_timesteps      | 1387520     |
| train/                  |             |
|    approx_kl            | 0.010667874 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.691       |
|    learning_rate        | 5e-05       |
|    loss                 | 51.5        |
|    n_updates            | 5400        |
|    policy_gradient_loss | 0.00257     |
|    std                  | 0.619       |
|    value_loss           | 188         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0921       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 127          |
|    mean_reward          | 146          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47108027   |
|    route_completion     | 0.446        |
|    success_rate         | 0.1          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1390000      |
| train/                  |              |
|    approx_kl            | 0.0042569702 |
|    arrive_dest          | 0.167        |
|    clip_fraction        | 0.093        |
|    clip_range           | 0.1          |
|    crash                | 0.265        |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.691        |
|    learning_rate        | 5e-05        |
|    loss                 | 104          |
|    max_step             | 0            |
|    n_updates            | 5420         |
|    out_of_road          | 0.833        |
|    policy_gradient_loss | -0.00136     |
|    route_completion     | 0.494        |
|    std                  | 0.618        |
|    total_cost           | 19.5         |
|    value_loss           | 217          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 299      |
| time/              |          |
|    fps             | 514      |
|    iterations      | 272      |
|    time_elapsed    | 2704     |
|    total_timesteps | 1392640  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 325          |
|    ep_rew_mean          | 298          |
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 273          |
|    time_elapsed         | 2709         |
|    total_timesteps      | 1397760      |
| train/                  |              |
|    approx_kl            | 0.0014757726 |
|    clip_fraction        | 0.0938       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.626        |
|    learning_rate        | 5e-05        |
|    loss                 | 113          |
|    n_updates            | 5440         |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.617        |
|    value_loss           | 276          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0914       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 93.2         |
|    mean_reward          | 102          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47099122   |
|    route_completion     | 0.445        |
|    success_rate         | 0.1          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1400000      |
| train/                  |              |
|    approx_kl            | 0.0017531838 |
|    arrive_dest          | 0.167        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.266        |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.764        |
|    learning_rate        | 5e-05        |
|    loss                 | 64.2         |
|    max_step             | 0            |
|    n_updates            | 5460         |
|    out_of_road          | 0.833        |
|    policy_gradient_loss | 6.18e-05     |
|    route_completion     | 0.494        |
|    std                  | 0.616        |
|    total_cost           | 19.4         |
|    value_loss           | 161          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 274      |
|    time_elapsed    | 2721     |
|    total_timesteps | 1402880  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 335          |
|    ep_rew_mean          | 307          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 275          |
|    time_elapsed         | 2727         |
|    total_timesteps      | 1408000      |
| train/                  |              |
|    approx_kl            | 0.0030220249 |
|    clip_fraction        | 0.117        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.751        |
|    learning_rate        | 5e-05        |
|    loss                 | 97.8         |
|    n_updates            | 5480         |
|    policy_gradient_loss | -0.0017      |
|    std                  | 0.617        |
|    value_loss           | 179          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0908     |
|    crash                | 0.247      |
|    max_step             | 0          |
|    mean_ep_length       | 113        |
|    mean_reward          | 128        |
|    num_episodes         | 5          |
|    out_of_road          | 0.909      |
|    raw_action           | 0.47117472 |
|    route_completion     | 0.445      |
|    success_rate         | 0.1        |
|    total_cost           | 11.9       |
| time/                   |            |
|    total_timesteps      | 1410000    |
| train/                  |            |
|    approx_kl            | 0.00339376 |
|    arrive_dest          | 0.167      |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.1        |
|    crash                | 0.265      |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.795      |
|    learning_rate        | 5e-05      |
|    loss                 | 86.7       |
|    max_step             | 0          |
|    n_updates            | 5500       |
|    out_of_road          | 0.833      |
|    policy_gradient_loss | 0.00365    |
|    route_completion     | 0.494      |
|    std                  | 0.617      |
|    total_cost           | 19.3       |
|    value_loss           | 149        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | 313      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 276      |
|    time_elapsed    | 2737     |
|    total_timesteps | 1413120  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 326          |
|    ep_rew_mean          | 300          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 277          |
|    time_elapsed         | 2744         |
|    total_timesteps      | 1418240      |
| train/                  |              |
|    approx_kl            | 0.0047798143 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.65         |
|    learning_rate        | 5e-05        |
|    loss                 | 142          |
|    n_updates            | 5520         |
|    policy_gradient_loss | -0.00064     |
|    std                  | 0.614        |
|    value_loss           | 229          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0901       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 166          |
|    mean_reward          | 150          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47058654   |
|    route_completion     | 0.445        |
|    success_rate         | 0.1          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1420000      |
| train/                  |              |
|    approx_kl            | 0.0020542827 |
|    arrive_dest          | 0.168        |
|    clip_fraction        | 0.0995       |
|    clip_range           | 0.1          |
|    crash                | 0.263        |
|    entropy_loss         | -1.81        |
|    explained_variance   | 0.721        |
|    learning_rate        | 5e-05        |
|    loss                 | 61.5         |
|    max_step             | 0            |
|    n_updates            | 5540         |
|    out_of_road          | 0.832        |
|    policy_gradient_loss | -0.00254     |
|    route_completion     | 0.494        |
|    std                  | 0.611        |
|    total_cost           | 19.3         |
|    value_loss           | 213          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 515      |
|    iterations      | 278      |
|    time_elapsed    | 2759     |
|    total_timesteps | 1423360  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 319          |
|    ep_rew_mean          | 290          |
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 279          |
|    time_elapsed         | 2765         |
|    total_timesteps      | 1428480      |
| train/                  |              |
|    approx_kl            | 0.0016314622 |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.68         |
|    learning_rate        | 5e-05        |
|    loss                 | 102          |
|    n_updates            | 5560         |
|    policy_gradient_loss | -0.000226    |
|    std                  | 0.61         |
|    value_loss           | 264          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0895       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47084123   |
|    route_completion     | 0.445        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1430000      |
| train/                  |              |
|    approx_kl            | 0.0013079096 |
|    arrive_dest          | 0.169        |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.1          |
|    crash                | 0.264        |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.697        |
|    learning_rate        | 5e-05        |
|    loss                 | 119          |
|    max_step             | 0            |
|    n_updates            | 5580         |
|    out_of_road          | 0.831        |
|    policy_gradient_loss | -0.00159     |
|    route_completion     | 0.495        |
|    std                  | 0.609        |
|    total_cost           | 19.3         |
|    value_loss           | 213          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 516      |
|    iterations      | 280      |
|    time_elapsed    | 2776     |
|    total_timesteps | 1433600  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 305          |
|    ep_rew_mean          | 273          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 281          |
|    time_elapsed         | 2782         |
|    total_timesteps      | 1438720      |
| train/                  |              |
|    approx_kl            | 0.0023925197 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0.642        |
|    learning_rate        | 5e-05        |
|    loss                 | 178          |
|    n_updates            | 5600         |
|    policy_gradient_loss | -0.00142     |
|    std                  | 0.609        |
|    value_loss           | 282          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0889      |
|    crash                | 0.247       |
|    max_step             | 0           |
|    mean_ep_length       | 121         |
|    mean_reward          | 149         |
|    num_episodes         | 5           |
|    out_of_road          | 0.911       |
|    raw_action           | 0.4709619   |
|    route_completion     | 0.445       |
|    success_rate         | 0           |
|    total_cost           | 11.9        |
| time/                   |             |
|    total_timesteps      | 1440000     |
| train/                  |             |
|    approx_kl            | 0.005311756 |
|    arrive_dest          | 0.168       |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.1         |
|    crash                | 0.263       |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.747       |
|    learning_rate        | 5e-05       |
|    loss                 | 88.4        |
|    max_step             | 0           |
|    n_updates            | 5620        |
|    out_of_road          | 0.832       |
|    policy_gradient_loss | 0.000484    |
|    route_completion     | 0.494       |
|    std                  | 0.609       |
|    total_cost           | 19.1        |
|    value_loss           | 169         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 282      |
|    time_elapsed    | 2792     |
|    total_timesteps | 1443840  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 308          |
|    ep_rew_mean          | 270          |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 283          |
|    time_elapsed         | 2798         |
|    total_timesteps      | 1448960      |
| train/                  |              |
|    approx_kl            | 0.0037854079 |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.768        |
|    learning_rate        | 5e-05        |
|    loss                 | 117          |
|    n_updates            | 5640         |
|    policy_gradient_loss | 0.000193     |
|    std                  | 0.608        |
|    value_loss           | 186          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0883       |
|    crash                | 0.246        |
|    max_step             | 0            |
|    mean_ep_length       | 106          |
|    mean_reward          | 123          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.47141537   |
|    route_completion     | 0.444        |
|    success_rate         | 0.3          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 1450000      |
| train/                  |              |
|    approx_kl            | 0.0046543246 |
|    arrive_dest          | 0.171        |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.59         |
|    learning_rate        | 5e-05        |
|    loss                 | 101          |
|    max_step             | 0            |
|    n_updates            | 5660         |
|    out_of_road          | 0.829        |
|    policy_gradient_loss | 0.00332      |
|    route_completion     | 0.496        |
|    std                  | 0.607        |
|    total_cost           | 19.1         |
|    value_loss           | 208          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 299      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 284      |
|    time_elapsed    | 2809     |
|    total_timesteps | 1454080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 321          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 285          |
|    time_elapsed         | 2815         |
|    total_timesteps      | 1459200      |
| train/                  |              |
|    approx_kl            | 0.0021989509 |
|    clip_fraction        | 0.0969       |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.637        |
|    learning_rate        | 5e-05        |
|    loss                 | 103          |
|    n_updates            | 5680         |
|    policy_gradient_loss | -0.000865    |
|    std                  | 0.606        |
|    value_loss           | 189          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.089        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 141          |
|    mean_reward          | 139          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.47138894   |
|    route_completion     | 0.445        |
|    success_rate         | 0.4          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1460000      |
| train/                  |              |
|    approx_kl            | 0.0014269861 |
|    arrive_dest          | 0.174        |
|    clip_fraction        | 0.161        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.764        |
|    learning_rate        | 5e-05        |
|    loss                 | 63.1         |
|    max_step             | 0            |
|    n_updates            | 5700         |
|    out_of_road          | 0.826        |
|    policy_gradient_loss | 0.000644     |
|    route_completion     | 0.497        |
|    std                  | 0.607        |
|    total_cost           | 19           |
|    value_loss           | 142          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    fps             | 517      |
|    iterations      | 286      |
|    time_elapsed    | 2828     |
|    total_timesteps | 1464320  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 333         |
|    ep_rew_mean          | 285         |
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 287         |
|    time_elapsed         | 2833        |
|    total_timesteps      | 1469440     |
| train/                  |             |
|    approx_kl            | 0.024113175 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.744       |
|    learning_rate        | 5e-05       |
|    loss                 | 58.6        |
|    n_updates            | 5720        |
|    policy_gradient_loss | 0.00137     |
|    std                  | 0.609       |
|    value_loss           | 151         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0898       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 207          |
|    mean_reward          | 268          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47165412   |
|    route_completion     | 0.446        |
|    success_rate         | 0.2          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1470000      |
| train/                  |              |
|    approx_kl            | 0.0012262182 |
|    arrive_dest          | 0.174        |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    crash                | 0.263        |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.881        |
|    learning_rate        | 5e-05        |
|    loss                 | 49           |
|    max_step             | 0            |
|    n_updates            | 5740         |
|    out_of_road          | 0.826        |
|    policy_gradient_loss | 0.00223      |
|    route_completion     | 0.497        |
|    std                  | 0.608        |
|    total_cost           | 18.9         |
|    value_loss           | 91.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 344      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 288      |
|    time_elapsed    | 2844     |
|    total_timesteps | 1474560  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 341         |
|    ep_rew_mean          | 291         |
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 289         |
|    time_elapsed         | 2851        |
|    total_timesteps      | 1479680     |
| train/                  |             |
|    approx_kl            | 0.008338416 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.727       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.3        |
|    n_updates            | 5760        |
|    policy_gradient_loss | 0.00105     |
|    std                  | 0.61        |
|    value_loss           | 161         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0905       |
|    crash                | 0.245        |
|    max_step             | 0            |
|    mean_ep_length       | 208          |
|    mean_reward          | 240          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4718514    |
|    route_completion     | 0.448        |
|    success_rate         | 0.3          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1480000      |
| train/                  |              |
|    approx_kl            | 0.0020278604 |
|    arrive_dest          | 0.176        |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.6          |
|    learning_rate        | 5e-05        |
|    loss                 | 117          |
|    max_step             | 0            |
|    n_updates            | 5780         |
|    out_of_road          | 0.824        |
|    policy_gradient_loss | -0.00113     |
|    route_completion     | 0.497        |
|    std                  | 0.61         |
|    total_cost           | 18.8         |
|    value_loss           | 296          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 290      |
|    time_elapsed    | 2863     |
|    total_timesteps | 1484800  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 349          |
|    ep_rew_mean          | 298          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 291          |
|    time_elapsed         | 2869         |
|    total_timesteps      | 1489920      |
| train/                  |              |
|    approx_kl            | 0.0019416444 |
|    clip_fraction        | 0.197        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.591        |
|    learning_rate        | 5e-05        |
|    loss                 | 80.5         |
|    n_updates            | 5800         |
|    policy_gradient_loss | 0.00234      |
|    std                  | 0.609        |
|    value_loss           | 199          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0926       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 202          |
|    mean_reward          | 259          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.4721414    |
|    route_completion     | 0.449        |
|    success_rate         | 0.3          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1490000      |
| train/                  |              |
|    approx_kl            | 0.0016351227 |
|    arrive_dest          | 0.176        |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.826        |
|    learning_rate        | 5e-05        |
|    loss                 | 30.7         |
|    max_step             | 0            |
|    n_updates            | 5820         |
|    out_of_road          | 0.824        |
|    policy_gradient_loss | 0.00231      |
|    route_completion     | 0.497        |
|    std                  | 0.608        |
|    total_cost           | 18.7         |
|    value_loss           | 98           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 292      |
|    time_elapsed    | 2880     |
|    total_timesteps | 1495040  |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.092       |
|    crash                | 0.243       |
|    max_step             | 0           |
|    mean_ep_length       | 168         |
|    mean_reward          | 204         |
|    num_episodes         | 5           |
|    out_of_road          | 0.908       |
|    raw_action           | 0.4723419   |
|    route_completion     | 0.45        |
|    success_rate         | 0.1         |
|    total_cost           | 12          |
| time/                   |             |
|    total_timesteps      | 1500000     |
| train/                  |             |
|    approx_kl            | 0.017866831 |
|    arrive_dest          | 0.176       |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.1         |
|    crash                | 0.26        |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.776       |
|    learning_rate        | 5e-05       |
|    loss                 | 79.4        |
|    max_step             | 0           |
|    n_updates            | 5840        |
|    out_of_road          | 0.824       |
|    policy_gradient_loss | 0.00104     |
|    route_completion     | 0.496       |
|    std                  | 0.608       |
|    total_cost           | 18.6        |
|    value_loss           | 136         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 518      |
|    iterations      | 293      |
|    time_elapsed    | 2890     |
|    total_timesteps | 1500160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 357          |
|    ep_rew_mean          | 308          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 294          |
|    time_elapsed         | 2896         |
|    total_timesteps      | 1505280      |
| train/                  |              |
|    approx_kl            | 0.0018368416 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.79        |
|    explained_variance   | 0.759        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.1         |
|    n_updates            | 5860         |
|    policy_gradient_loss | -0.000162    |
|    std                  | 0.607        |
|    value_loss           | 150          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.094        |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 203          |
|    mean_reward          | 198          |
|    num_episodes         | 5            |
|    out_of_road          | 0.906        |
|    raw_action           | 0.4722085    |
|    route_completion     | 0.451        |
|    success_rate         | 0.4          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1510000      |
| train/                  |              |
|    approx_kl            | 0.0018398924 |
|    arrive_dest          | 0.177        |
|    clip_fraction        | 0.16         |
|    clip_range           | 0.1          |
|    crash                | 0.261        |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.798        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.1         |
|    max_step             | 0            |
|    n_updates            | 5880         |
|    out_of_road          | 0.823        |
|    policy_gradient_loss | 0.000624     |
|    route_completion     | 0.497        |
|    std                  | 0.606        |
|    total_cost           | 18.5         |
|    value_loss           | 162          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 310      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 295      |
|    time_elapsed    | 2909     |
|    total_timesteps | 1510400  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 361          |
|    ep_rew_mean          | 313          |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 296          |
|    time_elapsed         | 2915         |
|    total_timesteps      | 1515520      |
| train/                  |              |
|    approx_kl            | 0.0017259909 |
|    clip_fraction        | 0.236        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 51           |
|    n_updates            | 5900         |
|    policy_gradient_loss | 0.00323      |
|    std                  | 0.607        |
|    value_loss           | 156          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0934       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 113          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.47215194   |
|    route_completion     | 0.451        |
|    success_rate         | 0            |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1520000      |
| train/                  |              |
|    approx_kl            | 0.0026061852 |
|    arrive_dest          | 0.176        |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.1          |
|    crash                | 0.261        |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.708        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.2         |
|    max_step             | 0            |
|    n_updates            | 5920         |
|    out_of_road          | 0.824        |
|    policy_gradient_loss | -0.00157     |
|    route_completion     | 0.499        |
|    std                  | 0.605        |
|    total_cost           | 18.4         |
|    value_loss           | 167          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 312      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 297      |
|    time_elapsed    | 2926     |
|    total_timesteps | 1520640  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 311          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 298          |
|    time_elapsed         | 2932         |
|    total_timesteps      | 1525760      |
| train/                  |              |
|    approx_kl            | 0.0048160315 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.707        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.5         |
|    n_updates            | 5940         |
|    policy_gradient_loss | -0.00215     |
|    std                  | 0.604        |
|    value_loss           | 242          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0941       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 295          |
|    mean_reward          | 228          |
|    num_episodes         | 5            |
|    out_of_road          | 0.906        |
|    raw_action           | 0.47206756   |
|    route_completion     | 0.453        |
|    success_rate         | 0.2          |
|    total_cost           | 12.4         |
| time/                   |              |
|    total_timesteps      | 1530000      |
| train/                  |              |
|    approx_kl            | 0.0018945711 |
|    arrive_dest          | 0.176        |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    crash                | 0.261        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5e-05        |
|    loss                 | 87.5         |
|    max_step             | 0            |
|    n_updates            | 5960         |
|    out_of_road          | 0.824        |
|    policy_gradient_loss | -0.00275     |
|    route_completion     | 0.499        |
|    std                  | 0.606        |
|    total_cost           | 18.4         |
|    value_loss           | 164          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 360      |
|    ep_rew_mean     | 312      |
| time/              |          |
|    fps             | 519      |
|    iterations      | 299      |
|    time_elapsed    | 2944     |
|    total_timesteps | 1530880  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 377          |
|    ep_rew_mean          | 327          |
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 300          |
|    time_elapsed         | 2950         |
|    total_timesteps      | 1536000      |
| train/                  |              |
|    approx_kl            | 0.0009514303 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.753        |
|    learning_rate        | 5e-05        |
|    loss                 | 62.1         |
|    n_updates            | 5980         |
|    policy_gradient_loss | 0.000501     |
|    std                  | 0.606        |
|    value_loss           | 179          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0935       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 92.2         |
|    mean_reward          | 94           |
|    num_episodes         | 5            |
|    out_of_road          | 0.906        |
|    raw_action           | 0.47179073   |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1540000      |
| train/                  |              |
|    approx_kl            | 0.0016688567 |
|    arrive_dest          | 0.175        |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    crash                | 0.261        |
|    entropy_loss         | -1.78        |
|    explained_variance   | 0.827        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.1         |
|    max_step             | 0            |
|    n_updates            | 6000         |
|    out_of_road          | 0.825        |
|    policy_gradient_loss | -0.000934    |
|    route_completion     | 0.498        |
|    std                  | 0.606        |
|    total_cost           | 18.3         |
|    value_loss           | 145          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 312      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 301      |
|    time_elapsed    | 2960     |
|    total_timesteps | 1541120  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 358          |
|    ep_rew_mean          | 312          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 302          |
|    time_elapsed         | 2966         |
|    total_timesteps      | 1546240      |
| train/                  |              |
|    approx_kl            | 0.0018480005 |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.706        |
|    learning_rate        | 5e-05        |
|    loss                 | 81.8         |
|    n_updates            | 6020         |
|    policy_gradient_loss | -0.0015      |
|    std                  | 0.605        |
|    value_loss           | 187          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0929       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 121          |
|    mean_reward          | 160          |
|    num_episodes         | 5            |
|    out_of_road          | 0.907        |
|    raw_action           | 0.47155127   |
|    route_completion     | 0.453        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1550000      |
| train/                  |              |
|    approx_kl            | 0.0030909807 |
|    arrive_dest          | 0.175        |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.72         |
|    learning_rate        | 5e-05        |
|    loss                 | 103          |
|    max_step             | 0            |
|    n_updates            | 6040         |
|    out_of_road          | 0.825        |
|    policy_gradient_loss | 0.000141     |
|    route_completion     | 0.498        |
|    std                  | 0.603        |
|    total_cost           | 18.2         |
|    value_loss           | 164          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    fps             | 520      |
|    iterations      | 303      |
|    time_elapsed    | 2978     |
|    total_timesteps | 1551360  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 351          |
|    ep_rew_mean          | 304          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 304          |
|    time_elapsed         | 2984         |
|    total_timesteps      | 1556480      |
| train/                  |              |
|    approx_kl            | 0.0046800305 |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.67         |
|    learning_rate        | 5e-05        |
|    loss                 | 116          |
|    n_updates            | 6060         |
|    policy_gradient_loss | -0.000203    |
|    std                  | 0.602        |
|    value_loss           | 238          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0923       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 211          |
|    mean_reward          | 195          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47178477   |
|    route_completion     | 0.453        |
|    success_rate         | 0.3          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1560000      |
| train/                  |              |
|    approx_kl            | 0.0072881384 |
|    arrive_dest          | 0.178        |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.777        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.1         |
|    max_step             | 0            |
|    n_updates            | 6080         |
|    out_of_road          | 0.822        |
|    policy_gradient_loss | 0.000141     |
|    route_completion     | 0.499        |
|    std                  | 0.602        |
|    total_cost           | 18.1         |
|    value_loss           | 141          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 305      |
|    time_elapsed    | 2996     |
|    total_timesteps | 1561600  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 354          |
|    ep_rew_mean          | 309          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 306          |
|    time_elapsed         | 3002         |
|    total_timesteps      | 1566720      |
| train/                  |              |
|    approx_kl            | 0.0016956853 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.66         |
|    learning_rate        | 5e-05        |
|    loss                 | 60.7         |
|    n_updates            | 6100         |
|    policy_gradient_loss | -0.000462    |
|    std                  | 0.603        |
|    value_loss           | 215          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0917       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 123          |
|    mean_reward          | 139          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47149482   |
|    route_completion     | 0.453        |
|    success_rate         | 0.2          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1570000      |
| train/                  |              |
|    approx_kl            | 0.0016403623 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.734        |
|    learning_rate        | 5e-05        |
|    loss                 | 136          |
|    max_step             | 0            |
|    n_updates            | 6120         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00267      |
|    route_completion     | 0.501        |
|    std                  | 0.603        |
|    total_cost           | 18.5         |
|    value_loss           | 210          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 346      |
|    ep_rew_mean     | 304      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 307      |
|    time_elapsed    | 3016     |
|    total_timesteps | 1571840  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 337          |
|    ep_rew_mean          | 294          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 308          |
|    time_elapsed         | 3021         |
|    total_timesteps      | 1576960      |
| train/                  |              |
|    approx_kl            | 0.0054526133 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.77         |
|    learning_rate        | 5e-05        |
|    loss                 | 63.8         |
|    n_updates            | 6140         |
|    policy_gradient_loss | -0.00138     |
|    std                  | 0.604        |
|    value_loss           | 159          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0911       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 167          |
|    mean_reward          | 136          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4710833    |
|    route_completion     | 0.453        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1580000      |
| train/                  |              |
|    approx_kl            | 0.0020656993 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.207        |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.825        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.8         |
|    max_step             | 0            |
|    n_updates            | 6160         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00524      |
|    route_completion     | 0.502        |
|    std                  | 0.605        |
|    total_cost           | 18.5         |
|    value_loss           | 123          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 309      |
|    time_elapsed    | 3036     |
|    total_timesteps | 1582080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 344          |
|    ep_rew_mean          | 299          |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 310          |
|    time_elapsed         | 3041         |
|    total_timesteps      | 1587200      |
| train/                  |              |
|    approx_kl            | 0.0041826395 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.758        |
|    learning_rate        | 5e-05        |
|    loss                 | 99.2         |
|    n_updates            | 6180         |
|    policy_gradient_loss | 0.000135     |
|    std                  | 0.604        |
|    value_loss           | 161          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0906       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 158          |
|    mean_reward          | 217          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47081503   |
|    route_completion     | 0.454        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1590000      |
| train/                  |              |
|    approx_kl            | 0.0011200393 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.192        |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.747        |
|    learning_rate        | 5e-05        |
|    loss                 | 115          |
|    max_step             | 0            |
|    n_updates            | 6200         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00214      |
|    route_completion     | 0.502        |
|    std                  | 0.604        |
|    total_cost           | 18.4         |
|    value_loss           | 198          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 521      |
|    iterations      | 311      |
|    time_elapsed    | 3053     |
|    total_timesteps | 1592320  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 328          |
|    ep_rew_mean          | 284          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 312          |
|    time_elapsed         | 3059         |
|    total_timesteps      | 1597440      |
| train/                  |              |
|    approx_kl            | 0.0023354373 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.79         |
|    learning_rate        | 5e-05        |
|    loss                 | 125          |
|    n_updates            | 6220         |
|    policy_gradient_loss | -1.41e-05    |
|    std                  | 0.604        |
|    value_loss           | 230          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.09         |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 93.8         |
|    mean_reward          | 104          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.47093225   |
|    route_completion     | 0.453        |
|    success_rate         | 0            |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 1600000      |
| train/                  |              |
|    approx_kl            | 0.0021791242 |
|    arrive_dest          | 0.179        |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.256        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.696        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.3         |
|    max_step             | 0            |
|    n_updates            | 6240         |
|    out_of_road          | 0.821        |
|    policy_gradient_loss | -0.000692    |
|    route_completion     | 0.503        |
|    std                  | 0.603        |
|    total_cost           | 18.4         |
|    value_loss           | 167          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 313      |
|    time_elapsed    | 3068     |
|    total_timesteps | 1602560  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 342          |
|    ep_rew_mean          | 291          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 314          |
|    time_elapsed         | 3074         |
|    total_timesteps      | 1607680      |
| train/                  |              |
|    approx_kl            | 0.0016691333 |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.742        |
|    learning_rate        | 5e-05        |
|    loss                 | 65.5         |
|    n_updates            | 6260         |
|    policy_gradient_loss | 0.00127      |
|    std                  | 0.604        |
|    value_loss           | 180          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0919       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 363          |
|    mean_reward          | 256          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47061846   |
|    route_completion     | 0.455        |
|    success_rate         | 0.4          |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 1610000      |
| train/                  |              |
|    approx_kl            | 0.0023871977 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.22         |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.808        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.7         |
|    max_step             | 0            |
|    n_updates            | 6280         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00374      |
|    route_completion     | 0.504        |
|    std                  | 0.605        |
|    total_cost           | 18.6         |
|    value_loss           | 128          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 352      |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 315      |
|    time_elapsed    | 3088     |
|    total_timesteps | 1612800  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 344          |
|    ep_rew_mean          | 292          |
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 316          |
|    time_elapsed         | 3093         |
|    total_timesteps      | 1617920      |
| train/                  |              |
|    approx_kl            | 0.0021462683 |
|    clip_fraction        | 0.112        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.77        |
|    explained_variance   | 0.661        |
|    learning_rate        | 5e-05        |
|    loss                 | 92.7         |
|    n_updates            | 6300         |
|    policy_gradient_loss | -0.00075     |
|    std                  | 0.604        |
|    value_loss           | 197          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0914       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 146          |
|    mean_reward          | 200          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47055775   |
|    route_completion     | 0.456        |
|    success_rate         | 0.1          |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 1620000      |
| train/                  |              |
|    approx_kl            | 0.0023658585 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.212        |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.816        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.1         |
|    max_step             | 0            |
|    n_updates            | 6320         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00319      |
|    route_completion     | 0.504        |
|    std                  | 0.603        |
|    total_cost           | 18.5         |
|    value_loss           | 144          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 522      |
|    iterations      | 317      |
|    time_elapsed    | 3103     |
|    total_timesteps | 1623040  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 344         |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 318         |
|    time_elapsed         | 3109        |
|    total_timesteps      | 1628160     |
| train/                  |             |
|    approx_kl            | 0.022718482 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.75        |
|    learning_rate        | 5e-05       |
|    loss                 | 64          |
|    n_updates            | 6340        |
|    policy_gradient_loss | 0.00204     |
|    std                  | 0.603       |
|    value_loss           | 149         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0908       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 135          |
|    mean_reward          | 116          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4704944    |
|    route_completion     | 0.455        |
|    success_rate         | 0.1          |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 1630000      |
| train/                  |              |
|    approx_kl            | 0.0023479569 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.257        |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.783        |
|    learning_rate        | 5e-05        |
|    loss                 | 58.5         |
|    max_step             | 0            |
|    n_updates            | 6360         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00389      |
|    route_completion     | 0.505        |
|    std                  | 0.603        |
|    total_cost           | 18.4         |
|    value_loss           | 133          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 319      |
|    time_elapsed    | 3120     |
|    total_timesteps | 1633280  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 364          |
|    ep_rew_mean          | 312          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 320          |
|    time_elapsed         | 3125         |
|    total_timesteps      | 1638400      |
| train/                  |              |
|    approx_kl            | 0.0021584867 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.783        |
|    learning_rate        | 5e-05        |
|    loss                 | 82.5         |
|    n_updates            | 6380         |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.603        |
|    value_loss           | 152          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0915      |
|    crash                | 0.241       |
|    max_step             | 0           |
|    mean_ep_length       | 263         |
|    mean_reward          | 190         |
|    num_episodes         | 5           |
|    out_of_road          | 0.909       |
|    raw_action           | 0.47051153  |
|    route_completion     | 0.456       |
|    success_rate         | 0.2         |
|    total_cost           | 12.9        |
| time/                   |             |
|    total_timesteps      | 1640000     |
| train/                  |             |
|    approx_kl            | 0.005084415 |
|    arrive_dest          | 0.18        |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.1         |
|    crash                | 0.259       |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.805       |
|    learning_rate        | 5e-05       |
|    loss                 | 60.3        |
|    max_step             | 0           |
|    n_updates            | 6400        |
|    out_of_road          | 0.82        |
|    policy_gradient_loss | 0.000762    |
|    route_completion     | 0.505       |
|    std                  | 0.602       |
|    total_cost           | 18.3        |
|    value_loss           | 187         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 321      |
|    time_elapsed    | 3138     |
|    total_timesteps | 1643520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 343          |
|    ep_rew_mean          | 301          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 322          |
|    time_elapsed         | 3144         |
|    total_timesteps      | 1648640      |
| train/                  |              |
|    approx_kl            | 0.0015008502 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.656        |
|    learning_rate        | 5e-05        |
|    loss                 | 124          |
|    n_updates            | 6420         |
|    policy_gradient_loss | -0.000292    |
|    std                  | 0.601        |
|    value_loss           | 321          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0909       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 136          |
|    mean_reward          | 165          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.47035292   |
|    route_completion     | 0.456        |
|    success_rate         | 0.1          |
|    total_cost           | 12.8         |
| time/                   |              |
|    total_timesteps      | 1650000      |
| train/                  |              |
|    approx_kl            | 0.0029779056 |
|    arrive_dest          | 0.181        |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.777        |
|    learning_rate        | 5e-05        |
|    loss                 | 92.5         |
|    max_step             | 0            |
|    n_updates            | 6440         |
|    out_of_road          | 0.819        |
|    policy_gradient_loss | 0.000761     |
|    route_completion     | 0.505        |
|    std                  | 0.602        |
|    total_cost           | 18.2         |
|    value_loss           | 166          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 524      |
|    iterations      | 323      |
|    time_elapsed    | 3155     |
|    total_timesteps | 1653760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 332          |
|    ep_rew_mean          | 294          |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 324          |
|    time_elapsed         | 3161         |
|    total_timesteps      | 1658880      |
| train/                  |              |
|    approx_kl            | 0.0035178666 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.76        |
|    explained_variance   | 0.609        |
|    learning_rate        | 5e-05        |
|    loss                 | 175          |
|    n_updates            | 6460         |
|    policy_gradient_loss | 0.000252     |
|    std                  | 0.601        |
|    value_loss           | 283          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0916       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 268          |
|    mean_reward          | 123          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47037572   |
|    route_completion     | 0.456        |
|    success_rate         | 0.1          |
|    total_cost           | 13           |
| time/                   |              |
|    total_timesteps      | 1660000      |
| train/                  |              |
|    approx_kl            | 0.0076820715 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.21         |
|    clip_range           | 0.1          |
|    crash                | 0.258        |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.794        |
|    learning_rate        | 5e-05        |
|    loss                 | 51.8         |
|    max_step             | 0            |
|    n_updates            | 6480         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00292      |
|    route_completion     | 0.506        |
|    std                  | 0.6          |
|    total_cost           | 18.2         |
|    value_loss           | 145          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 290      |
| time/              |          |
|    fps             | 523      |
|    iterations      | 325      |
|    time_elapsed    | 3176     |
|    total_timesteps | 1664000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 287         |
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 326         |
|    time_elapsed         | 3181        |
|    total_timesteps      | 1669120     |
| train/                  |             |
|    approx_kl            | 0.010909859 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.712       |
|    learning_rate        | 5e-05       |
|    loss                 | 106         |
|    n_updates            | 6500        |
|    policy_gradient_loss | 0.00051     |
|    std                  | 0.6         |
|    value_loss           | 206         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.091        |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 115          |
|    mean_reward          | 137          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4705713    |
|    route_completion     | 0.456        |
|    success_rate         | 0            |
|    total_cost           | 13           |
| time/                   |              |
|    total_timesteps      | 1670000      |
| train/                  |              |
|    approx_kl            | 0.0030092015 |
|    arrive_dest          | 0.178        |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.709        |
|    learning_rate        | 5e-05        |
|    loss                 | 133          |
|    max_step             | 0            |
|    n_updates            | 6520         |
|    out_of_road          | 0.822        |
|    policy_gradient_loss | 0.00134      |
|    route_completion     | 0.506        |
|    std                  | 0.598        |
|    total_cost           | 18.1         |
|    value_loss           | 232          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 305      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 524      |
|    iterations      | 327      |
|    time_elapsed    | 3190     |
|    total_timesteps | 1674240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 316         |
|    ep_rew_mean          | 284         |
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 328         |
|    time_elapsed         | 3196        |
|    total_timesteps      | 1679360     |
| train/                  |             |
|    approx_kl            | 0.006641973 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.763       |
|    learning_rate        | 5e-05       |
|    loss                 | 82.7        |
|    n_updates            | 6540        |
|    policy_gradient_loss | -0.000372   |
|    std                  | 0.597       |
|    value_loss           | 178         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0917       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 185          |
|    mean_reward          | 253          |
|    num_episodes         | 5            |
|    out_of_road          | 0.908        |
|    raw_action           | 0.47058702   |
|    route_completion     | 0.458        |
|    success_rate         | 0.1          |
|    total_cost           | 12.9         |
| time/                   |              |
|    total_timesteps      | 1680000      |
| train/                  |              |
|    approx_kl            | 0.0068819597 |
|    arrive_dest          | 0.177        |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.706        |
|    learning_rate        | 5e-05        |
|    loss                 | 103          |
|    max_step             | 0            |
|    n_updates            | 6560         |
|    out_of_road          | 0.823        |
|    policy_gradient_loss | -0.000954    |
|    route_completion     | 0.506        |
|    std                  | 0.595        |
|    total_cost           | 18           |
|    value_loss           | 230          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 525      |
|    iterations      | 329      |
|    time_elapsed    | 3207     |
|    total_timesteps | 1684480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 308          |
|    ep_rew_mean          | 281          |
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 330          |
|    time_elapsed         | 3213         |
|    total_timesteps      | 1689600      |
| train/                  |              |
|    approx_kl            | 0.0014378894 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.763        |
|    learning_rate        | 5e-05        |
|    loss                 | 101          |
|    n_updates            | 6580         |
|    policy_gradient_loss | -0.000957    |
|    std                  | 0.596        |
|    value_loss           | 187          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0911       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 191          |
|    mean_reward          | 244          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4702543    |
|    route_completion     | 0.459        |
|    success_rate         | 0            |
|    total_cost           | 13           |
| time/                   |              |
|    total_timesteps      | 1690000      |
| train/                  |              |
|    approx_kl            | 0.0057233977 |
|    arrive_dest          | 0.176        |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.73         |
|    learning_rate        | 5e-05        |
|    loss                 | 93.8         |
|    max_step             | 0            |
|    n_updates            | 6600         |
|    out_of_road          | 0.824        |
|    policy_gradient_loss | -0.000427    |
|    route_completion     | 0.506        |
|    std                  | 0.596        |
|    total_cost           | 17.9         |
|    value_loss           | 204          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    fps             | 525      |
|    iterations      | 331      |
|    time_elapsed    | 3223     |
|    total_timesteps | 1694720  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 287         |
|    ep_rew_mean          | 264         |
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 332         |
|    time_elapsed         | 3228        |
|    total_timesteps      | 1699840     |
| train/                  |             |
|    approx_kl            | 0.006448619 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.629       |
|    learning_rate        | 5e-05       |
|    loss                 | 190         |
|    n_updates            | 6620        |
|    policy_gradient_loss | -0.000202   |
|    std                  | 0.596       |
|    value_loss           | 279         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0906       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 122          |
|    mean_reward          | 147          |
|    num_episodes         | 5            |
|    out_of_road          | 0.909        |
|    raw_action           | 0.4702691    |
|    route_completion     | 0.459        |
|    success_rate         | 0            |
|    total_cost           | 12.9         |
| time/                   |              |
|    total_timesteps      | 1700000      |
| train/                  |              |
|    approx_kl            | 0.0016529728 |
|    arrive_dest          | 0.175        |
|    clip_fraction        | 0.138        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.705        |
|    learning_rate        | 5e-05        |
|    loss                 | 85.2         |
|    max_step             | 0            |
|    n_updates            | 6640         |
|    out_of_road          | 0.825        |
|    policy_gradient_loss | 0.000124     |
|    route_completion     | 0.506        |
|    std                  | 0.595        |
|    total_cost           | 17.8         |
|    value_loss           | 204          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 295      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 333      |
|    time_elapsed    | 3238     |
|    total_timesteps | 1704960  |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0901       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 107          |
|    mean_reward          | 129          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.4704628    |
|    route_completion     | 0.459        |
|    success_rate         | 0.2          |
|    total_cost           | 12.8         |
| time/                   |              |
|    total_timesteps      | 1710000      |
| train/                  |              |
|    approx_kl            | 0.0036105707 |
|    arrive_dest          | 0.177        |
|    clip_fraction        | 0.195        |
|    clip_range           | 0.1          |
|    crash                | 0.262        |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.729        |
|    learning_rate        | 5e-05        |
|    loss                 | 87.4         |
|    max_step             | 0            |
|    n_updates            | 6660         |
|    out_of_road          | 0.823        |
|    policy_gradient_loss | 0.000531     |
|    route_completion     | 0.507        |
|    std                  | 0.597        |
|    total_cost           | 17.8         |
|    value_loss           | 194          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 301      |
|    ep_rew_mean     | 278      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 334      |
|    time_elapsed    | 3250     |
|    total_timesteps | 1710080  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 297          |
|    ep_rew_mean          | 279          |
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 335          |
|    time_elapsed         | 3256         |
|    total_timesteps      | 1715200      |
| train/                  |              |
|    approx_kl            | 0.0017642168 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.752        |
|    learning_rate        | 5e-05        |
|    loss                 | 62           |
|    n_updates            | 6680         |
|    policy_gradient_loss | -0.000877    |
|    std                  | 0.596        |
|    value_loss           | 174          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0895       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 138          |
|    mean_reward          | 135          |
|    num_episodes         | 5            |
|    out_of_road          | 0.91         |
|    raw_action           | 0.46953645   |
|    route_completion     | 0.458        |
|    success_rate         | 0.2          |
|    total_cost           | 12.8         |
| time/                   |              |
|    total_timesteps      | 1720000      |
| train/                  |              |
|    approx_kl            | 0.0039225896 |
|    arrive_dest          | 0.178        |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    crash                | 0.26         |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.688        |
|    learning_rate        | 5e-05        |
|    loss                 | 77           |
|    max_step             | 0            |
|    n_updates            | 6700         |
|    out_of_road          | 0.822        |
|    policy_gradient_loss | 0.00177      |
|    route_completion     | 0.509        |
|    std                  | 0.594        |
|    total_cost           | 17.9         |
|    value_loss           | 182          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 336      |
|    time_elapsed    | 3269     |
|    total_timesteps | 1720320  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 306          |
|    ep_rew_mean          | 285          |
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 337          |
|    time_elapsed         | 3275         |
|    total_timesteps      | 1725440      |
| train/                  |              |
|    approx_kl            | 0.0013597588 |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.707        |
|    learning_rate        | 5e-05        |
|    loss                 | 53.4         |
|    n_updates            | 6720         |
|    policy_gradient_loss | -0.000955    |
|    std                  | 0.595        |
|    value_loss           | 200          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.089        |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 77.6         |
|    mean_reward          | 78.5         |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.46945763   |
|    route_completion     | 0.457        |
|    success_rate         | 0.4          |
|    total_cost           | 12.8         |
| time/                   |              |
|    total_timesteps      | 1730000      |
| train/                  |              |
|    approx_kl            | 0.0017661536 |
|    arrive_dest          | 0.182        |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.605        |
|    learning_rate        | 5e-05        |
|    loss                 | 88.8         |
|    max_step             | 0            |
|    n_updates            | 6740         |
|    out_of_road          | 0.818        |
|    policy_gradient_loss | -0.000833    |
|    route_completion     | 0.51         |
|    std                  | 0.596        |
|    total_cost           | 17.9         |
|    value_loss           | 231          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 338      |
|    time_elapsed    | 3287     |
|    total_timesteps | 1730560  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 311         |
|    ep_rew_mean          | 289         |
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 339         |
|    time_elapsed         | 3293        |
|    total_timesteps      | 1735680     |
| train/                  |             |
|    approx_kl            | 0.006402454 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.713       |
|    learning_rate        | 5e-05       |
|    loss                 | 98.1        |
|    n_updates            | 6760        |
|    policy_gradient_loss | 0.000353    |
|    std                  | 0.595       |
|    value_loss           | 234         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0885       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 102          |
|    mean_reward          | 128          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.46936172   |
|    route_completion     | 0.456        |
|    success_rate         | 0.2          |
|    total_cost           | 12.7         |
| time/                   |              |
|    total_timesteps      | 1740000      |
| train/                  |              |
|    approx_kl            | 0.0036342316 |
|    arrive_dest          | 0.183        |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.1          |
|    crash                | 0.259        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.695        |
|    learning_rate        | 5e-05        |
|    loss                 | 99.3         |
|    max_step             | 0            |
|    n_updates            | 6780         |
|    out_of_road          | 0.817        |
|    policy_gradient_loss | -0.00068     |
|    route_completion     | 0.511        |
|    std                  | 0.595        |
|    total_cost           | 17.9         |
|    value_loss           | 189          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 526      |
|    iterations      | 340      |
|    time_elapsed    | 3304     |
|    total_timesteps | 1740800  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 301          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 341          |
|    time_elapsed         | 3310         |
|    total_timesteps      | 1745920      |
| train/                  |              |
|    approx_kl            | 0.0012472977 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.682        |
|    learning_rate        | 5e-05        |
|    loss                 | 105          |
|    n_updates            | 6800         |
|    policy_gradient_loss | -0.000385    |
|    std                  | 0.595        |
|    value_loss           | 247          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.088        |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 85.8         |
|    mean_reward          | 85.7         |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.46940625   |
|    route_completion     | 0.455        |
|    success_rate         | 0            |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 1750000      |
| train/                  |              |
|    approx_kl            | 0.0015895705 |
|    arrive_dest          | 0.182        |
|    clip_fraction        | 0.188        |
|    clip_range           | 0.1          |
|    crash                | 0.257        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.75         |
|    learning_rate        | 5e-05        |
|    loss                 | 59.2         |
|    max_step             | 0            |
|    n_updates            | 6820         |
|    out_of_road          | 0.818        |
|    policy_gradient_loss | 0.00272      |
|    route_completion     | 0.511        |
|    std                  | 0.594        |
|    total_cost           | 17.9         |
|    value_loss           | 179          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 342      |
|    time_elapsed    | 3321     |
|    total_timesteps | 1751040  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 298          |
|    ep_rew_mean          | 276          |
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 343          |
|    time_elapsed         | 3327         |
|    total_timesteps      | 1756160      |
| train/                  |              |
|    approx_kl            | 0.0032677464 |
|    clip_fraction        | 0.261        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.622        |
|    learning_rate        | 5e-05        |
|    loss                 | 74.5         |
|    n_updates            | 6840         |
|    policy_gradient_loss | 0.00593      |
|    std                  | 0.594        |
|    value_loss           | 252          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0886       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 126          |
|    mean_reward          | 160          |
|    num_episodes         | 5            |
|    out_of_road          | 0.911        |
|    raw_action           | 0.46944323   |
|    route_completion     | 0.455        |
|    success_rate         | 0.1          |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 1760000      |
| train/                  |              |
|    approx_kl            | 0.0018226609 |
|    arrive_dest          | 0.181        |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    crash                | 0.257        |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.709        |
|    learning_rate        | 5e-05        |
|    loss                 | 130          |
|    max_step             | 0            |
|    n_updates            | 6860         |
|    out_of_road          | 0.819        |
|    policy_gradient_loss | -0.000616    |
|    route_completion     | 0.512        |
|    std                  | 0.594        |
|    total_cost           | 17.8         |
|    value_loss           | 211          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 285      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 344      |
|    time_elapsed    | 3339     |
|    total_timesteps | 1761280  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 304          |
|    ep_rew_mean          | 277          |
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 345          |
|    time_elapsed         | 3345         |
|    total_timesteps      | 1766400      |
| train/                  |              |
|    approx_kl            | 0.0024022975 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.765        |
|    learning_rate        | 5e-05        |
|    loss                 | 72.1         |
|    n_updates            | 6880         |
|    policy_gradient_loss | 0.000462     |
|    std                  | 0.594        |
|    value_loss           | 185          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0881       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 199          |
|    mean_reward          | 256          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.4696183    |
|    route_completion     | 0.457        |
|    success_rate         | 0.1          |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 1770000      |
| train/                  |              |
|    approx_kl            | 0.0017431595 |
|    arrive_dest          | 0.181        |
|    clip_fraction        | 0.18         |
|    clip_range           | 0.1          |
|    crash                | 0.255        |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.769        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.7         |
|    max_step             | 0            |
|    n_updates            | 6900         |
|    out_of_road          | 0.819        |
|    policy_gradient_loss | 0.00206      |
|    route_completion     | 0.512        |
|    std                  | 0.594        |
|    total_cost           | 17.8         |
|    value_loss           | 183          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 294      |
|    ep_rew_mean     | 277      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 346      |
|    time_elapsed    | 3356     |
|    total_timesteps | 1771520  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 306          |
|    ep_rew_mean          | 286          |
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 347          |
|    time_elapsed         | 3362         |
|    total_timesteps      | 1776640      |
| train/                  |              |
|    approx_kl            | 0.0016047682 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.667        |
|    learning_rate        | 5e-05        |
|    loss                 | 161          |
|    n_updates            | 6920         |
|    policy_gradient_loss | -0.00119     |
|    std                  | 0.594        |
|    value_loss           | 247          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0876       |
|    crash                | 0.244        |
|    max_step             | 0            |
|    mean_ep_length       | 112          |
|    mean_reward          | 121          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.46983555   |
|    route_completion     | 0.456        |
|    success_rate         | 0            |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 1780000      |
| train/                  |              |
|    approx_kl            | 0.0021464597 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.1          |
|    crash                | 0.257        |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.779        |
|    learning_rate        | 5e-05        |
|    loss                 | 66.7         |
|    max_step             | 0            |
|    n_updates            | 6940         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | 0.00259      |
|    route_completion     | 0.512        |
|    std                  | 0.594        |
|    total_cost           | 17.8         |
|    value_loss           | 149          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 348      |
|    time_elapsed    | 3377     |
|    total_timesteps | 1781760  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 296          |
|    ep_rew_mean          | 280          |
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 349          |
|    time_elapsed         | 3382         |
|    total_timesteps      | 1786880      |
| train/                  |              |
|    approx_kl            | 0.0012039362 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.607        |
|    learning_rate        | 5e-05        |
|    loss                 | 167          |
|    n_updates            | 6960         |
|    policy_gradient_loss | 0.000679     |
|    std                  | 0.593        |
|    value_loss           | 297          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0883       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 187          |
|    mean_reward          | 192          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.46939453   |
|    route_completion     | 0.457        |
|    success_rate         | 0.1          |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 1790000      |
| train/                  |              |
|    approx_kl            | 0.0060195825 |
|    arrive_dest          | 0.179        |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.1          |
|    crash                | 0.256        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.674        |
|    learning_rate        | 5e-05        |
|    loss                 | 96           |
|    max_step             | 0            |
|    n_updates            | 6980         |
|    out_of_road          | 0.821        |
|    policy_gradient_loss | 0.00218      |
|    route_completion     | 0.511        |
|    std                  | 0.59         |
|    total_cost           | 17.8         |
|    value_loss           | 187          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 350      |
|    time_elapsed    | 3395     |
|    total_timesteps | 1792000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 312         |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 351         |
|    time_elapsed         | 3401        |
|    total_timesteps      | 1797120     |
| train/                  |             |
|    approx_kl            | 0.006207787 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.709       |
|    learning_rate        | 5e-05       |
|    loss                 | 101         |
|    n_updates            | 7000        |
|    policy_gradient_loss | 0.00096     |
|    std                  | 0.591       |
|    value_loss           | 244         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0878       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 153          |
|    mean_reward          | 165          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.46908775   |
|    route_completion     | 0.457        |
|    success_rate         | 0.1          |
|    total_cost           | 12.6         |
| time/                   |              |
|    total_timesteps      | 1800000      |
| train/                  |              |
|    approx_kl            | 0.0025000693 |
|    arrive_dest          | 0.179        |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    crash                | 0.256        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.708        |
|    learning_rate        | 5e-05        |
|    loss                 | 126          |
|    max_step             | 0            |
|    n_updates            | 7020         |
|    out_of_road          | 0.821        |
|    policy_gradient_loss | -0.00124     |
|    route_completion     | 0.512        |
|    std                  | 0.59         |
|    total_cost           | 17.7         |
|    value_loss           | 185          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    fps             | 527      |
|    iterations      | 352      |
|    time_elapsed    | 3413     |
|    total_timesteps | 1802240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 316         |
|    ep_rew_mean          | 297         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 353         |
|    time_elapsed         | 3419        |
|    total_timesteps      | 1807360     |
| train/                  |             |
|    approx_kl            | 0.002148872 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.635       |
|    learning_rate        | 5e-05       |
|    loss                 | 165         |
|    n_updates            | 7040        |
|    policy_gradient_loss | -0.000922   |
|    std                  | 0.592       |
|    value_loss           | 233         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0873       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 154          |
|    mean_reward          | 164          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.46894056   |
|    route_completion     | 0.458        |
|    success_rate         | 0.1          |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 1810000      |
| train/                  |              |
|    approx_kl            | 0.0021151723 |
|    arrive_dest          | 0.179        |
|    clip_fraction        | 0.237        |
|    clip_range           | 0.1          |
|    crash                | 0.254        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.748        |
|    learning_rate        | 5e-05        |
|    loss                 | 60.9         |
|    max_step             | 0            |
|    n_updates            | 7060         |
|    out_of_road          | 0.821        |
|    policy_gradient_loss | 0.00485      |
|    route_completion     | 0.512        |
|    std                  | 0.592        |
|    total_cost           | 17.7         |
|    value_loss           | 167          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 305      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    fps             | 528      |
|    iterations      | 354      |
|    time_elapsed    | 3430     |
|    total_timesteps | 1812480  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 318         |
|    ep_rew_mean          | 298         |
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 355         |
|    time_elapsed         | 3436        |
|    total_timesteps      | 1817600     |
| train/                  |             |
|    approx_kl            | 0.008216942 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.636       |
|    learning_rate        | 5e-05       |
|    loss                 | 126         |
|    n_updates            | 7080        |
|    policy_gradient_loss | 0.000277    |
|    std                  | 0.591       |
|    value_loss           | 250         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0868       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 110          |
|    mean_reward          | 146          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.4688247    |
|    route_completion     | 0.458        |
|    success_rate         | 0.3          |
|    total_cost           | 12.5         |
| time/                   |              |
|    total_timesteps      | 1820000      |
| train/                  |              |
|    approx_kl            | 0.0020565973 |
|    arrive_dest          | 0.181        |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.1          |
|    crash                | 0.253        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.792        |
|    learning_rate        | 5e-05        |
|    loss                 | 73.3         |
|    max_step             | 0            |
|    n_updates            | 7100         |
|    out_of_road          | 0.819        |
|    policy_gradient_loss | -0.000361    |
|    route_completion     | 0.514        |
|    std                  | 0.593        |
|    total_cost           | 17.7         |
|    value_loss           | 171          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 528      |
|    iterations      | 356      |
|    time_elapsed    | 3447     |
|    total_timesteps | 1822720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 278          |
|    ep_rew_mean          | 261          |
| time/                   |              |
|    fps                  | 529          |
|    iterations           | 357          |
|    time_elapsed         | 3453         |
|    total_timesteps      | 1827840      |
| train/                  |              |
|    approx_kl            | 0.0021123006 |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.621        |
|    learning_rate        | 5e-05        |
|    loss                 | 182          |
|    n_updates            | 7120         |
|    policy_gradient_loss | -0.00102     |
|    std                  | 0.593        |
|    value_loss           | 295          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0874       |
|    crash                | 0.24         |
|    max_step             | 0            |
|    mean_ep_length       | 91.6         |
|    mean_reward          | 99           |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.46857497   |
|    route_completion     | 0.458        |
|    success_rate         | 0.1          |
|    total_cost           | 12.4         |
| time/                   |              |
|    total_timesteps      | 1830000      |
| train/                  |              |
|    approx_kl            | 0.0060715815 |
|    arrive_dest          | 0.18         |
|    clip_fraction        | 0.133        |
|    clip_range           | 0.1          |
|    crash                | 0.252        |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.592        |
|    learning_rate        | 5e-05        |
|    loss                 | 99.4         |
|    max_step             | 0            |
|    n_updates            | 7140         |
|    out_of_road          | 0.82         |
|    policy_gradient_loss | -0.00111     |
|    route_completion     | 0.514        |
|    std                  | 0.595        |
|    total_cost           | 17.6         |
|    value_loss           | 281          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 271      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 358      |
|    time_elapsed    | 3463     |
|    total_timesteps | 1832960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 280          |
|    ep_rew_mean          | 258          |
| time/                   |              |
|    fps                  | 529          |
|    iterations           | 359          |
|    time_elapsed         | 3470         |
|    total_timesteps      | 1838080      |
| train/                  |              |
|    approx_kl            | 0.0018158151 |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.71        |
|    explained_variance   | 0.637        |
|    learning_rate        | 5e-05        |
|    loss                 | 99.1         |
|    n_updates            | 7160         |
|    policy_gradient_loss | -3.71e-05    |
|    std                  | 0.595        |
|    value_loss           | 276          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.088       |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 97.8        |
|    mean_reward          | 118         |
|    num_episodes         | 5           |
|    out_of_road          | 0.912       |
|    raw_action           | 0.4684349   |
|    route_completion     | 0.457       |
|    success_rate         | 0.2         |
|    total_cost           | 12.4        |
| time/                   |             |
|    total_timesteps      | 1840000     |
| train/                  |             |
|    approx_kl            | 0.006236189 |
|    arrive_dest          | 0.18        |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.1         |
|    crash                | 0.251       |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.647       |
|    learning_rate        | 5e-05       |
|    loss                 | 76.2        |
|    max_step             | 0           |
|    n_updates            | 7180        |
|    out_of_road          | 0.82        |
|    policy_gradient_loss | -0.000203   |
|    route_completion     | 0.513       |
|    std                  | 0.595       |
|    total_cost           | 17.6        |
|    value_loss           | 217         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 253      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 360      |
|    time_elapsed    | 3480     |
|    total_timesteps | 1843200  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 278         |
|    ep_rew_mean          | 254         |
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 361         |
|    time_elapsed         | 3486        |
|    total_timesteps      | 1848320     |
| train/                  |             |
|    approx_kl            | 0.001333991 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.564       |
|    learning_rate        | 5e-05       |
|    loss                 | 136         |
|    n_updates            | 7200        |
|    policy_gradient_loss | -0.00125    |
|    std                  | 0.593       |
|    value_loss           | 291         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0876      |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 130         |
|    mean_reward          | 146         |
|    num_episodes         | 5           |
|    out_of_road          | 0.912       |
|    raw_action           | 0.46781874  |
|    route_completion     | 0.457       |
|    success_rate         | 0.1         |
|    total_cost           | 12.3        |
| time/                   |             |
|    total_timesteps      | 1850000     |
| train/                  |             |
|    approx_kl            | 0.006922572 |
|    arrive_dest          | 0.181       |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.1         |
|    crash                | 0.25        |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.635       |
|    learning_rate        | 5e-05       |
|    loss                 | 69.9        |
|    max_step             | 0           |
|    n_updates            | 7220        |
|    out_of_road          | 0.819       |
|    policy_gradient_loss | 0.00131     |
|    route_completion     | 0.513       |
|    std                  | 0.594       |
|    total_cost           | 17.6        |
|    value_loss           | 210         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 280      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 362      |
|    time_elapsed    | 3501     |
|    total_timesteps | 1853440  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 282         |
|    ep_rew_mean          | 259         |
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 363         |
|    time_elapsed         | 3507        |
|    total_timesteps      | 1858560     |
| train/                  |             |
|    approx_kl            | 0.015510492 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.438       |
|    learning_rate        | 5e-05       |
|    loss                 | 149         |
|    n_updates            | 7240        |
|    policy_gradient_loss | 0.00019     |
|    std                  | 0.593       |
|    value_loss           | 298         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0871       |
|    crash                | 0.243        |
|    max_step             | 0            |
|    mean_ep_length       | 103          |
|    mean_reward          | 120          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.4678364    |
|    route_completion     | 0.457        |
|    success_rate         | 0.1          |
|    total_cost           | 12.3         |
| time/                   |              |
|    total_timesteps      | 1860000      |
| train/                  |              |
|    approx_kl            | 0.0045209564 |
|    arrive_dest          | 0.181        |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    crash                | 0.249        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.557        |
|    learning_rate        | 5e-05        |
|    loss                 | 159          |
|    max_step             | 0            |
|    n_updates            | 7260         |
|    out_of_road          | 0.819        |
|    policy_gradient_loss | -8.62e-05    |
|    route_completion     | 0.513        |
|    std                  | 0.593        |
|    total_cost           | 17.5         |
|    value_loss           | 268          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    fps             | 529      |
|    iterations      | 364      |
|    time_elapsed    | 3516     |
|    total_timesteps | 1863680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 272          |
|    ep_rew_mean          | 249          |
| time/                   |              |
|    fps                  | 530          |
|    iterations           | 365          |
|    time_elapsed         | 3522         |
|    total_timesteps      | 1868800      |
| train/                  |              |
|    approx_kl            | 0.0023094357 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.582        |
|    learning_rate        | 5e-05        |
|    loss                 | 162          |
|    n_updates            | 7280         |
|    policy_gradient_loss | -0.00105     |
|    std                  | 0.592        |
|    value_loss           | 231          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0877       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 156          |
|    mean_reward          | 180          |
|    num_episodes         | 5            |
|    out_of_road          | 0.912        |
|    raw_action           | 0.4677504    |
|    route_completion     | 0.457        |
|    success_rate         | 0.4          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 1870000      |
| train/                  |              |
|    approx_kl            | 0.0015161844 |
|    arrive_dest          | 0.183        |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.1          |
|    crash                | 0.248        |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.708        |
|    learning_rate        | 5e-05        |
|    loss                 | 109          |
|    max_step             | 0            |
|    n_updates            | 7300         |
|    out_of_road          | 0.817        |
|    policy_gradient_loss | -0.00175     |
|    route_completion     | 0.514        |
|    std                  | 0.593        |
|    total_cost           | 17.4         |
|    value_loss           | 209          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 273      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 530      |
|    iterations      | 366      |
|    time_elapsed    | 3534     |
|    total_timesteps | 1873920  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 280          |
|    ep_rew_mean          | 254          |
| time/                   |              |
|    fps                  | 530          |
|    iterations           | 367          |
|    time_elapsed         | 3540         |
|    total_timesteps      | 1879040      |
| train/                  |              |
|    approx_kl            | 0.0030025055 |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.7         |
|    explained_variance   | 0.666        |
|    learning_rate        | 5e-05        |
|    loss                 | 68.6         |
|    n_updates            | 7320         |
|    policy_gradient_loss | 0.00226      |
|    std                  | 0.591        |
|    value_loss           | 208          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0872       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 124          |
|    mean_reward          | 147          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.46805173   |
|    route_completion     | 0.457        |
|    success_rate         | 0.2          |
|    total_cost           | 12.2         |
| time/                   |              |
|    total_timesteps      | 1880000      |
| train/                  |              |
|    approx_kl            | 0.0049533094 |
|    arrive_dest          | 0.184        |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.1          |
|    crash                | 0.247        |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.633        |
|    learning_rate        | 5e-05        |
|    loss                 | 76.5         |
|    max_step             | 0            |
|    n_updates            | 7340         |
|    out_of_road          | 0.816        |
|    policy_gradient_loss | -0.000751    |
|    route_completion     | 0.515        |
|    std                  | 0.591        |
|    total_cost           | 17.4         |
|    value_loss           | 241          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | 240      |
| time/              |          |
|    fps             | 530      |
|    iterations      | 368      |
|    time_elapsed    | 3550     |
|    total_timesteps | 1884160  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 283          |
|    ep_rew_mean          | 249          |
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 369          |
|    time_elapsed         | 3556         |
|    total_timesteps      | 1889280      |
| train/                  |              |
|    approx_kl            | 0.0025617243 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.536        |
|    learning_rate        | 5e-05        |
|    loss                 | 100          |
|    n_updates            | 7360         |
|    policy_gradient_loss | 0.000124     |
|    std                  | 0.589        |
|    value_loss           | 252          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0868       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 148          |
|    mean_reward          | 166          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.46815318   |
|    route_completion     | 0.457        |
|    success_rate         | 0.2          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1890000      |
| train/                  |              |
|    approx_kl            | 0.0090933535 |
|    arrive_dest          | 0.185        |
|    clip_fraction        | 0.216        |
|    clip_range           | 0.1          |
|    crash                | 0.246        |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.743        |
|    learning_rate        | 5e-05        |
|    loss                 | 69.3         |
|    max_step             | 0            |
|    n_updates            | 7380         |
|    out_of_road          | 0.815        |
|    policy_gradient_loss | 0.00153      |
|    route_completion     | 0.516        |
|    std                  | 0.587        |
|    total_cost           | 17.3         |
|    value_loss           | 145          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 273      |
|    ep_rew_mean     | 241      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 370      |
|    time_elapsed    | 3567     |
|    total_timesteps | 1894400  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 280         |
|    ep_rew_mean          | 247         |
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 371         |
|    time_elapsed         | 3574        |
|    total_timesteps      | 1899520     |
| train/                  |             |
|    approx_kl            | 0.009000015 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.367       |
|    learning_rate        | 5e-05       |
|    loss                 | 199         |
|    n_updates            | 7400        |
|    policy_gradient_loss | 0.00127     |
|    std                  | 0.587       |
|    value_loss           | 322         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0863       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 99.8         |
|    mean_reward          | 117          |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.4681692    |
|    route_completion     | 0.457        |
|    success_rate         | 0.3          |
|    total_cost           | 12.1         |
| time/                   |              |
|    total_timesteps      | 1900000      |
| train/                  |              |
|    approx_kl            | 0.0019138487 |
|    arrive_dest          | 0.187        |
|    clip_fraction        | 0.221        |
|    clip_range           | 0.1          |
|    crash                | 0.245        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.673        |
|    learning_rate        | 5e-05        |
|    loss                 | 113          |
|    max_step             | 0            |
|    n_updates            | 7420         |
|    out_of_road          | 0.813        |
|    policy_gradient_loss | 0.00388      |
|    route_completion     | 0.517        |
|    std                  | 0.589        |
|    total_cost           | 17.3         |
|    value_loss           | 209          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 275      |
|    ep_rew_mean     | 243      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 372      |
|    time_elapsed    | 3583     |
|    total_timesteps | 1904640  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 270          |
|    ep_rew_mean          | 238          |
| time/                   |              |
|    fps                  | 532          |
|    iterations           | 373          |
|    time_elapsed         | 3589         |
|    total_timesteps      | 1909760      |
| train/                  |              |
|    approx_kl            | 0.0037026461 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.57         |
|    learning_rate        | 5e-05        |
|    loss                 | 192          |
|    n_updates            | 7440         |
|    policy_gradient_loss | -0.00202     |
|    std                  | 0.586        |
|    value_loss           | 279          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0869       |
|    crash                | 0.242        |
|    max_step             | 0            |
|    mean_ep_length       | 219          |
|    mean_reward          | 269          |
|    num_episodes         | 5            |
|    out_of_road          | 0.913        |
|    raw_action           | 0.46819913   |
|    route_completion     | 0.458        |
|    success_rate         | 0.2          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1910000      |
| train/                  |              |
|    approx_kl            | 0.0016801904 |
|    arrive_dest          | 0.187        |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.1          |
|    crash                | 0.246        |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.567        |
|    learning_rate        | 5e-05        |
|    loss                 | 75.9         |
|    max_step             | 0            |
|    n_updates            | 7460         |
|    out_of_road          | 0.813        |
|    policy_gradient_loss | 0.00129      |
|    route_completion     | 0.517        |
|    std                  | 0.586        |
|    total_cost           | 17.3         |
|    value_loss           | 202          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 275      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    fps             | 531      |
|    iterations      | 374      |
|    time_elapsed    | 3599     |
|    total_timesteps | 1914880  |
---------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0865       |
|    crash                | 0.241        |
|    max_step             | 0            |
|    mean_ep_length       | 89           |
|    mean_reward          | 95.1         |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.46810567   |
|    route_completion     | 0.457        |
|    success_rate         | 0            |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1920000      |
| train/                  |              |
|    approx_kl            | 0.0025865554 |
|    arrive_dest          | 0.186        |
|    clip_fraction        | 0.181        |
|    clip_range           | 0.1          |
|    crash                | 0.245        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.589        |
|    learning_rate        | 5e-05        |
|    loss                 | 62.3         |
|    max_step             | 0            |
|    n_updates            | 7480         |
|    out_of_road          | 0.814        |
|    policy_gradient_loss | 0.00123      |
|    route_completion     | 0.517        |
|    std                  | 0.587        |
|    total_cost           | 17.2         |
|    value_loss           | 201          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 250      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 375      |
|    time_elapsed    | 3607     |
|    total_timesteps | 1920000  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 278         |
|    ep_rew_mean          | 248         |
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 376         |
|    time_elapsed         | 3614        |
|    total_timesteps      | 1925120     |
| train/                  |             |
|    approx_kl            | 0.010560023 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.557       |
|    learning_rate        | 5e-05       |
|    loss                 | 118         |
|    n_updates            | 7500        |
|    policy_gradient_loss | 0.00189     |
|    std                  | 0.588       |
|    value_loss           | 249         |
-----------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.086        |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 143          |
|    mean_reward          | 199          |
|    num_episodes         | 5            |
|    out_of_road          | 0.914        |
|    raw_action           | 0.46749714   |
|    route_completion     | 0.458        |
|    success_rate         | 0.1          |
|    total_cost           | 12           |
| time/                   |              |
|    total_timesteps      | 1930000      |
| train/                  |              |
|    approx_kl            | 0.0025285308 |
|    arrive_dest          | 0.187        |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.49         |
|    learning_rate        | 5e-05        |
|    loss                 | 64.5         |
|    max_step             | 0            |
|    n_updates            | 7520         |
|    out_of_road          | 0.813        |
|    policy_gradient_loss | -0.00189     |
|    route_completion     | 0.516        |
|    std                  | 0.589        |
|    total_cost           | 17.1         |
|    value_loss           | 244          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 302      |
|    ep_rew_mean     | 266      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 377      |
|    time_elapsed    | 3626     |
|    total_timesteps | 1930240  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 296          |
|    ep_rew_mean          | 263          |
| time/                   |              |
|    fps                  | 532          |
|    iterations           | 378          |
|    time_elapsed         | 3632         |
|    total_timesteps      | 1935360      |
| train/                  |              |
|    approx_kl            | 0.0017401138 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.695        |
|    learning_rate        | 5e-05        |
|    loss                 | 64           |
|    n_updates            | 7540         |
|    policy_gradient_loss | 0.00267      |
|    std                  | 0.59         |
|    value_loss           | 184          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0856      |
|    crash                | 0.24        |
|    max_step             | 0           |
|    mean_ep_length       | 91.4        |
|    mean_reward          | 99.7        |
|    num_episodes         | 5           |
|    out_of_road          | 0.914       |
|    raw_action           | 0.4668837   |
|    route_completion     | 0.457       |
|    success_rate         | 0.1         |
|    total_cost           | 11.9        |
| time/                   |             |
|    total_timesteps      | 1940000     |
| train/                  |             |
|    approx_kl            | 0.007383193 |
|    arrive_dest          | 0.187       |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.1         |
|    crash                | 0.242       |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.69        |
|    learning_rate        | 5e-05       |
|    loss                 | 54.8        |
|    max_step             | 0           |
|    n_updates            | 7560        |
|    out_of_road          | 0.813       |
|    policy_gradient_loss | -0.00069    |
|    route_completion     | 0.517       |
|    std                  | 0.591       |
|    total_cost           | 17.1        |
|    value_loss           | 156         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 379      |
|    time_elapsed    | 3643     |
|    total_timesteps | 1940480  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 307          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 380          |
|    time_elapsed         | 3649         |
|    total_timesteps      | 1945600      |
| train/                  |              |
|    approx_kl            | 0.0032462967 |
|    clip_fraction        | 0.184        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5e-05        |
|    loss                 | 94.6         |
|    n_updates            | 7580         |
|    policy_gradient_loss | 0.00185      |
|    std                  | 0.592        |
|    value_loss           | 176          |
------------------------------------------
----------------------------------------
| eval/                   |            |
|    arrive_dest          | 0.0851     |
|    crash                | 0.239      |
|    max_step             | 0          |
|    mean_ep_length       | 127        |
|    mean_reward          | 158        |
|    num_episodes         | 5          |
|    out_of_road          | 0.915      |
|    raw_action           | 0.46683174 |
|    route_completion     | 0.456      |
|    success_rate         | 0          |
|    total_cost           | 11.9       |
| time/                   |            |
|    total_timesteps      | 1950000    |
| train/                  |            |
|    approx_kl            | 0.00728087 |
|    arrive_dest          | 0.186      |
|    clip_fraction        | 0.149      |
|    clip_range           | 0.1        |
|    crash                | 0.243      |
|    entropy_loss         | -1.69      |
|    explained_variance   | 0.759      |
|    learning_rate        | 5e-05      |
|    loss                 | 57.1       |
|    max_step             | 0          |
|    n_updates            | 7600       |
|    out_of_road          | 0.814      |
|    policy_gradient_loss | 0.000659   |
|    route_completion     | 0.517      |
|    std                  | 0.592      |
|    total_cost           | 17.1       |
|    value_loss           | 159        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    fps             | 532      |
|    iterations      | 381      |
|    time_elapsed    | 3660     |
|    total_timesteps | 1950720  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 313          |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 382          |
|    time_elapsed         | 3666         |
|    total_timesteps      | 1955840      |
| train/                  |              |
|    approx_kl            | 0.0026730963 |
|    clip_fraction        | 0.252        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0.679        |
|    learning_rate        | 5e-05        |
|    loss                 | 82           |
|    n_updates            | 7620         |
|    policy_gradient_loss | 0.00421      |
|    std                  | 0.592        |
|    value_loss           | 217          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0847       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 105          |
|    mean_reward          | 133          |
|    num_episodes         | 5            |
|    out_of_road          | 0.915        |
|    raw_action           | 0.46715215   |
|    route_completion     | 0.456        |
|    success_rate         | 0            |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 1960000      |
| train/                  |              |
|    approx_kl            | 0.0023199448 |
|    arrive_dest          | 0.185        |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.1          |
|    crash                | 0.243        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.689        |
|    learning_rate        | 5e-05        |
|    loss                 | 107          |
|    max_step             | 0            |
|    n_updates            | 7640         |
|    out_of_road          | 0.815        |
|    policy_gradient_loss | 0.00242      |
|    route_completion     | 0.516        |
|    std                  | 0.589        |
|    total_cost           | 17           |
|    value_loss           | 178          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 383      |
|    time_elapsed    | 3674     |
|    total_timesteps | 1960960  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 305          |
|    ep_rew_mean          | 259          |
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 384          |
|    time_elapsed         | 3680         |
|    total_timesteps      | 1966080      |
| train/                  |              |
|    approx_kl            | 0.0033291553 |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.627        |
|    learning_rate        | 5e-05        |
|    loss                 | 137          |
|    n_updates            | 7660         |
|    policy_gradient_loss | -1.38e-06    |
|    std                  | 0.59         |
|    value_loss           | 249          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.0843       |
|    crash                | 0.239        |
|    max_step             | 0            |
|    mean_ep_length       | 157          |
|    mean_reward          | 114          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.46701437   |
|    route_completion     | 0.456        |
|    success_rate         | 0.1          |
|    total_cost           | 11.9         |
| time/                   |              |
|    total_timesteps      | 1970000      |
| train/                  |              |
|    approx_kl            | 0.0023627584 |
|    arrive_dest          | 0.185        |
|    clip_fraction        | 0.183        |
|    clip_range           | 0.1          |
|    crash                | 0.244        |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.497        |
|    learning_rate        | 5e-05        |
|    loss                 | 79.5         |
|    max_step             | 0            |
|    n_updates            | 7680         |
|    out_of_road          | 0.815        |
|    policy_gradient_loss | -0.000551    |
|    route_completion     | 0.516        |
|    std                  | 0.589        |
|    total_cost           | 16.9         |
|    value_loss           | 245          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 305      |
|    ep_rew_mean     | 251      |
| time/              |          |
|    fps             | 533      |
|    iterations      | 385      |
|    time_elapsed    | 3694     |
|    total_timesteps | 1971200  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 287          |
|    ep_rew_mean          | 237          |
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 386          |
|    time_elapsed         | 3700         |
|    total_timesteps      | 1976320      |
| train/                  |              |
|    approx_kl            | 0.0064807064 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.495        |
|    learning_rate        | 5e-05        |
|    loss                 | 159          |
|    n_updates            | 7700         |
|    policy_gradient_loss | 0.000272     |
|    std                  | 0.59         |
|    value_loss           | 285          |
------------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0838      |
|    crash                | 0.238       |
|    max_step             | 0           |
|    mean_ep_length       | 108         |
|    mean_reward          | 130         |
|    num_episodes         | 5           |
|    out_of_road          | 0.916       |
|    raw_action           | 0.46691525  |
|    route_completion     | 0.455       |
|    success_rate         | 0           |
|    total_cost           | 11.8        |
| time/                   |             |
|    total_timesteps      | 1980000     |
| train/                  |             |
|    approx_kl            | 0.009835913 |
|    arrive_dest          | 0.184       |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.1         |
|    crash                | 0.243       |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.558       |
|    learning_rate        | 5e-05       |
|    loss                 | 119         |
|    max_step             | 0           |
|    n_updates            | 7720        |
|    out_of_road          | 0.816       |
|    policy_gradient_loss | 0.00206     |
|    route_completion     | 0.515       |
|    std                  | 0.587       |
|    total_cost           | 16.9        |
|    value_loss           | 262         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 262      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 387      |
|    time_elapsed    | 3709     |
|    total_timesteps | 1981440  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 252         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 388         |
|    time_elapsed         | 3715        |
|    total_timesteps      | 1986560     |
| train/                  |             |
|    approx_kl            | 0.004436341 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.399       |
|    learning_rate        | 5e-05       |
|    loss                 | 171         |
|    n_updates            | 7740        |
|    policy_gradient_loss | 0.00188     |
|    std                  | 0.587       |
|    value_loss           | 345         |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0.0844      |
|    crash                | 0.237       |
|    max_step             | 0           |
|    mean_ep_length       | 99.6        |
|    mean_reward          | 124         |
|    num_episodes         | 5           |
|    out_of_road          | 0.916       |
|    raw_action           | 0.4668885   |
|    route_completion     | 0.455       |
|    success_rate         | 0.3         |
|    total_cost           | 11.8        |
| time/                   |             |
|    total_timesteps      | 1990000     |
| train/                  |             |
|    approx_kl            | 0.003740868 |
|    arrive_dest          | 0.185       |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.1         |
|    crash                | 0.244       |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.565       |
|    learning_rate        | 5e-05       |
|    loss                 | 85          |
|    max_step             | 0           |
|    n_updates            | 7760        |
|    out_of_road          | 0.815       |
|    policy_gradient_loss | -0.00114    |
|    route_completion     | 0.516       |
|    std                  | 0.586       |
|    total_cost           | 16.8        |
|    value_loss           | 203         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 389      |
|    time_elapsed    | 3725     |
|    total_timesteps | 1991680  |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 261          |
|    ep_rew_mean          | 224          |
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 390          |
|    time_elapsed         | 3731         |
|    total_timesteps      | 1996800      |
| train/                  |              |
|    approx_kl            | 0.0018497274 |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.67        |
|    explained_variance   | 0.69         |
|    learning_rate        | 5e-05        |
|    loss                 | 90.2         |
|    n_updates            | 7780         |
|    policy_gradient_loss | 0.000441     |
|    std                  | 0.586        |
|    value_loss           | 204          |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0.084        |
|    crash                | 0.237        |
|    max_step             | 0            |
|    mean_ep_length       | 239          |
|    mean_reward          | 252          |
|    num_episodes         | 5            |
|    out_of_road          | 0.916        |
|    raw_action           | 0.46667594   |
|    route_completion     | 0.456        |
|    success_rate         | 0.1          |
|    total_cost           | 11.8         |
| time/                   |              |
|    total_timesteps      | 2000000      |
| train/                  |              |
|    approx_kl            | 0.0044725235 |
|    arrive_dest          | 0.185        |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.1          |
|    crash                | 0.243        |
|    entropy_loss         | -1.66        |
|    explained_variance   | 0.718        |
|    learning_rate        | 5e-05        |
|    loss                 | 52.7         |
|    max_step             | 0            |
|    n_updates            | 7800         |
|    out_of_road          | 0.815        |
|    policy_gradient_loss | 0.00169      |
|    route_completion     | 0.516        |
|    std                  | 0.584        |
|    total_cost           | 16.7         |
|    value_loss           | 162          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 534      |
|    iterations      | 391      |
|    time_elapsed    | 3743     |
|    total_timesteps | 2001920  |
---------------------------------
