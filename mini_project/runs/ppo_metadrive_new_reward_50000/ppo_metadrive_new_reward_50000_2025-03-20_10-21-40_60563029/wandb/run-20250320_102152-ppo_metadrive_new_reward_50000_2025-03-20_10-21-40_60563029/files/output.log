Using cpu device
Logging to runs\ppo_metadrive_new_reward_50000\ppo_metadrive_new_reward_50000_2025-03-20_10-21-40_60563029\ppo_metadrive_new_reward_50000_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 506      |
|    ep_rew_mean     | 2.93     |
| time/              |          |
|    fps             | 1516     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 5120     |
---------------------------------
-----------------------------------------
| eval/                   |             |
|    arrive_dest          | 0           |
|    crash                | 0.2         |
|    max_step             | 0           |
|    mean_ep_length       | 151         |
|    mean_reward          | 28.4        |
|    num_episodes         | 5           |
|    out_of_road          | 1           |
|    raw_action           | 0.04646224  |
|    route_completion     | 0.103       |
|    success_rate         | 0           |
|    total_cost           | 1           |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.002968752 |
|    arrive_dest          | 0           |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.1         |
|    crash                | 0           |
|    entropy_loss         | -2.83       |
|    explained_variance   | -0.00231    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0147     |
|    max_step             | 0           |
|    n_updates            | 20          |
|    out_of_road          | 1           |
|    policy_gradient_loss | -0.00774    |
|    route_completion     | 0.148       |
|    std                  | 0.996       |
|    total_cost           | 3.2         |
|    value_loss           | 0.0383      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 27.7     |
| time/              |          |
|    fps             | 788      |
|    iterations      | 2        |
|    time_elapsed    | 12       |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 466          |
|    ep_rew_mean          | 24.6         |
| time/                   |              |
|    fps                  | 915          |
|    iterations           | 3            |
|    time_elapsed         | 16           |
|    total_timesteps      | 15360        |
| train/                  |              |
|    approx_kl            | 0.0034079049 |
|    clip_fraction        | 0.208        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.0257       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.000759    |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00925     |
|    std                  | 0.998        |
|    value_loss           | 0.0355       |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 128          |
|    mean_reward          | 51.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.07364347   |
|    route_completion     | 0.143        |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0036066421 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.1          |
|    crash                | 0            |
|    entropy_loss         | -2.83        |
|    explained_variance   | -0.0415      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0198       |
|    max_step             | 0            |
|    n_updates            | 60           |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00788     |
|    route_completion     | 0.134        |
|    std                  | 0.995        |
|    total_cost           | 2.1          |
|    value_loss           | 0.0542       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 26.3     |
| time/              |          |
|    fps             | 778      |
|    iterations      | 4        |
|    time_elapsed    | 26       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 417          |
|    ep_rew_mean          | 24.9         |
| time/                   |              |
|    fps                  | 820          |
|    iterations           | 5            |
|    time_elapsed         | 31           |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0024733033 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00967      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.171        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00417     |
|    std                  | 0.993        |
|    value_loss           | 0.355        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 138          |
|    mean_reward          | 83           |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.10777976   |
|    route_completion     | 0.2          |
|    success_rate         | 0            |
|    total_cost           | 1            |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0026332103 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.1          |
|    crash                | 0.133        |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.0525       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0611       |
|    max_step             | 0            |
|    n_updates            | 100          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00529     |
|    route_completion     | 0.178        |
|    std                  | 0.985        |
|    total_cost           | 1.73         |
|    value_loss           | 0.148        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 472      |
|    ep_rew_mean     | 38.3     |
| time/              |          |
|    fps             | 748      |
|    iterations      | 6        |
|    time_elapsed    | 41       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 459          |
|    ep_rew_mean          | 36.4         |
| time/                   |              |
|    fps                  | 798          |
|    iterations           | 7            |
|    time_elapsed         | 44           |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 0.0023435527 |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.00784      |
|    learning_rate        | 5e-05        |
|    loss                 | 0.717        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00299     |
|    std                  | 0.981        |
|    value_loss           | 1.65         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 99           |
|    mean_reward          | 72.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1320676    |
|    route_completion     | 0.2          |
|    success_rate         | 0            |
|    total_cost           | 1.1          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0034735892 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.233        |
|    clip_range           | 0.1          |
|    crash                | 0.1          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0942       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.0746       |
|    max_step             | 0            |
|    n_updates            | 140          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0108      |
|    route_completion     | 0.166        |
|    std                  | 0.974        |
|    total_cost           | 1.7          |
|    value_loss           | 0.133        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 34.6     |
| time/              |          |
|    fps             | 753      |
|    iterations      | 8        |
|    time_elapsed    | 54       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 439          |
|    ep_rew_mean          | 31.4         |
| time/                   |              |
|    fps                  | 777          |
|    iterations           | 9            |
|    time_elapsed         | 59           |
|    total_timesteps      | 46080        |
| train/                  |              |
|    approx_kl            | 0.0027652583 |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.0752       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.309        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00582     |
|    std                  | 0.966        |
|    value_loss           | 0.858        |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.08         |
|    max_step             | 0            |
|    mean_ep_length       | 68.6         |
|    mean_reward          | 45.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.1615028    |
|    route_completion     | 0.191        |
|    success_rate         | 0            |
|    total_cost           | 1.08         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0034185345 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.181        |
|    clip_range           | 0.1          |
|    crash                | 0.08         |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.0738       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.18         |
|    max_step             | 0            |
|    n_updates            | 180          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0071      |
|    route_completion     | 0.17         |
|    std                  | 0.954        |
|    total_cost           | 1.56         |
|    value_loss           | 0.456        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 30.3     |
| time/              |          |
|    fps             | 737      |
|    iterations      | 10       |
|    time_elapsed    | 69       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 402          |
|    ep_rew_mean          | 27.3         |
| time/                   |              |
|    fps                  | 740          |
|    iterations           | 11           |
|    time_elapsed         | 76           |
|    total_timesteps      | 56320        |
| train/                  |              |
|    approx_kl            | 0.0023811387 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.127        |
|    learning_rate        | 5e-05        |
|    loss                 | 0.384        |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00366     |
|    std                  | 0.95         |
|    value_loss           | 1.16         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0667       |
|    max_step             | 0            |
|    mean_ep_length       | 77.2         |
|    mean_reward          | 68.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.19350147   |
|    route_completion     | 0.188        |
|    success_rate         | 0            |
|    total_cost           | 1.07         |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0016710663 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0469       |
|    clip_range           | 0.1          |
|    crash                | 0.0667       |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0134       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.565        |
|    max_step             | 0            |
|    n_updates            | 220          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00131     |
|    route_completion     | 0.176        |
|    std                  | 0.946        |
|    total_cost           | 5.87         |
|    value_loss           | 0.981        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 25.4     |
| time/              |          |
|    fps             | 661      |
|    iterations      | 12       |
|    time_elapsed    | 92       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 353          |
|    ep_rew_mean          | 24.9         |
| time/                   |              |
|    fps                  | 666          |
|    iterations           | 13           |
|    time_elapsed         | 99           |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 0.0014265422 |
|    clip_fraction        | 0.0597       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.0438       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.834        |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00205     |
|    std                  | 0.941        |
|    value_loss           | 1.85         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.0857       |
|    max_step             | 0            |
|    mean_ep_length       | 59.8         |
|    mean_reward          | 43.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.21259493   |
|    route_completion     | 0.186        |
|    success_rate         | 0            |
|    total_cost           | 1.06         |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0023076485 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.1          |
|    crash                | 0.0571       |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.0924       |
|    learning_rate        | 5e-05        |
|    loss                 | 0.868        |
|    max_step             | 0            |
|    n_updates            | 260          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0038      |
|    route_completion     | 0.168        |
|    std                  | 0.931        |
|    total_cost           | 5.17         |
|    value_loss           | 1.82         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 22.3     |
| time/              |          |
|    fps             | 637      |
|    iterations      | 14       |
|    time_elapsed    | 112      |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 217          |
|    ep_rew_mean          | 16.4         |
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 15           |
|    time_elapsed         | 121          |
|    total_timesteps      | 76800        |
| train/                  |              |
|    approx_kl            | 0.0016782312 |
|    clip_fraction        | 0.0447       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.0744       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.29         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00127     |
|    std                  | 0.925        |
|    value_loss           | 2.81         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.1          |
|    max_step             | 0            |
|    mean_ep_length       | 51.2         |
|    mean_reward          | 34.6         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.22516054   |
|    route_completion     | 0.177        |
|    success_rate         | 0            |
|    total_cost           | 1.05         |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0017407428 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0563       |
|    clip_range           | 0.1          |
|    crash                | 0.05         |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.0617       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.76         |
|    max_step             | 0            |
|    n_updates            | 300          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.0016      |
|    route_completion     | 0.158        |
|    std                  | 0.919        |
|    total_cost           | 4.65         |
|    value_loss           | 2.95         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 15.7     |
| time/              |          |
|    fps             | 604      |
|    iterations      | 16       |
|    time_elapsed    | 135      |
|    total_timesteps | 81920    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 150           |
|    ep_rew_mean          | 13.8          |
| time/                   |               |
|    fps                  | 596           |
|    iterations           | 17            |
|    time_elapsed         | 145           |
|    total_timesteps      | 87040         |
| train/                  |               |
|    approx_kl            | 0.00089298683 |
|    clip_fraction        | 0.0181        |
|    clip_range           | 0.1           |
|    entropy_loss         | -2.66         |
|    explained_variance   | 0.019         |
|    learning_rate        | 5e-05         |
|    loss                 | 2.57          |
|    n_updates            | 320           |
|    policy_gradient_loss | -0.000648     |
|    std                  | 0.915         |
|    value_loss           | 4.75          |
-------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 66.4         |
|    mean_reward          | 60.2         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.24531518   |
|    route_completion     | 0.18         |
|    success_rate         | 0            |
|    total_cost           | 1.04         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0017232758 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.05         |
|    clip_range           | 0.1          |
|    crash                | 0.0667       |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.0647       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.5          |
|    max_step             | 0            |
|    n_updates            | 340          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00162     |
|    route_completion     | 0.163        |
|    std                  | 0.913        |
|    total_cost           | 4.24         |
|    value_loss           | 4.18         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 14.2     |
| time/              |          |
|    fps             | 582      |
|    iterations      | 18       |
|    time_elapsed    | 158      |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 145          |
|    ep_rew_mean          | 15.4         |
| time/                   |              |
|    fps                  | 580          |
|    iterations           | 19           |
|    time_elapsed         | 167          |
|    total_timesteps      | 97280        |
| train/                  |              |
|    approx_kl            | 0.0012267225 |
|    clip_fraction        | 0.0507       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.0522       |
|    learning_rate        | 5e-05        |
|    loss                 | 1.83         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.913        |
|    value_loss           | 3.91         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.16         |
|    max_step             | 0            |
|    mean_ep_length       | 62.4         |
|    mean_reward          | 57.4         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.25929582   |
|    route_completion     | 0.185        |
|    success_rate         | 0            |
|    total_cost           | 1.04         |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0012739649 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0459       |
|    clip_range           | 0.1          |
|    crash                | 0.06         |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0494       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.31         |
|    max_step             | 0            |
|    n_updates            | 380          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00174     |
|    route_completion     | 0.162        |
|    std                  | 0.908        |
|    total_cost           | 3.92         |
|    value_loss           | 4.98         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 19.3     |
| time/              |          |
|    fps             | 565      |
|    iterations      | 20       |
|    time_elapsed    | 181      |
|    total_timesteps | 102400   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | 19.9         |
| time/                   |              |
|    fps                  | 564          |
|    iterations           | 21           |
|    time_elapsed         | 190          |
|    total_timesteps      | 107520       |
| train/                  |              |
|    approx_kl            | 0.0009854909 |
|    clip_fraction        | 0.0275       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.64        |
|    explained_variance   | 0.0137       |
|    learning_rate        | 5e-05        |
|    loss                 | 5.81         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.000862    |
|    std                  | 0.902        |
|    value_loss           | 14.5         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.145        |
|    max_step             | 0            |
|    mean_ep_length       | 84           |
|    mean_reward          | 99.8         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.28957784   |
|    route_completion     | 0.196        |
|    success_rate         | 0            |
|    total_cost           | 1.11         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0015518443 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0459       |
|    clip_range           | 0.1          |
|    crash                | 0.0727       |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.0575       |
|    learning_rate        | 5e-05        |
|    loss                 | 2.96         |
|    max_step             | 0            |
|    n_updates            | 420          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00187     |
|    route_completion     | 0.18         |
|    std                  | 0.896        |
|    total_cost           | 6.31         |
|    value_loss           | 6.98         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 154      |
|    ep_rew_mean     | 26.7     |
| time/              |          |
|    fps             | 525      |
|    iterations      | 22       |
|    time_elapsed    | 214      |
|    total_timesteps | 112640   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 151          |
|    ep_rew_mean          | 26.2         |
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 23           |
|    time_elapsed         | 224          |
|    total_timesteps      | 117760       |
| train/                  |              |
|    approx_kl            | 0.0015999895 |
|    clip_fraction        | 0.0617       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.0867       |
|    learning_rate        | 5e-05        |
|    loss                 | 5.66         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00188     |
|    std                  | 0.892        |
|    value_loss           | 11.6         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.133        |
|    max_step             | 0            |
|    mean_ep_length       | 67           |
|    mean_reward          | 67.1         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.30529812   |
|    route_completion     | 0.197        |
|    success_rate         | 0            |
|    total_cost           | 1.1          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0013244369 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0287       |
|    clip_range           | 0.1          |
|    crash                | 0.0667       |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.0599       |
|    learning_rate        | 5e-05        |
|    loss                 | 4.05         |
|    max_step             | 0            |
|    n_updates            | 460          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00232     |
|    route_completion     | 0.19         |
|    std                  | 0.887        |
|    total_cost           | 5.87         |
|    value_loss           | 9.55         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 29.1     |
| time/              |          |
|    fps             | 510      |
|    iterations      | 24       |
|    time_elapsed    | 240      |
|    total_timesteps | 122880   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 26.8         |
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 25           |
|    time_elapsed         | 249          |
|    total_timesteps      | 128000       |
| train/                  |              |
|    approx_kl            | 0.0010154721 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.081        |
|    learning_rate        | 5e-05        |
|    loss                 | 6.88         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00245     |
|    std                  | 0.883        |
|    value_loss           | 13.2         |
------------------------------------------
------------------------------------------
| eval/                   |              |
|    arrive_dest          | 0            |
|    crash                | 0.154        |
|    max_step             | 0            |
|    mean_ep_length       | 85           |
|    mean_reward          | 92.5         |
|    num_episodes         | 5            |
|    out_of_road          | 1            |
|    raw_action           | 0.3179987    |
|    route_completion     | 0.206        |
|    success_rate         | 0            |
|    total_cost           | 1.26         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0014641057 |
|    arrive_dest          | 0            |
|    clip_fraction        | 0.0545       |
|    clip_range           | 0.1          |
|    crash                | 0.138        |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.159        |
|    learning_rate        | 5e-05        |
|    loss                 | 4.83         |
|    max_step             | 0            |
|    n_updates            | 500          |
|    out_of_road          | 1            |
|    policy_gradient_loss | -0.00226     |
|    route_completion     | 0.196        |
|    std                  | 0.875        |
|    total_cost           | 5.49         |
|    value_loss           | 9.64         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 29.1     |
| time/              |          |
|    fps             | 505      |
|    iterations      | 26       |
|    time_elapsed    | 263      |
|    total_timesteps | 133120   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 152          |
|    ep_rew_mean          | 33.5         |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 27           |
|    time_elapsed         | 271          |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0013505241 |
|    clip_fraction        | 0.0433       |
|    clip_range           | 0.1          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.17         |
|    learning_rate        | 5e-05        |
|    loss                 | 5.56         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00202     |
|    std                  | 0.873        |
|    value_loss           | 12.7         |
------------------------------------------
